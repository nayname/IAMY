{
    "messages": [
        {
            "content": "[{\"label\": \"EthereumJSON_RPC\", \"query\": \"Get proof for an account at block 0x1\"}, {\"label\": \"EthereumJSON_RPC\", \"query\": \"Create a new pending transaction filter\"}, {\"label\": \"EthereumJSON_RPC\", \"query\": \"Get filter changes for a pending transaction filter\"}, {\"label\": \"EthereumJSON_RPC\", \"query\": \"Unsubscribe from websocket subscription id\"}, {\"label\": \"EthereumJSON_RPC\", \"query\": \"List personal accounts managed by the node\"}]",
            "additional_kwargs": {},
            "response_metadata": {},
            "type": "human",
            "name": null,
            "id": "263f2413-e922-403f-8192-770d7f4f643b",
            "example": false
        },
        {
            "content": "",
            "additional_kwargs": {
                "tool_calls": [
                    {
                        "id": "call_bh3EI9oPLvikA4lZr7G6Pc9D",
                        "function": {
                            "arguments": "{\"query\": \"abci_query proof account cosmos height\"}",
                            "name": "SearchCosmosDocumentation"
                        },
                        "type": "function"
                    }
                ],
                "refusal": null
            },
            "response_metadata": {
                "token_usage": {
                    "completion_tokens": 544,
                    "prompt_tokens": 703,
                    "total_tokens": 1247,
                    "completion_tokens_details": {
                        "accepted_prediction_tokens": 0,
                        "audio_tokens": 0,
                        "reasoning_tokens": 512,
                        "rejected_prediction_tokens": 0
                    },
                    "prompt_tokens_details": {
                        "audio_tokens": 0,
                        "cached_tokens": 0
                    }
                },
                "model_name": "o3-2025-04-16",
                "system_fingerprint": null,
                "id": "chatcmpl-CPvzzRL0S6XYIs0pZRuNWv9ESZCrl",
                "service_tier": "default",
                "finish_reason": "tool_calls",
                "logprobs": null
            },
            "type": "ai",
            "name": null,
            "id": "run--0cdf8eea-f109-4f49-a1d5-dc45dbc832b1-0",
            "example": false,
            "tool_calls": [
                {
                    "name": "SearchCosmosDocumentation",
                    "args": {
                        "query": "abci_query proof account cosmos height"
                    },
                    "id": "call_bh3EI9oPLvikA4lZr7G6Pc9D",
                    "type": "tool_call"
                }
            ],
            "invalid_tool_calls": [],
            "usage_metadata": {
                "input_tokens": 703,
                "output_tokens": 544,
                "total_tokens": 1247,
                "input_token_details": {
                    "audio": 0,
                    "cache_read": 0
                },
                "output_token_details": {
                    "audio": 0,
                    "reasoning": 512
                }
            }
        },
        {
            "content": "[\"Title: ABCI (Application Blockchain Interface)\u200b\\nLink: https://evm.cosmos.network/docs/sdk/v0.47/learn/glossary\\nContent: The interface between the Tendermint consensus engine and the application state machine, allowing them to communicate and perform state transitions. ABCI is a critical component of the Cosmos SDK, enabling developers to build applications using any programming language that can communicate via ABCI.\\n\\nCosmos SDK\u200b\\nA framework for building blockchain applications, focusing on modularity, scalability, and interoperability.\\n\\nStaking\u200b\\nThe process of locking up tokens as collateral to secure the network, participate in consensus, and earn rewards in a Proof of Stake (PoS) blockchain like Cosmos.\\n\\n\", \"Title: Accessing old state versions\\nLink: https://evm.cosmos.network/docs/sdk/v0.50/build/architecture/adr-040-storage-and-smt-state-commitments\\nContent: One of the functional requirements is to access old state. This is done through abci.RequestQuery structure.  The version is specified by a block height (so we query for an object by a key K at block height H ). The number of old versions supported for abci.RequestQuery is configurable. Accessing an old state is done by using available snapshots.\\nabci.RequestQuery doesn't need old state of SC unless the prove=true parameter is set. The SMT merkle proof must be included in the abci.ResponseQuery only if both SC and SS have a snapshot for requested version. Moreover, Cosmos SDK could provide a way to directly access a historical state. However, a state machine shouldn't do that - since the number of snapshots is configurable, it would lead to nondeterministic execution. We positively validated a versioning and snapshot mechanism for querying old state with regards to the database we evaluated.\\n\\nContext\\nCurrently, Cosmos SDK uses IAVL for both state commitments and data storage. IAVL has effectively become an orphaned project within the Cosmos ecosystem and it's proven to be an inefficient state commitment data structure.\\nIn the current design, IAVL is used for both data storage and as a Merkle Tree for state commitments. IAVL is meant to be a standalone Merkelized key/value database, however it's using a KV DB engine to store all tree nodes. So, each node is stored in a separate record in the KV DB. This causes many inefficiencies and problems: Each object query requires a tree traversal from the root. Subsequent queries for the same object are cached on the Cosmos SDK level. Each edge traversal requires a DB query. Creating snapshots is expensive . It takes about 30 seconds to export less than 100 MB of state (as of March 2020). Updates in IAVL may trigger tree reorganization and possible O(log(n)) hashes re-computation, which can become a CPU bottleneck. The node structure is pretty expensive - it contains a standard tree node elements (key, value, left and right element) and additional metadata such as height, version (which is not required by the Cosmos SDK). The entire node is hashed, and that hash is used as the key in the underlying database, ref. Moreover, the IAVL project lacks support and a maintainer and we already see better and well-established alternatives. Instead of optimizing the IAVL, we are looking into other solutions for both storage and state commitments.\\n\\nBackwards Compatibility\\nThis ADR doesn't introduce any Cosmos SDK level API changes. We change the storage layout of the state machine, a storage hard fork and network upgrade is required to incorporate these changes. SMT provides a merkle proof functionality, however it is not compatible with ICS23. Updating the proofs for ICS23 compatibility is required.\\n\\n\", \"Title: Accessing old state versions\\nLink: https://evm.cosmos.network/docs/sdk/v0.47/build/architecture/adr-040-storage-and-smt-state-commitments\\nContent: One of the functional requirements is to access old state. This is done through abci.RequestQuery structure.  The version is specified by a block height (so we query for an object by a key K at block height H ). The number of old versions supported for abci.RequestQuery is configurable. Accessing an old state is done by using available snapshots.\\nabci.RequestQuery doesn't need old state of SC unless the prove=true parameter is set. The SMT merkle proof must be included in the abci.ResponseQuery only if both SC and SS have a snapshot for requested version. Moreover, Cosmos SDK could provide a way to directly access a historical state. However, a state machine shouldn't do that - since the number of snapshots is configurable, it would lead to nondeterministic execution. We positively validated a versioning and snapshot mechanism for querying old state with regards to the database we evaluated.\\n\\nContext\\nCurrently, Cosmos SDK uses IAVL for both state commitments and data storage. IAVL has effectively become an orphaned project within the Cosmos ecosystem and it's proven to be an inefficient state commitment data structure.\\nIn the current design, IAVL is used for both data storage and as a Merkle Tree for state commitments. IAVL is meant to be a standalone Merkelized key/value database, however it's using a KV DB engine to store all tree nodes. So, each node is stored in a separate record in the KV DB. This causes many inefficiencies and problems: Each object query requires a tree traversal from the root. Subsequent queries for the same object are cached on the Cosmos SDK level. Each edge traversal requires a DB query. Creating snapshots is expensive . It takes about 30 seconds to export less than 100 MB of state (as of March 2020). Updates in IAVL may trigger tree reorganization and possible O(log(n)) hashes re-computation, which can become a CPU bottleneck. The node structure is pretty expensive - it contains a standard tree node elements (key, value, left and right element) and additional metadata such as height, version (which is not required by the Cosmos SDK). The entire node is hashed, and that hash is used as the key in the underlying database, ref. Moreover, the IAVL project lacks support and a maintainer and we already see better and well-established alternatives. Instead of optimizing the IAVL, we are looking into other solutions for both storage and state commitments.\\n\\nBackwards Compatibility\\nThis ADR doesn't introduce any Cosmos SDK level API changes. We change the storage layout of the state machine, a storage hard fork and network upgrade is required to incorporate these changes. SMT provides a merkle proof functionality, however it is not compatible with ICS23. Updating the proofs for ICS23 compatibility is required.\\n\\n\", \"Title: Accessing old state versions\\nLink: https://evm.cosmos.network/docs/sdk/v0.53/build/architecture/adr-040-storage-and-smt-state-commitments\\nContent: One of the functional requirements is to access old state. This is done through abci.RequestQuery structure.  The version is specified by a block height (so we query for an object by a key K at block height H ). The number of old versions supported for abci.RequestQuery is configurable. Accessing an old state is done by using available snapshots.\\nabci.RequestQuery doesn't need old state of SC unless the prove=true parameter is set. The SMT merkle proof must be included in the abci.ResponseQuery only if both SC and SS have a snapshot for requested version. Moreover, Cosmos SDK could provide a way to directly access a historical state. However, a state machine shouldn't do that - since the number of snapshots is configurable, it would lead to nondeterministic execution. We positively validated a versioning and snapshot mechanism for querying old state with regards to the database we evaluated.\\n\\nContext\\nCurrently, Cosmos SDK uses IAVL for both state commitments and data storage. IAVL has effectively become an orphaned project within the Cosmos ecosystem and it's proven to be an inefficient state commitment data structure.\\nIn the current design, IAVL is used for both data storage and as a Merkle Tree for state commitments. IAVL is meant to be a standalone Merkelized key/value database, however it's using a KV DB engine to store all tree nodes. So, each node is stored in a separate record in the KV DB. This causes many inefficiencies and problems: Each object query requires a tree traversal from the root. Subsequent queries for the same object are cached on the Cosmos SDK level. Each edge traversal requires a DB query. Creating snapshots is expensive . It takes about 30 seconds to export less than 100 MB of state (as of March 2020). Updates in IAVL may trigger tree reorganization and possible O(log(n)) hashes re-computation, which can become a CPU bottleneck. The node structure is pretty expensive - it contains a standard tree node elements (key, value, left and right element) and additional metadata such as height, version (which is not required by the Cosmos SDK). The entire node is hashed, and that hash is used as the key in the underlying database, ref. Moreover, the IAVL project lacks support and a maintainer and we already see better and well-established alternatives. Instead of optimizing the IAVL, we are looking into other solutions for both storage and state commitments.\\n\\nBackwards Compatibility\\nThis ADR doesn't introduce any Cosmos SDK level API changes. We change the storage layout of the state machine, a storage hard fork and network upgrade is required to incorporate these changes. SMT provides a merkle proof functionality, however it is not compatible with ICS23. Updating the proofs for ICS23 compatibility is required.\\n\\n\", \"Title: Query Commands\\nLink: https://evm.cosmos.network/docs/sdk/v0.50/learn/advanced/cli\\nContent: Queries are objects that allow users to retrieve information about the application's state. To enable the creation of queries using the CLI interface, a function queryCommand is generally added to the rootCmd: This queryCommand function adds all the queries available to end-users for the application. This typically includes: QueryTx and/or other transaction query commands from the auth module which allow the user to search for a transaction by inputting its hash, a list of tags, or a block height. These queries allow users to see if transactions have been included in a block. Account command from the auth module, which displays the state (e.g. account balance) of an account given an address. Validator command from the Cosmos SDK rpc client tools, which displays the validator set of a given height. Block command from the Cosmos SDK RPC client tools, which displays the block data for a given height. All module query commands the application is dependent on, retrieved by using the basic module manager's AddQueryCommands() function, or enhanced by AutoCLI. Here is an example of a queryCommand aggregating subcommands from the simapp application: //go:build !app_v1\\n\\npackage cmd\\n\\nimport (\\n    \\n\\t\\\"errors\\\"\\n    \\\"io\\\"\\n    \\\"os\\\"\\n\\n\\tcmtcfg \\\"github.com/cometbft/cometbft/config\\\"\\n\\tdbm \\\"github.com/cosmos/cosmos-db\\\"\\n    \\\"github.com/spf13/cobra\\\"\\n    \\\"github.com/spf13/viper\\\"\\n    \\\"cosmossdk.io/client/v2/autocli\\\"\\n    \\\"cosmossdk.io/depinject\\\"\\n    \\\"cosmossdk.io/log\\\"\\n    \\\"cosmossdk.io/simapp\\\"\\n\\tconfixcmd \\\"cosmossdk.io/tools/confix/cmd\\\"\\n\\trosettaCmd \\\"cosmossdk.io/tools/rosetta/cmd\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/config\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/debug\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/flags\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/keys\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/pruning\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/rpc\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/snapshot\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/codec\\\"\\n\\tcodectypes \\\"github.com/cosmos/cosmos-sdk/codec/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/server\\\"\\n\\tserverconfig \\\"github.com/cosmos/cosmos-sdk/server/config\\\"\\n\\tservertypes \\\"github.com/cosmos/cosmos-sdk/server/types\\\"\\n\\tsdk \\\"github.com/cosmos/cosmos-sdk/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/types/module\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/types/tx/signing\\\"\\n\\tauthcmd \\\"github.com/cosmos/cosmos-sdk/x/auth/client/cli\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/auth/tx\\\"\\n\\ttxmodule \\\"github.com/cosmos/cosmos-sdk/x/auth/tx/config\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/auth/types\\\"\\n\\tbanktypes \\\"github.com/cosmos/cosmos-sdk/x/bank/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/crisis\\\"\\n\\tgenutilcli \\\"github.com/cosmos/cosmos-sdk/x/genutil/client/cli\\\"\\n)\\n\\n// NewRootCmd creates a new root command for simd. It is called once in the main function.\\nfunc NewRootCmd() *cobra.Command {\\n    var (\\n\\t\\tinterfaceRegistry  codectypes.InterfaceRegistry\\n\\t\\tappCodec           codec.Codec\\n\\t\\ttxConfig           client.TxConfig\\n\\t\\tlegacyAmino        *codec.LegacyAmino\\n\\t\\tautoCliOpts        autocli.AppOptions\\n\\t\\tmoduleBasicManager module.BasicManager\\n\\t)\\n    if err := depinject.Inject(depinject.Configs(simapp.AppConfig, depinject.Supply(log.NewNopLogger())),\\n\\t\\t&interfaceRegistry,\\n\\t\\t&appCodec,\\n\\t\\t&txConfig,\\n\\t\\t&legacyAmino,\\n\\t\\t&autoCliOpts,\\n\\t\\t&moduleBasicManager,\\n\\t); err != nil {\\n    panic(err)\\n}\\n    initClientCtx := client.Context{\\n}.\\n\\t\\tWithCodec(appCodec).\\n\\t\\tWithInterfaceRegistry(interfaceRegistry).\\n\\t\\tWithLegacyAmino(legacyAmino).\\n\\t\\tWithInput(os.Stdin).\\n\\t\\tWithAccountRetriever(types.AccountRetriever{\\n}).\\n\\t\\tWithHomeDir(simapp.DefaultNodeHome).\\n\\t\\tWithViper(\\\"\\\") // In simapp, we don't use any prefix for env variables.\\n    rootCmd := &cobra.Command{\\n    Use:   \\\"simd\\\",\\n    Short: \\\"simulation app\\\",\\n    PersistentPreRunE: func(cmd *cobra.Command, _ []string)\\n\\nerror {\\n\\t\\t\\t// set the default command outputs\\n\\t\\t\\tcmd.SetOut(cmd.OutOrStdout())\\n\\ncmd.SetErr(cmd.ErrOrStderr())\\n\\ninitClientCtx = initClientCtx.WithCmdContext(cmd.Context())\\n\\ninitClientCtx, err := client.ReadPersistentCommandFlags(initClientCtx, cmd.Flags())\\n    if err != nil {\\n    return err\\n}\\n\\ninitClientCtx, err = config.ReadFromClientConfig(initClientCtx)\\n    if err != nil {\\n    return err\\n}\\n\\n\\t\\t\\t// This needs to go after ReadFromClientConfig, as that function\\n\\t\\t\\t// sets the RPC client needed for SIGN_MODE_TEXTUAL.\\n    enabledSignModes := append(tx.DefaultSignModes, signing.SignMode_SIGN_MODE_TEXTUAL)\\n    txConfigOpts := tx.ConfigOptions{\\n    EnabledSignModes:           enabledSignModes,\\n    TextualCoinMetadataQueryFn: txmodule.NewGRPCCoinMetadataQueryFn(initClientCtx),\\n}\\n\\ntxConfigWithTextual, err := tx.NewTxConfigWithOptions(\\n\\t\\t\\t\\tcodec.NewProtoCodec(interfaceRegistry),\\n\\t\\t\\t\\ttxConfigOpts,\\n\\t\\t\\t)\\n    if err != nil {\\n    return err\\n}\\n\\ninitClientCtx = initClientCtx.WithTxConfig(txConfigWithTextual)\\n    if err := client.SetCmdClientContextHandler(initClientCtx, cmd); err != nil {\\n    return err\\n}\\n\\ncustomAppTemplate, customAppConfig := initAppConfig()\\n    customCMTConfig := initCometBFTConfig()\\n\\nreturn server.InterceptConfigsPreRunHandler(cmd, customAppTemplate, customAppConfig, customCMTConfig)\\n},\\n}\\n\\ninitRootCmd(rootCmd, txConfig, interfaceRegistry, appCodec, moduleBasicManager)\\n    if err := autoCliOpts.EnhanceRootCommand(rootCmd); err != nil {\\n    panic(err)\\n}\\n\\nreturn rootCmd\\n}\\n\\n// initCometBFTConfig helps to override default CometBFT Config values.\\n// return cmtcfg.DefaultConfig if no custom configuration is required for the application.\\nfunc initCometBFTConfig() *cmtcfg.Config {\\n    cfg := cmtcfg.DefaultConfig()\\n\\n\\t// these values put a higher strain on node memory\\n\\t// cfg.P2P.MaxNumInboundPeers = 100\\n\\t// cfg.P2P.MaxNumOutboundPeers = 40\\n\\n\\treturn cfg\\n}\\n\\n// initAppConfig helps to override default appConfig template and configs.\\n// return \\\"\\\", nil if no custom configuration is required for the application.\\nfunc initAppConfig() (string, interface{\\n}) {\\n\\t// The following code snippet is just for reference.\\n\\n\\t// WASMConfig defines configuration for the wasm module.\\n\\ttype WASMConfig struct {\\n\\t\\t// This is the maximum sdk gas (wasm and storage)\\n\\nthat we allow for any x/wasm \\\"smart\\\" queries\\n\\t\\tQueryGasLimit uint64 `mapstructure:\\\"query_gas_limit\\\"`\\n\\n\\t\\t// Address defines the gRPC-web server to listen on\\n\\t\\tLruSize uint64 `mapstructure:\\\"lru_size\\\"`\\n}\\n\\ntype CustomAppConfig struct {\\n    serverconfig.Config\\n\\n\\t\\tWASM WASMConfig `mapstructure:\\\"wasm\\\"`\\n}\\n\\n\\t// Optionally allow the chain developer to overwrite the SDK's default\\n\\t// server config.\\n    srvCfg := serverconfig.DefaultConfig()\\n\\t// The SDK's default minimum gas price is set to \\\"\\\" (empty value)\\n\\ninside\\n\\t// app.toml. If left empty by validators, the node will halt on startup.\\n\\t// However, the chain developer can set a default app.toml value for their\\n\\t// validators here.\\n\\t//\\n\\t// In summary:\\n\\t// - if you leave srvCfg.MinGasPrices = \\\"\\\", all validators MUST tweak their\\n\\t//   own app.toml config,\\n\\t// - if you set srvCfg.MinGasPrices non-empty, validators CAN tweak their\\n\\t//   own app.toml to override, or use this default value.\\n\\t//\\n\\t// In simapp, we set the min gas prices to 0.\\n\\tsrvCfg.MinGasPrices = \\\"0stake\\\"\\n\\t// srvCfg.BaseConfig.IAVLDisableFastNode = true // disable fastnode by default\\n    customAppConfig := CustomAppConfig{\\n    Config: *srvCfg,\\n    WASM: WASMConfig{\\n    LruSize:       1,\\n    QueryGasLimit: 300000,\\n},\\n}\\n    customAppTemplate := serverconfig.DefaultConfigTemplate + `\\n[wasm]\\n# This is the maximum sdk gas (wasm and storage)\\n\\nthat we allow for any x/wasm \\\"smart\\\" queries\\nquery_gas_limit = 300000\\n# This is the number of wasm vm instances we keep cached in memory for speed-up\\n# Warning: this is currently unstable and may lead to crashes, best to keep for 0 unless testing locally\\nlru_size = 0`\\n\\n\\treturn customAppTemplate, customAppConfig\\n}\\n\\nfunc initRootCmd(\\n\\trootCmd *cobra.Command,\\n\\ttxConfig client.TxConfig,\\n\\tinterfaceRegistry codectypes.InterfaceRegistry,\\n\\tappCodec codec.Codec,\\n\\tbasicManager module.BasicManager,\\n) {\\n    cfg := sdk.GetConfig()\\n\\ncfg.Seal()\\n\\nrootCmd.AddCommand(\\n\\t\\tgenutilcli.InitCmd(basicManager, simapp.DefaultNodeHome),\\n\\t\\tNewTestnetCmd(basicManager, banktypes.GenesisBalancesIterator{\\n}),\\n\\t\\tdebug.Cmd(),\\n\\t\\tconfixcmd.ConfigCommand(),\\n\\t\\tpruning.Cmd(newApp),\\n\\t\\tsnapshot.Cmd(newApp),\\n\\t)\\n\\nserver.AddCommands(rootCmd, simapp.DefaultNodeHome, newApp, appExport, addModuleInitFlags)\\n\\n\\t// add keybase, auxiliary RPC, query, genesis, and tx child commands\\n\\trootCmd.AddCommand(\\n\\t\\trpc.StatusCommand(),\\n\\t\\tgenesisCommand(txConfig, basicManager),\\n\\t\\tqueryCommand(),\\n\\t\\ttxCommand(),\\n\\t\\tkeys.Commands(simapp.DefaultNodeHome),\\n\\t)\\n\\n\\t// add rosetta\\n\\trootCmd.AddCommand(rosettaCmd.RosettaCommand(interfaceRegistry, appCodec))\\n}\\n\\nfunc addModuleInitFlags(startCmd *cobra.Command) {\\n    crisis.AddModuleInitFlags(startCmd)\\n}\\n\\n// genesisCommand builds genesis-related `simd genesis` command. Users may provide application specific commands as a parameter\\nfunc genesisCommand(txConfig client.TxConfig, basicManager module.BasicManager, cmds ...*cobra.Command) *cobra.Command {\\n    cmd := genutilcli.Commands(txConfig, basicManager, simapp.DefaultNodeHome)\\n    for _, subCmd := range cmds {\\n    cmd.AddCommand(subCmd)\\n}\\n\\nreturn cmd\\n}\\n\\nfunc queryCommand() *cobra.Command {\\n    cmd := &cobra.Command{\\n    Use:                        \\\"query\\\",\\n    Aliases:                    []string{\\\"q\\\"\\n},\\n    Short:                      \\\"Querying subcommands\\\",\\n    DisableFlagParsing:         false,\\n    SuggestionsMinimumDistance: 2,\\n    RunE:                       client.ValidateCmd,\\n}\\n\\ncmd.AddCommand(\\n\\t\\trpc.ValidatorCommand(),\\n\\t\\tserver.QueryBlockCmd(),\\n\\t\\tauthcmd.QueryTxsByEventsCmd(),\\n\\t\\tserver.QueryBlocksCmd(),\\n\\t\\tauthcmd.QueryTxCmd(),\\n\\t)\\n\\nreturn cmd\\n}\\n\\nfunc txCommand() *cobra.Command {\\n    cmd := &cobra.Command{\\n    Use:                        \\\"tx\\\",\\n    Short:                      \\\"Transactions subcommands\\\",\\n    DisableFlagParsing:         false,\\n    SuggestionsMinimumDistance: 2,\\n    RunE:                       client.ValidateCmd,\\n}\\n\\ncmd.AddCommand(\\n\\t\\tauthcmd.GetSignCommand(),\\n\\t\\tauthcmd.GetSignBatchCommand(),\\n\\t\\tauthcmd.GetMultiSignCommand(),\\n\\t\\tauthcmd.GetMultiSignBatchCmd(),\\n\\t\\tauthcmd.GetValidateSignaturesCommand(),\\n\\t\\tauthcmd.GetBroadcastCommand(),\\n\\t\\tauthcmd.GetEncodeCommand(),\\n\\t\\tauthcmd.GetDecodeCommand(),\\n\\t\\tauthcmd.GetAuxToFeeCommand(),\\n\\t)\\n\\nreturn cmd\\n}\\n\\n// newApp creates the application\\nfunc newApp(\\n\\tlogger log.Logger,\\n\\tdb dbm.DB,\\n\\ttraceStore io.Writer,\\n\\tappOpts servertypes.AppOptions,\\n)\\n\\nservertypes.Application {\\n    baseappOptions := server.DefaultBaseappOptions(appOpts)\\n\\nreturn simapp.NewSimApp(\\n\\t\\tlogger, db, traceStore, true,\\n\\t\\tappOpts,\\n\\t\\tbaseappOptions...,\\n\\t)\\n}\\n\\n// appExport creates a new simapp (optionally at a given height)\\n\\nand exports state.\\nfunc appExport(\\n\\tlogger log.Logger,\\n\\tdb dbm.DB,\\n\\ttraceStore io.Writer,\\n\\theight int64,\\n    forZeroHeight bool,\\n\\tjailAllowedAddrs []string,\\n\\tappOpts servertypes.AppOptions,\\n\\tmodulesToExport []string,\\n) (servertypes.ExportedApp, error) {\\n\\t// this check is necessary as we use the flag in x/upgrade.\\n\\t// we can exit more gracefully by checking the flag here.\\n\\thomePath, ok := appOpts.Get(flags.FlagHome).(string)\\n    if !ok || homePath == \\\"\\\" {\\n    return servertypes.ExportedApp{\\n}, errors.New(\\\"application home not set\\\")\\n}\\n\\nviperAppOpts, ok := appOpts.(*viper.Viper)\\n    if !ok {\\n    return servertypes.ExportedApp{\\n}, errors.New(\\\"appOpts is not viper.Viper\\\")\\n}\\n\\n\\t// overwrite the FlagInvCheckPeriod\\n\\tviperAppOpts.Set(server.FlagInvCheckPeriod, 1)\\n\\nappOpts = viperAppOpts\\n\\n\\tvar simApp *simapp.SimApp\\n    if height != -1 {\\n    simApp = simapp.NewSimApp(logger, db, traceStore, false, appOpts)\\n    if err := simApp.LoadHeight(height); err != nil {\\n    return servertypes.ExportedApp{\\n}, err\\n}\\n\\t\\n}\\n\\nelse {\\n    simApp = simapp.NewSimApp(logger, db, traceStore, true, appOpts)\\n}\\n\\nreturn simApp.ExportAppStateAndValidators(forZeroHeight, jailAllowedAddrs, modulesToExport)\\n}\\n\\nQueries are objects that allow users to retrieve information about the application's state. To enable the creation of queries using the CLI interface, a function queryCommand is generally added to the rootCmd: This queryCommand function adds all the queries available to end-users for the application. This typically includes: QueryTx and/or other transaction query commands from the auth module which allow the user to search for a transaction by inputting its hash, a list of tags, or a block height. These queries allow users to see if transactions have been included in a block. Account command from the auth module, which displays the state (e.g. account balance) of an account given an address. Validator command from the Cosmos SDK rpc client tools, which displays the validator set of a given height. Block command from the Cosmos SDK RPC client tools, which displays the block data for a given height. All module query commands the application is dependent on, retrieved by using the basic module manager's AddQueryCommands() function, or enhanced by AutoCLI. Here is an example of a queryCommand aggregating subcommands from the simapp application: When using AutoCLI to generate module query commands, EnhanceRootCommand() automatically adds the module query command to the root command.\\nRead more about AutoCLI in its dedicated section.\\n\\nQueries are objects that allow users to retrieve information about the application's state. To enable the creation of queries using the CLI interface, a function queryCommand is generally added to the rootCmd: //go:build !app_v1\\n\\npackage cmd\\n\\nimport (\\n    \\n\\t\\\"errors\\\"\\n    \\\"io\\\"\\n    \\\"os\\\"\\n\\n\\tcmtcfg \\\"github.com/cometbft/cometbft/config\\\"\\n\\tdbm \\\"github.com/cosmos/cosmos-db\\\"\\n    \\\"github.com/spf13/cobra\\\"\\n    \\\"github.com/spf13/viper\\\"\\n    \\\"cosmossdk.io/client/v2/autocli\\\"\\n    \\\"cosmossdk.io/depinject\\\"\\n    \\\"cosmossdk.io/log\\\"\\n    \\\"cosmossdk.io/simapp\\\"\\n\\tconfixcmd \\\"cosmossdk.io/tools/confix/cmd\\\"\\n\\trosettaCmd \\\"cosmossdk.io/tools/rosetta/cmd\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/config\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/debug\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/flags\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/keys\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/pruning\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/rpc\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/snapshot\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/codec\\\"\\n\\tcodectypes \\\"github.com/cosmos/cosmos-sdk/codec/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/server\\\"\\n\\tserverconfig \\\"github.com/cosmos/cosmos-sdk/server/config\\\"\\n\\tservertypes \\\"github.com/cosmos/cosmos-sdk/server/types\\\"\\n\\tsdk \\\"github.com/cosmos/cosmos-sdk/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/types/module\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/types/tx/signing\\\"\\n\\tauthcmd \\\"github.com/cosmos/cosmos-sdk/x/auth/client/cli\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/auth/tx\\\"\\n\\ttxmodule \\\"github.com/cosmos/cosmos-sdk/x/auth/tx/config\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/auth/types\\\"\\n\\tbanktypes \\\"github.com/cosmos/cosmos-sdk/x/bank/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/crisis\\\"\\n\\tgenutilcli \\\"github.com/cosmos/cosmos-sdk/x/genutil/client/cli\\\"\\n)\\n\\n// NewRootCmd creates a new root command for simd. It is called once in the main function.\\nfunc NewRootCmd() *cobra.Command {\\n    var (\\n\\t\\tinterfaceRegistry  codectypes.InterfaceRegistry\\n\\t\\tappCodec           codec.Codec\\n\\t\\ttxConfig           client.TxConfig\\n\\t\\tlegacyAmino        *codec.LegacyAmino\\n\\t\\tautoCliOpts        autocli.AppOptions\\n\\t\\tmoduleBasicManager module.BasicManager\\n\\t)\\n    if err := depinject.Inject(depinject.Configs(simapp.AppConfig, depinject.Supply(log.NewNopLogger())),\\n\\t\\t&interfaceRegistry,\\n\\t\\t&appCodec,\\n\\t\\t&txConfig,\\n\\t\\t&legacyAmino,\\n\\t\\t&autoCliOpts,\\n\\t\\t&moduleBasicManager,\\n\\t); err != nil {\\n    panic(err)\\n}\\n    initClientCtx := client.Context{\\n}.\\n\\t\\tWithCodec(appCodec).\\n\\t\\tWithInterfaceRegistry(interfaceRegistry).\\n\\t\\tWithLegacyAmino(legacyAmino).\\n\\t\\tWithInput(os.Stdin).\\n\\t\\tWithAccountRetriever(types.AccountRetriever{\\n}).\\n\\t\\tWithHomeDir(simapp.DefaultNodeHome).\\n\\t\\tWithViper(\\\"\\\") // In simapp, we don't use any prefix for env variables.\\n    rootCmd := &cobra.Command{\\n    Use:   \\\"simd\\\",\\n    Short: \\\"simulation app\\\",\\n    PersistentPreRunE: func(cmd *cobra.Command, _ []string)\\n\\nerror {\\n\\t\\t\\t// set the default command outputs\\n\\t\\t\\tcmd.SetOut(cmd.OutOrStdout())\\n\\ncmd.SetErr(cmd.ErrOrStderr())\\n\\ninitClientCtx = initClientCtx.WithCmdContext(cmd.Context())\\n\\ninitClientCtx, err := client.ReadPersistentCommandFlags(initClientCtx, cmd.Flags())\\n    if err != nil {\\n    return err\\n}\\n\\ninitClientCtx, err = config.ReadFromClientConfig(initClientCtx)\\n    if err != nil {\\n    return err\\n}\\n\\n\\t\\t\\t// This needs to go after ReadFromClientConfig, as that function\\n\\t\\t\\t// sets the RPC client needed for SIGN_MODE_TEXTUAL.\\n    enabledSignModes := append(tx.DefaultSignModes, signing.SignMode_SIGN_MODE_TEXTUAL)\\n    txConfigOpts := tx.ConfigOptions{\\n    EnabledSignModes:           enabledSignModes,\\n    TextualCoinMetadataQueryFn: txmodule.NewGRPCCoinMetadataQueryFn(initClientCtx),\\n}\\n\\ntxConfigWithTextual, err := tx.NewTxConfigWithOptions(\\n\\t\\t\\t\\tcodec.NewProtoCodec(interfaceRegistry),\\n\\t\\t\\t\\ttxConfigOpts,\\n\\t\\t\\t)\\n    if err != nil {\\n    return err\\n}\\n\\ninitClientCtx = initClientCtx.WithTxConfig(txConfigWithTextual)\\n    if err := client.SetCmdClientContextHandler(initClientCtx, cmd); err != nil {\\n    return err\\n}\\n\\ncustomAppTemplate, customAppConfig := initAppConfig()\\n    customCMTConfig := initCometBFTConfig()\\n\\nreturn server.InterceptConfigsPreRunHandler(cmd, customAppTemplate, customAppConfig, customCMTConfig)\\n},\\n}\\n\\ninitRootCmd(rootCmd, txConfig, interfaceRegistry, appCodec, moduleBasicManager)\\n    if err := autoCliOpts.EnhanceRootCommand(rootCmd); err != nil {\\n    panic(err)\\n}\\n\\nreturn rootCmd\\n}\\n\\n// initCometBFTConfig helps to override default CometBFT Config values.\\n// return cmtcfg.DefaultConfig if no custom configuration is required for the application.\\nfunc initCometBFTConfig() *cmtcfg.Config {\\n    cfg := cmtcfg.DefaultConfig()\\n\\n\\t// these values put a higher strain on node memory\\n\\t// cfg.P2P.MaxNumInboundPeers = 100\\n\\t// cfg.P2P.MaxNumOutboundPeers = 40\\n\\n\\treturn cfg\\n}\\n\\n// initAppConfig helps to override default appConfig template and configs.\\n// return \\\"\\\", nil if no custom configuration is required for the application.\\nfunc initAppConfig() (string, interface{\\n}) {\\n\\t// The following code snippet is just for reference.\\n\\n\\t// WASMConfig defines configuration for the wasm module.\\n\\ttype WASMConfig struct {\\n\\t\\t// This is the maximum sdk gas (wasm and storage)\\n\\nthat we allow for any x/wasm \\\"smart\\\" queries\\n\\t\\tQueryGasLimit uint64 `mapstructure:\\\"query_gas_limit\\\"`\\n\\n\\t\\t// Address defines the gRPC-web server to listen on\\n\\t\\tLruSize uint64 `mapstructure:\\\"lru_size\\\"`\\n}\\n\\ntype CustomAppConfig struct {\\n    serverconfig.Config\\n\\n\\t\\tWASM WASMConfig `mapstructure:\\\"wasm\\\"`\\n}\\n\\n\\t// Optionally allow the chain developer to overwrite the SDK's default\\n\\t// server config.\\n    srvCfg := serverconfig.DefaultConfig()\\n\\t// The SDK's default minimum gas price is set to \\\"\\\" (empty value)\\n\\ninside\\n\\t// app.toml. If left empty by validators, the node will halt on startup.\\n\\t// However, the chain developer can set a default app.toml value for their\\n\\t// validators here.\\n\\t//\\n\\t// In summary:\\n\\t// - if you leave srvCfg.MinGasPrices = \\\"\\\", all validators MUST tweak their\\n\\t//   own app.toml config,\\n\\t// - if you set srvCfg.MinGasPrices non-empty, validators CAN tweak their\\n\\t//   own app.toml to override, or use this default value.\\n\\t//\\n\\t// In simapp, we set the min gas prices to 0.\\n\\tsrvCfg.MinGasPrices = \\\"0stake\\\"\\n\\t// srvCfg.BaseConfig.IAVLDisableFastNode = true // disable fastnode by default\\n    customAppConfig := CustomAppConfig{\\n    Config: *srvCfg,\\n    WASM: WASMConfig{\\n    LruSize:       1,\\n    QueryGasLimit: 300000,\\n},\\n}\\n    customAppTemplate := serverconfig.DefaultConfigTemplate + `\\n[wasm]\\n# This is the maximum sdk gas (wasm and storage)\\n\\nthat we allow for any x/wasm \\\"smart\\\" queries\\nquery_gas_limit = 300000\\n# This is the number of wasm vm instances we keep cached in memory for speed-up\\n# Warning: this is currently unstable and may lead to crashes, best to keep for 0 unless testing locally\\nlru_size = 0`\\n\\n\\treturn customAppTemplate, customAppConfig\\n}\\n\\nfunc initRootCmd(\\n\\trootCmd *cobra.Command,\\n\\ttxConfig client.TxConfig,\\n\\tinterfaceRegistry codectypes.InterfaceRegistry,\\n\\tappCodec codec.Codec,\\n\\tbasicManager module.BasicManager,\\n) {\\n    cfg := sdk.GetConfig()\\n\\ncfg.Seal()\\n\\nrootCmd.AddCommand(\\n\\t\\tgenutilcli.InitCmd(basicManager, simapp.DefaultNodeHome),\\n\\t\\tNewTestnetCmd(basicManager, banktypes.GenesisBalancesIterator{\\n}),\\n\\t\\tdebug.Cmd(),\\n\\t\\tconfixcmd.ConfigCommand(),\\n\\t\\tpruning.Cmd(newApp),\\n\\t\\tsnapshot.Cmd(newApp),\\n\\t)\\n\\nserver.AddCommands(rootCmd, simapp.DefaultNodeHome, newApp, appExport, addModuleInitFlags)\\n\\n\\t// add keybase, auxiliary RPC, query, genesis, and tx child commands\\n\\trootCmd.AddCommand(\\n\\t\\trpc.StatusCommand(),\\n\\t\\tgenesisCommand(txConfig, basicManager),\\n\\t\\tqueryCommand(),\\n\\t\\ttxCommand(),\\n\\t\\tkeys.Commands(simapp.DefaultNodeHome),\\n\\t)\\n\\n\\t// add rosetta\\n\\trootCmd.AddCommand(rosettaCmd.RosettaCommand(interfaceRegistry, appCodec))\\n}\\n\\nfunc addModuleInitFlags(startCmd *cobra.Command) {\\n    crisis.AddModuleInitFlags(startCmd)\\n}\\n\\n// genesisCommand builds genesis-related `simd genesis` command. Users may provide application specific commands as a parameter\\nfunc genesisCommand(txConfig client.TxConfig, basicManager module.BasicManager, cmds ...*cobra.Command) *cobra.Command {\\n    cmd := genutilcli.Commands(txConfig, basicManager, simapp.DefaultNodeHome)\\n    for _, subCmd := range cmds {\\n    cmd.AddCommand(subCmd)\\n}\\n\\nreturn cmd\\n}\\n\\nfunc queryCommand() *cobra.Command {\\n    cmd := &cobra.Command{\\n    Use:                        \\\"query\\\",\\n    Aliases:                    []string{\\\"q\\\"\\n},\\n    Short:                      \\\"Querying subcommands\\\",\\n    DisableFlagParsing:         false,\\n    SuggestionsMinimumDistance: 2,\\n    RunE:                       client.ValidateCmd,\\n}\\n\\ncmd.AddCommand(\\n\\t\\trpc.ValidatorCommand(),\\n\\t\\tserver.QueryBlockCmd(),\\n\\t\\tauthcmd.QueryTxsByEventsCmd(),\\n\\t\\tserver.QueryBlocksCmd(),\\n\\t\\tauthcmd.QueryTxCmd(),\\n\\t)\\n\\nreturn cmd\\n}\\n\\nfunc txCommand() *cobra.Command {\\n    cmd := &cobra.Command{\\n    Use:                        \\\"tx\\\",\\n    Short:                      \\\"Transactions subcommands\\\",\\n    DisableFlagParsing:         false,\\n    SuggestionsMinimumDistance: 2,\\n    RunE:                       client.ValidateCmd,\\n}\\n\\ncmd.AddCommand(\\n\\t\\tauthcmd.GetSignCommand(),\\n\\t\\tauthcmd.GetSignBatchCommand(),\\n\\t\\tauthcmd.GetMultiSignCommand(),\\n\\t\\tauthcmd.GetMultiSignBatchCmd(),\\n\\t\\tauthcmd.GetValidateSignaturesCommand(),\\n\\t\\tauthcmd.GetBroadcastCommand(),\\n\\t\\tauthcmd.GetEncodeCommand(),\\n\\t\\tauthcmd.GetDecodeCommand(),\\n\\t\\tauthcmd.GetAuxToFeeCommand(),\\n\\t)\\n\\nreturn cmd\\n}\\n\\n// newApp creates the application\\nfunc newApp(\\n\\tlogger log.Logger,\\n\\tdb dbm.DB,\\n\\ttraceStore io.Writer,\\n\\tappOpts servertypes.AppOptions,\\n)\\n\\nservertypes.Application {\\n    baseappOptions := server.DefaultBaseappOptions(appOpts)\\n\\nreturn simapp.NewSimApp(\\n\\t\\tlogger, db, traceStore, true,\\n\\t\\tappOpts,\\n\\t\\tbaseappOptions...,\\n\\t)\\n}\\n\\n// appExport creates a new simapp (optionally at a given height)\\n\\nand exports state.\\nfunc appExport(\\n\\tlogger log.Logger,\\n\\tdb dbm.DB,\\n\\ttraceStore io.Writer,\\n\\theight int64,\\n    forZeroHeight bool,\\n\\tjailAllowedAddrs []string,\\n\\tappOpts servertypes.AppOptions,\\n\\tmodulesToExport []string,\\n) (servertypes.ExportedApp, error) {\\n\\t// this check is necessary as we use the flag in x/upgrade.\\n\\t// we can exit more gracefully by checking the flag here.\\n\\thomePath, ok := appOpts.Get(flags.FlagHome).(string)\\n    if !ok || homePath == \\\"\\\" {\\n    return servertypes.ExportedApp{\\n}, errors.New(\\\"application home not set\\\")\\n}\\n\\nviperAppOpts, ok := appOpts.(*viper.Viper)\\n    if !ok {\\n    return servertypes.ExportedApp{\\n}, errors.New(\\\"appOpts is not viper.Viper\\\")\\n}\\n\\n\\t// overwrite the FlagInvCheckPeriod\\n\\tviperAppOpts.Set(server.FlagInvCheckPeriod, 1)\\n\\nappOpts = viperAppOpts\\n\\n\\tvar simApp *simapp.SimApp\\n    if height != -1 {\\n    simApp = simapp.NewSimApp(logger, db, traceStore, false, appOpts)\\n    if err := simApp.LoadHeight(height); err != nil {\\n    return servertypes.ExportedApp{\\n}, err\\n}\\n\\t\\n}\\n\\nelse {\\n    simApp = simapp.NewSimApp(logger, db, traceStore, true, appOpts)\\n}\\n\\nreturn simApp.ExportAppStateAndValidators(forZeroHeight, jailAllowedAddrs, modulesToExport)\\n}\\n\\n\", \"Title: eth_getProof\\nLink: https://evm.cosmos.network/docs/evm/next/api-reference/ethereum-json-rpc/methods\\nContent: Returns the account- and storage-values of the specified account including the Merkle-proof. Implementation Note : This method requires a valid block height. Using \\\"latest\\\" or block heights less than 1 will return an error: \\\"cannot query with height < 0; please provide a valid height\\\". You must specify an actual block number.\\n\\nclique - Proof of Authority (Not Applicable)\\nThe  clique  namespace implements Proof of Authority consensus for private networks. Cosmos EVM uses 'CometBFT' consensus.\\n\\nNon-Implemented Namespaces\\nThe following namespaces are not implemented in Cosmos EVM but may be present in the interactive explorer for testing against other networks: The debug namespace provides debugging and tracing tools for development. Some tracing and profiling methods are implemented in Cosmos EVM. Many methods require the Profiling config to be enabled. The admin namespace handles node administration and peer management. Cosmos nodes use different administration mechanisms through the Cosmos SDK CLI and configuration files. The miner namespace controls Proof of Work mining operations. Cosmos EVM uses 'CometBFT' Byzantine Fault Tolerant consensus instead of mining. The engine namespace implements Ethereum's post-merge Engine API for communication with the consensus layer. Cosmos EVM uses 'CometBFT' consensus instead of the beacon chain. The clique namespace implements Proof of Authority consensus for private networks. Cosmos EVM uses 'CometBFT' consensus. The les namespace implements the Light Ethereum Subprotocol. Cosmos has a different light client architecture through IBC.\\n\\n\", \"Title: eth_getProof\\nLink: https://evm.cosmos.network/docs/evm/v0.4.x/api-reference/ethereum-json-rpc/methods\\nContent: Returns the account- and storage-values of the specified account including the Merkle-proof. Implementation Note : This method requires a valid block height. Using \\\"latest\\\" or block heights less than 1 will return an error: \\\"cannot query with height < 0; please provide a valid height\\\". You must specify an actual block number.\\n\\nclique - Proof of Authority (Not Applicable)\\nThe  clique  namespace implements Proof of Authority consensus for private networks. Cosmos EVM uses 'CometBFT' consensus.\\n\\nNon-Implemented Namespaces\\nThe following namespaces are not implemented in Cosmos EVM but may be present in the interactive explorer for testing against other networks: The debug namespace provides debugging and tracing tools for development. Some tracing and profiling methods are implemented in Cosmos EVM. Many methods require the Profiling config to be enabled. The admin namespace handles node administration and peer management. Cosmos nodes use different administration mechanisms through the Cosmos SDK CLI and configuration files. The miner namespace controls Proof of Work mining operations. Cosmos EVM uses 'CometBFT' Byzantine Fault Tolerant consensus instead of mining. The engine namespace implements Ethereum's post-merge Engine API for communication with the consensus layer. Cosmos EVM uses 'CometBFT' consensus instead of the beacon chain. The clique namespace implements Proof of Authority consensus for private networks. Cosmos EVM uses 'CometBFT' consensus. The les namespace implements the Light Ethereum Subprotocol. Cosmos has a different light client architecture through IBC.\\n\\n\", \"Title: Store Queries\\nLink: https://evm.cosmos.network/docs/sdk/v0.47/build/building-modules/messages-and-queries\\nContent: Store queries query directly for store keys. They use clientCtx.QueryABCI(req abci.RequestQuery) to return the full abci.ResponseQuery with inclusion Merkle proofs. See following examples: package baseapp\\n\\nimport (\\n    \\n\\t\\\"crypto/sha256\\\"\\n    \\\"errors\\\"\\n    \\\"fmt\\\"\\n    \\\"os\\\"\\n    \\\"sort\\\"\\n    \\\"strings\\\"\\n    \\\"syscall\\\"\\n    \\\"time\\\"\\n    \\\"github.com/cosmos/gogoproto/proto\\\"\\n\\tabci \\\"github.com/tendermint/tendermint/abci/types\\\"\\n\\ttmproto \\\"github.com/tendermint/tendermint/proto/tendermint/types\\\"\\n    \\\"google.golang.org/grpc/codes\\\"\\n\\tgrpcstatus \\\"google.golang.org/grpc/status\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/codec\\\"\\n\\tsnapshottypes \\\"github.com/cosmos/cosmos-sdk/snapshots/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/telemetry\\\"\\n\\tsdk \\\"github.com/cosmos/cosmos-sdk/types\\\"\\n\\tsdkerrors \\\"github.com/cosmos/cosmos-sdk/types/errors\\\"\\n)\\n\\n// Supported ABCI Query prefixes\\nconst (\\n\\tQueryPathApp    = \\\"app\\\"\\n\\tQueryPathCustom = \\\"custom\\\"\\n\\tQueryPathP2P    = \\\"p2p\\\"\\n\\tQueryPathStore  = \\\"store\\\"\\n)\\n\\n// InitChain implements the ABCI interface. It runs the initialization logic\\n// directly on the CommitMultiStore.\\nfunc (app *BaseApp)\\n\\nInitChain(req abci.RequestInitChain) (res abci.ResponseInitChain) {\\n\\t// On a new chain, we consider the init chain block height as 0, even though\\n\\t// req.InitialHeight is 1 by default.\\n    initHeader := tmproto.Header{\\n    ChainID: req.ChainId,\\n    Time: req.Time\\n}\\n\\napp.logger.Info(\\\"InitChain\\\", \\\"initialHeight\\\", req.InitialHeight, \\\"chainID\\\", req.ChainId)\\n\\n\\t// If req.InitialHeight is > 1, then we set the initial version in the\\n\\t// stores.\\n    if req.InitialHeight > 1 {\\n    app.initialHeight = req.InitialHeight\\n\\t\\tinitHeader = tmproto.Header{\\n    ChainID: req.ChainId,\\n    Height: req.InitialHeight,\\n    Time: req.Time\\n}\\n    err := app.cms.SetInitialVersion(req.InitialHeight)\\n    if err != nil {\\n    panic(err)\\n}\\n\\t\\n}\\n\\n\\t// initialize states with a correct header\\n\\tapp.setState(runTxModeDeliver, initHeader)\\n\\napp.setState(runTxModeCheck, initHeader)\\n\\napp.setState(runTxPrepareProposal, initHeader)\\n\\napp.setState(runTxProcessProposal, initHeader)\\n\\n\\t// Store the consensus params in the BaseApp's paramstore. Note, this must be\\n\\t// done after the deliver state and context have been set as it's persisted\\n\\t// to state.\\n    if req.ConsensusParams != nil {\\n    app.StoreConsensusParams(app.deliverState.ctx, req.ConsensusParams)\\n}\\n    if app.initChainer == nil {\\n    return\\n}\\n\\n\\t// add block gas meter for any genesis transactions (allow infinite gas)\\n\\napp.deliverState.ctx = app.deliverState.ctx.WithBlockGasMeter(sdk.NewInfiniteGasMeter())\\n\\nres = app.initChainer(app.deliverState.ctx, req)\\n\\n\\t// sanity check\\n    if len(req.Validators) > 0 {\\n    if len(req.Validators) != len(res.Validators) {\\n    panic(\\n\\t\\t\\t\\tfmt.Errorf(\\n\\t\\t\\t\\t\\t\\\"len(RequestInitChain.Validators) != len(GenesisValidators) (%d != %d)\\\",\\n\\t\\t\\t\\t\\tlen(req.Validators), len(res.Validators),\\n\\t\\t\\t\\t),\\n\\t\\t\\t)\\n}\\n\\nsort.Sort(abci.ValidatorUpdates(req.Validators))\\n\\nsort.Sort(abci.ValidatorUpdates(res.Validators))\\n    for i := range res.Validators {\\n    if !proto.Equal(&res.Validators[i], &req.Validators[i]) {\\n    panic(fmt.Errorf(\\\"genesisValidators[%d] != req.Validators[%d] \\\", i, i))\\n}\\n\\t\\n}\\n\\t\\n}\\n\\n\\t// In the case of a new chain, AppHash will be the hash of an empty string.\\n\\t// During an upgrade, it'll be the hash of the last committed block.\\n\\tvar appHash []byte\\n    if !app.LastCommitID().IsZero() {\\n    appHash = app.LastCommitID().Hash\\n}\\n\\nelse {\\n\\t\\t// $ echo -n '' | sha256sum\\n\\t\\t// e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\\n    emptyHash := sha256.Sum256([]byte{\\n})\\n\\nappHash = emptyHash[:]\\n}\\n\\n\\t// NOTE: We don't commit, but BeginBlock for block `initial_height` starts from this\\n\\t// deliverState.\\n\\treturn abci.ResponseInitChain{\\n    ConsensusParams: res.ConsensusParams,\\n    Validators:      res.Validators,\\n    AppHash:         appHash,\\n}\\n}\\n\\n// Info implements the ABCI interface.\\nfunc (app *BaseApp)\\n\\nInfo(req abci.RequestInfo)\\n\\nabci.ResponseInfo {\\n    lastCommitID := app.cms.LastCommitID()\\n\\nreturn abci.ResponseInfo{\\n    Data:             app.name,\\n    Version:          app.version,\\n    AppVersion:       app.appVersion,\\n    LastBlockHeight:  lastCommitID.Version,\\n    LastBlockAppHash: lastCommitID.Hash,\\n}\\n}\\n\\n// FilterPeerByAddrPort filters peers by address/port.\\nfunc (app *BaseApp)\\n\\nFilterPeerByAddrPort(info string)\\n\\nabci.ResponseQuery {\\n    if app.addrPeerFilter != nil {\\n    return app.addrPeerFilter(info)\\n}\\n\\nreturn abci.ResponseQuery{\\n}\\n}\\n\\n// FilterPeerByID filters peers by node ID.\\nfunc (app *BaseApp)\\n\\nFilterPeerByID(info string)\\n\\nabci.ResponseQuery {\\n    if app.idPeerFilter != nil {\\n    return app.idPeerFilter(info)\\n}\\n\\nreturn abci.ResponseQuery{\\n}\\n}\\n\\n// BeginBlock implements the ABCI application interface.\\nfunc (app *BaseApp)\\n\\nBeginBlock(req abci.RequestBeginBlock) (res abci.ResponseBeginBlock) {\\n    if app.cms.TracingEnabled() {\\n    app.cms.SetTracingContext(sdk.TraceContext(\\n\\t\\t\\tmap[string]interface{\\n}{\\\"blockHeight\\\": req.Header.Height\\n},\\n\\t\\t))\\n}\\n    if err := app.validateHeight(req); err != nil {\\n    panic(err)\\n}\\n\\n\\t// Initialize the DeliverTx state. If this is the first block, it should\\n\\t// already be initialized in InitChain. Otherwise app.deliverState will be\\n\\t// nil, since it is reset on Commit.\\n    if app.deliverState == nil {\\n    app.setState(runTxModeDeliver, req.Header)\\n}\\n\\nelse {\\n\\t\\t// In the first block, app.deliverState.ctx will already be initialized\\n\\t\\t// by InitChain. Context is now updated with Header information.\\n\\t\\tapp.deliverState.ctx = app.deliverState.ctx.\\n\\t\\t\\tWithBlockHeader(req.Header).\\n\\t\\t\\tWithBlockHeight(req.Header.Height)\\n}\\n\\n\\t// add block gas meter\\n\\tvar gasMeter sdk.GasMeter\\n    if maxGas := app.GetMaximumBlockGas(app.deliverState.ctx); maxGas > 0 {\\n    gasMeter = sdk.NewGasMeter(maxGas)\\n}\\n\\nelse {\\n    gasMeter = sdk.NewInfiniteGasMeter()\\n}\\n\\n\\t// NOTE: header hash is not set in NewContext, so we manually set it here\\n\\n\\tapp.deliverState.ctx = app.deliverState.ctx.\\n\\t\\tWithBlockGasMeter(gasMeter).\\n\\t\\tWithHeaderHash(req.Hash).\\n\\t\\tWithConsensusParams(app.GetConsensusParams(app.deliverState.ctx))\\n    if app.checkState != nil {\\n    app.checkState.ctx = app.checkState.ctx.\\n\\t\\t\\tWithBlockGasMeter(gasMeter).\\n\\t\\t\\tWithHeaderHash(req.Hash)\\n}\\n    if app.beginBlocker != nil {\\n    res = app.beginBlocker(app.deliverState.ctx, req)\\n\\nres.Events = sdk.MarkEventsToIndex(res.Events, app.indexEvents)\\n}\\n\\t// set the signed validators for addition to context in deliverTx\\n\\tapp.voteInfos = req.LastCommitInfo.GetVotes()\\n\\n\\t// call the hooks with the BeginBlock messages\\n    for _, streamingListener := range app.abciListeners {\\n    if err := streamingListener.ListenBeginBlock(app.deliverState.ctx, req, res); err != nil {\\n    panic(fmt.Errorf(\\\"BeginBlock listening hook failed, height: %d, err: %w\\\", req.Header.Height, err))\\n}\\n\\t\\n}\\n\\nreturn res\\n}\\n\\n// EndBlock implements the ABCI interface.\\nfunc (app *BaseApp)\\n\\nEndBlock(req abci.RequestEndBlock) (res abci.ResponseEndBlock) {\\n    if app.deliverState.ms.TracingEnabled() {\\n    app.deliverState.ms = app.deliverState.ms.SetTracingContext(nil).(sdk.CacheMultiStore)\\n}\\n    if app.endBlocker != nil {\\n    res = app.endBlocker(app.deliverState.ctx, req)\\n\\nres.Events = sdk.MarkEventsToIndex(res.Events, app.indexEvents)\\n}\\n    if cp := app.GetConsensusParams(app.deliverState.ctx); cp != nil {\\n    res.ConsensusParamUpdates = cp\\n}\\n\\n\\t// call the streaming service hooks with the EndBlock messages\\n    for _, streamingListener := range app.abciListeners {\\n    if err := streamingListener.ListenEndBlock(app.deliverState.ctx, req, res); err != nil {\\n    panic(fmt.Errorf(\\\"EndBlock listening hook failed, height: %d, err: %w\\\", req.Height, err))\\n}\\n\\t\\n}\\n\\nreturn res\\n}\\n\\n// PrepareProposal implements the PrepareProposal ABCI method and returns a\\n// ResponsePrepareProposal object to the client. The PrepareProposal method is\\n// responsible for allowing the block proposer to perform application-dependent\\n// work in a block before proposing it.\\n//\\n// Transactions can be modified, removed, or added by the application. Since the\\n// application maintains its own local mempool, it will ignore the transactions\\n// provided to it in RequestPrepareProposal. Instead, it will determine which\\n// transactions to return based on the mempool's semantics and the MaxTxBytes\\n// provided by the client's request.\\n//\\n// Ref: https://github.com/cosmos/cosmos-sdk/blob/main/docs/architecture/adr-060-abci-1.0.md\\n// Ref: https://github.com/tendermint/tendermint/blob/main/spec/abci/abci%2B%2B_basic_concepts.md\\nfunc (app *BaseApp)\\n\\nPrepareProposal(req abci.RequestPrepareProposal) (resp abci.ResponsePrepareProposal) {\\n    if app.prepareProposal == nil {\\n    panic(\\\"PrepareProposal method not set\\\")\\n}\\n\\n\\t// Tendermint must never call PrepareProposal with a height of 0.\\n\\t// Ref: https://github.com/tendermint/tendermint/blob/059798a4f5b0c9f52aa8655fa619054a0154088c/spec/core/state.md?plain=1#L37-L38\\n    if req.Height < 1 {\\n    panic(\\\"PrepareProposal called with invalid height\\\")\\n}\\n    ctx := app.getContextForProposal(app.prepareProposalState.ctx, req.Height)\\n\\nctx = ctx.WithVoteInfos(app.voteInfos).\\n\\t\\tWithBlockHeight(req.Height).\\n\\t\\tWithBlockTime(req.Time).\\n\\t\\tWithProposer(req.ProposerAddress).\\n\\t\\tWithConsensusParams(app.GetConsensusParams(ctx))\\n\\ndefer func() {\\n    if err := recover(); err != nil {\\n    app.logger.Error(\\n\\t\\t\\t\\t\\\"panic recovered in PrepareProposal\\\",\\n\\t\\t\\t\\t\\\"height\\\", req.Height,\\n\\t\\t\\t\\t\\\"time\\\", req.Time,\\n\\t\\t\\t\\t\\\"panic\\\", err,\\n\\t\\t\\t)\\n\\nresp = abci.ResponsePrepareProposal{\\n    Txs: req.Txs\\n}\\n\\t\\n}\\n\\t\\n}()\\n\\nresp = app.prepareProposal(ctx, req)\\n\\nreturn resp\\n}\\n\\n// ProcessProposal implements the ProcessProposal ABCI method and returns a\\n// ResponseProcessProposal object to the client. The ProcessProposal method is\\n// responsible for allowing execution of application-dependent work in a proposed\\n// block. Note, the application defines the exact implementation details of\\n// ProcessProposal. In general, the application must at the very least ensure\\n// that all transactions are valid. If all transactions are valid, then we inform\\n// Tendermint that the Status is ACCEPT. However, the application is also able\\n// to implement optimizations such as executing the entire proposed block\\n// immediately.\\n//\\n// If a panic is detected during execution of an application's ProcessProposal\\n// handler, it will be recovered and we will reject the proposal.\\n//\\n// Ref: https://github.com/cosmos/cosmos-sdk/blob/main/docs/architecture/adr-060-abci-1.0.md\\n// Ref: https://github.com/tendermint/tendermint/blob/main/spec/abci/abci%2B%2B_basic_concepts.md\\nfunc (app *BaseApp)\\n\\nProcessProposal(req abci.RequestProcessProposal) (resp abci.ResponseProcessProposal) {\\n    if app.processProposal == nil {\\n    panic(\\\"app.ProcessProposal is not set\\\")\\n}\\n    ctx := app.getContextForProposal(app.processProposalState.ctx, req.Height)\\n\\nctx = ctx.\\n\\t\\tWithVoteInfos(app.voteInfos).\\n\\t\\tWithBlockHeight(req.Height).\\n\\t\\tWithBlockTime(req.Time).\\n\\t\\tWithHeaderHash(req.Hash).\\n\\t\\tWithProposer(req.ProposerAddress).\\n\\t\\tWithConsensusParams(app.GetConsensusParams(ctx))\\n\\ndefer func() {\\n    if err := recover(); err != nil {\\n    app.logger.Error(\\n\\t\\t\\t\\t\\\"panic recovered in ProcessProposal\\\",\\n\\t\\t\\t\\t\\\"height\\\", req.Height,\\n\\t\\t\\t\\t\\\"time\\\", req.Time,\\n\\t\\t\\t\\t\\\"hash\\\", fmt.Sprintf(\\\"%X\\\", req.Hash),\\n\\t\\t\\t\\t\\\"panic\\\", err,\\n\\t\\t\\t)\\n\\nresp = abci.ResponseProcessProposal{\\n    Status: abci.ResponseProcessProposal_REJECT\\n}\\n\\t\\n}\\n\\t\\n}()\\n\\nresp = app.processProposal(ctx, req)\\n\\nreturn resp\\n}\\n\\n// CheckTx implements the ABCI interface and executes a tx in CheckTx mode. In\\n// CheckTx mode, messages are not executed. This means messages are only validated\\n// and only the AnteHandler is executed. State is persisted to the BaseApp's\\n// internal CheckTx state if the AnteHandler passes. Otherwise, the ResponseCheckTx\\n// will contain relevant error information. Regardless of tx execution outcome,\\n// the ResponseCheckTx will contain relevant gas execution context.\\nfunc (app *BaseApp)\\n\\nCheckTx(req abci.RequestCheckTx)\\n\\nabci.ResponseCheckTx {\\n    var mode runTxMode\\n    switch {\\n    case req.Type == abci.CheckTxType_New:\\n\\t\\tmode = runTxModeCheck\\n    case req.Type == abci.CheckTxType_Recheck:\\n\\t\\tmode = runTxModeReCheck\\n\\n\\tdefault:\\n\\t\\tpanic(fmt.Sprintf(\\\"unknown RequestCheckTx type: %s\\\", req.Type))\\n}\\n\\ngInfo, result, anteEvents, priority, err := app.runTx(mode, req.Tx)\\n    if err != nil {\\n    return sdkerrors.ResponseCheckTxWithEvents(err, gInfo.GasWanted, gInfo.GasUsed, anteEvents, app.trace)\\n}\\n\\nreturn abci.ResponseCheckTx{\\n    GasWanted: int64(gInfo.GasWanted), // TODO: Should type accept unsigned ints?\\n\\t\\tGasUsed:   int64(gInfo.GasUsed),   // TODO: Should type accept unsigned ints?\\n\\t\\tLog:       result.Log,\\n    Data:      result.Data,\\n    Events:    sdk.MarkEventsToIndex(result.Events, app.indexEvents),\\n    Priority:  priority,\\n}\\n}\\n\\n// DeliverTx implements the ABCI interface and executes a tx in DeliverTx mode.\\n// State only gets persisted if all messages are valid and get executed successfully.\\n// Otherwise, the ResponseDeliverTx will contain relevant error information.\\n// Regardless of tx execution outcome, the ResponseDeliverTx will contain relevant\\n// gas execution context.\\nfunc (app *BaseApp)\\n\\nDeliverTx(req abci.RequestDeliverTx) (res abci.ResponseDeliverTx) {\\n    gInfo := sdk.GasInfo{\\n}\\n    resultStr := \\\"successful\\\"\\n\\n\\tdefer func() {\\n    for _, streamingListener := range app.abciListeners {\\n    if err := streamingListener.ListenDeliverTx(app.deliverState.ctx, req, res); err != nil {\\n    panic(fmt.Errorf(\\\"DeliverTx listening hook failed: %w\\\", err))\\n}\\n\\t\\n}\\n\\t\\n}()\\n\\ndefer func() {\\n    telemetry.IncrCounter(1, \\\"tx\\\", \\\"count\\\")\\n\\ntelemetry.IncrCounter(1, \\\"tx\\\", resultStr)\\n\\ntelemetry.SetGauge(float32(gInfo.GasUsed), \\\"tx\\\", \\\"gas\\\", \\\"used\\\")\\n\\ntelemetry.SetGauge(float32(gInfo.GasWanted), \\\"tx\\\", \\\"gas\\\", \\\"wanted\\\")\\n}()\\n\\ngInfo, result, anteEvents, _, err := app.runTx(runTxModeDeliver, req.Tx)\\n    if err != nil {\\n    resultStr = \\\"failed\\\"\\n\\t\\treturn sdkerrors.ResponseDeliverTxWithEvents(err, gInfo.GasWanted, gInfo.GasUsed, sdk.MarkEventsToIndex(anteEvents, app.indexEvents), app.trace)\\n}\\n\\nreturn abci.ResponseDeliverTx{\\n    GasWanted: int64(gInfo.GasWanted), // TODO: Should type accept unsigned ints?\\n\\t\\tGasUsed:   int64(gInfo.GasUsed),   // TODO: Should type accept unsigned ints?\\n\\t\\tLog:       result.Log,\\n    Data:      result.Data,\\n    Events:    sdk.MarkEventsToIndex(result.Events, app.indexEvents),\\n}\\n}\\n\\n// Commit implements the ABCI interface. It will commit all state that exists in\\n// the deliver state's multi-store and includes the resulting commit ID in the\\n// returned abci.ResponseCommit. Commit will set the check state based on the\\n// latest header and reset the deliver state. Also, if a non-zero halt height is\\n// defined in config, Commit will execute a deferred function call to check\\n// against that height and gracefully halt if it matches the latest committed\\n// height.\\nfunc (app *BaseApp)\\n\\nCommit()\\n\\nabci.ResponseCommit {\\n    header := app.deliverState.ctx.BlockHeader()\\n    retainHeight := app.GetBlockRetentionHeight(header.Height)\\n\\n\\t// Write the DeliverTx state into branched storage and commit the MultiStore.\\n\\t// The write to the DeliverTx state writes all state transitions to the root\\n\\t// MultiStore (app.cms)\\n\\nso when Commit()\\n\\nis called is persists those values.\\n\\tapp.deliverState.ms.Write()\\n    commitID := app.cms.Commit()\\n    res := abci.ResponseCommit{\\n    Data:         commitID.Hash,\\n    RetainHeight: retainHeight,\\n}\\n\\n\\t// call the hooks with the Commit message\\n    for _, streamingListener := range app.abciListeners {\\n    if err := streamingListener.ListenCommit(app.deliverState.ctx, res); err != nil {\\n    panic(fmt.Errorf(\\\"Commit listening hook failed, height: %d, err: %w\\\", header.Height, err))\\n}\\n\\t\\n}\\n\\napp.logger.Info(\\\"commit synced\\\", \\\"commit\\\", fmt.Sprintf(\\\"%X\\\", commitID))\\n\\n\\t// Reset the Check state to the latest committed.\\n\\t//\\n\\t// NOTE: This is safe because Tendermint holds a lock on the mempool for\\n\\t// Commit. Use the header from this latest block.\\n\\tapp.setState(runTxModeCheck, header)\\n\\napp.setState(runTxPrepareProposal, header)\\n\\napp.setState(runTxProcessProposal, header)\\n\\n\\t// empty/reset the deliver state\\n\\tapp.deliverState = nil\\n\\n\\tvar halt bool\\n    switch {\\n    case app.haltHeight > 0 && uint64(header.Height) >= app.haltHeight:\\n\\t\\thalt = true\\n    case app.haltTime > 0 && header.Time.Unix() >= int64(app.haltTime):\\n\\t\\thalt = true\\n}\\n    if halt {\\n\\t\\t// Halt the binary and allow Tendermint to receive the ResponseCommit\\n\\t\\t// response with the commit ID hash. This will allow the node to successfully\\n\\t\\t// restart and process blocks assuming the halt configuration has been\\n\\t\\t// reset or moved to a more distant value.\\n\\t\\tapp.halt()\\n}\\n\\ngo app.snapshotManager.SnapshotIfApplicable(header.Height)\\n\\nreturn res\\n}\\n\\n// halt attempts to gracefully shutdown the node via SIGINT and SIGTERM falling\\n// back on os.Exit if both fail.\\nfunc (app *BaseApp)\\n\\nhalt() {\\n    app.logger.Info(\\\"halting node per configuration\\\", \\\"height\\\", app.haltHeight, \\\"time\\\", app.haltTime)\\n\\np, err := os.FindProcess(os.Getpid())\\n    if err == nil {\\n\\t\\t// attempt cascading signals in case SIGINT fails (os dependent)\\n    sigIntErr := p.Signal(syscall.SIGINT)\\n    sigTermErr := p.Signal(syscall.SIGTERM)\\n    if sigIntErr == nil || sigTermErr == nil {\\n    return\\n}\\n\\t\\n}\\n\\n\\t// Resort to exiting immediately if the process could not be found or killed\\n\\t// via SIGINT/SIGTERM signals.\\n\\tapp.logger.Info(\\\"failed to send SIGINT/SIGTERM; exiting...\\\")\\n\\nos.Exit(0)\\n}\\n\\n// Query implements the ABCI interface. It delegates to CommitMultiStore if it\\n// implements Queryable.\\nfunc (app *BaseApp)\\n\\nQuery(req abci.RequestQuery) (res abci.ResponseQuery) {\\n\\t// Add panic recovery for all queries.\\n\\t// ref: https://github.com/cosmos/cosmos-sdk/pull/8039\\n\\tdefer func() {\\n    if r := recover(); r != nil {\\n    res = sdkerrors.QueryResult(sdkerrors.Wrapf(sdkerrors.ErrPanic, \\\"%v\\\", r), app.trace)\\n}\\n\\t\\n}()\\n\\n\\t// when a client did not provide a query height, manually inject the latest\\n    if req.Height == 0 {\\n    req.Height = app.LastBlockHeight()\\n}\\n\\ntelemetry.IncrCounter(1, \\\"query\\\", \\\"count\\\")\\n\\ntelemetry.IncrCounter(1, \\\"query\\\", req.Path)\\n\\ndefer telemetry.MeasureSince(time.Now(), req.Path)\\n\\n\\t// handle gRPC routes first rather than calling splitPath because '/' characters\\n\\t// are used as part of gRPC paths\\n    if grpcHandler := app.grpcQueryRouter.Route(req.Path); grpcHandler != nil {\\n    return app.handleQueryGRPC(grpcHandler, req)\\n}\\n    path := SplitABCIQueryPath(req.Path)\\n    if len(path) == 0 {\\n    return sdkerrors.QueryResult(sdkerrors.Wrap(sdkerrors.ErrUnknownRequest, \\\"no query path provided\\\"), app.trace)\\n}\\n    switch path[0] {\\n    case QueryPathApp:\\n\\t\\t// \\\"/app\\\" prefix for special application queries\\n\\t\\treturn handleQueryApp(app, path, req)\\n    case QueryPathStore:\\n\\t\\treturn handleQueryStore(app, path, req)\\n    case QueryPathP2P:\\n\\t\\treturn handleQueryP2P(app, path)\\n}\\n\\nreturn sdkerrors.QueryResult(sdkerrors.Wrap(sdkerrors.ErrUnknownRequest, \\\"unknown query path\\\"), app.trace)\\n}\\n\\n// ListSnapshots implements the ABCI interface. It delegates to app.snapshotManager if set.\\nfunc (app *BaseApp)\\n\\nListSnapshots(req abci.RequestListSnapshots)\\n\\nabci.ResponseListSnapshots {\\n    resp := abci.ResponseListSnapshots{\\n    Snapshots: []*abci.Snapshot{\\n}}\\n    if app.snapshotManager == nil {\\n    return resp\\n}\\n\\nsnapshots, err := app.snapshotManager.List()\\n    if err != nil {\\n    app.logger.Error(\\\"failed to list snapshots\\\", \\\"err\\\", err)\\n\\nreturn resp\\n}\\n    for _, snapshot := range snapshots {\\n    abciSnapshot, err := snapshot.ToABCI()\\n    if err != nil {\\n    app.logger.Error(\\\"failed to list snapshots\\\", \\\"err\\\", err)\\n\\nreturn resp\\n}\\n\\nresp.Snapshots = append(resp.Snapshots, &abciSnapshot)\\n}\\n\\nreturn resp\\n}\\n\\n// LoadSnapshotChunk implements the ABCI interface. It delegates to app.snapshotManager if set.\\nfunc (app *BaseApp)\\n\\nLoadSnapshotChunk(req abci.RequestLoadSnapshotChunk)\\n\\nabci.ResponseLoadSnapshotChunk {\\n    if app.snapshotManager == nil {\\n    return abci.ResponseLoadSnapshotChunk{\\n}\\n\\t\\n}\\n\\nchunk, err := app.snapshotManager.LoadChunk(req.Height, req.Format, req.Chunk)\\n    if err != nil {\\n    app.logger.Error(\\n\\t\\t\\t\\\"failed to load snapshot chunk\\\",\\n\\t\\t\\t\\\"height\\\", req.Height,\\n\\t\\t\\t\\\"format\\\", req.Format,\\n\\t\\t\\t\\\"chunk\\\", req.Chunk,\\n\\t\\t\\t\\\"err\\\", err,\\n\\t\\t)\\n\\nreturn abci.ResponseLoadSnapshotChunk{\\n}\\n\\t\\n}\\n\\nreturn abci.ResponseLoadSnapshotChunk{\\n    Chunk: chunk\\n}\\n}\\n\\n// OfferSnapshot implements the ABCI interface. It delegates to app.snapshotManager if set.\\nfunc (app *BaseApp)\\n\\nOfferSnapshot(req abci.RequestOfferSnapshot)\\n\\nabci.ResponseOfferSnapshot {\\n    if app.snapshotManager == nil {\\n    app.logger.Error(\\\"snapshot manager not configured\\\")\\n\\nreturn abci.ResponseOfferSnapshot{\\n    Result: abci.ResponseOfferSnapshot_ABORT\\n}\\n\\t\\n}\\n    if req.Snapshot == nil {\\n    app.logger.Error(\\\"received nil snapshot\\\")\\n\\nreturn abci.ResponseOfferSnapshot{\\n    Result: abci.ResponseOfferSnapshot_REJECT\\n}\\n\\t\\n}\\n\\nsnapshot, err := snapshottypes.SnapshotFromABCI(req.Snapshot)\\n    if err != nil {\\n    app.logger.Error(\\\"failed to decode snapshot metadata\\\", \\\"err\\\", err)\\n\\nreturn abci.ResponseOfferSnapshot{\\n    Result: abci.ResponseOfferSnapshot_REJECT\\n}\\n\\t\\n}\\n\\nerr = app.snapshotManager.Restore(snapshot)\\n    switch {\\n    case err == nil:\\n\\t\\treturn abci.ResponseOfferSnapshot{\\n    Result: abci.ResponseOfferSnapshot_ACCEPT\\n}\\n    case errors.Is(err, snapshottypes.ErrUnknownFormat):\\n\\t\\treturn abci.ResponseOfferSnapshot{\\n    Result: abci.ResponseOfferSnapshot_REJECT_FORMAT\\n}\\n    case errors.Is(err, snapshottypes.ErrInvalidMetadata):\\n\\t\\tapp.logger.Error(\\n\\t\\t\\t\\\"rejecting invalid snapshot\\\",\\n\\t\\t\\t\\\"height\\\", req.Snapshot.Height,\\n\\t\\t\\t\\\"format\\\", req.Snapshot.Format,\\n\\t\\t\\t\\\"err\\\", err,\\n\\t\\t)\\n\\nreturn abci.ResponseOfferSnapshot{\\n    Result: abci.ResponseOfferSnapshot_REJECT\\n}\\n\\ndefault:\\n\\t\\tapp.logger.Error(\\n\\t\\t\\t\\\"failed to restore snapshot\\\",\\n\\t\\t\\t\\\"height\\\", req.Snapshot.Height,\\n\\t\\t\\t\\\"format\\\", req.Snapshot.Format,\\n\\t\\t\\t\\\"err\\\", err,\\n\\t\\t)\\n\\n\\t\\t// We currently don't support resetting the IAVL stores and retrying a different snapshot,\\n\\t\\t// so we ask Tendermint to abort all snapshot restoration.\\n\\t\\treturn abci.ResponseOfferSnapshot{\\n    Result: abci.ResponseOfferSnapshot_ABORT\\n}\\n\\t\\n}\\n}\\n\\n// ApplySnapshotChunk implements the ABCI interface. It delegates to app.snapshotManager if set.\\nfunc (app *BaseApp)\\n\\nApplySnapshotChunk(req abci.RequestApplySnapshotChunk)\\n\\nabci.ResponseApplySnapshotChunk {\\n    if app.snapshotManager == nil {\\n    app.logger.Error(\\\"snapshot manager not configured\\\")\\n\\nreturn abci.ResponseApplySnapshotChunk{\\n    Result: abci.ResponseApplySnapshotChunk_ABORT\\n}\\n\\t\\n}\\n\\n\\t_, err := app.snapshotManager.RestoreChunk(req.Chunk)\\n    switch {\\n    case err == nil:\\n\\t\\treturn abci.ResponseApplySnapshotChunk{\\n    Result: abci.ResponseApplySnapshotChunk_ACCEPT\\n}\\n    case errors.Is(err, snapshottypes.ErrChunkHashMismatch):\\n\\t\\tapp.logger.Error(\\n\\t\\t\\t\\\"chunk checksum mismatch; rejecting sender and requesting refetch\\\",\\n\\t\\t\\t\\\"chunk\\\", req.Index,\\n\\t\\t\\t\\\"sender\\\", req.Sender,\\n\\t\\t\\t\\\"err\\\", err,\\n\\t\\t)\\n\\nreturn abci.ResponseApplySnapshotChunk{\\n    Result:        abci.ResponseApplySnapshotChunk_RETRY,\\n    RefetchChunks: []uint32{\\n    req.Index\\n},\\n    RejectSenders: []string{\\n    req.Sender\\n},\\n}\\n\\ndefault:\\n\\t\\tapp.logger.Error(\\\"failed to restore snapshot\\\", \\\"err\\\", err)\\n\\nreturn abci.ResponseApplySnapshotChunk{\\n    Result: abci.ResponseApplySnapshotChunk_ABORT\\n}\\n\\t\\n}\\n}\\n\\nfunc (app *BaseApp)\\n\\nhandleQueryGRPC(handler GRPCQueryHandler, req abci.RequestQuery)\\n\\nabci.ResponseQuery {\\n    ctx, err := app.CreateQueryContext(req.Height, req.Prove)\\n    if err != nil {\\n    return sdkerrors.QueryResult(err, app.trace)\\n}\\n\\nres, err := handler(ctx, req)\\n    if err != nil {\\n    res = sdkerrors.QueryResult(gRPCErrorToSDKError(err), app.trace)\\n\\nres.Height = req.Height\\n\\t\\treturn res\\n}\\n\\nreturn res\\n}\\n\\nfunc gRPCErrorToSDKError(err error)\\n\\nerror {\\n    status, ok := grpcstatus.FromError(err)\\n    if !ok {\\n    return sdkerrors.Wrap(sdkerrors.ErrInvalidRequest, err.Error())\\n}\\n    switch status.Code() {\\n    case codes.NotFound:\\n\\t\\treturn sdkerrors.Wrap(sdkerrors.ErrKeyNotFound, err.Error())\\n    case codes.InvalidArgument:\\n\\t\\treturn sdkerrors.Wrap(sdkerrors.ErrInvalidRequest, err.Error())\\n    case codes.FailedPrecondition:\\n\\t\\treturn sdkerrors.Wrap(sdkerrors.ErrInvalidRequest, err.Error())\\n    case codes.Unauthenticated:\\n\\t\\treturn sdkerrors.Wrap(sdkerrors.ErrUnauthorized, err.Error())\\n\\ndefault:\\n\\t\\treturn sdkerrors.Wrap(sdkerrors.ErrUnknownRequest, err.Error())\\n}\\n}\\n\\nfunc checkNegativeHeight(height int64)\\n\\nerror {\\n    if height < 0 {\\n\\t\\t// Reject invalid heights.\\n\\t\\treturn sdkerrors.Wrap(\\n\\t\\t\\tsdkerrors.ErrInvalidRequest,\\n\\t\\t\\t\\\"cannot query with height < 0; please provide a valid height\\\",\\n\\t\\t)\\n}\\n\\nreturn nil\\n}\\n\\n// createQueryContext creates a new sdk.Context for a query, taking as args\\n// the block height and whether the query needs a proof or not.\\nfunc (app *BaseApp)\\n\\nCreateQueryContext(height int64, prove bool) (sdk.Context, error) {\\n    if err := checkNegativeHeight(height); err != nil {\\n    return sdk.Context{\\n}, err\\n}\\n\\n\\t// use custom query multistore if provided\\n    qms := app.qms\\n    if qms == nil {\\n    qms = app.cms.(sdk.MultiStore)\\n}\\n    lastBlockHeight := qms.LatestVersion()\\n    if height > lastBlockHeight {\\n    return sdk.Context{\\n},\\n\\t\\t\\tsdkerrors.Wrap(\\n\\t\\t\\t\\tsdkerrors.ErrInvalidHeight,\\n\\t\\t\\t\\t\\\"cannot query with height in the future; please provide a valid height\\\",\\n\\t\\t\\t)\\n}\\n\\n\\t// when a client did not provide a query height, manually inject the latest\\n    if height == 0 {\\n    height = lastBlockHeight\\n}\\n    if height <= 1 && prove {\\n    return sdk.Context{\\n},\\n\\t\\t\\tsdkerrors.Wrap(\\n\\t\\t\\t\\tsdkerrors.ErrInvalidRequest,\\n\\t\\t\\t\\t\\\"cannot query with proof when height <= 1; please provide a valid height\\\",\\n\\t\\t\\t)\\n}\\n\\ncacheMS, err := qms.CacheMultiStoreWithVersion(height)\\n    if err != nil {\\n    return sdk.Context{\\n},\\n\\t\\t\\tsdkerrors.Wrapf(\\n\\t\\t\\t\\tsdkerrors.ErrInvalidRequest,\\n\\t\\t\\t\\t\\\"failed to load state at height %d; %s (latest height: %d)\\\", height, err, lastBlockHeight,\\n\\t\\t\\t)\\n}\\n\\n\\t// branch the commit-multistore for safety\\n    ctx := sdk.NewContext(\\n\\t\\tcacheMS, app.checkState.ctx.BlockHeader(), true, app.logger,\\n\\t).WithMinGasPrices(app.minGasPrices).WithBlockHeight(height)\\n\\nreturn ctx, nil\\n}\\n\\n// GetBlockRetentionHeight returns the height for which all blocks below this height\\n// are pruned from Tendermint. Given a commitment height and a non-zero local\\n// minRetainBlocks configuration, the retentionHeight is the smallest height that\\n// satisfies:\\n//\\n// - Unbonding (safety threshold)\\n\\ntime: The block interval in which validators\\n// can be economically punished for misbehavior. Blocks in this interval must be\\n// auditable e.g. by the light client.\\n//\\n// - Logical store snapshot interval: The block interval at which the underlying\\n// logical store database is persisted to disk, e.g. every 10000 heights. Blocks\\n// since the last IAVL snapshot must be available for replay on application restart.\\n//\\n// - State sync snapshots: Blocks since the oldest available snapshot must be\\n// available for state sync nodes to catch up (oldest because a node may be\\n// restoring an old snapshot while a new snapshot was taken).\\n//\\n// - Local (minRetainBlocks)\\n\\nconfig: Archive nodes may want to retain more or\\n// all blocks, e.g. via a local config option min-retain-blocks. There may also\\n// be a need to vary retention for other nodes, e.g. sentry nodes which do not\\n// need historical blocks.\\nfunc (app *BaseApp)\\n\\nGetBlockRetentionHeight(commitHeight int64)\\n\\nint64 {\\n\\t// pruning is disabled if minRetainBlocks is zero\\n    if app.minRetainBlocks == 0 {\\n    return 0\\n}\\n    minNonZero := func(x, y int64)\\n\\nint64 {\\n    switch {\\n    case x == 0:\\n\\t\\t\\treturn y\\n    case y == 0:\\n\\t\\t\\treturn x\\n    case x < y:\\n\\t\\t\\treturn x\\n\\t\\tdefault:\\n\\t\\t\\treturn y\\n}\\n\\t\\n}\\n\\n\\t// Define retentionHeight as the minimum value that satisfies all non-zero\\n\\t// constraints. All blocks below (commitHeight-retentionHeight)\\n\\nare pruned\\n\\t// from Tendermint.\\n\\tvar retentionHeight int64\\n\\n\\t// Define the number of blocks needed to protect against misbehaving validators\\n\\t// which allows light clients to operate safely. Note, we piggy back of the\\n\\t// evidence parameters instead of computing an estimated nubmer of blocks based\\n\\t// on the unbonding period and block commitment time as the two should be\\n\\t// equivalent.\\n    cp := app.GetConsensusParams(app.deliverState.ctx)\\n    if cp != nil && cp.Evidence != nil && cp.Evidence.MaxAgeNumBlocks > 0 {\\n    retentionHeight = commitHeight - cp.Evidence.MaxAgeNumBlocks\\n}\\n    if app.snapshotManager != nil {\\n    snapshotRetentionHeights := app.snapshotManager.GetSnapshotBlockRetentionHeights()\\n    if snapshotRetentionHeights > 0 {\\n    retentionHeight = minNonZero(retentionHeight, commitHeight-snapshotRetentionHeights)\\n}\\n\\t\\n}\\n    v := commitHeight - int64(app.minRetainBlocks)\\n\\nretentionHeight = minNonZero(retentionHeight, v)\\n    if retentionHeight <= 0 {\\n\\t\\t// prune nothing in the case of a non-positive height\\n\\t\\treturn 0\\n}\\n\\nreturn retentionHeight\\n}\\n\\nfunc handleQueryApp(app *BaseApp, path []string, req abci.RequestQuery)\\n\\nabci.ResponseQuery {\\n    if len(path) >= 2 {\\n    switch path[1] {\\n    case \\\"simulate\\\":\\n    txBytes := req.Data\\n\\n\\t\\t\\tgInfo, res, err := app.Simulate(txBytes)\\n    if err != nil {\\n    return sdkerrors.QueryResult(sdkerrors.Wrap(err, \\\"failed to simulate tx\\\"), app.trace)\\n}\\n    simRes := &sdk.SimulationResponse{\\n    GasInfo: gInfo,\\n    Result:  res,\\n}\\n\\nbz, err := codec.ProtoMarshalJSON(simRes, app.interfaceRegistry)\\n    if err != nil {\\n    return sdkerrors.QueryResult(sdkerrors.Wrap(err, \\\"failed to JSON encode simulation response\\\"), app.trace)\\n}\\n\\nreturn abci.ResponseQuery{\\n    Codespace: sdkerrors.RootCodespace,\\n    Height:    req.Height,\\n    Value:     bz,\\n}\\n    case \\\"version\\\":\\n\\t\\t\\treturn abci.ResponseQuery{\\n    Codespace: sdkerrors.RootCodespace,\\n    Height:    req.Height,\\n    Value:     []byte(app.version),\\n}\\n\\ndefault:\\n\\t\\t\\treturn sdkerrors.QueryResult(sdkerrors.Wrapf(sdkerrors.ErrUnknownRequest, \\\"unknown query: %s\\\", path), app.trace)\\n}\\n\\t\\n}\\n\\nreturn sdkerrors.QueryResult(\\n\\t\\tsdkerrors.Wrap(\\n\\t\\t\\tsdkerrors.ErrUnknownRequest,\\n\\t\\t\\t\\\"expected second parameter to be either 'simulate' or 'version', neither was present\\\",\\n\\t\\t), app.trace)\\n}\\n\\nfunc handleQueryStore(app *BaseApp, path []string, req abci.RequestQuery)\\n\\nabci.ResponseQuery {\\n\\t// \\\"/store\\\" prefix for store queries\\n\\tqueryable, ok := app.cms.(sdk.Queryable)\\n    if !ok {\\n    return sdkerrors.QueryResult(sdkerrors.Wrap(sdkerrors.ErrUnknownRequest, \\\"multistore doesn't support queries\\\"), app.trace)\\n}\\n\\nreq.Path = \\\"/\\\" + strings.Join(path[1:], \\\"/\\\")\\n    if req.Height <= 1 && req.Prove {\\n    return sdkerrors.QueryResult(\\n\\t\\t\\tsdkerrors.Wrap(\\n\\t\\t\\t\\tsdkerrors.ErrInvalidRequest,\\n\\t\\t\\t\\t\\\"cannot query with proof when height <= 1; please provide a valid height\\\",\\n\\t\\t\\t), app.trace)\\n}\\n    resp := queryable.Query(req)\\n\\nresp.Height = req.Height\\n\\n\\treturn resp\\n}\\n\\nfunc handleQueryP2P(app *BaseApp, path []string)\\n\\nabci.ResponseQuery {\\n\\t// \\\"/p2p\\\" prefix for p2p queries\\n    if len(path) < 4 {\\n    return sdkerrors.QueryResult(\\n\\t\\t\\tsdkerrors.Wrap(\\n\\t\\t\\t\\tsdkerrors.ErrUnknownRequest, \\\"path should be p2p filter <addr|id> <parameter>\\\",\\n\\t\\t\\t), app.trace)\\n}\\n\\nvar resp abci.ResponseQuery\\n\\n\\tcmd, typ, arg := path[1], path[2], path[3]\\n    switch cmd {\\n    case \\\"filter\\\":\\n    switch typ {\\n    case \\\"addr\\\":\\n\\t\\t\\tresp = app.FilterPeerByAddrPort(arg)\\n    case \\\"id\\\":\\n\\t\\t\\tresp = app.FilterPeerByID(arg)\\n}\\n\\ndefault:\\n\\t\\tresp = sdkerrors.QueryResult(sdkerrors.Wrap(sdkerrors.ErrUnknownRequest, \\\"expected second parameter to be 'filter'\\\"), app.trace)\\n}\\n\\nreturn resp\\n}\\n\\n// SplitABCIQueryPath splits a string path using the delimiter '/'.\\n//\\n// e.g. \\\"this/is/funny\\\" becomes []string{\\\"this\\\", \\\"is\\\", \\\"funny\\\"\\n}\\n\\nfunc SplitABCIQueryPath(requestPath string) (path []string) {\\n    path = strings.Split(requestPath, \\\"/\\\")\\n\\n\\t// first element is empty string\\n    if len(path) > 0 && path[0] == \\\"\\\" {\\n    path = path[1:]\\n}\\n\\nreturn path\\n}\\n\\n// getContextForProposal returns the right context for PrepareProposal and\\n// ProcessProposal. We use deliverState on the first block to be able to access\\n// any state changes made in InitChain.\\nfunc (app *BaseApp)\\n\\ngetContextForProposal(ctx sdk.Context, height int64)\\n\\nsdk.Context {\\n    if height == 1 {\\n    ctx, _ = app.deliverState.ctx.CacheContext()\\n\\nreturn ctx\\n}\\n\\nreturn ctx\\n}\\n\\nStore queries query directly for store keys. They use clientCtx.QueryABCI(req abci.RequestQuery) to return the full abci.ResponseQuery with inclusion Merkle proofs. See following examples:\\n\\nQueries\\nA query is a request for information made by end-users of applications through an interface and processed by a full-node. A query is received by a full-node through its consensus engine and relayed to the application via the ABCI. It is then routed to the appropriate module via BaseApp 's QueryRouter so that it can be processed by the module's query service (./04-query-services.md). For a deeper look at the lifecycle of a query , click here.\\n\\n\", \"Title: Query Commands\\nLink: https://evm.cosmos.network/docs/sdk/v0.47/learn/advanced/cli\\nContent: Queries are objects that allow users to retrieve information about the application's state. To enable the creation of queries using the CLI interface, a function queryCommand is generally added to the rootCmd: This queryCommand function adds all the queries available to end-users for the application. This typically includes: QueryTx and/or other transaction query commands] from the auth module which allow the user to search for a transaction by inputting its hash, a list of tags, or a block height. These queries allow users to see if transactions have been included in a block. Account command from the auth module, which displays the state (e.g. account balance) of an account given an address. Validator command from the Cosmos SDK rpc client tools, which displays the validator set of a given height. Block command from the Cosmos SDK RPC client tools, which displays the block data for a given height. All module query commands the application is dependent on, retrieved by using the basic module manager's AddQueryCommands() function. Here is an example of a queryCommand aggregating subcommands from the simapp application: package cmd\\n\\nimport (\\n    \\n\\t\\\"errors\\\"\\n    \\\"io\\\"\\n    \\\"os\\\"\\n\\n\\trosettaCmd \\\"cosmossdk.io/tools/rosetta/cmd\\\"\\n    \\\"github.com/spf13/cobra\\\"\\n    \\\"github.com/spf13/viper\\\"\\n\\ttmcfg \\\"github.com/tendermint/tendermint/config\\\"\\n    \\\"github.com/tendermint/tendermint/libs/log\\\"\\n\\tdbm \\\"github.com/tendermint/tm-db\\\"\\n    \\\"cosmossdk.io/simapp\\\"\\n    \\\"cosmossdk.io/simapp/params\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/config\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/debug\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/flags\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/keys\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/pruning\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/rpc\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/server\\\"\\n\\tserverconfig \\\"github.com/cosmos/cosmos-sdk/server/config\\\"\\n\\tservertypes \\\"github.com/cosmos/cosmos-sdk/server/types\\\"\\n\\tsimtestutil \\\"github.com/cosmos/cosmos-sdk/testutil/sims\\\"\\n\\tsdk \\\"github.com/cosmos/cosmos-sdk/types\\\"\\n\\tauthcmd \\\"github.com/cosmos/cosmos-sdk/x/auth/client/cli\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/auth/types\\\"\\n\\tbanktypes \\\"github.com/cosmos/cosmos-sdk/x/bank/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/crisis\\\"\\n\\tgenutilcli \\\"github.com/cosmos/cosmos-sdk/x/genutil/client/cli\\\"\\n)\\n\\n// NewRootCmd creates a new root command for simd. It is called once in the\\n// main function.\\nfunc NewRootCmd() *cobra.Command {\\n\\t// we \\\"pre\\\"-instantiate the application for getting the injected/configured encoding configuration\\n    tempApp := simapp.NewSimApp(log.NewNopLogger(), dbm.NewMemDB(), nil, true, simtestutil.NewAppOptionsWithFlagHome(simapp.DefaultNodeHome))\\n    encodingConfig := params.EncodingConfig{\\n    InterfaceRegistry: tempApp.InterfaceRegistry(),\\n    Codec:             tempApp.AppCodec(),\\n    TxConfig:          tempApp.TxConfig(),\\n    Amino:             tempApp.LegacyAmino(),\\n}\\n    initClientCtx := client.Context{\\n}.\\n\\t\\tWithCodec(encodingConfig.Codec).\\n\\t\\tWithInterfaceRegistry(encodingConfig.InterfaceRegistry).\\n\\t\\tWithTxConfig(encodingConfig.TxConfig).\\n\\t\\tWithLegacyAmino(encodingConfig.Amino).\\n\\t\\tWithInput(os.Stdin).\\n\\t\\tWithAccountRetriever(types.AccountRetriever{\\n}).\\n\\t\\tWithHomeDir(simapp.DefaultNodeHome).\\n\\t\\tWithViper(\\\"\\\") // In simapp, we don't use any prefix for env variables.\\n    rootCmd := &cobra.Command{\\n    Use:   \\\"simd\\\",\\n    Short: \\\"simulation app\\\",\\n    PersistentPreRunE: func(cmd *cobra.Command, _ []string)\\n\\nerror {\\n\\t\\t\\t// set the default command outputs\\n\\t\\t\\tcmd.SetOut(cmd.OutOrStdout())\\n\\ncmd.SetErr(cmd.ErrOrStderr())\\n\\ninitClientCtx, err := client.ReadPersistentCommandFlags(initClientCtx, cmd.Flags())\\n    if err != nil {\\n    return err\\n}\\n\\ninitClientCtx, err = config.ReadFromClientConfig(initClientCtx)\\n    if err != nil {\\n    return err\\n}\\n    if err := client.SetCmdClientContextHandler(initClientCtx, cmd); err != nil {\\n    return err\\n}\\n\\ncustomAppTemplate, customAppConfig := initAppConfig()\\n    customTMConfig := initTendermintConfig()\\n\\nreturn server.InterceptConfigsPreRunHandler(cmd, customAppTemplate, customAppConfig, customTMConfig)\\n},\\n}\\n\\ninitRootCmd(rootCmd, encodingConfig)\\n\\nreturn rootCmd\\n}\\n\\n// initTendermintConfig helps to override default Tendermint Config values.\\n// return tmcfg.DefaultConfig if no custom configuration is required for the application.\\nfunc initTendermintConfig() *tmcfg.Config {\\n    cfg := tmcfg.DefaultConfig()\\n\\n\\t// these values put a higher strain on node memory\\n\\t// cfg.P2P.MaxNumInboundPeers = 100\\n\\t// cfg.P2P.MaxNumOutboundPeers = 40\\n\\n\\treturn cfg\\n}\\n\\n// initAppConfig helps to override default appConfig template and configs.\\n// return \\\"\\\", nil if no custom configuration is required for the application.\\nfunc initAppConfig() (string, interface{\\n}) {\\n\\t// The following code snippet is just for reference.\\n\\n\\t// WASMConfig defines configuration for the wasm module.\\n\\ttype WASMConfig struct {\\n\\t\\t// This is the maximum sdk gas (wasm and storage)\\n\\nthat we allow for any x/wasm \\\"smart\\\" queries\\n\\t\\tQueryGasLimit uint64 `mapstructure:\\\"query_gas_limit\\\"`\\n\\n\\t\\t// Address defines the gRPC-web server to listen on\\n\\t\\tLruSize uint64 `mapstructure:\\\"lru_size\\\"`\\n}\\n\\ntype CustomAppConfig struct {\\n    serverconfig.Config\\n\\n\\t\\tWASM WASMConfig `mapstructure:\\\"wasm\\\"`\\n}\\n\\n\\t// Optionally allow the chain developer to overwrite the SDK's default\\n\\t// server config.\\n    srvCfg := serverconfig.DefaultConfig()\\n\\t// The SDK's default minimum gas price is set to \\\"\\\" (empty value)\\n\\ninside\\n\\t// app.toml. If left empty by validators, the node will halt on startup.\\n\\t// However, the chain developer can set a default app.toml value for their\\n\\t// validators here.\\n\\t//\\n\\t// In summary:\\n\\t// - if you leave srvCfg.MinGasPrices = \\\"\\\", all validators MUST tweak their\\n\\t//   own app.toml config,\\n\\t// - if you set srvCfg.MinGasPrices non-empty, validators CAN tweak their\\n\\t//   own app.toml to override, or use this default value.\\n\\t//\\n\\t// In simapp, we set the min gas prices to 0.\\n\\tsrvCfg.MinGasPrices = \\\"0stake\\\"\\n\\t// srvCfg.BaseConfig.IAVLDisableFastNode = true // disable fastnode by default\\n    customAppConfig := CustomAppConfig{\\n    Config: *srvCfg,\\n    WASM: WASMConfig{\\n    LruSize:       1,\\n    QueryGasLimit: 300000,\\n},\\n}\\n    customAppTemplate := serverconfig.DefaultConfigTemplate + `\\n[wasm]\\n# This is the maximum sdk gas (wasm and storage)\\n\\nthat we allow for any x/wasm \\\"smart\\\" queries\\nquery_gas_limit = 300000\\n# This is the number of wasm vm instances we keep cached in memory for speed-up\\n# Warning: this is currently unstable and may lead to crashes, best to keep for 0 unless testing locally\\nlru_size = 0`\\n\\n\\treturn customAppTemplate, customAppConfig\\n}\\n\\nfunc initRootCmd(rootCmd *cobra.Command, encodingConfig params.EncodingConfig) {\\n    cfg := sdk.GetConfig()\\n\\ncfg.Seal()\\n\\nrootCmd.AddCommand(\\n\\t\\tgenutilcli.InitCmd(simapp.ModuleBasics, simapp.DefaultNodeHome),\\n\\t\\tNewTestnetCmd(simapp.ModuleBasics, banktypes.GenesisBalancesIterator{\\n}),\\n\\t\\tdebug.Cmd(),\\n\\t\\tconfig.Cmd(),\\n\\t\\tpruning.PruningCmd(newApp),\\n\\t)\\n\\nserver.AddCommands(rootCmd, simapp.DefaultNodeHome, newApp, appExport, addModuleInitFlags)\\n\\n\\t// add keybase, auxiliary RPC, query, genesis, and tx child commands\\n\\trootCmd.AddCommand(\\n\\t\\trpc.StatusCommand(),\\n\\t\\tgenesisCommand(encodingConfig),\\n\\t\\tqueryCommand(),\\n\\t\\ttxCommand(),\\n\\t\\tkeys.Commands(simapp.DefaultNodeHome),\\n\\t)\\n\\n\\t// add rosetta\\n\\trootCmd.AddCommand(rosettaCmd.RosettaCommand(encodingConfig.InterfaceRegistry, encodingConfig.Codec))\\n}\\n\\nfunc addModuleInitFlags(startCmd *cobra.Command) {\\n    crisis.AddModuleInitFlags(startCmd)\\n}\\n\\n// genesisCommand builds genesis-related `simd genesis` command. Users may provide application specific commands as a parameter\\nfunc genesisCommand(encodingConfig params.EncodingConfig, cmds ...*cobra.Command) *cobra.Command {\\n    cmd := genutilcli.GenesisCoreCommand(encodingConfig.TxConfig, simapp.ModuleBasics, simapp.DefaultNodeHome)\\n    for _, sub_cmd := range cmds {\\n    cmd.AddCommand(sub_cmd)\\n}\\n\\nreturn cmd\\n}\\n\\nfunc queryCommand() *cobra.Command {\\n    cmd := &cobra.Command{\\n    Use:                        \\\"query\\\",\\n    Aliases:                    []string{\\\"q\\\"\\n},\\n    Short:                      \\\"Querying subcommands\\\",\\n    DisableFlagParsing:         false,\\n    SuggestionsMinimumDistance: 2,\\n    RunE:                       client.ValidateCmd,\\n}\\n\\ncmd.AddCommand(\\n\\t\\tauthcmd.GetAccountCmd(),\\n\\t\\trpc.ValidatorCommand(),\\n\\t\\trpc.BlockCommand(),\\n\\t\\tauthcmd.QueryTxsByEventsCmd(),\\n\\t\\tauthcmd.QueryTxCmd(),\\n\\t)\\n\\nsimapp.ModuleBasics.AddQueryCommands(cmd)\\n\\nreturn cmd\\n}\\n\\nfunc txCommand() *cobra.Command {\\n    cmd := &cobra.Command{\\n    Use:                        \\\"tx\\\",\\n    Short:                      \\\"Transactions subcommands\\\",\\n    DisableFlagParsing:         false,\\n    SuggestionsMinimumDistance: 2,\\n    RunE:                       client.ValidateCmd,\\n}\\n\\ncmd.AddCommand(\\n\\t\\tauthcmd.GetSignCommand(),\\n\\t\\tauthcmd.GetSignBatchCommand(),\\n\\t\\tauthcmd.GetMultiSignCommand(),\\n\\t\\tauthcmd.GetMultiSignBatchCmd(),\\n\\t\\tauthcmd.GetValidateSignaturesCommand(),\\n\\t\\tauthcmd.GetBroadcastCommand(),\\n\\t\\tauthcmd.GetEncodeCommand(),\\n\\t\\tauthcmd.GetDecodeCommand(),\\n\\t\\tauthcmd.GetAuxToFeeCommand(),\\n\\t)\\n\\nsimapp.ModuleBasics.AddTxCommands(cmd)\\n\\nreturn cmd\\n}\\n\\n// newApp creates the application\\nfunc newApp(\\n\\tlogger log.Logger,\\n\\tdb dbm.DB,\\n\\ttraceStore io.Writer,\\n\\tappOpts servertypes.AppOptions,\\n)\\n\\nservertypes.Application {\\n    baseappOptions := server.DefaultBaseappOptions(appOpts)\\n\\nreturn simapp.NewSimApp(\\n\\t\\tlogger, db, traceStore, true,\\n\\t\\tappOpts,\\n\\t\\tbaseappOptions...,\\n\\t)\\n}\\n\\n// appExport creates a new simapp (optionally at a given height)\\n\\nand exports state.\\nfunc appExport(\\n\\tlogger log.Logger,\\n\\tdb dbm.DB,\\n\\ttraceStore io.Writer,\\n\\theight int64,\\n    forZeroHeight bool,\\n\\tjailAllowedAddrs []string,\\n\\tappOpts servertypes.AppOptions,\\n\\tmodulesToExport []string,\\n) (servertypes.ExportedApp, error) {\\n    var simApp *simapp.SimApp\\n\\n\\t// this check is necessary as we use the flag in x/upgrade.\\n\\t// we can exit more gracefully by checking the flag here.\\n\\thomePath, ok := appOpts.Get(flags.FlagHome).(string)\\n    if !ok || homePath == \\\"\\\" {\\n    return servertypes.ExportedApp{\\n}, errors.New(\\\"application home not set\\\")\\n}\\n\\nviperAppOpts, ok := appOpts.(*viper.Viper)\\n    if !ok {\\n    return servertypes.ExportedApp{\\n}, errors.New(\\\"appOpts is not viper.Viper\\\")\\n}\\n\\n\\t// overwrite the FlagInvCheckPeriod\\n\\tviperAppOpts.Set(server.FlagInvCheckPeriod, 1)\\n\\nappOpts = viperAppOpts\\n    if height != -1 {\\n    simApp = simapp.NewSimApp(logger, db, traceStore, false, appOpts)\\n    if err := simApp.LoadHeight(height); err != nil {\\n    return servertypes.ExportedApp{\\n}, err\\n}\\n\\t\\n}\\n\\nelse {\\n    simApp = simapp.NewSimApp(logger, db, traceStore, true, appOpts)\\n}\\n\\nreturn simApp.ExportAppStateAndValidators(forZeroHeight, jailAllowedAddrs, modulesToExport)\\n}\\n\\nQueries are objects that allow users to retrieve information about the application's state. To enable the creation of queries using the CLI interface, a function queryCommand is generally added to the rootCmd: This queryCommand function adds all the queries available to end-users for the application. This typically includes: QueryTx and/or other transaction query commands] from the auth module which allow the user to search for a transaction by inputting its hash, a list of tags, or a block height. These queries allow users to see if transactions have been included in a block. Account command from the auth module, which displays the state (e.g. account balance) of an account given an address. Validator command from the Cosmos SDK rpc client tools, which displays the validator set of a given height. Block command from the Cosmos SDK RPC client tools, which displays the block data for a given height. All module query commands the application is dependent on, retrieved by using the basic module manager's AddQueryCommands() function. Here is an example of a queryCommand aggregating subcommands from the simapp application:\\n\\nQueries are objects that allow users to retrieve information about the application's state. To enable the creation of queries using the CLI interface, a function queryCommand is generally added to the rootCmd: package cmd\\n\\nimport (\\n    \\n\\t\\\"errors\\\"\\n    \\\"io\\\"\\n    \\\"os\\\"\\n\\n\\trosettaCmd \\\"cosmossdk.io/tools/rosetta/cmd\\\"\\n    \\\"github.com/spf13/cobra\\\"\\n    \\\"github.com/spf13/viper\\\"\\n\\ttmcfg \\\"github.com/tendermint/tendermint/config\\\"\\n    \\\"github.com/tendermint/tendermint/libs/log\\\"\\n\\tdbm \\\"github.com/tendermint/tm-db\\\"\\n    \\\"cosmossdk.io/simapp\\\"\\n    \\\"cosmossdk.io/simapp/params\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/config\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/debug\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/flags\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/keys\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/pruning\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/rpc\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/server\\\"\\n\\tserverconfig \\\"github.com/cosmos/cosmos-sdk/server/config\\\"\\n\\tservertypes \\\"github.com/cosmos/cosmos-sdk/server/types\\\"\\n\\tsimtestutil \\\"github.com/cosmos/cosmos-sdk/testutil/sims\\\"\\n\\tsdk \\\"github.com/cosmos/cosmos-sdk/types\\\"\\n\\tauthcmd \\\"github.com/cosmos/cosmos-sdk/x/auth/client/cli\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/auth/types\\\"\\n\\tbanktypes \\\"github.com/cosmos/cosmos-sdk/x/bank/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/crisis\\\"\\n\\tgenutilcli \\\"github.com/cosmos/cosmos-sdk/x/genutil/client/cli\\\"\\n)\\n\\n// NewRootCmd creates a new root command for simd. It is called once in the\\n// main function.\\nfunc NewRootCmd() *cobra.Command {\\n\\t// we \\\"pre\\\"-instantiate the application for getting the injected/configured encoding configuration\\n    tempApp := simapp.NewSimApp(log.NewNopLogger(), dbm.NewMemDB(), nil, true, simtestutil.NewAppOptionsWithFlagHome(simapp.DefaultNodeHome))\\n    encodingConfig := params.EncodingConfig{\\n    InterfaceRegistry: tempApp.InterfaceRegistry(),\\n    Codec:             tempApp.AppCodec(),\\n    TxConfig:          tempApp.TxConfig(),\\n    Amino:             tempApp.LegacyAmino(),\\n}\\n    initClientCtx := client.Context{\\n}.\\n\\t\\tWithCodec(encodingConfig.Codec).\\n\\t\\tWithInterfaceRegistry(encodingConfig.InterfaceRegistry).\\n\\t\\tWithTxConfig(encodingConfig.TxConfig).\\n\\t\\tWithLegacyAmino(encodingConfig.Amino).\\n\\t\\tWithInput(os.Stdin).\\n\\t\\tWithAccountRetriever(types.AccountRetriever{\\n}).\\n\\t\\tWithHomeDir(simapp.DefaultNodeHome).\\n\\t\\tWithViper(\\\"\\\") // In simapp, we don't use any prefix for env variables.\\n    rootCmd := &cobra.Command{\\n    Use:   \\\"simd\\\",\\n    Short: \\\"simulation app\\\",\\n    PersistentPreRunE: func(cmd *cobra.Command, _ []string)\\n\\nerror {\\n\\t\\t\\t// set the default command outputs\\n\\t\\t\\tcmd.SetOut(cmd.OutOrStdout())\\n\\ncmd.SetErr(cmd.ErrOrStderr())\\n\\ninitClientCtx, err := client.ReadPersistentCommandFlags(initClientCtx, cmd.Flags())\\n    if err != nil {\\n    return err\\n}\\n\\ninitClientCtx, err = config.ReadFromClientConfig(initClientCtx)\\n    if err != nil {\\n    return err\\n}\\n    if err := client.SetCmdClientContextHandler(initClientCtx, cmd); err != nil {\\n    return err\\n}\\n\\ncustomAppTemplate, customAppConfig := initAppConfig()\\n    customTMConfig := initTendermintConfig()\\n\\nreturn server.InterceptConfigsPreRunHandler(cmd, customAppTemplate, customAppConfig, customTMConfig)\\n},\\n}\\n\\ninitRootCmd(rootCmd, encodingConfig)\\n\\nreturn rootCmd\\n}\\n\\n// initTendermintConfig helps to override default Tendermint Config values.\\n// return tmcfg.DefaultConfig if no custom configuration is required for the application.\\nfunc initTendermintConfig() *tmcfg.Config {\\n    cfg := tmcfg.DefaultConfig()\\n\\n\\t// these values put a higher strain on node memory\\n\\t// cfg.P2P.MaxNumInboundPeers = 100\\n\\t// cfg.P2P.MaxNumOutboundPeers = 40\\n\\n\\treturn cfg\\n}\\n\\n// initAppConfig helps to override default appConfig template and configs.\\n// return \\\"\\\", nil if no custom configuration is required for the application.\\nfunc initAppConfig() (string, interface{\\n}) {\\n\\t// The following code snippet is just for reference.\\n\\n\\t// WASMConfig defines configuration for the wasm module.\\n\\ttype WASMConfig struct {\\n\\t\\t// This is the maximum sdk gas (wasm and storage)\\n\\nthat we allow for any x/wasm \\\"smart\\\" queries\\n\\t\\tQueryGasLimit uint64 `mapstructure:\\\"query_gas_limit\\\"`\\n\\n\\t\\t// Address defines the gRPC-web server to listen on\\n\\t\\tLruSize uint64 `mapstructure:\\\"lru_size\\\"`\\n}\\n\\ntype CustomAppConfig struct {\\n    serverconfig.Config\\n\\n\\t\\tWASM WASMConfig `mapstructure:\\\"wasm\\\"`\\n}\\n\\n\\t// Optionally allow the chain developer to overwrite the SDK's default\\n\\t// server config.\\n    srvCfg := serverconfig.DefaultConfig()\\n\\t// The SDK's default minimum gas price is set to \\\"\\\" (empty value)\\n\\ninside\\n\\t// app.toml. If left empty by validators, the node will halt on startup.\\n\\t// However, the chain developer can set a default app.toml value for their\\n\\t// validators here.\\n\\t//\\n\\t// In summary:\\n\\t// - if you leave srvCfg.MinGasPrices = \\\"\\\", all validators MUST tweak their\\n\\t//   own app.toml config,\\n\\t// - if you set srvCfg.MinGasPrices non-empty, validators CAN tweak their\\n\\t//   own app.toml to override, or use this default value.\\n\\t//\\n\\t// In simapp, we set the min gas prices to 0.\\n\\tsrvCfg.MinGasPrices = \\\"0stake\\\"\\n\\t// srvCfg.BaseConfig.IAVLDisableFastNode = true // disable fastnode by default\\n    customAppConfig := CustomAppConfig{\\n    Config: *srvCfg,\\n    WASM: WASMConfig{\\n    LruSize:       1,\\n    QueryGasLimit: 300000,\\n},\\n}\\n    customAppTemplate := serverconfig.DefaultConfigTemplate + `\\n[wasm]\\n# This is the maximum sdk gas (wasm and storage)\\n\\nthat we allow for any x/wasm \\\"smart\\\" queries\\nquery_gas_limit = 300000\\n# This is the number of wasm vm instances we keep cached in memory for speed-up\\n# Warning: this is currently unstable and may lead to crashes, best to keep for 0 unless testing locally\\nlru_size = 0`\\n\\n\\treturn customAppTemplate, customAppConfig\\n}\\n\\nfunc initRootCmd(rootCmd *cobra.Command, encodingConfig params.EncodingConfig) {\\n    cfg := sdk.GetConfig()\\n\\ncfg.Seal()\\n\\nrootCmd.AddCommand(\\n\\t\\tgenutilcli.InitCmd(simapp.ModuleBasics, simapp.DefaultNodeHome),\\n\\t\\tNewTestnetCmd(simapp.ModuleBasics, banktypes.GenesisBalancesIterator{\\n}),\\n\\t\\tdebug.Cmd(),\\n\\t\\tconfig.Cmd(),\\n\\t\\tpruning.PruningCmd(newApp),\\n\\t)\\n\\nserver.AddCommands(rootCmd, simapp.DefaultNodeHome, newApp, appExport, addModuleInitFlags)\\n\\n\\t// add keybase, auxiliary RPC, query, genesis, and tx child commands\\n\\trootCmd.AddCommand(\\n\\t\\trpc.StatusCommand(),\\n\\t\\tgenesisCommand(encodingConfig),\\n\\t\\tqueryCommand(),\\n\\t\\ttxCommand(),\\n\\t\\tkeys.Commands(simapp.DefaultNodeHome),\\n\\t)\\n\\n\\t// add rosetta\\n\\trootCmd.AddCommand(rosettaCmd.RosettaCommand(encodingConfig.InterfaceRegistry, encodingConfig.Codec))\\n}\\n\\nfunc addModuleInitFlags(startCmd *cobra.Command) {\\n    crisis.AddModuleInitFlags(startCmd)\\n}\\n\\n// genesisCommand builds genesis-related `simd genesis` command. Users may provide application specific commands as a parameter\\nfunc genesisCommand(encodingConfig params.EncodingConfig, cmds ...*cobra.Command) *cobra.Command {\\n    cmd := genutilcli.GenesisCoreCommand(encodingConfig.TxConfig, simapp.ModuleBasics, simapp.DefaultNodeHome)\\n    for _, sub_cmd := range cmds {\\n    cmd.AddCommand(sub_cmd)\\n}\\n\\nreturn cmd\\n}\\n\\nfunc queryCommand() *cobra.Command {\\n    cmd := &cobra.Command{\\n    Use:                        \\\"query\\\",\\n    Aliases:                    []string{\\\"q\\\"\\n},\\n    Short:                      \\\"Querying subcommands\\\",\\n    DisableFlagParsing:         false,\\n    SuggestionsMinimumDistance: 2,\\n    RunE:                       client.ValidateCmd,\\n}\\n\\ncmd.AddCommand(\\n\\t\\tauthcmd.GetAccountCmd(),\\n\\t\\trpc.ValidatorCommand(),\\n\\t\\trpc.BlockCommand(),\\n\\t\\tauthcmd.QueryTxsByEventsCmd(),\\n\\t\\tauthcmd.QueryTxCmd(),\\n\\t)\\n\\nsimapp.ModuleBasics.AddQueryCommands(cmd)\\n\\nreturn cmd\\n}\\n\\nfunc txCommand() *cobra.Command {\\n    cmd := &cobra.Command{\\n    Use:                        \\\"tx\\\",\\n    Short:                      \\\"Transactions subcommands\\\",\\n    DisableFlagParsing:         false,\\n    SuggestionsMinimumDistance: 2,\\n    RunE:                       client.ValidateCmd,\\n}\\n\\ncmd.AddCommand(\\n\\t\\tauthcmd.GetSignCommand(),\\n\\t\\tauthcmd.GetSignBatchCommand(),\\n\\t\\tauthcmd.GetMultiSignCommand(),\\n\\t\\tauthcmd.GetMultiSignBatchCmd(),\\n\\t\\tauthcmd.GetValidateSignaturesCommand(),\\n\\t\\tauthcmd.GetBroadcastCommand(),\\n\\t\\tauthcmd.GetEncodeCommand(),\\n\\t\\tauthcmd.GetDecodeCommand(),\\n\\t\\tauthcmd.GetAuxToFeeCommand(),\\n\\t)\\n\\nsimapp.ModuleBasics.AddTxCommands(cmd)\\n\\nreturn cmd\\n}\\n\\n// newApp creates the application\\nfunc newApp(\\n\\tlogger log.Logger,\\n\\tdb dbm.DB,\\n\\ttraceStore io.Writer,\\n\\tappOpts servertypes.AppOptions,\\n)\\n\\nservertypes.Application {\\n    baseappOptions := server.DefaultBaseappOptions(appOpts)\\n\\nreturn simapp.NewSimApp(\\n\\t\\tlogger, db, traceStore, true,\\n\\t\\tappOpts,\\n\\t\\tbaseappOptions...,\\n\\t)\\n}\\n\\n// appExport creates a new simapp (optionally at a given height)\\n\\nand exports state.\\nfunc appExport(\\n\\tlogger log.Logger,\\n\\tdb dbm.DB,\\n\\ttraceStore io.Writer,\\n\\theight int64,\\n    forZeroHeight bool,\\n\\tjailAllowedAddrs []string,\\n\\tappOpts servertypes.AppOptions,\\n\\tmodulesToExport []string,\\n) (servertypes.ExportedApp, error) {\\n    var simApp *simapp.SimApp\\n\\n\\t// this check is necessary as we use the flag in x/upgrade.\\n\\t// we can exit more gracefully by checking the flag here.\\n\\thomePath, ok := appOpts.Get(flags.FlagHome).(string)\\n    if !ok || homePath == \\\"\\\" {\\n    return servertypes.ExportedApp{\\n}, errors.New(\\\"application home not set\\\")\\n}\\n\\nviperAppOpts, ok := appOpts.(*viper.Viper)\\n    if !ok {\\n    return servertypes.ExportedApp{\\n}, errors.New(\\\"appOpts is not viper.Viper\\\")\\n}\\n\\n\\t// overwrite the FlagInvCheckPeriod\\n\\tviperAppOpts.Set(server.FlagInvCheckPeriod, 1)\\n\\nappOpts = viperAppOpts\\n    if height != -1 {\\n    simApp = simapp.NewSimApp(logger, db, traceStore, false, appOpts)\\n    if err := simApp.LoadHeight(height); err != nil {\\n    return servertypes.ExportedApp{\\n}, err\\n}\\n\\t\\n}\\n\\nelse {\\n    simApp = simapp.NewSimApp(logger, db, traceStore, true, appOpts)\\n}\\n\\nreturn simApp.ExportAppStateAndValidators(forZeroHeight, jailAllowedAddrs, modulesToExport)\\n}\\n\\n\", \"Title: Query\\nLink: https://evm.cosmos.network/docs/sdk/v0.47/learn/advanced/baseapp\\nContent: The Query ABCI message is used to serve queries received from the underlying consensus engine, including queries received via RPC like CometBFT RPC. It used to be the main entrypoint to build interfaces with the application, but with the introduction of gRPC queries in Cosmos SDK v0.40, its usage is more limited. The application must respect a few rules when implementing the Query method, which are outlined here. Each CometBFT query comes with a path , which is a string which denotes what to query. If the path matches a gRPC fully-qualified service method, then BaseApp will defer the query to the grpcQueryRouter and let it handle it like explained above . Otherwise, the path represents a query that is not (yet) handled by the gRPC router. BaseApp splits the path string with the / delimiter. By convention, the first element of the split string ( split[0] ) contains the category of query ( app , p2p , store or custom ). The BaseApp implementation of the Query(req abci.RequestQuery) method is a simple dispatcher serving these 4 main categories of queries: Application-related queries like querying the application's version, which are served via the handleQueryApp method. Direct queries to the multistore, which are served by the handlerQueryStore method. These direct queries are different from custom queries which go through app.queryRouter , and are mainly used by third-party service provider like block explorers. P2P queries, which are served via the handleQueryP2P method. These queries return either app.addrPeerFilter or app.ipPeerFilter that contain the list of peers filtered by address or IP respectively. These lists are first initialized via options in BaseApp 's constructor.\\n\\nMain ABCI 1.0 Messages\\nThe Application-Blockchain Interface (ABCI) is a generic interface that connects a state-machine with a consensus engine to form a functional full-node. It can be wrapped in any language, and needs to be implemented by each application-specific blockchain built on top of an ABCI-compatible consensus engine like CometBFT. The consensus engine handles two main tasks: The networking logic, which mainly consists in gossiping block parts, transactions and consensus votes. The consensus logic, which results in the deterministic ordering of transactions in the form of blocks. It is not the role of the consensus engine to define the state or the validity of transactions. Generally, transactions are handled by the consensus engine in the form of []bytes , and relayed to the application via the ABCI to be decoded and processed. At keys moments in the networking and consensus processes (e.g. beginning of a block, commit of a block, reception of an unconfirmed transaction, ...), the consensus engine emits ABCI messages for the state-machine to act on. Developers building on top of the Cosmos SDK need not implement the ABCI themselves, as BaseApp comes with a built-in implementation of the interface. Let us go through the main ABCI messages that BaseApp implements: Prepare Proposal Process Proposal CheckTx DeliverTx\\n\\nBeginBlock\\nThe BeginBlock ABCI message is sent from the underlying CometBFT engine when a block proposal created by the correct proposer is received, before DeliverTx is run for each transaction in the block. It allows developers to have logic be executed at the beginning of each block. In the Cosmos SDK, the BeginBlock(req abci.RequestBeginBlock) method does the following: Initialize deliverState with the latest header using the req abci.RequestBeginBlock passed as parameter via the setState function. package baseapp\\n\\nimport (\\n    \\n\\t\\\"errors\\\"\\n    \\\"fmt\\\"\\n    \\\"sort\\\"\\n    \\\"strings\\\"\\n    \\\"github.com/cosmos/gogoproto/proto\\\"\\n\\tabci \\\"github.com/tendermint/tendermint/abci/types\\\"\\n    \\\"github.com/tendermint/tendermint/crypto/tmhash\\\"\\n    \\\"github.com/tendermint/tendermint/libs/log\\\"\\n\\ttmproto \\\"github.com/tendermint/tendermint/proto/tendermint/types\\\"\\n\\tdbm \\\"github.com/tendermint/tm-db\\\"\\n    \\\"golang.org/x/exp/maps\\\"\\n\\n\\tcodectypes \\\"github.com/cosmos/cosmos-sdk/codec/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/snapshots\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/store\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/store/rootmulti\\\"\\n\\tstoretypes \\\"github.com/cosmos/cosmos-sdk/store/types\\\"\\n\\tsdk \\\"github.com/cosmos/cosmos-sdk/types\\\"\\n\\tsdkerrors \\\"github.com/cosmos/cosmos-sdk/types/errors\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/types/mempool\\\"\\n)\\n\\nconst (\\n\\trunTxModeCheck    runTxMode = iota // Check a transaction\\n\\trunTxModeReCheck                   // Recheck a (pending)\\n\\ntransaction after a commit\\n\\trunTxModeSimulate                  // Simulate a transaction\\n\\trunTxModeDeliver                   // Deliver a transaction\\n\\trunTxPrepareProposal\\n\\trunTxProcessProposal\\n)\\n\\nvar _ abci.Application = (*BaseApp)(nil)\\n\\ntype (\\n\\t// Enum mode for app.runTx\\n\\trunTxMode uint8\\n\\n\\t// StoreLoader defines a customizable function to control how we load the CommitMultiStore\\n\\t// from disk. This is useful for state migration, when loading a datastore written with\\n\\t// an older version of the software. In particular, if a module changed the substore key name\\n\\t// (or removed a substore)\\n\\nbetween two versions of the software.\\n\\tStoreLoader func(ms sdk.CommitMultiStore)\\n\\nerror\\n)\\n\\n// BaseApp reflects the ABCI application implementation.\\ntype BaseApp struct { //nolint: maligned\\n\\t// initialized on creation\\n\\tlogger            log.Logger\\n\\tname              string               // application name from abci.Info\\n\\tdb                dbm.DB               // common DB backend\\n\\tcms               sdk.CommitMultiStore // Main (uncached)\\n\\nstate\\n\\tqms               sdk.MultiStore       // Optional alternative multistore for querying only.\\n\\tstoreLoader       StoreLoader          // function to handle store loading, may be overridden with SetStoreLoader()\\n\\ngrpcRouter   *GRPCQueryRouter     // router for redirecting gRPC query calls\\n\\tmsgServiceRouter  *MsgServiceRouter    // router for redirecting Msg service messages\\n\\tinterfaceRegistry codectypes.InterfaceRegistry\\n\\ttxDecoder         sdk.TxDecoder // unmarshal []byte into sdk.Tx\\n\\ttxEncoder         sdk.TxEncoder // marshal sdk.Tx into []byte\\n\\n\\tmempool         mempool.Mempool            // application side mempool\\n\\tanteHandler     sdk.AnteHandler            // ante handler for fee and auth\\n\\tpostHandler     sdk.AnteHandler            // post handler, optional, e.g. for tips\\n\\tinitChainer     sdk.InitChainer            // initialize state with validators and state blob\\n\\tbeginBlocker    sdk.BeginBlocker           // logic to run before any txs\\n\\tprocessProposal sdk.ProcessProposalHandler // the handler which runs on ABCI ProcessProposal\\n\\tprepareProposal sdk.PrepareProposalHandler // the handler which runs on ABCI PrepareProposal\\n\\tendBlocker      sdk.EndBlocker             // logic to run after all txs, and to determine valset changes\\n\\taddrPeerFilter  sdk.PeerFilter             // filter peers by address and port\\n\\tidPeerFilter    sdk.PeerFilter             // filter peers by node ID\\n\\tfauxMerkleMode  bool                       // if true, IAVL MountStores uses MountStoresDB for simulation speed.\\n\\n\\t// manages snapshots, i.e. dumps of app state at certain intervals\\n\\tsnapshotManager *snapshots.Manager\\n\\n\\t// volatile states:\\n\\t//\\n\\t// checkState is set on InitChain and reset on Commit\\n\\t// deliverState is set on InitChain and BeginBlock and set to nil on Commit\\n\\tcheckState           *state // for CheckTx\\n\\tdeliverState         *state // for DeliverTx\\n\\tprocessProposalState *state // for ProcessProposal\\n\\tprepareProposalState *state // for PrepareProposal\\n\\n\\t// an inter-block write-through cache provided to the context during deliverState\\n\\tinterBlockCache sdk.MultiStorePersistentCache\\n\\n\\t// absent validators from begin block\\n\\tvoteInfos []abci.VoteInfo\\n\\n\\t// paramStore is used to query for ABCI consensus parameters from an\\n\\t// application parameter store.\\n\\tparamStore ParamStore\\n\\n\\t// The minimum gas prices a validator is willing to accept for processing a\\n\\t// transaction. This is mainly used for DoS and spam prevention.\\n\\tminGasPrices sdk.DecCoins\\n\\n\\t// initialHeight is the initial height at which we start the baseapp\\n\\tinitialHeight int64\\n\\n\\t// flag for sealing options and parameters to a BaseApp\\n\\tsealed bool\\n\\n\\t// block height at which to halt the chain and gracefully shutdown\\n\\thaltHeight uint64\\n\\n\\t// minimum block time (in Unix seconds)\\n\\nat which to halt the chain and gracefully shutdown\\n\\thaltTime uint64\\n\\n\\t// minRetainBlocks defines the minimum block height offset from the current\\n\\t// block being committed, such that all blocks past this offset are pruned\\n\\t// from Tendermint. It is used as part of the process of determining the\\n\\t// ResponseCommit.RetainHeight value during ABCI Commit. A value of 0 indicates\\n\\t// that no blocks should be pruned.\\n\\t//\\n\\t// Note: Tendermint block pruning is dependant on this parameter in conunction\\n\\t// with the unbonding (safety threshold)\\n\\nperiod, state pruning and state sync\\n\\t// snapshot parameters to determine the correct minimum value of\\n\\t// ResponseCommit.RetainHeight.\\n\\tminRetainBlocks uint64\\n\\n\\t// application's version string\\n\\tversion string\\n\\n\\t// application's protocol version that increments on every upgrade\\n\\t// if BaseApp is passed to the upgrade keeper's NewKeeper method.\\n\\tappVersion uint64\\n\\n\\t// recovery handler for app.runTx method\\n\\trunTxRecoveryMiddleware recoveryMiddleware\\n\\n\\t// trace set will return full stack traces for errors in ABCI Log field\\n\\ttrace bool\\n\\n\\t// indexEvents defines the set of events in the form {\\n    eventType\\n}.{\\n    attributeKey\\n},\\n\\t// which informs Tendermint what to index. If empty, all events will be indexed.\\n\\tindexEvents map[string]struct{\\n}\\n\\n\\t// abciListeners for hooking into the ABCI message processing of the BaseApp\\n\\t// and exposing the requests and responses to external consumers\\n\\tabciListeners []ABCIListener\\n}\\n\\n// NewBaseApp returns a reference to an initialized BaseApp. It accepts a\\n// variadic number of option functions, which act on the BaseApp to set\\n// configuration choices.\\n//\\n// NOTE: The db is used to store the version number for now.\\nfunc NewBaseApp(\\n\\tname string, logger log.Logger, db dbm.DB, txDecoder sdk.TxDecoder, options ...func(*BaseApp),\\n) *BaseApp {\\n    app := &BaseApp{\\n    logger:           logger,\\n\\t\\tname:             name,\\n\\t\\tdb:               db,\\n\\t\\tcms:              store.NewCommitMultiStore(db),\\n\\t\\tstoreLoader:      DefaultStoreLoader,\\n\\t\\tgrpcQueryRouter:  NewGRPCQueryRouter(),\\n\\t\\tmsgServiceRouter: NewMsgServiceRouter(),\\n\\t\\ttxDecoder:        txDecoder,\\n\\t\\tfauxMerkleMode:   false,\\n}\\n    for _, option := range options {\\n    option(app)\\n}\\n    if app.mempool == nil {\\n    app.SetMempool(mempool.NoOpMempool{\\n})\\n}\\n    if app.processProposal == nil {\\n    app.SetProcessProposal(app.DefaultProcessProposal())\\n}\\n    if app.prepareProposal == nil {\\n    app.SetPrepareProposal(app.DefaultPrepareProposal())\\n}\\n    if app.interBlockCache != nil {\\n    app.cms.SetInterBlockCache(app.interBlockCache)\\n}\\n\\napp.runTxRecoveryMiddleware = newDefaultRecoveryMiddleware()\\n\\nreturn app\\n}\\n\\n// Name returns the name of the BaseApp.\\nfunc (app *BaseApp)\\n\\nName()\\n\\nstring {\\n    return app.name\\n}\\n\\n// AppVersion returns the application's protocol version.\\nfunc (app *BaseApp)\\n\\nAppVersion()\\n\\nuint64 {\\n    return app.appVersion\\n}\\n\\n// Version returns the application's version string.\\nfunc (app *BaseApp)\\n\\nVersion()\\n\\nstring {\\n    return app.version\\n}\\n\\n// Logger returns the logger of the BaseApp.\\nfunc (app *BaseApp)\\n\\nLogger()\\n\\nlog.Logger {\\n    return app.logger\\n}\\n\\n// Trace returns the boolean value for logging error stack traces.\\nfunc (app *BaseApp)\\n\\nTrace()\\n\\nbool {\\n    return app.trace\\n}\\n\\n// MsgServiceRouter returns the MsgServiceRouter of a BaseApp.\\nfunc (app *BaseApp)\\n\\nMsgServiceRouter() *MsgServiceRouter {\\n    return app.msgServiceRouter\\n}\\n\\n// SetMsgServiceRouter sets the MsgServiceRouter of a BaseApp.\\nfunc (app *BaseApp)\\n\\nSetMsgServiceRouter(msgServiceRouter *MsgServiceRouter) {\\n    app.msgServiceRouter = msgServiceRouter\\n}\\n\\n// MountStores mounts all IAVL or DB stores to the provided keys in the BaseApp\\n// multistore.\\nfunc (app *BaseApp)\\n\\nMountStores(keys ...storetypes.StoreKey) {\\n    for _, key := range keys {\\n    switch key.(type) {\\n    case *storetypes.KVStoreKey:\\n    if !app.fauxMerkleMode {\\n    app.MountStore(key, storetypes.StoreTypeIAVL)\\n}\\n\\nelse {\\n\\t\\t\\t\\t// StoreTypeDB doesn't do anything upon commit, and it doesn't\\n\\t\\t\\t\\t// retain history, but it's useful for faster simulation.\\n\\t\\t\\t\\tapp.MountStore(key, storetypes.StoreTypeDB)\\n}\\n    case *storetypes.TransientStoreKey:\\n\\t\\t\\tapp.MountStore(key, storetypes.StoreTypeTransient)\\n    case *storetypes.MemoryStoreKey:\\n\\t\\t\\tapp.MountStore(key, storetypes.StoreTypeMemory)\\n\\ndefault:\\n\\t\\t\\tpanic(fmt.Sprintf(\\\"Unrecognized store key type :%T\\\", key))\\n}\\n\\t\\n}\\n}\\n\\n// MountKVStores mounts all IAVL or DB stores to the provided keys in the\\n// BaseApp multistore.\\nfunc (app *BaseApp)\\n\\nMountKVStores(keys map[string]*storetypes.KVStoreKey) {\\n    for _, key := range keys {\\n    if !app.fauxMerkleMode {\\n    app.MountStore(key, storetypes.StoreTypeIAVL)\\n}\\n\\nelse {\\n\\t\\t\\t// StoreTypeDB doesn't do anything upon commit, and it doesn't\\n\\t\\t\\t// retain history, but it's useful for faster simulation.\\n\\t\\t\\tapp.MountStore(key, storetypes.StoreTypeDB)\\n}\\n\\t\\n}\\n}\\n\\n// MountTransientStores mounts all transient stores to the provided keys in\\n// the BaseApp multistore.\\nfunc (app *BaseApp)\\n\\nMountTransientStores(keys map[string]*storetypes.TransientStoreKey) {\\n    for _, key := range keys {\\n    app.MountStore(key, storetypes.StoreTypeTransient)\\n}\\n}\\n\\n// MountMemoryStores mounts all in-memory KVStores with the BaseApp's internal\\n// commit multi-store.\\nfunc (app *BaseApp)\\n\\nMountMemoryStores(keys map[string]*storetypes.MemoryStoreKey) {\\n    skeys := maps.Keys(keys)\\n\\nsort.Strings(skeys)\\n    for _, key := range skeys {\\n    memKey := keys[key]\\n\\t\\tapp.MountStore(memKey, storetypes.StoreTypeMemory)\\n}\\n}\\n\\n// MountStore mounts a store to the provided key in the BaseApp multistore,\\n// using the default DB.\\nfunc (app *BaseApp)\\n\\nMountStore(key storetypes.StoreKey, typ storetypes.StoreType) {\\n    app.cms.MountStoreWithDB(key, typ, nil)\\n}\\n\\n// LoadLatestVersion loads the latest application version. It will panic if\\n// called more than once on a running BaseApp.\\nfunc (app *BaseApp)\\n\\nLoadLatestVersion()\\n\\nerror {\\n    err := app.storeLoader(app.cms)\\n    if err != nil {\\n    return fmt.Errorf(\\\"failed to load latest version: %w\\\", err)\\n}\\n\\nreturn app.Init()\\n}\\n\\n// DefaultStoreLoader will be used by default and loads the latest version\\nfunc DefaultStoreLoader(ms sdk.CommitMultiStore)\\n\\nerror {\\n    return ms.LoadLatestVersion()\\n}\\n\\n// CommitMultiStore returns the root multi-store.\\n// App constructor can use this to access the `cms`.\\n// UNSAFE: must not be used during the abci life cycle.\\nfunc (app *BaseApp)\\n\\nCommitMultiStore()\\n\\nsdk.CommitMultiStore {\\n    return app.cms\\n}\\n\\n// SnapshotManager returns the snapshot manager.\\n// application use this to register extra extension snapshotters.\\nfunc (app *BaseApp)\\n\\nSnapshotManager() *snapshots.Manager {\\n    return app.snapshotManager\\n}\\n\\n// LoadVersion loads the BaseApp application version. It will panic if called\\n// more than once on a running baseapp.\\nfunc (app *BaseApp)\\n\\nLoadVersion(version int64)\\n\\nerror {\\n    app.logger.Info(\\\"NOTICE: this could take a long time to migrate IAVL store to fastnode if you enable Fast Node.\\\\n\\\")\\n    err := app.cms.LoadVersion(version)\\n    if err != nil {\\n    return fmt.Errorf(\\\"failed to load version %d: %w\\\", version, err)\\n}\\n\\nreturn app.Init()\\n}\\n\\n// LastCommitID returns the last CommitID of the multistore.\\nfunc (app *BaseApp)\\n\\nLastCommitID()\\n\\nstoretypes.CommitID {\\n    return app.cms.LastCommitID()\\n}\\n\\n// LastBlockHeight returns the last committed block height.\\nfunc (app *BaseApp)\\n\\nLastBlockHeight()\\n\\nint64 {\\n    return app.cms.LastCommitID().Version\\n}\\n\\n// Init initializes the app. It seals the app, preventing any\\n// further modifications. In addition, it validates the app against\\n// the earlier provided settings. Returns an error if validation fails.\\n// nil otherwise. Panics if the app is already sealed.\\nfunc (app *BaseApp)\\n\\nInit()\\n\\nerror {\\n    if app.sealed {\\n    panic(\\\"cannot call initFromMainStore: baseapp already sealed\\\")\\n}\\n    emptyHeader := tmproto.Header{\\n}\\n\\n\\t// needed for the export command which inits from store but never calls initchain\\n\\tapp.setState(runTxModeCheck, emptyHeader)\\n\\n\\t// needed for ABCI Replay Blocks mode which calls Prepare/Process proposal (InitChain is not called)\\n\\napp.setState(runTxPrepareProposal, emptyHeader)\\n\\napp.setState(runTxProcessProposal, emptyHeader)\\n\\napp.Seal()\\n\\nrms, ok := app.cms.(*rootmulti.Store)\\n    if !ok {\\n    return fmt.Errorf(\\\"invalid commit multi-store; expected %T, got: %T\\\", &rootmulti.Store{\\n}, app.cms)\\n}\\n\\nreturn rms.GetPruning().Validate()\\n}\\n\\nfunc (app *BaseApp)\\n\\nsetMinGasPrices(gasPrices sdk.DecCoins) {\\n    app.minGasPrices = gasPrices\\n}\\n\\nfunc (app *BaseApp)\\n\\nsetHaltHeight(haltHeight uint64) {\\n    app.haltHeight = haltHeight\\n}\\n\\nfunc (app *BaseApp)\\n\\nsetHaltTime(haltTime uint64) {\\n    app.haltTime = haltTime\\n}\\n\\nfunc (app *BaseApp)\\n\\nsetMinRetainBlocks(minRetainBlocks uint64) {\\n    app.minRetainBlocks = minRetainBlocks\\n}\\n\\nfunc (app *BaseApp)\\n\\nsetInterBlockCache(cache sdk.MultiStorePersistentCache) {\\n    app.interBlockCache = cache\\n}\\n\\nfunc (app *BaseApp)\\n\\nsetTrace(trace bool) {\\n    app.trace = trace\\n}\\n\\nfunc (app *BaseApp)\\n\\nsetIndexEvents(ie []string) {\\n    app.indexEvents = make(map[string]struct{\\n})\\n    for _, e := range ie {\\n    app.indexEvents[e] = struct{\\n}{\\n}\\n\\t\\n}\\n}\\n\\n// Seal seals a BaseApp. It prohibits any further modifications to a BaseApp.\\nfunc (app *BaseApp)\\n\\nSeal() {\\n    app.sealed = true\\n}\\n\\n// IsSealed returns true if the BaseApp is sealed and false otherwise.\\nfunc (app *BaseApp)\\n\\nIsSealed()\\n\\nbool {\\n    return app.sealed\\n}\\n\\n// setState sets the BaseApp's state for the corresponding mode with a branched\\n// multi-store (i.e. a CacheMultiStore)\\n\\nand a new Context with the same\\n// multi-store branch, and provided header.\\nfunc (app *BaseApp)\\n\\nsetState(mode runTxMode, header tmproto.Header) {\\n    ms := app.cms.CacheMultiStore()\\n    baseState := &state{\\n    ms:  ms,\\n\\t\\tctx: sdk.NewContext(ms, header, false, app.logger),\\n}\\n    switch mode {\\n    case runTxModeCheck:\\n\\t\\t// Minimum gas prices are also set. It is set on InitChain and reset on Commit.\\n\\t\\tbaseState.ctx = baseState.ctx.WithIsCheckTx(true).WithMinGasPrices(app.minGasPrices)\\n\\napp.checkState = baseState\\n    case runTxModeDeliver:\\n\\t\\t// It is set on InitChain and BeginBlock and set to nil on Commit.\\n\\t\\tapp.deliverState = baseState\\n    case runTxPrepareProposal:\\n\\t\\t// It is set on InitChain and Commit.\\n\\t\\tapp.prepareProposalState = baseState\\n    case runTxProcessProposal:\\n\\t\\t// It is set on InitChain and Commit.\\n\\t\\tapp.processProposalState = baseState\\n\\tdefault:\\n\\t\\tpanic(fmt.Sprintf(\\\"invalid runTxMode for setState: %d\\\", mode))\\n}\\n}\\n\\n// GetConsensusParams returns the current consensus parameters from the BaseApp's\\n// ParamStore. If the BaseApp has no ParamStore defined, nil is returned.\\nfunc (app *BaseApp)\\n\\nGetConsensusParams(ctx sdk.Context) *tmproto.ConsensusParams {\\n    if app.paramStore == nil {\\n    return nil\\n}\\n\\ncp, err := app.paramStore.Get(ctx)\\n    if err != nil {\\n    panic(err)\\n}\\n\\nreturn cp\\n}\\n\\n// StoreConsensusParams sets the consensus parameters to the baseapp's param store.\\nfunc (app *BaseApp)\\n\\nStoreConsensusParams(ctx sdk.Context, cp *tmproto.ConsensusParams) {\\n    if app.paramStore == nil {\\n    panic(\\\"cannot store consensus params with no params store set\\\")\\n}\\n    if cp == nil {\\n    return\\n}\\n\\napp.paramStore.Set(ctx, cp)\\n\\t// We're explicitly not storing the Tendermint app_version in the param store. It's\\n\\t// stored instead in the x/upgrade store, with its own bump logic.\\n}\\n\\n// AddRunTxRecoveryHandler adds custom app.runTx method panic handlers.\\nfunc (app *BaseApp)\\n\\nAddRunTxRecoveryHandler(handlers ...RecoveryHandler) {\\n    for _, h := range handlers {\\n    app.runTxRecoveryMiddleware = newRecoveryMiddleware(h, app.runTxRecoveryMiddleware)\\n}\\n}\\n\\n// GetMaximumBlockGas gets the maximum gas from the consensus params. It panics\\n// if maximum block gas is less than negative one and returns zero if negative\\n// one.\\nfunc (app *BaseApp)\\n\\nGetMaximumBlockGas(ctx sdk.Context)\\n\\nuint64 {\\n    cp := app.GetConsensusParams(ctx)\\n    if cp == nil || cp.Block == nil {\\n    return 0\\n}\\n    maxGas := cp.Block.MaxGas\\n    switch {\\n    case maxGas < -1:\\n\\t\\tpanic(fmt.Sprintf(\\\"invalid maximum block gas: %d\\\", maxGas))\\n    case maxGas == -1:\\n\\t\\treturn 0\\n\\n\\tdefault:\\n\\t\\treturn uint64(maxGas)\\n}\\n}\\n\\nfunc (app *BaseApp)\\n\\nvalidateHeight(req abci.RequestBeginBlock)\\n\\nerror {\\n    if req.Header.Height < 1 {\\n    return fmt.Errorf(\\\"invalid height: %d\\\", req.Header.Height)\\n}\\n\\n\\t// expectedHeight holds the expected height to validate.\\n\\tvar expectedHeight int64\\n    if app.LastBlockHeight() == 0 && app.initialHeight > 1 {\\n\\t\\t// In this case, we're validating the first block of the chain (no\\n\\t\\t// previous commit). The height we're expecting is the initial height.\\n\\t\\texpectedHeight = app.initialHeight\\n}\\n\\nelse {\\n\\t\\t// This case can mean two things:\\n\\t\\t// - either there was already a previous commit in the store, in which\\n\\t\\t// case we increment the version from there,\\n\\t\\t// - or there was no previous commit, and initial version was not set,\\n\\t\\t// in which case we start at version 1.\\n\\t\\texpectedHeight = app.LastBlockHeight() + 1\\n}\\n    if req.Header.Height != expectedHeight {\\n    return fmt.Errorf(\\\"invalid height: %d; expected: %d\\\", req.Header.Height, expectedHeight)\\n}\\n\\nreturn nil\\n}\\n\\n// validateBasicTxMsgs executes basic validator calls for messages.\\nfunc validateBasicTxMsgs(msgs []sdk.Msg)\\n\\nerror {\\n    if len(msgs) == 0 {\\n    return sdkerrors.Wrap(sdkerrors.ErrInvalidRequest, \\\"must contain at least one message\\\")\\n}\\n    for _, msg := range msgs {\\n    err := msg.ValidateBasic()\\n    if err != nil {\\n    return err\\n}\\n\\t\\n}\\n\\nreturn nil\\n}\\n\\n// Returns the application's deliverState if app is in runTxModeDeliver,\\n// prepareProposalState if app is in runTxPrepareProposal, processProposalState\\n// if app is in runTxProcessProposal, and checkState otherwise.\\nfunc (app *BaseApp)\\n\\ngetState(mode runTxMode) *state {\\n    switch mode {\\n    case runTxModeDeliver:\\n\\t\\treturn app.deliverState\\n    case runTxPrepareProposal:\\n\\t\\treturn app.prepareProposalState\\n    case runTxProcessProposal:\\n\\t\\treturn app.processProposalState\\n\\tdefault:\\n\\t\\treturn app.checkState\\n}\\n}\\n\\n// retrieve the context for the tx w/ txBytes and other memoized values.\\nfunc (app *BaseApp)\\n\\ngetContextForTx(mode runTxMode, txBytes []byte)\\n\\nsdk.Context {\\n    modeState := app.getState(mode)\\n    if modeState == nil {\\n    panic(fmt.Sprintf(\\\"state is nil for mode %v\\\", mode))\\n}\\n    ctx := modeState.ctx.\\n\\t\\tWithTxBytes(txBytes).\\n\\t\\tWithVoteInfos(app.voteInfos)\\n\\nctx = ctx.WithConsensusParams(app.GetConsensusParams(ctx))\\n    if mode == runTxModeReCheck {\\n    ctx = ctx.WithIsReCheckTx(true)\\n}\\n    if mode == runTxModeSimulate {\\n    ctx, _ = ctx.CacheContext()\\n}\\n\\nreturn ctx\\n}\\n\\n// cacheTxContext returns a new context based off of the provided context with\\n// a branched multi-store.\\nfunc (app *BaseApp)\\n\\ncacheTxContext(ctx sdk.Context, txBytes []byte) (sdk.Context, sdk.CacheMultiStore) {\\n    ms := ctx.MultiStore()\\n\\t// TODO: https://github.com/cosmos/cosmos-sdk/issues/2824\\n    msCache := ms.CacheMultiStore()\\n    if msCache.TracingEnabled() {\\n    msCache = msCache.SetTracingContext(\\n\\t\\t\\tsdk.TraceContext(\\n\\t\\t\\t\\tmap[string]interface{\\n}{\\n\\t\\t\\t\\t\\t\\\"txHash\\\": fmt.Sprintf(\\\"%X\\\", tmhash.Sum(txBytes)),\\n},\\n\\t\\t\\t),\\n\\t\\t).(sdk.CacheMultiStore)\\n}\\n\\nreturn ctx.WithMultiStore(msCache), msCache\\n}\\n\\n// runTx processes a transaction within a given execution mode, encoded transaction\\n// bytes, and the decoded transaction itself. All state transitions occur through\\n// a cached Context depending on the mode provided. State only gets persisted\\n// if all messages get executed successfully and the execution mode is DeliverTx.\\n// Note, gas execution info is always returned. A reference to a Result is\\n// returned if the tx does not run out of gas and if all the messages are valid\\n// and execute successfully. An error is returned otherwise.\\nfunc (app *BaseApp)\\n\\nrunTx(mode runTxMode, txBytes []byte) (gInfo sdk.GasInfo, result *sdk.Result, anteEvents []abci.Event, priority int64, err error) {\\n\\t// NOTE: GasWanted should be returned by the AnteHandler. GasUsed is\\n\\t// determined by the GasMeter. We need access to the context to get the gas\\n\\t// meter, so we initialize upfront.\\n\\tvar gasWanted uint64\\n    ctx := app.getContextForTx(mode, txBytes)\\n    ms := ctx.MultiStore()\\n\\n\\t// only run the tx if there is block gas remaining\\n    if mode == runTxModeDeliver && ctx.BlockGasMeter().IsOutOfGas() {\\n    return gInfo, nil, nil, 0, sdkerrors.Wrap(sdkerrors.ErrOutOfGas, \\\"no block gas left to run tx\\\")\\n}\\n\\ndefer func() {\\n    if r := recover(); r != nil {\\n    recoveryMW := newOutOfGasRecoveryMiddleware(gasWanted, ctx, app.runTxRecoveryMiddleware)\\n\\nerr, result = processRecovery(r, recoveryMW), nil\\n}\\n\\ngInfo = sdk.GasInfo{\\n    GasWanted: gasWanted,\\n    GasUsed: ctx.GasMeter().GasConsumed()\\n}\\n\\t\\n}()\\n    blockGasConsumed := false\\n\\t// consumeBlockGas makes sure block gas is consumed at most once. It must happen after\\n\\t// tx processing, and must be executed even if tx processing fails. Hence, we use trick with `defer`\\n    consumeBlockGas := func() {\\n    if !blockGasConsumed {\\n    blockGasConsumed = true\\n\\t\\t\\tctx.BlockGasMeter().ConsumeGas(\\n\\t\\t\\t\\tctx.GasMeter().GasConsumedToLimit(), \\\"block gas meter\\\",\\n\\t\\t\\t)\\n}\\n\\t\\n}\\n\\n\\t// If BlockGasMeter()\\n\\npanics it will be caught by the above recover and will\\n\\t// return an error - in any case BlockGasMeter will consume gas past the limit.\\n\\t//\\n\\t// NOTE: This must exist in a separate defer function for the above recovery\\n\\t// to recover from this one.\\n    if mode == runTxModeDeliver {\\n    defer consumeBlockGas()\\n}\\n\\ntx, err := app.txDecoder(txBytes)\\n    if err != nil {\\n    return sdk.GasInfo{\\n}, nil, nil, 0, err\\n}\\n    msgs := tx.GetMsgs()\\n    if err := validateBasicTxMsgs(msgs); err != nil {\\n    return sdk.GasInfo{\\n}, nil, nil, 0, err\\n}\\n    if app.anteHandler != nil {\\n    var (\\n\\t\\t\\tanteCtx sdk.Context\\n\\t\\t\\tmsCache sdk.CacheMultiStore\\n\\t\\t)\\n\\n\\t\\t// Branch context before AnteHandler call in case it aborts.\\n\\t\\t// This is required for both CheckTx and DeliverTx.\\n\\t\\t// Ref: https://github.com/cosmos/cosmos-sdk/issues/2772\\n\\t\\t//\\n\\t\\t// NOTE: Alternatively, we could require that AnteHandler ensures that\\n\\t\\t// writes do not happen if aborted/failed.  This may have some\\n\\t\\t// performance benefits, but it'll be more difficult to get right.\\n\\t\\tanteCtx, msCache = app.cacheTxContext(ctx, txBytes)\\n\\nanteCtx = anteCtx.WithEventManager(sdk.NewEventManager())\\n\\nnewCtx, err := app.anteHandler(anteCtx, tx, mode == runTxModeSimulate)\\n    if !newCtx.IsZero() {\\n\\t\\t\\t// At this point, newCtx.MultiStore()\\n\\nis a store branch, or something else\\n\\t\\t\\t// replaced by the AnteHandler. We want the original multistore.\\n\\t\\t\\t//\\n\\t\\t\\t// Also, in the case of the tx aborting, we need to track gas consumed via\\n\\t\\t\\t// the instantiated gas meter in the AnteHandler, so we update the context\\n\\t\\t\\t// prior to returning.\\n\\t\\t\\tctx = newCtx.WithMultiStore(ms)\\n}\\n    events := ctx.EventManager().Events()\\n\\n\\t\\t// GasMeter expected to be set in AnteHandler\\n\\t\\tgasWanted = ctx.GasMeter().Limit()\\n    if err != nil {\\n    return gInfo, nil, nil, 0, err\\n}\\n\\npriority = ctx.Priority()\\n\\nmsCache.Write()\\n\\nanteEvents = events.ToABCIEvents()\\n}\\n    if mode == runTxModeCheck {\\n    err = app.mempool.Insert(ctx, tx)\\n    if err != nil {\\n    return gInfo, nil, anteEvents, priority, err\\n}\\n\\t\\n}\\n\\nelse if mode == runTxModeDeliver {\\n    err = app.mempool.Remove(tx)\\n    if err != nil && !errors.Is(err, mempool.ErrTxNotFound) {\\n    return gInfo, nil, anteEvents, priority,\\n\\t\\t\\t\\tfmt.Errorf(\\\"failed to remove tx from mempool: %w\\\", err)\\n}\\n\\t\\n}\\n\\n\\t// Create a new Context based off of the existing Context with a MultiStore branch\\n\\t// in case message processing fails. At this point, the MultiStore\\n\\t// is a branch of a branch.\\n\\trunMsgCtx, msCache := app.cacheTxContext(ctx, txBytes)\\n\\n\\t// Attempt to execute all messages and only update state if all messages pass\\n\\t// and we're in DeliverTx. Note, runMsgs will never return a reference to a\\n\\t// Result if any single message fails or does not have a registered Handler.\\n\\tresult, err = app.runMsgs(runMsgCtx, msgs, mode)\\n    if err == nil {\\n\\n\\t\\t// Run optional postHandlers.\\n\\t\\t//\\n\\t\\t// Note: If the postHandler fails, we also revert the runMsgs state.\\n    if app.postHandler != nil {\\n\\t\\t\\t// The runMsgCtx context currently contains events emitted by the ante handler.\\n\\t\\t\\t// We clear this to correctly order events without duplicates.\\n\\t\\t\\t// Note that the state is still preserved.\\n    postCtx := runMsgCtx.WithEventManager(sdk.NewEventManager())\\n\\nnewCtx, err := app.postHandler(postCtx, tx, mode == runTxModeSimulate)\\n    if err != nil {\\n    return gInfo, nil, anteEvents, priority, err\\n}\\n\\nresult.Events = append(result.Events, newCtx.EventManager().ABCIEvents()...)\\n}\\n    if mode == runTxModeDeliver {\\n\\t\\t\\t// When block gas exceeds, it'll panic and won't commit the cached store.\\n\\t\\t\\tconsumeBlockGas()\\n\\nmsCache.Write()\\n}\\n    if len(anteEvents) > 0 && (mode == runTxModeDeliver || mode == runTxModeSimulate) {\\n\\t\\t\\t// append the events in the order of occurrence\\n\\t\\t\\tresult.Events = append(anteEvents, result.Events...)\\n}\\n\\t\\n}\\n\\nreturn gInfo, result, anteEvents, priority, err\\n}\\n\\n// runMsgs iterates through a list of messages and executes them with the provided\\n// Context and execution mode. Messages will only be executed during simulation\\n// and DeliverTx. An error is returned if any single message fails or if a\\n// Handler does not exist for a given message route. Otherwise, a reference to a\\n// Result is returned. The caller must not commit state if an error is returned.\\nfunc (app *BaseApp)\\n\\nrunMsgs(ctx sdk.Context, msgs []sdk.Msg, mode runTxMode) (*sdk.Result, error) {\\n    msgLogs := make(sdk.ABCIMessageLogs, 0, len(msgs))\\n    events := sdk.EmptyEvents()\\n\\nvar msgResponses []*codectypes.Any\\n\\n\\t// NOTE: GasWanted is determined by the AnteHandler and GasUsed by the GasMeter.\\n    for i, msg := range msgs {\\n    if mode != runTxModeDeliver && mode != runTxModeSimulate {\\n    break\\n}\\n    handler := app.msgServiceRouter.Handler(msg)\\n    if handler == nil {\\n    return nil, sdkerrors.Wrapf(sdkerrors.ErrUnknownRequest, \\\"can't route message %+v\\\", msg)\\n}\\n\\n\\t\\t// ADR 031 request type routing\\n\\t\\tmsgResult, err := handler(ctx, msg)\\n    if err != nil {\\n    return nil, sdkerrors.Wrapf(err, \\\"failed to execute message; message index: %d\\\", i)\\n}\\n\\n\\t\\t// create message events\\n    msgEvents := createEvents(msgResult.GetEvents(), msg)\\n\\n\\t\\t// append message events, data and logs\\n\\t\\t//\\n\\t\\t// Note: Each message result's data must be length-prefixed in order to\\n\\t\\t// separate each result.\\n\\t\\tevents = events.AppendEvents(msgEvents)\\n\\n\\t\\t// Each individual sdk.Result that went through the MsgServiceRouter\\n\\t\\t// (which should represent 99% of the Msgs now, since everyone should\\n\\t\\t// be using protobuf Msgs)\\n\\nhas exactly one Msg response, set inside\\n\\t\\t// `WrapServiceResult`. We take that Msg response, and aggregate it\\n\\t\\t// into an array.\\n    if len(msgResult.MsgResponses) > 0 {\\n    msgResponse := msgResult.MsgResponses[0]\\n    if msgResponse == nil {\\n    return nil, sdkerrors.ErrLogic.Wrapf(\\\"got nil Msg response at index %d for msg %s\\\", i, sdk.MsgTypeURL(msg))\\n}\\n\\nmsgResponses = append(msgResponses, msgResponse)\\n}\\n\\nmsgLogs = append(msgLogs, sdk.NewABCIMessageLog(uint32(i), msgResult.Log, msgEvents))\\n}\\n\\ndata, err := makeABCIData(msgResponses)\\n    if err != nil {\\n    return nil, sdkerrors.Wrap(err, \\\"failed to marshal tx data\\\")\\n}\\n\\nreturn &sdk.Result{\\n    Data:         data,\\n    Log:          strings.TrimSpace(msgLogs.String()),\\n    Events:       events.ToABCIEvents(),\\n    MsgResponses: msgResponses,\\n}, nil\\n}\\n\\n// makeABCIData generates the Data field to be sent to ABCI Check/DeliverTx.\\nfunc makeABCIData(msgResponses []*codectypes.Any) ([]byte, error) {\\n    return proto.Marshal(&sdk.TxMsgData{\\n    MsgResponses: msgResponses\\n})\\n}\\n\\nfunc createEvents(events sdk.Events, msg sdk.Msg)\\n\\nsdk.Events {\\n    eventMsgName := sdk.MsgTypeURL(msg)\\n    msgEvent := sdk.NewEvent(sdk.EventTypeMessage, sdk.NewAttribute(sdk.AttributeKeyAction, eventMsgName))\\n\\n\\t// we set the signer attribute as the sender\\n    if len(msg.GetSigners()) > 0 && !msg.GetSigners()[0].Empty() {\\n    msgEvent = msgEvent.AppendAttributes(sdk.NewAttribute(sdk.AttributeKeySender, msg.GetSigners()[0].String()))\\n}\\n\\n\\t// verify that events have no module attribute set\\n    if _, found := events.GetAttributes(sdk.AttributeKeyModule); !found {\\n\\t\\t// here we assume that routes module name is the second element of the route\\n\\t\\t// e.g. \\\"cosmos.bank.v1beta1.MsgSend\\\" => \\\"bank\\\"\\n    moduleName := strings.Split(eventMsgName, \\\".\\\")\\n    if len(moduleName) > 1 {\\n    msgEvent = msgEvent.AppendAttributes(sdk.NewAttribute(sdk.AttributeKeyModule, moduleName[1]))\\n}\\n\\t\\n}\\n\\nreturn sdk.Events{\\n    msgEvent\\n}.AppendEvents(events)\\n}\\n\\n// DefaultPrepareProposal returns the default implementation for processing an\\n// ABCI proposal. The application's mempool is enumerated and all valid\\n// transactions are added to the proposal. Transactions are valid if they:\\n//\\n// 1)\\n\\nSuccessfully encode to bytes.\\n// 2)\\n\\nAre valid (i.e. pass runTx, AnteHandler only).\\n//\\n// Enumeration is halted once RequestPrepareProposal.MaxBytes of transactions is\\n// reached or the mempool is exhausted.\\n//\\n// Note:\\n//\\n// - Step (2)\\n\\nis identical to the validation step performed in\\n// DefaultProcessProposal. It is very important that the same validation logic\\n// is used in both steps, and applications must ensure that this is the case in\\n// non-default handlers.\\n//\\n// - If no mempool is set or if the mempool is a no-op mempool, the transactions\\n// requested from Tendermint will simply be returned, which, by default, are in\\n// FIFO order.\\nfunc (app *BaseApp)\\n\\nDefaultPrepareProposal()\\n\\nsdk.PrepareProposalHandler {\\n    return func(ctx sdk.Context, req abci.RequestPrepareProposal)\\n\\nabci.ResponsePrepareProposal {\\n\\t\\t// If the mempool is nil or a no-op mempool, we simply return the transactions\\n\\t\\t// requested from Tendermint, which, by default, should be in FIFO order.\\n\\t\\t_, isNoOp := app.mempool.(mempool.NoOpMempool)\\n    if app.mempool == nil || isNoOp {\\n    return abci.ResponsePrepareProposal{\\n    Txs: req.Txs\\n}\\n\\t\\n}\\n\\nvar (\\n\\t\\t\\ttxsBytes  [][]byte\\n\\t\\t\\tbyteCount int64\\n\\t\\t)\\n    iterator := app.mempool.Select(ctx, req.Txs)\\n    for iterator != nil {\\n    memTx := iterator.Tx()\\n\\nbz, err := app.txEncoder(memTx)\\n    if err != nil {\\n    panic(err)\\n}\\n    txSize := int64(len(bz))\\n\\n\\t\\t\\t// NOTE: Since runTx was already executed in CheckTx, which calls\\n\\t\\t\\t// mempool.Insert, ideally everything in the pool should be valid. But\\n\\t\\t\\t// some mempool implementations may insert invalid txs, so we check again.\\n\\t\\t\\t_, _, _, _, err = app.runTx(runTxPrepareProposal, bz)\\n    if err != nil {\\n    err := app.mempool.Remove(memTx)\\n    if err != nil && !errors.Is(err, mempool.ErrTxNotFound) {\\n    panic(err)\\n}\\n\\niterator = iterator.Next()\\n\\ncontinue\\n}\\n\\nelse if byteCount += txSize; byteCount <= req.MaxTxBytes {\\n    txsBytes = append(txsBytes, bz)\\n}\\n\\nelse {\\n    break\\n}\\n\\niterator = iterator.Next()\\n}\\n\\nreturn abci.ResponsePrepareProposal{\\n    Txs: txsBytes\\n}\\n\\t\\n}\\n}\\n\\n// DefaultProcessProposal returns the default implementation for processing an ABCI proposal.\\n// Every transaction in the proposal must pass 2 conditions:\\n//\\n// 1. The transaction bytes must decode to a valid transaction.\\n// 2. The transaction must be valid (i.e. pass runTx, AnteHandler only)\\n//\\n// If any transaction fails to pass either condition, the proposal is rejected.  Note that step (2)\\n\\nis identical to the\\n// validation step performed in DefaultPrepareProposal.  It is very important that the same validation logic is used\\n// in both steps, and applications must ensure that this is the case in non-default handlers.\\nfunc (app *BaseApp)\\n\\nDefaultProcessProposal()\\n\\nsdk.ProcessProposalHandler {\\n    return func(ctx sdk.Context, req abci.RequestProcessProposal)\\n\\nabci.ResponseProcessProposal {\\n    for _, txBytes := range req.Txs {\\n\\t\\t\\t_, err := app.txDecoder(txBytes)\\n    if err != nil {\\n    return abci.ResponseProcessProposal{\\n    Status: abci.ResponseProcessProposal_REJECT\\n}\\n\\t\\n}\\n\\n\\t\\t\\t_, _, _, _, err = app.runTx(runTxProcessProposal, txBytes)\\n    if err != nil {\\n    return abci.ResponseProcessProposal{\\n    Status: abci.ResponseProcessProposal_REJECT\\n}\\n\\t\\n}\\n\\t\\n}\\n\\nreturn abci.ResponseProcessProposal{\\n    Status: abci.ResponseProcessProposal_ACCEPT\\n}\\n\\t\\n}\\n}\\n\\n// NoOpPrepareProposal defines a no-op PrepareProposal handler. It will always\\n// return the transactions sent by the client's request.\\nfunc NoOpPrepareProposal()\\n\\nsdk.PrepareProposalHandler {\\n    return func(_ sdk.Context, req abci.RequestPrepareProposal)\\n\\nabci.ResponsePrepareProposal {\\n    return abci.ResponsePrepareProposal{\\n    Txs: req.Txs\\n}\\n\\t\\n}\\n}\\n\\n// NoOpProcessProposal defines a no-op ProcessProposal Handler. It will always\\n// return ACCEPT.\\nfunc NoOpProcessProposal()\\n\\nsdk.ProcessProposalHandler {\\n    return func(_ sdk.Context, _ abci.RequestProcessProposal)\\n\\nabci.ResponseProcessProposal {\\n    return abci.ResponseProcessProposal{\\n    Status: abci.ResponseProcessProposal_ACCEPT\\n}\\n\\t\\n}\\n}\\n\\n\"]",
            "additional_kwargs": {},
            "response_metadata": {},
            "type": "tool",
            "name": "SearchCosmosDocumentation",
            "id": "856f7200-e3aa-4dc3-a94b-53efa7f3c6e3",
            "tool_call_id": "call_bh3EI9oPLvikA4lZr7G6Pc9D",
            "artifact": null,
            "status": "success"
        },
        {
            "content": "",
            "additional_kwargs": {
                "tool_calls": [
                    {
                        "id": "call_9Bm0IvDdntoEAdmRJzB4n2Yx",
                        "function": {
                            "arguments": "{\"query\": \"eth_newPendingTransactionFilter cosmos\"}",
                            "name": "SearchCosmosDocumentation"
                        },
                        "type": "function"
                    }
                ],
                "refusal": null
            },
            "response_metadata": {
                "token_usage": {
                    "completion_tokens": 351,
                    "prompt_tokens": 41859,
                    "total_tokens": 42210,
                    "completion_tokens_details": {
                        "accepted_prediction_tokens": 0,
                        "audio_tokens": 0,
                        "reasoning_tokens": 320,
                        "rejected_prediction_tokens": 0
                    },
                    "prompt_tokens_details": {
                        "audio_tokens": 0,
                        "cached_tokens": 0
                    }
                },
                "model_name": "o3-2025-04-16",
                "system_fingerprint": null,
                "id": "chatcmpl-CPw0AcKxZIuE5SJzjn2rszcATJiOp",
                "service_tier": "default",
                "finish_reason": "tool_calls",
                "logprobs": null
            },
            "type": "ai",
            "name": null,
            "id": "run--b7b23b02-2505-41b7-b793-0846f1480e57-0",
            "example": false,
            "tool_calls": [
                {
                    "name": "SearchCosmosDocumentation",
                    "args": {
                        "query": "eth_newPendingTransactionFilter cosmos"
                    },
                    "id": "call_9Bm0IvDdntoEAdmRJzB4n2Yx",
                    "type": "tool_call"
                }
            ],
            "invalid_tool_calls": [],
            "usage_metadata": {
                "input_tokens": 41859,
                "output_tokens": 351,
                "total_tokens": 42210,
                "input_token_details": {
                    "audio": 0,
                    "cache_read": 0
                },
                "output_token_details": {
                    "audio": 0,
                    "reasoning": 320
                }
            }
        },
        {
            "content": "[\"Title: eth_newPendingTransactionFilter\\nLink: https://evm.cosmos.network/docs/evm/v0.4.x/api-reference/ethereum-json-rpc/methods\\nContent: Creates a filter in the node, to notify when new pending transactions arrive.\\n\\nCreates a filter in the node, to notify when new pending transactions arrive. // Request\\ncurl -X POST --data '{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"method\\\":\\\"eth_newPendingTransactionFilter\\\",\\\"params\\\":[],\\\"id\\\":1}' -H \\\"Content-Type: application/json\\\" http://localhost:8545\\n// Result\\n{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"id\\\":1,\\\"result\\\":\\\"0x9daacfb5893d946997d3801ea18e9902\\\"}\\n\\neth_newBlockFilter\\nCreates a filter in the node, to notify when a new block arrives.\\n\\n\", \"Title: eth_newPendingTransactionFilter\\nLink: https://evm.cosmos.network/docs/evm/next/api-reference/ethereum-json-rpc/methods\\nContent: Creates a filter in the node, to notify when new pending transactions arrive.\\n\\nCreates a filter in the node, to notify when new pending transactions arrive. // Request\\ncurl -X POST --data '{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"method\\\":\\\"eth_newPendingTransactionFilter\\\",\\\"params\\\":[],\\\"id\\\":1}' -H \\\"Content-Type: application/json\\\" http://localhost:8545\\n// Result\\n{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"id\\\":1,\\\"result\\\":\\\"0x9daacfb5893d946997d3801ea18e9902\\\"}\\n\\neth_newBlockFilter\\nCreates a filter in the node, to notify when a new block arrives.\\n\\n\", \"Title: Filters\u200b\\nLink: https://evm.cosmos.network/docs/evm/v0.4.x/api-reference/ethereum-json-rpc/index\\nContent: Cosmos EVM also supports the Ethereum JSON-RPC filters calls to subscribe to state logs , blocks or pending transactions changes. Under the hood, it uses the CometBFT RPC client's event system to process subscriptions that are then formatted to Ethereum-compatible events. Then you can check if the state changes with the eth_getFilterChanges call:\\n\\nCosmos EVM also supports the Ethereum JSON-RPC filters calls to subscribe to state logs , blocks or pending transactions changes. Under the hood, it uses the CometBFT RPC client's event system to process subscriptions that are then formatted to Ethereum-compatible events. Then you can check if the state changes with the eth_getFilterChanges call: curl -X POST --data '{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"method\\\":\\\"eth_getFilterChanges\\\",\\\"params\\\":[\\\"0x3503de5f0c766c68f78a03a3b05036a5\\\"],\\\"id\\\":1}' -H \\\"Content-Type: application/json\\\" http://localhost:8545{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"id\\\":1,\\\"result\\\":[\\\"0x7d44dceff05d5963b5bc81df7e9f79b27e777b0a03a6feca09f3447b99c6fa71\\\",\\\"0x3961e4050c27ce0145d375255b3cb829a5b4e795ac475c05a219b3733723d376\\\",\\\"0xd7a497f95167d63e6feca70f344d9f6e843d097b62729b8f43bdcd5febf142ab\\\",\\\"0x55d80a4ba6ef54f2a8c0b99589d017b810ed13a1fda6a111e1b87725bc8ceb0e\\\",\\\"0x9e8b92c17280dd05f2562af6eea3285181c562ebf41fc758527d4c30364bcbc4\\\",\\\"0x7353a4b9d6b35c9eafeccaf9722dd293c46ae2ffd4093b2367165c3620a0c7c9\\\",\\\"0x026d91bda61c8789c59632c349b38fd7e7557e6b598b94879654a644cfa75f30\\\",\\\"0x73e3245d4ddc3bba48fa67633f9993c6e11728a36401fa1206437f8be94ef1d3\\\"]}\\n\\nEthereum JSON-RPC\\nJSON-RPC is a stateless, light-weight remote procedure call (RPC) protocol. It defines several data structures and the rules around their processing. JSON-RPC is provided on multiple transports. Cosmos EVM supports JSON-RPC over HTTP and WebSocket. Transports must be enabled through command-line flags or through the app.toml configuration file. It uses JSON ( RFC 4627 ) as data format. More on Ethereum JSON-RPC: EthWiki JSON-RPC API Geth JSON-RPC Server Ethereum's PubSub JSON-RPC API Cosmos-Specific Extensions : These methods are unique to Cosmos EVM and not found in standard Ethereum: Additional Eth Methods: eth_getTransactionLogs - Returns logs for a specific transaction eth_getBlockReceipts - Returns all receipts for a given block Extended Debug Methods: debug_freeOSMemory - Forces garbage collection debug_setGCPercent - Sets garbage collection percentage debug_memStats - Returns detailed memory statistics debug_setBlockProfileRate - Sets block profiling rate debug_writeBlockProfile - Writes block profile to file debug_writeMemProfile - Writes memory profile to file debug_writeMutexProfile - Writes mutex contention profile to file Notable Unsupported Methods : The following standard Ethereum methods are not implemented: eth_fillTransaction - Transaction filling utility All debug_getRaw* methods - Raw data access not implemented eth_subscribe syncing events - Only newHeads, logs, and newPendingTransactions work All trace_* methods - Parity/OpenEthereum trace namespace All engine_* methods - Post-merge Engine API See the methods page for complete details.\\n\\n\", \"Title: Filters\u200b\\nLink: https://evm.cosmos.network/docs/evm/next/api-reference/ethereum-json-rpc/index\\nContent: Cosmos EVM also supports the Ethereum JSON-RPC filters calls to subscribe to state logs , blocks or pending transactions changes. Under the hood, it uses the CometBFT RPC client's event system to process subscriptions that are then formatted to Ethereum-compatible events. Then you can check if the state changes with the eth_getFilterChanges call:\\n\\nCosmos EVM also supports the Ethereum JSON-RPC filters calls to subscribe to state logs , blocks or pending transactions changes. Under the hood, it uses the CometBFT RPC client's event system to process subscriptions that are then formatted to Ethereum-compatible events. Then you can check if the state changes with the eth_getFilterChanges call: curl -X POST --data '{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"method\\\":\\\"eth_getFilterChanges\\\",\\\"params\\\":[\\\"0x3503de5f0c766c68f78a03a3b05036a5\\\"],\\\"id\\\":1}' -H \\\"Content-Type: application/json\\\" http://localhost:8545{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"id\\\":1,\\\"result\\\":[\\\"0x7d44dceff05d5963b5bc81df7e9f79b27e777b0a03a6feca09f3447b99c6fa71\\\",\\\"0x3961e4050c27ce0145d375255b3cb829a5b4e795ac475c05a219b3733723d376\\\",\\\"0xd7a497f95167d63e6feca70f344d9f6e843d097b62729b8f43bdcd5febf142ab\\\",\\\"0x55d80a4ba6ef54f2a8c0b99589d017b810ed13a1fda6a111e1b87725bc8ceb0e\\\",\\\"0x9e8b92c17280dd05f2562af6eea3285181c562ebf41fc758527d4c30364bcbc4\\\",\\\"0x7353a4b9d6b35c9eafeccaf9722dd293c46ae2ffd4093b2367165c3620a0c7c9\\\",\\\"0x026d91bda61c8789c59632c349b38fd7e7557e6b598b94879654a644cfa75f30\\\",\\\"0x73e3245d4ddc3bba48fa67633f9993c6e11728a36401fa1206437f8be94ef1d3\\\"]}\\n\\nEthereum JSON-RPC\\nJSON-RPC is a stateless, light-weight remote procedure call (RPC) protocol. It defines several data structures and the rules around their processing. JSON-RPC is provided on multiple transports. Cosmos EVM supports JSON-RPC over HTTP and WebSocket. Transports must be enabled through command-line flags or through the app.toml configuration file. It uses JSON ( RFC 4627 ) as data format. More on Ethereum JSON-RPC: EthWiki JSON-RPC API Geth JSON-RPC Server Ethereum's PubSub JSON-RPC API Cosmos-Specific Extensions : These methods are unique to Cosmos EVM and not found in standard Ethereum: Additional Eth Methods: eth_getTransactionLogs - Returns logs for a specific transaction eth_getBlockReceipts - Returns all receipts for a given block Extended Debug Methods: debug_freeOSMemory - Forces garbage collection debug_setGCPercent - Sets garbage collection percentage debug_memStats - Returns detailed memory statistics debug_setBlockProfileRate - Sets block profiling rate debug_writeBlockProfile - Writes block profile to file debug_writeMemProfile - Writes memory profile to file debug_writeMutexProfile - Writes mutex contention profile to file Notable Unsupported Methods : The following standard Ethereum methods are not implemented: eth_fillTransaction - Transaction filling utility All debug_getRaw* methods - Raw data access not implemented eth_subscribe syncing events - Only newHeads, logs, and newPendingTransactions work All trace_* methods - Parity/OpenEthereum trace namespace All engine_* methods - Post-merge Engine API See the methods page for complete details.\\n\\n\", \"Title: What is the Cosmos SDK\\nLink: https://evm.cosmos.network/docs/sdk/v0.47/learn/intro/overview\\nContent: The Cosmos SDK is an open-source framework for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains. We envision the Cosmos SDK as the npm-like framework to build secure blockchain applications on top of CometBFT . SDK-based blockchains are built out of composable modules , most of which are open-source and readily available for any developers to use. Anyone can create a module for the Cosmos SDK, and integrating already-built modules is as simple as importing them into your blockchain application. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model.\\n\\nWhat is the Cosmos SDK\\nThe Cosmos SDK is an open-source framework for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains. We envision the Cosmos SDK as the npm-like framework to build secure blockchain applications on top of CometBFT . SDK-based blockchains are built out of composable modules , most of which are open-source and readily available for any developers to use. Anyone can create a module for the Cosmos SDK, and integrating already-built modules is as simple as importing them into your blockchain application. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model.\\n\\nWhy the Cosmos SDK\\nThe Cosmos SDK is the most advanced framework for building custom application-specific blockchains today. Here are a few reasons why you might want to consider building your decentralized application with the Cosmos SDK: The default consensus engine available within the Cosmos SDK is CometBFT . CometBFT is the most (and only) mature BFT consensus engine in existence. It is widely used across the industry and is considered the gold standard consensus engine for building Proof-of-Stake systems. The Cosmos SDK is open-source and designed to make it easy to build blockchains out of composable modules . As the ecosystem of open-source Cosmos SDK modules grows, it will become increasingly easier to build complex decentralized platforms with it. The Cosmos SDK is inspired by capabilities-based security, and informed by years of wrestling with blockchain state-machines. This makes the Cosmos SDK a very secure environment to build blockchains. Most importantly, the Cosmos SDK has already been used to build many application-specific blockchains that are already in production. Among others, we can cite Cosmos Hub , IRIS Hub , Binance Chain , Terra or Kava . Many more are building on the Cosmos SDK.\\n\\n\", \"Title: What is the Cosmos SDK\\nLink: https://evm.cosmos.network/docs/sdk/v0.50/learn/intro/overview\\nContent: The Cosmos SDK is an open-source toolkit for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains.\\nWe further this modular approach by allowing developers to plug and play with different consensus engines this can range from the CometBFT or Rollkit. SDK-based blockchains have the choice to use the predefined modules or to build their own modules. What this means is that developers can build a blockchain that is tailored to their specific use case, without having to worry about the low-level details of building a blockchain from scratch. Predefined modules include staking, governance, and token issuance, among others. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model. How you can look at this is if we imagine that the SDK is like a lego kit. You can choose to build the basic house from the instructions or you can choose to modify your house and add more floors, more doors, more windows. The choice is yours.\\n\\nWhat is the Cosmos SDK\\nThe Cosmos SDK is an open-source toolkit for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains.\\nWe further this modular approach by allowing developers to plug and play with different consensus engines this can range from the CometBFT or Rollkit. SDK-based blockchains have the choice to use the predefined modules or to build their own modules. What this means is that developers can build a blockchain that is tailored to their specific use case, without having to worry about the low-level details of building a blockchain from scratch. Predefined modules include staking, governance, and token issuance, among others. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model. How you can look at this is if we imagine that the SDK is like a lego kit. You can choose to build the basic house from the instructions or you can choose to modify your house and add more floors, more doors, more windows. The choice is yours.\\n\\nWhy the Cosmos SDK\\nThe Cosmos SDK is the most advanced framework for building custom modular application-specific blockchains today. Here are a few reasons why you might want to consider building your decentralized application with the Cosmos SDK: It allows you to plug and play and customize your consensus layer. As above you can use Rollkit and Celestia as your consensus and data availability layer. This offers a lot of flexibility and customisation. Previously the default consensus engine available within the Cosmos SDK is CometBFT . CometBFT is the most (and only) mature BFT consensus engine in existence. It is widely used across the industry and is considered the gold standard consensus engine for building Proof-of-Stake systems. The Cosmos SDK is open-source and designed to make it easy to build blockchains out of composable modules . As the ecosystem of open-source Cosmos SDK modules grows, it will become increasingly easier to build complex decentralized platforms with it. The Cosmos SDK is inspired by capabilities-based security, and informed by years of wrestling with blockchain state-machines. This makes the Cosmos SDK a very secure environment to build blockchains. Most importantly, the Cosmos SDK has already been used to build many application-specific blockchains that are already in production. Among others, we can cite Cosmos Hub , IRIS Hub , Binance Chain , Terra or Kava . Many more are building on the Cosmos SDK.\\n\\n\", \"Title: What is the Cosmos SDK\\nLink: https://evm.cosmos.network/docs/sdk/v0.53/learn/intro/overview\\nContent: The Cosmos SDK is an open-source toolkit for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains.\\nWe further this modular approach by allowing developers to plug and play with different consensus engines this can range from the CometBFT or Rollkit. SDK-based blockchains have the choice to use the predefined modules or to build their own modules. What this means is that developers can build a blockchain that is tailored to their specific use case, without having to worry about the low-level details of building a blockchain from scratch. Predefined modules include staking, governance, and token issuance, among others. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model. How you can look at this is if we imagine that the SDK is like a lego kit. You can choose to build the basic house from the instructions or you can choose to modify your house and add more floors, more doors, more windows. The choice is yours.\\n\\nWhat is the Cosmos SDK\\nThe Cosmos SDK is an open-source toolkit for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains.\\nWe further this modular approach by allowing developers to plug and play with different consensus engines this can range from the CometBFT or Rollkit. SDK-based blockchains have the choice to use the predefined modules or to build their own modules. What this means is that developers can build a blockchain that is tailored to their specific use case, without having to worry about the low-level details of building a blockchain from scratch. Predefined modules include staking, governance, and token issuance, among others. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model. How you can look at this is if we imagine that the SDK is like a lego kit. You can choose to build the basic house from the instructions or you can choose to modify your house and add more floors, more doors, more windows. The choice is yours.\\n\\nWhy the Cosmos SDK\\nThe Cosmos SDK is the most advanced framework for building custom modular application-specific blockchains today. Here are a few reasons why you might want to consider building your decentralized application with the Cosmos SDK: It allows you to plug and play and customize your consensus layer. As above you can use Rollkit and Celestia as your consensus and data availability layer. This offers a lot of flexibility and customisation. Previously the default consensus engine available within the Cosmos SDK is CometBFT . CometBFT is the most (and only) mature BFT consensus engine in existence. It is widely used across the industry and is considered the gold standard consensus engine for building Proof-of-Stake systems. The Cosmos SDK is open-source and designed to make it easy to build blockchains out of composable modules . As the ecosystem of open-source Cosmos SDK modules grows, it will become increasingly easier to build complex decentralized platforms with it. The Cosmos SDK is inspired by capabilities-based security, and informed by years of wrestling with blockchain state-machines. This makes the Cosmos SDK a very secure environment to build blockchains. Most importantly, the Cosmos SDK has already been used to build many application-specific blockchains that are already in production. Among others, we can cite Cosmos Hub , IRIS Hub , Binance Chain , Terra or Kava . Many more are building on the Cosmos SDK.\\n\\n\", \"Title: Main Components of the Cosmos SDK\\nLink: https://evm.cosmos.network/docs/sdk/v0.50/learn/intro/sdk-design\\nContent: The Cosmos SDK is a framework that facilitates the development of secure state-machines on top of CometBFT. At its core, the Cosmos SDK is a boilerplate implementation of the ABCI in Golang. It comes with a multistore to persist data and a router to handle transactions. Here is a simplified view of how transactions are handled by an application built on top of the Cosmos SDK when transferred from CometBFT via DeliverTx: Decode transactions received from the CometBFT consensus engine (remember that CometBFT only deals with []bytes ). Extract messages from transactions and do basic sanity checks. Route each message to the appropriate module so that it can be processed. Commit state changes.\\n\\nMain Components of the Cosmos SDK\\nThe Cosmos SDK is a framework that facilitates the development of secure state-machines on top of CometBFT. At its core, the Cosmos SDK is a boilerplate implementation of the ABCI in Golang. It comes with a multistore to persist data and a router to handle transactions. Here is a simplified view of how transactions are handled by an application built on top of the Cosmos SDK when transferred from CometBFT via DeliverTx: Decode transactions received from the CometBFT consensus engine (remember that CometBFT only deals with []bytes ). Extract messages from transactions and do basic sanity checks. Route each message to the appropriate module so that it can be processed. Commit state changes.\\n\\nModules\\nThe power of the Cosmos SDK lies in its modularity. Cosmos SDK applications are built by aggregating a collection of interoperable modules. Each module defines a subset of the state and contains its own message/transaction processor, while the Cosmos SDK is responsible for routing each message to its respective module. Here is a simplified view of how a transaction is processed by the application of each full-node when it is received in a valid block: Each module can be seen as a little state-machine. Developers need to define the subset of the state handled by the module, as well as custom message types that modify the state ( Note: messages are extracted from transactions by baseapp ). In general, each module declares its own KVStore in the multistore to persist the subset of the state it defines. Most developers will need to access other 3rd party modules when building their own modules. Given that the Cosmos SDK is an open framework, some of the modules may be malicious, which means there is a need for security principles to reason about inter-module interactions. These principles are based on object-capabilities . In practice, this means that instead of having each module keep an access control list for other modules, each module implements special objects called keepers that can be passed to other modules to grant a pre-defined set of capabilities. Cosmos SDK modules are defined in the x/ folder of the Cosmos SDK. Some core modules include: x/auth : Used to manage accounts and signatures. x/bank : Used to enable tokens and token transfers. x/staking + x/slashing : Used to build Proof-Of-Stake blockchains. In addition to the already existing modules in x/ , that anyone can use in their app, the Cosmos SDK lets you build your own custom modules. You can check an example of that in the tutorial.\\n\\n\", \"Title: Main Components of the Cosmos SDK\\nLink: https://evm.cosmos.network/docs/sdk/v0.47/learn/intro/sdk-design\\nContent: The Cosmos SDK is a framework that facilitates the development of secure state-machines on top of CometBFT. At its core, the Cosmos SDK is a boilerplate implementation of the ABCI in Golang. It comes with a multistore to persist data and a router to handle transactions. Here is a simplified view of how transactions are handled by an application built on top of the Cosmos SDK when transferred from CometBFT via DeliverTx: Decode transactions received from the CometBFT consensus engine (remember that CometBFT only deals with []bytes ). Extract messages from transactions and do basic sanity checks. Route each message to the appropriate module so that it can be processed. Commit state changes.\\n\\nMain Components of the Cosmos SDK\\nThe Cosmos SDK is a framework that facilitates the development of secure state-machines on top of CometBFT. At its core, the Cosmos SDK is a boilerplate implementation of the ABCI in Golang. It comes with a multistore to persist data and a router to handle transactions. Here is a simplified view of how transactions are handled by an application built on top of the Cosmos SDK when transferred from CometBFT via DeliverTx: Decode transactions received from the CometBFT consensus engine (remember that CometBFT only deals with []bytes ). Extract messages from transactions and do basic sanity checks. Route each message to the appropriate module so that it can be processed. Commit state changes.\\n\\nbaseapp\\nbaseapp is the boilerplate implementation of a Cosmos SDK application. It comes with an implementation of the ABCI to handle the connection with the underlying consensus engine. Typically, a Cosmos SDK application extends baseapp by embedding it in app.go. Here is an example of this from simapp , the Cosmos SDK demonstration app: //go:build app_v1\\n\\npackage simapp\\n\\nimport (\\n    \\n\\t\\\"encoding/json\\\"\\n    \\\"io\\\"\\n    \\\"os\\\"\\n    \\\"path/filepath\\\"\\n\\n\\tautocliv1 \\\"cosmossdk.io/api/cosmos/autocli/v1\\\"\\n\\treflectionv1 \\\"cosmossdk.io/api/cosmos/reflection/v1\\\"\\n    \\\"github.com/spf13/cast\\\"\\n\\tabci \\\"github.com/tendermint/tendermint/abci/types\\\"\\n    \\\"github.com/tendermint/tendermint/libs/log\\\"\\n\\tdbm \\\"github.com/tendermint/tm-db\\\"\\n\\n\\tsimappparams \\\"cosmossdk.io/simapp/params\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/baseapp\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/flags\\\"\\n\\tnodeservice \\\"github.com/cosmos/cosmos-sdk/client/grpc/node\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/client/grpc/tmservice\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/codec\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/codec/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/runtime\\\"\\n\\truntimeservices \\\"github.com/cosmos/cosmos-sdk/runtime/services\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/server\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/server/api\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/server/config\\\"\\n\\tservertypes \\\"github.com/cosmos/cosmos-sdk/server/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/std\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/store/streaming\\\"\\n\\tstoretypes \\\"github.com/cosmos/cosmos-sdk/store/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/testutil/testdata_pulsar\\\"\\n\\tsdk \\\"github.com/cosmos/cosmos-sdk/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/types/module\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/version\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/auth\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/auth/ante\\\"\\n\\tauthkeeper \\\"github.com/cosmos/cosmos-sdk/x/auth/keeper\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/auth/posthandler\\\"\\n\\tauthsims \\\"github.com/cosmos/cosmos-sdk/x/auth/simulation\\\"\\n\\tauthtx \\\"github.com/cosmos/cosmos-sdk/x/auth/tx\\\"\\n\\tauthtypes \\\"github.com/cosmos/cosmos-sdk/x/auth/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/auth/vesting\\\"\\n\\tvestingtypes \\\"github.com/cosmos/cosmos-sdk/x/auth/vesting/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/authz\\\"\\n\\tauthzkeeper \\\"github.com/cosmos/cosmos-sdk/x/authz/keeper\\\"\\n\\tauthzmodule \\\"github.com/cosmos/cosmos-sdk/x/authz/module\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/bank\\\"\\n\\tbankkeeper \\\"github.com/cosmos/cosmos-sdk/x/bank/keeper\\\"\\n\\tbanktypes \\\"github.com/cosmos/cosmos-sdk/x/bank/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/capability\\\"\\n\\tcapabilitykeeper \\\"github.com/cosmos/cosmos-sdk/x/capability/keeper\\\"\\n\\tcapabilitytypes \\\"github.com/cosmos/cosmos-sdk/x/capability/types\\\"\\n\\tconsensus \\\"github.com/cosmos/cosmos-sdk/x/consensus\\\"\\n\\tconsensusparamkeeper \\\"github.com/cosmos/cosmos-sdk/x/consensus/keeper\\\"\\n\\tconsensusparamtypes \\\"github.com/cosmos/cosmos-sdk/x/consensus/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/crisis\\\"\\n\\tcrisiskeeper \\\"github.com/cosmos/cosmos-sdk/x/crisis/keeper\\\"\\n\\tcrisistypes \\\"github.com/cosmos/cosmos-sdk/x/crisis/types\\\"\\n\\tdistr \\\"github.com/cosmos/cosmos-sdk/x/distribution\\\"\\n\\tdistrkeeper \\\"github.com/cosmos/cosmos-sdk/x/distribution/keeper\\\"\\n\\tdistrtypes \\\"github.com/cosmos/cosmos-sdk/x/distribution/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/evidence\\\"\\n\\tevidencekeeper \\\"github.com/cosmos/cosmos-sdk/x/evidence/keeper\\\"\\n\\tevidencetypes \\\"github.com/cosmos/cosmos-sdk/x/evidence/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/feegrant\\\"\\n\\tfeegrantkeeper \\\"github.com/cosmos/cosmos-sdk/x/feegrant/keeper\\\"\\n\\tfeegrantmodule \\\"github.com/cosmos/cosmos-sdk/x/feegrant/module\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/genutil\\\"\\n\\tgenutiltypes \\\"github.com/cosmos/cosmos-sdk/x/genutil/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/gov\\\"\\n\\tgovclient \\\"github.com/cosmos/cosmos-sdk/x/gov/client\\\"\\n\\tgovkeeper \\\"github.com/cosmos/cosmos-sdk/x/gov/keeper\\\"\\n\\tgovtypes \\\"github.com/cosmos/cosmos-sdk/x/gov/types\\\"\\n\\tgovv1 \\\"github.com/cosmos/cosmos-sdk/x/gov/types/v1\\\"\\n\\tgovv1beta1 \\\"github.com/cosmos/cosmos-sdk/x/gov/types/v1beta1\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/group\\\"\\n\\tgroupkeeper \\\"github.com/cosmos/cosmos-sdk/x/group/keeper\\\"\\n\\tgroupmodule \\\"github.com/cosmos/cosmos-sdk/x/group/module\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/mint\\\"\\n\\tmintkeeper \\\"github.com/cosmos/cosmos-sdk/x/mint/keeper\\\"\\n\\tminttypes \\\"github.com/cosmos/cosmos-sdk/x/mint/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/nft\\\"\\n\\tnftkeeper \\\"github.com/cosmos/cosmos-sdk/x/nft/keeper\\\"\\n\\tnftmodule \\\"github.com/cosmos/cosmos-sdk/x/nft/module\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/params\\\"\\n\\tparamsclient \\\"github.com/cosmos/cosmos-sdk/x/params/client\\\"\\n\\tparamskeeper \\\"github.com/cosmos/cosmos-sdk/x/params/keeper\\\"\\n\\tparamstypes \\\"github.com/cosmos/cosmos-sdk/x/params/types\\\"\\n\\tparamproposal \\\"github.com/cosmos/cosmos-sdk/x/params/types/proposal\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/slashing\\\"\\n\\tslashingkeeper \\\"github.com/cosmos/cosmos-sdk/x/slashing/keeper\\\"\\n\\tslashingtypes \\\"github.com/cosmos/cosmos-sdk/x/slashing/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/staking\\\"\\n\\tstakingkeeper \\\"github.com/cosmos/cosmos-sdk/x/staking/keeper\\\"\\n\\tstakingtypes \\\"github.com/cosmos/cosmos-sdk/x/staking/types\\\"\\n    \\\"github.com/cosmos/cosmos-sdk/x/upgrade\\\"\\n\\tupgradeclient \\\"github.com/cosmos/cosmos-sdk/x/upgrade/client\\\"\\n\\tupgradekeeper \\\"github.com/cosmos/cosmos-sdk/x/upgrade/keeper\\\"\\n\\tupgradetypes \\\"github.com/cosmos/cosmos-sdk/x/upgrade/types\\\"\\n)\\n\\nconst appName = \\\"SimApp\\\"\\n\\nvar (\\n\\t// DefaultNodeHome default home directories for the application daemon\\n\\tDefaultNodeHome string\\n\\n\\t// ModuleBasics defines the module BasicManager is in charge of setting up basic,\\n\\t// non-dependant module elements, such as codec registration\\n\\t// and genesis verification.\\n\\tModuleBasics = module.NewBasicManager(\\n\\t\\tauth.AppModuleBasic{\\n},\\n\\t\\tgenutil.NewAppModuleBasic(genutiltypes.DefaultMessageValidator),\\n\\t\\tbank.AppModuleBasic{\\n},\\n\\t\\tcapability.AppModuleBasic{\\n},\\n\\t\\tstaking.AppModuleBasic{\\n},\\n\\t\\tmint.AppModuleBasic{\\n},\\n\\t\\tdistr.AppModuleBasic{\\n},\\n\\t\\tgov.NewAppModuleBasic(\\n\\t\\t\\t[]govclient.ProposalHandler{\\n    paramsclient.ProposalHandler,\\n\\t\\t\\t\\tupgradeclient.LegacyProposalHandler,\\n\\t\\t\\t\\tupgradeclient.LegacyCancelProposalHandler,\\n},\\n\\t\\t),\\n\\t\\tparams.AppModuleBasic{\\n},\\n\\t\\tcrisis.AppModuleBasic{\\n},\\n\\t\\tslashing.AppModuleBasic{\\n},\\n\\t\\tfeegrantmodule.AppModuleBasic{\\n},\\n\\t\\tupgrade.AppModuleBasic{\\n},\\n\\t\\tevidence.AppModuleBasic{\\n},\\n\\t\\tauthzmodule.AppModuleBasic{\\n},\\n\\t\\tgroupmodule.AppModuleBasic{\\n},\\n\\t\\tvesting.AppModuleBasic{\\n},\\n\\t\\tnftmodule.AppModuleBasic{\\n},\\n\\t\\tconsensus.AppModuleBasic{\\n},\\n\\t)\\n\\n\\t// module account permissions\\n\\tmaccPerms = map[string][]string{\\n    authtypes.FeeCollectorName:     nil,\\n\\t\\tdistrtypes.ModuleName:          nil,\\n\\t\\tminttypes.ModuleName:           {\\n    authtypes.Minter\\n},\\n\\t\\tstakingtypes.BondedPoolName:    {\\n    authtypes.Burner, authtypes.Staking\\n},\\n\\t\\tstakingtypes.NotBondedPoolName: {\\n    authtypes.Burner, authtypes.Staking\\n},\\n\\t\\tgovtypes.ModuleName:            {\\n    authtypes.Burner\\n},\\n\\t\\tnft.ModuleName:                 nil,\\n}\\n)\\n\\nvar (\\n\\t_ runtime.AppI            = (*SimApp)(nil)\\n\\t_ servertypes.Application = (*SimApp)(nil)\\n)\\n\\n// SimApp extends an ABCI application, but with most of its parameters exported.\\n// They are exported for convenience in creating helper functions, as object\\n// capabilities aren't needed for testing.\\ntype SimApp struct {\\n\\t*baseapp.BaseApp\\n\\tlegacyAmino       *codec.LegacyAmino\\n\\tappCodec          codec.Codec\\n\\ttxConfig          client.TxConfig\\n\\tinterfaceRegistry types.InterfaceRegistry\\n\\n\\t// keys to access the substores\\n\\tkeys    map[string]*storetypes.KVStoreKey\\n\\ttkeys   map[string]*storetypes.TransientStoreKey\\n\\tmemKeys map[string]*storetypes.MemoryStoreKey\\n\\n\\t// keepers\\n\\tAccountKeeper         authkeeper.AccountKeeper\\n\\tBankKeeper            bankkeeper.Keeper\\n\\tCapabilityKeeper      *capabilitykeeper.Keeper\\n\\tStakingKeeper         *stakingkeeper.Keeper\\n\\tSlashingKeeper        slashingkeeper.Keeper\\n\\tMintKeeper            mintkeeper.Keeper\\n\\tDistrKeeper           distrkeeper.Keeper\\n\\tGovKeeper             govkeeper.Keeper\\n\\tCrisisKeeper          *crisiskeeper.Keeper\\n\\tUpgradeKeeper         *upgradekeeper.Keeper\\n\\tParamsKeeper          paramskeeper.Keeper\\n\\tAuthzKeeper           authzkeeper.Keeper\\n\\tEvidenceKeeper        evidencekeeper.Keeper\\n\\tFeeGrantKeeper        feegrantkeeper.Keeper\\n\\tGroupKeeper           groupkeeper.Keeper\\n\\tNFTKeeper             nftkeeper.Keeper\\n\\tConsensusParamsKeeper consensusparamkeeper.Keeper\\n\\n\\t// the module manager\\n\\tModuleManager *module.Manager\\n\\n\\t// simulation manager\\n\\tsm *module.SimulationManager\\n\\n\\t// module configurator\\n\\tconfigurator module.Configurator\\n}\\n\\nfunc init() {\\n    userHomeDir, err := os.UserHomeDir()\\n    if err != nil {\\n    panic(err)\\n}\\n\\nDefaultNodeHome = filepath.Join(userHomeDir, \\\".simapp\\\")\\n}\\n\\n// NewSimApp returns a reference to an initialized SimApp.\\nfunc NewSimApp(\\n\\tlogger log.Logger,\\n\\tdb dbm.DB,\\n\\ttraceStore io.Writer,\\n\\tloadLatest bool,\\n\\tappOpts servertypes.AppOptions,\\n\\tbaseAppOptions ...func(*baseapp.BaseApp),\\n) *SimApp {\\n    encodingConfig := makeEncodingConfig()\\n    appCodec := encodingConfig.Codec\\n    legacyAmino := encodingConfig.Amino\\n    interfaceRegistry := encodingConfig.InterfaceRegistry\\n    txConfig := encodingConfig.TxConfig\\n\\n\\t// Below we could construct and set an application specific mempool and ABCI 1.0 Prepare and Process Proposal\\n\\t// handlers. These defaults are already set in the SDK's BaseApp, this shows an example of how to override\\n\\t// them.\\n\\t//\\n\\t// nonceMempool := mempool.NewSenderNonceMempool()\\n\\t// mempoolOpt   := baseapp.SetMempool(nonceMempool)\\n\\t// prepareOpt   := func(app *baseapp.BaseApp) {\\n\\t// \\tapp.SetPrepareProposal(app.DefaultPrepareProposal())\\n\\t//\\n}\\n\\t// processOpt := func(app *baseapp.BaseApp) {\\n\\t// \\tapp.SetProcessProposal(app.DefaultProcessProposal())\\n\\t//\\n}\\n\\t//\\n\\t// Further down we'd set the options in the AppBuilder like below.\\n\\t// baseAppOptions = append(baseAppOptions, mempoolOpt, prepareOpt, processOpt)\\n    bApp := baseapp.NewBaseApp(appName, logger, db, txConfig.TxDecoder(), baseAppOptions...)\\n\\nbApp.SetCommitMultiStoreTracer(traceStore)\\n\\nbApp.SetVersion(version.Version)\\n\\nbApp.SetInterfaceRegistry(interfaceRegistry)\\n\\nbApp.SetTxEncoder(txConfig.TxEncoder())\\n    keys := sdk.NewKVStoreKeys(\\n\\t\\tauthtypes.StoreKey, banktypes.StoreKey, stakingtypes.StoreKey, crisistypes.StoreKey,\\n\\t\\tminttypes.StoreKey, distrtypes.StoreKey, slashingtypes.StoreKey,\\n\\t\\tgovtypes.StoreKey, paramstypes.StoreKey, consensusparamtypes.StoreKey, upgradetypes.StoreKey, feegrant.StoreKey,\\n\\t\\tevidencetypes.StoreKey, capabilitytypes.StoreKey,\\n\\t\\tauthzkeeper.StoreKey, nftkeeper.StoreKey, group.StoreKey,\\n\\t)\\n    tkeys := sdk.NewTransientStoreKeys(paramstypes.TStoreKey)\\n\\t// NOTE: The testingkey is just mounted for testing purposes. Actual applications should\\n\\t// not include this key.\\n    memKeys := sdk.NewMemoryStoreKeys(capabilitytypes.MemStoreKey, \\\"testingkey\\\")\\n\\n\\t// load state streaming if enabled\\n    if _, _, err := streaming.LoadStreamingServices(bApp, appOpts, appCodec, logger, keys); err != nil {\\n    logger.Error(\\\"failed to load state streaming\\\", \\\"err\\\", err)\\n\\nos.Exit(1)\\n}\\n    app := &SimApp{\\n    BaseApp:           bApp,\\n\\t\\tlegacyAmino:       legacyAmino,\\n\\t\\tappCodec:          appCodec,\\n\\t\\ttxConfig:          txConfig,\\n\\t\\tinterfaceRegistry: interfaceRegistry,\\n\\t\\tkeys:              keys,\\n\\t\\ttkeys:             tkeys,\\n\\t\\tmemKeys:           memKeys,\\n}\\n\\napp.ParamsKeeper = initParamsKeeper(appCodec, legacyAmino, keys[paramstypes.StoreKey], tkeys[paramstypes.TStoreKey])\\n\\n\\t// set the BaseApp's parameter store\\n\\tapp.ConsensusParamsKeeper = consensusparamkeeper.NewKeeper(appCodec, keys[upgradetypes.StoreKey], authtypes.NewModuleAddress(govtypes.ModuleName).String())\\n\\nbApp.SetParamStore(&app.ConsensusParamsKeeper)\\n\\napp.CapabilityKeeper = capabilitykeeper.NewKeeper(appCodec, keys[capabilitytypes.StoreKey], memKeys[capabilitytypes.MemStoreKey])\\n\\t// Applications that wish to enforce statically created ScopedKeepers should call `Seal` after creating\\n\\t// their scoped modules in `NewApp` with `ScopeToModule`\\n\\tapp.CapabilityKeeper.Seal()\\n\\n\\t// add keepers\\n\\tapp.AccountKeeper = authkeeper.NewAccountKeeper(appCodec, keys[authtypes.StoreKey], authtypes.ProtoBaseAccount, maccPerms, sdk.Bech32MainPrefix, authtypes.NewModuleAddress(govtypes.ModuleName).String())\\n\\napp.BankKeeper = bankkeeper.NewBaseKeeper(\\n\\t\\tappCodec,\\n\\t\\tkeys[banktypes.StoreKey],\\n\\t\\tapp.AccountKeeper,\\n\\t\\tBlockedAddresses(),\\n\\t\\tauthtypes.NewModuleAddress(govtypes.ModuleName).String(),\\n\\t)\\n\\napp.StakingKeeper = stakingkeeper.NewKeeper(\\n\\t\\tappCodec, keys[stakingtypes.StoreKey], app.AccountKeeper, app.BankKeeper, authtypes.NewModuleAddress(govtypes.ModuleName).String(),\\n\\t)\\n\\napp.MintKeeper = mintkeeper.NewKeeper(appCodec, keys[minttypes.StoreKey], app.StakingKeeper, app.AccountKeeper, app.BankKeeper, authtypes.FeeCollectorName, authtypes.NewModuleAddress(govtypes.ModuleName).String())\\n\\napp.DistrKeeper = distrkeeper.NewKeeper(appCodec, keys[distrtypes.StoreKey], app.AccountKeeper, app.BankKeeper, app.StakingKeeper, authtypes.FeeCollectorName, authtypes.NewModuleAddress(govtypes.ModuleName).String())\\n\\napp.SlashingKeeper = slashingkeeper.NewKeeper(\\n\\t\\tappCodec, legacyAmino, keys[slashingtypes.StoreKey], app.StakingKeeper, authtypes.NewModuleAddress(govtypes.ModuleName).String(),\\n\\t)\\n    invCheckPeriod := cast.ToUint(appOpts.Get(server.FlagInvCheckPeriod))\\n\\napp.CrisisKeeper = crisiskeeper.NewKeeper(appCodec, keys[crisistypes.StoreKey], invCheckPeriod,\\n\\t\\tapp.BankKeeper, authtypes.FeeCollectorName, authtypes.NewModuleAddress(govtypes.ModuleName).String())\\n\\napp.FeeGrantKeeper = feegrantkeeper.NewKeeper(appCodec, keys[feegrant.StoreKey], app.AccountKeeper)\\n\\n\\t// register the staking hooks\\n\\t// NOTE: stakingKeeper above is passed by reference, so that it will contain these hooks\\n\\tapp.StakingKeeper.SetHooks(\\n\\t\\tstakingtypes.NewMultiStakingHooks(app.DistrKeeper.Hooks(), app.SlashingKeeper.Hooks()),\\n\\t)\\n\\napp.AuthzKeeper = authzkeeper.NewKeeper(keys[authzkeeper.StoreKey], appCodec, app.MsgServiceRouter(), app.AccountKeeper)\\n    groupConfig := group.DefaultConfig()\\n\\t/*\\n\\t\\tExample of setting group params:\\n\\t\\tgroupConfig.MaxMetadataLen = 1000\\n\\t*/\\n\\tapp.GroupKeeper = groupkeeper.NewKeeper(keys[group.StoreKey], appCodec, app.MsgServiceRouter(), app.AccountKeeper, groupConfig)\\n\\n\\t// get skipUpgradeHeights from the app options\\n    skipUpgradeHeights := map[int64]bool{\\n}\\n    for _, h := range cast.ToIntSlice(appOpts.Get(server.FlagUnsafeSkipUpgrades)) {\\n    skipUpgradeHeights[int64(h)] = true\\n}\\n    homePath := cast.ToString(appOpts.Get(flags.FlagHome))\\n\\t// set the governance module account as the authority for conducting upgrades\\n\\tapp.UpgradeKeeper = upgradekeeper.NewKeeper(skipUpgradeHeights, keys[upgradetypes.StoreKey], appCodec, homePath, app.BaseApp, authtypes.NewModuleAddress(govtypes.ModuleName).String())\\n\\n\\t// Register the proposal types\\n\\t// Deprecated: Avoid adding new handlers, instead use the new proposal flow\\n\\t// by granting the governance module the right to execute the message.\\n\\t// See: https://github.com/cosmos/cosmos-sdk/blob/release/v0.46.x/x/gov/spec/01_concepts.md#proposal-messages\\n    govRouter := govv1beta1.NewRouter()\\n\\ngovRouter.AddRoute(govtypes.RouterKey, govv1beta1.ProposalHandler).\\n\\t\\tAddRoute(paramproposal.RouterKey, params.NewParamChangeProposalHandler(app.ParamsKeeper)).\\n\\t\\tAddRoute(upgradetypes.RouterKey, upgrade.NewSoftwareUpgradeProposalHandler(app.UpgradeKeeper))\\n    govConfig := govtypes.DefaultConfig()\\n\\t/*\\n\\t\\tExample of setting gov params:\\n\\t\\tgovConfig.MaxMetadataLen = 10000\\n\\t*/\\n    govKeeper := govkeeper.NewKeeper(\\n\\t\\tappCodec, keys[govtypes.StoreKey], app.AccountKeeper, app.BankKeeper,\\n\\t\\tapp.StakingKeeper, app.MsgServiceRouter(), govConfig, authtypes.NewModuleAddress(govtypes.ModuleName).String(),\\n\\t)\\n\\n\\t// Set legacy router for backwards compatibility with gov v1beta1\\n\\tgovKeeper.SetLegacyRouter(govRouter)\\n\\napp.GovKeeper = *govKeeper.SetHooks(\\n\\t\\tgovtypes.NewMultiGovHooks(\\n\\t\\t// register the governance hooks\\n\\t\\t),\\n\\t)\\n\\napp.NFTKeeper = nftkeeper.NewKeeper(keys[nftkeeper.StoreKey], appCodec, app.AccountKeeper, app.BankKeeper)\\n\\n\\t// create evidence keeper with router\\n    evidenceKeeper := evidencekeeper.NewKeeper(\\n\\t\\tappCodec, keys[evidencetypes.StoreKey], app.StakingKeeper, app.SlashingKeeper,\\n\\t)\\n\\t// If evidence needs to be handled for the app, set routes in router here and seal\\n\\tapp.EvidenceKeeper = *evidenceKeeper\\n\\n\\t/****  Module Options ****/\\n\\n\\t// NOTE: we may consider parsing `appOpts` inside module constructors. For the moment\\n\\t// we prefer to be more strict in what arguments the modules expect.\\n    skipGenesisInvariants := cast.ToBool(appOpts.Get(crisis.FlagSkipGenesisInvariants))\\n\\n\\t// NOTE: Any module instantiated in the module manager that is later modified\\n\\t// must be passed by reference here.\\n\\tapp.ModuleManager = module.NewManager(\\n\\t\\tgenutil.NewAppModule(\\n\\t\\t\\tapp.AccountKeeper, app.StakingKeeper, app.BaseApp.DeliverTx,\\n\\t\\t\\tencodingConfig.TxConfig,\\n\\t\\t),\\n\\t\\tauth.NewAppModule(appCodec, app.AccountKeeper, authsims.RandomGenesisAccounts, app.GetSubspace(authtypes.ModuleName)),\\n\\t\\tvesting.NewAppModule(app.AccountKeeper, app.BankKeeper),\\n\\t\\tbank.NewAppModule(appCodec, app.BankKeeper, app.AccountKeeper, app.GetSubspace(banktypes.ModuleName)),\\n\\t\\tcapability.NewAppModule(appCodec, *app.CapabilityKeeper, false),\\n\\t\\tcrisis.NewAppModule(app.CrisisKeeper, skipGenesisInvariants, app.GetSubspace(crisistypes.ModuleName)),\\n\\t\\tfeegrantmodule.NewAppModule(appCodec, app.AccountKeeper, app.BankKeeper, app.FeeGrantKeeper, app.interfaceRegistry),\\n\\t\\tgov.NewAppModule(appCodec, &app.GovKeeper, app.AccountKeeper, app.BankKeeper, app.GetSubspace(govtypes.ModuleName)),\\n\\t\\tmint.NewAppModule(appCodec, app.MintKeeper, app.AccountKeeper, nil, app.GetSubspace(minttypes.ModuleName)),\\n\\t\\tslashing.NewAppModule(appCodec, app.SlashingKeeper, app.AccountKeeper, app.BankKeeper, app.StakingKeeper, app.GetSubspace(slashingtypes.ModuleName)),\\n\\t\\tdistr.NewAppModule(appCodec, app.DistrKeeper, app.AccountKeeper, app.BankKeeper, app.StakingKeeper, app.GetSubspace(distrtypes.ModuleName)),\\n\\t\\tstaking.NewAppModule(appCodec, app.StakingKeeper, app.AccountKeeper, app.BankKeeper, app.GetSubspace(stakingtypes.ModuleName)),\\n\\t\\tupgrade.NewAppModule(app.UpgradeKeeper),\\n\\t\\tevidence.NewAppModule(app.EvidenceKeeper),\\n\\t\\tparams.NewAppModule(app.ParamsKeeper),\\n\\t\\tauthzmodule.NewAppModule(appCodec, app.AuthzKeeper, app.AccountKeeper, app.BankKeeper, app.interfaceRegistry),\\n\\t\\tgroupmodule.NewAppModule(appCodec, app.GroupKeeper, app.AccountKeeper, app.BankKeeper, app.interfaceRegistry),\\n\\t\\tnftmodule.NewAppModule(appCodec, app.NFTKeeper, app.AccountKeeper, app.BankKeeper, app.interfaceRegistry),\\n\\t\\tconsensus.NewAppModule(appCodec, app.ConsensusParamsKeeper),\\n\\t)\\n\\n\\t// During begin block slashing happens after distr.BeginBlocker so that\\n\\t// there is nothing left over in the validator fee pool, so as to keep the\\n\\t// CanWithdrawInvariant invariant.\\n\\t// NOTE: staking module is required if HistoricalEntries param > 0\\n\\t// NOTE: capability module's beginblocker must come before any modules using capabilities (e.g. IBC)\\n\\napp.ModuleManager.SetOrderBeginBlockers(\\n\\t\\tupgradetypes.ModuleName, capabilitytypes.ModuleName, minttypes.ModuleName, distrtypes.ModuleName, slashingtypes.ModuleName,\\n\\t\\tevidencetypes.ModuleName, stakingtypes.ModuleName,\\n\\t\\tauthtypes.ModuleName, banktypes.ModuleName, govtypes.ModuleName, crisistypes.ModuleName, genutiltypes.ModuleName,\\n\\t\\tauthz.ModuleName, feegrant.ModuleName, nft.ModuleName, group.ModuleName,\\n\\t\\tparamstypes.ModuleName, vestingtypes.ModuleName, consensusparamtypes.ModuleName,\\n\\t)\\n\\napp.ModuleManager.SetOrderEndBlockers(\\n\\t\\tcrisistypes.ModuleName, govtypes.ModuleName, stakingtypes.ModuleName,\\n\\t\\tcapabilitytypes.ModuleName, authtypes.ModuleName, banktypes.ModuleName, distrtypes.ModuleName,\\n\\t\\tslashingtypes.ModuleName, minttypes.ModuleName,\\n\\t\\tgenutiltypes.ModuleName, evidencetypes.ModuleName, authz.ModuleName,\\n\\t\\tfeegrant.ModuleName, nft.ModuleName, group.ModuleName,\\n\\t\\tparamstypes.ModuleName, upgradetypes.ModuleName, vestingtypes.ModuleName, consensusparamtypes.ModuleName,\\n\\t)\\n\\n\\t// NOTE: The genutils module must occur after staking so that pools are\\n\\t// properly initialized with tokens from genesis accounts.\\n\\t// NOTE: The genutils module must also occur after auth so that it can access the params from auth.\\n\\t// NOTE: Capability module must occur first so that it can initialize any capabilities\\n\\t// so that other modules that want to create or claim capabilities afterwards in InitChain\\n\\t// can do so safely.\\n    genesisModuleOrder := []string{\\n    capabilitytypes.ModuleName, authtypes.ModuleName, banktypes.ModuleName,\\n\\t\\tdistrtypes.ModuleName, stakingtypes.ModuleName, slashingtypes.ModuleName, govtypes.ModuleName,\\n\\t\\tminttypes.ModuleName, crisistypes.ModuleName, genutiltypes.ModuleName, evidencetypes.ModuleName, authz.ModuleName,\\n\\t\\tfeegrant.ModuleName, nft.ModuleName, group.ModuleName, paramstypes.ModuleName, upgradetypes.ModuleName,\\n\\t\\tvestingtypes.ModuleName, consensusparamtypes.ModuleName,\\n}\\n\\napp.ModuleManager.SetOrderInitGenesis(genesisModuleOrder...)\\n\\napp.ModuleManager.SetOrderExportGenesis(genesisModuleOrder...)\\n\\n\\t// Uncomment if you want to set a custom migration order here.\\n\\t// app.ModuleManager.SetOrderMigrations(custom order)\\n\\napp.ModuleManager.RegisterInvariants(app.CrisisKeeper)\\n\\napp.configurator = module.NewConfigurator(app.appCodec, app.MsgServiceRouter(), app.GRPCQueryRouter())\\n\\napp.ModuleManager.RegisterServices(app.configurator)\\n\\n\\t// RegisterUpgradeHandlers is used for registering any on-chain upgrades.\\n\\t// Make sure it's called after `app.ModuleManager` and `app.configurator` are set.\\n\\tapp.RegisterUpgradeHandlers()\\n\\nautocliv1.RegisterQueryServer(app.GRPCQueryRouter(), runtimeservices.NewAutoCLIQueryService(app.ModuleManager.Modules))\\n\\nreflectionSvc, err := runtimeservices.NewReflectionService()\\n    if err != nil {\\n    panic(err)\\n}\\n\\nreflectionv1.RegisterReflectionServiceServer(app.GRPCQueryRouter(), reflectionSvc)\\n\\n\\t// add test gRPC service for testing gRPC queries in isolation\\n\\ttestdata_pulsar.RegisterQueryServer(app.GRPCQueryRouter(), testdata_pulsar.QueryImpl{\\n})\\n\\n\\t// create the simulation manager and define the order of the modules for deterministic simulations\\n\\t//\\n\\t// NOTE: this is not required apps that don't use the simulator for fuzz testing\\n\\t// transactions\\n    overrideModules := map[string]module.AppModuleSimulation{\\n    authtypes.ModuleName: auth.NewAppModule(app.appCodec, app.AccountKeeper, authsims.RandomGenesisAccounts, app.GetSubspace(authtypes.ModuleName)),\\n}\\n\\napp.sm = module.NewSimulationManagerFromAppModules(app.ModuleManager.Modules, overrideModules)\\n\\napp.sm.RegisterStoreDecoders()\\n\\n\\t// initialize stores\\n\\tapp.MountKVStores(keys)\\n\\napp.MountTransientStores(tkeys)\\n\\napp.MountMemoryStores(memKeys)\\n\\n\\t// initialize BaseApp\\n\\tapp.SetInitChainer(app.InitChainer)\\n\\napp.SetBeginBlocker(app.BeginBlocker)\\n\\napp.SetEndBlocker(app.EndBlocker)\\n\\napp.setAnteHandler(encodingConfig.TxConfig)\\n\\n\\t// In v0.46, the SDK introduces _postHandlers_. PostHandlers are like\\n\\t// antehandlers, but are run _after_ the `runMsgs` execution. They are also\\n\\t// defined as a chain, and have the same signature as antehandlers.\\n\\t//\\n\\t// In baseapp, postHandlers are run in the same store branch as `runMsgs`,\\n\\t// meaning that both `runMsgs` and `postHandler` state will be committed if\\n\\t// both are successful, and both will be reverted if any of the two fails.\\n\\t//\\n\\t// The SDK exposes a default postHandlers chain, which comprises of only\\n\\t// one decorator: the Transaction Tips decorator. However, some chains do\\n\\t// not need it by default, so feel free to comment the next line if you do\\n\\t// not need tips.\\n\\t// To read more about tips:\\n\\t// https://docs.cosmos.network/main/core/tips.html\\n\\t//\\n\\t// Please note that changing any of the anteHandler or postHandler chain is\\n\\t// likely to be a state-machine breaking change, which needs a coordinated\\n\\t// upgrade.\\n\\tapp.setPostHandler()\\n    if loadLatest {\\n    if err := app.LoadLatestVersion(); err != nil {\\n    logger.Error(\\\"error on loading last version\\\", \\\"err\\\", err)\\n\\nos.Exit(1)\\n}\\n\\t\\n}\\n\\nreturn app\\n}\\n\\nfunc (app *SimApp)\\n\\nsetAnteHandler(txConfig client.TxConfig) {\\n    anteHandler, err := ante.NewAnteHandler(\\n\\t\\tante.HandlerOptions{\\n    AccountKeeper:   app.AccountKeeper,\\n    BankKeeper:      app.BankKeeper,\\n    SignModeHandler: txConfig.SignModeHandler(),\\n    FeegrantKeeper:  app.FeeGrantKeeper,\\n    SigGasConsumer:  ante.DefaultSigVerificationGasConsumer,\\n},\\n\\t)\\n    if err != nil {\\n    panic(err)\\n}\\n\\napp.SetAnteHandler(anteHandler)\\n}\\n\\nfunc (app *SimApp)\\n\\nsetPostHandler() {\\n    postHandler, err := posthandler.NewPostHandler(\\n\\t\\tposthandler.HandlerOptions{\\n},\\n\\t)\\n    if err != nil {\\n    panic(err)\\n}\\n\\napp.SetPostHandler(postHandler)\\n}\\n\\n// Name returns the name of the App\\nfunc (app *SimApp)\\n\\nName()\\n\\nstring {\\n    return app.BaseApp.Name()\\n}\\n\\n// BeginBlocker application updates every begin block\\nfunc (app *SimApp)\\n\\nBeginBlocker(ctx sdk.Context, req abci.RequestBeginBlock)\\n\\nabci.ResponseBeginBlock {\\n    return app.ModuleManager.BeginBlock(ctx, req)\\n}\\n\\n// EndBlocker application updates every end block\\nfunc (app *SimApp)\\n\\nEndBlocker(ctx sdk.Context, req abci.RequestEndBlock)\\n\\nabci.ResponseEndBlock {\\n    return app.ModuleManager.EndBlock(ctx, req)\\n}\\n\\nfunc (a *SimApp)\\n\\nConfigurator()\\n\\nmodule.Configurator {\\n    return a.configurator\\n}\\n\\n// InitChainer application update at chain initialization\\nfunc (app *SimApp)\\n\\nInitChainer(ctx sdk.Context, req abci.RequestInitChain)\\n\\nabci.ResponseInitChain {\\n    var genesisState GenesisState\\n    if err := json.Unmarshal(req.AppStateBytes, &genesisState); err != nil {\\n    panic(err)\\n}\\n\\napp.UpgradeKeeper.SetModuleVersionMap(ctx, app.ModuleManager.GetVersionMap())\\n\\nreturn app.ModuleManager.InitGenesis(ctx, app.appCodec, genesisState)\\n}\\n\\n// LoadHeight loads a particular height\\nfunc (app *SimApp)\\n\\nLoadHeight(height int64)\\n\\nerror {\\n    return app.LoadVersion(height)\\n}\\n\\n// LegacyAmino returns SimApp's amino codec.\\n//\\n// NOTE: This is solely to be used for testing purposes as it may be desirable\\n// for modules to register their own custom testing types.\\nfunc (app *SimApp)\\n\\nLegacyAmino() *codec.LegacyAmino {\\n    return app.legacyAmino\\n}\\n\\n// AppCodec returns SimApp's app codec.\\n//\\n// NOTE: This is solely to be used for testing purposes as it may be desirable\\n// for modules to register their own custom testing types.\\nfunc (app *SimApp)\\n\\nAppCodec()\\n\\ncodec.Codec {\\n    return app.appCodec\\n}\\n\\n// InterfaceRegistry returns SimApp's InterfaceRegistry\\nfunc (app *SimApp)\\n\\nInterfaceRegistry()\\n\\ntypes.InterfaceRegistry {\\n    return app.interfaceRegistry\\n}\\n\\n// TxConfig returns SimApp's TxConfig\\nfunc (app *SimApp)\\n\\nTxConfig()\\n\\nclient.TxConfig {\\n    return app.txConfig\\n}\\n\\n// DefaultGenesis returns a default genesis from the registered AppModuleBasic's.\\nfunc (a *SimApp)\\n\\nDefaultGenesis()\\n\\nmap[string]json.RawMessage {\\n    return ModuleBasics.DefaultGenesis(a.appCodec)\\n}\\n\\n// GetKey returns the KVStoreKey for the provided store key.\\n//\\n// NOTE: This is solely to be used for testing purposes.\\nfunc (app *SimApp)\\n\\nGetKey(storeKey string) *storetypes.KVStoreKey {\\n    return app.keys[storeKey]\\n}\\n\\n// GetTKey returns the TransientStoreKey for the provided store key.\\n//\\n// NOTE: This is solely to be used for testing purposes.\\nfunc (app *SimApp)\\n\\nGetTKey(storeKey string) *storetypes.TransientStoreKey {\\n    return app.tkeys[storeKey]\\n}\\n\\n// GetMemKey returns the MemStoreKey for the provided mem key.\\n//\\n// NOTE: This is solely used for testing purposes.\\nfunc (app *SimApp)\\n\\nGetMemKey(storeKey string) *storetypes.MemoryStoreKey {\\n    return app.memKeys[storeKey]\\n}\\n\\n// GetSubspace returns a param subspace for a given module name.\\n//\\n// NOTE: This is solely to be used for testing purposes.\\nfunc (app *SimApp)\\n\\nGetSubspace(moduleName string)\\n\\nparamstypes.Subspace {\\n    subspace, _ := app.ParamsKeeper.GetSubspace(moduleName)\\n\\nreturn subspace\\n}\\n\\n// SimulationManager implements the SimulationApp interface\\nfunc (app *SimApp)\\n\\nSimulationManager() *module.SimulationManager {\\n    return app.sm\\n}\\n\\n// RegisterAPIRoutes registers all application module routes with the provided\\n// API server.\\nfunc (app *SimApp)\\n\\nRegisterAPIRoutes(apiSvr *api.Server, apiConfig config.APIConfig) {\\n    clientCtx := apiSvr.ClientCtx\\n\\t// Register new tx routes from grpc-gateway.\\n\\tauthtx.RegisterGRPCGatewayRoutes(clientCtx, apiSvr.GRPCGatewayRouter)\\n\\n\\t// Register new tendermint queries routes from grpc-gateway.\\n\\ttmservice.RegisterGRPCGatewayRoutes(clientCtx, apiSvr.GRPCGatewayRouter)\\n\\n\\t// Register node gRPC service for grpc-gateway.\\n\\tnodeservice.RegisterGRPCGatewayRoutes(clientCtx, apiSvr.GRPCGatewayRouter)\\n\\n\\t// Register grpc-gateway routes for all modules.\\n\\tModuleBasics.RegisterGRPCGatewayRoutes(clientCtx, apiSvr.GRPCGatewayRouter)\\n\\n\\t// register swagger API from root so that other applications can override easily\\n    if err := server.RegisterSwaggerAPI(apiSvr.ClientCtx, apiSvr.Router, apiConfig.Swagger); err != nil {\\n    panic(err)\\n}\\n}\\n\\n// RegisterTxService implements the Application.RegisterTxService method.\\nfunc (app *SimApp)\\n\\nRegisterTxService(clientCtx client.Context) {\\n    authtx.RegisterTxService(app.BaseApp.GRPCQueryRouter(), clientCtx, app.BaseApp.Simulate, app.interfaceRegistry)\\n}\\n\\n// RegisterTendermintService implements the Application.RegisterTendermintService method.\\nfunc (app *SimApp)\\n\\nRegisterTendermintService(clientCtx client.Context) {\\n    tmservice.RegisterTendermintService(\\n\\t\\tclientCtx,\\n\\t\\tapp.BaseApp.GRPCQueryRouter(),\\n\\t\\tapp.interfaceRegistry,\\n\\t\\tapp.Query,\\n\\t)\\n}\\n\\nfunc (app *SimApp)\\n\\nRegisterNodeService(clientCtx client.Context) {\\n    nodeservice.RegisterNodeService(clientCtx, app.GRPCQueryRouter())\\n}\\n\\n// GetMaccPerms returns a copy of the module account permissions\\n//\\n// NOTE: This is solely to be used for testing purposes.\\nfunc GetMaccPerms()\\n\\nmap[string][]string {\\n    dupMaccPerms := make(map[string][]string)\\n    for k, v := range maccPerms {\\n    dupMaccPerms[k] = v\\n}\\n\\nreturn dupMaccPerms\\n}\\n\\n// BlockedAddresses returns all the app's blocked account addresses.\\nfunc BlockedAddresses()\\n\\nmap[string]bool {\\n    modAccAddrs := make(map[string]bool)\\n    for acc := range GetMaccPerms() {\\n    modAccAddrs[authtypes.NewModuleAddress(acc).String()] = true\\n}\\n\\n\\t// allow the following addresses to receive funds\\n\\tdelete(modAccAddrs, authtypes.NewModuleAddress(govtypes.ModuleName).String())\\n\\nreturn modAccAddrs\\n}\\n\\n// initParamsKeeper init params keeper and its subspaces\\nfunc initParamsKeeper(appCodec codec.BinaryCodec, legacyAmino *codec.LegacyAmino, key, tkey storetypes.StoreKey)\\n\\nparamskeeper.Keeper {\\n    paramsKeeper := paramskeeper.NewKeeper(appCodec, legacyAmino, key, tkey)\\n\\nparamsKeeper.Subspace(authtypes.ModuleName)\\n\\nparamsKeeper.Subspace(banktypes.ModuleName)\\n\\nparamsKeeper.Subspace(stakingtypes.ModuleName)\\n\\nparamsKeeper.Subspace(minttypes.ModuleName)\\n\\nparamsKeeper.Subspace(distrtypes.ModuleName)\\n\\nparamsKeeper.Subspace(slashingtypes.ModuleName)\\n\\nparamsKeeper.Subspace(govtypes.ModuleName).WithKeyTable(govv1.ParamKeyTable())\\n\\nparamsKeeper.Subspace(crisistypes.ModuleName)\\n\\nreturn paramsKeeper\\n}\\n\\nfunc makeEncodingConfig()\\n\\nsimappparams.EncodingConfig {\\n    encodingConfig := simappparams.MakeTestEncodingConfig()\\n\\nstd.RegisterLegacyAminoCodec(encodingConfig.Amino)\\n\\nstd.RegisterInterfaces(encodingConfig.InterfaceRegistry)\\n\\nModuleBasics.RegisterLegacyAminoCodec(encodingConfig.Amino)\\n\\nModuleBasics.RegisterInterfaces(encodingConfig.InterfaceRegistry)\\n\\nreturn encodingConfig\\n}\\n\\n\", \"Title: Main Components of the Cosmos SDK\\nLink: https://evm.cosmos.network/docs/sdk/v0.53/learn/intro/sdk-design\\nContent: The Cosmos SDK is a framework that facilitates the development of secure state-machines on top of CometBFT. At its core, the Cosmos SDK is a boilerplate implementation of the ABCI in Golang. It comes with a multistore to persist data and a router to handle transactions. Here is a simplified view of how transactions are handled by an application built on top of the Cosmos SDK when transferred from CometBFT via DeliverTx: Decode transactions received from the CometBFT consensus engine (remember that CometBFT only deals with []bytes ). Extract messages from transactions and do basic sanity checks. Route each message to the appropriate module so that it can be processed. Commit state changes.\\n\\nMain Components of the Cosmos SDK\\nThe Cosmos SDK is a framework that facilitates the development of secure state-machines on top of CometBFT. At its core, the Cosmos SDK is a boilerplate implementation of the ABCI in Golang. It comes with a multistore to persist data and a router to handle transactions. Here is a simplified view of how transactions are handled by an application built on top of the Cosmos SDK when transferred from CometBFT via DeliverTx: Decode transactions received from the CometBFT consensus engine (remember that CometBFT only deals with []bytes ). Extract messages from transactions and do basic sanity checks. Route each message to the appropriate module so that it can be processed. Commit state changes.\\n\\nModules\\nThe power of the Cosmos SDK lies in its modularity. Cosmos SDK applications are built by aggregating a collection of interoperable modules. Each module defines a subset of the state and contains its own message/transaction processor, while the Cosmos SDK is responsible for routing each message to its respective module. Here is a simplified view of how a transaction is processed by the application of each full-node when it is received in a valid block: flowchart TD\\n    A[Transaction relayed from the full-node's CometBFT engine to the node's application via DeliverTx] --> B[APPLICATION]\\n    B -->|\\\"Using baseapp's methods: Decode the Tx, extract and route the message(s)\\\"| C[Message routed to the correct module to be processed]\\n    C --> D1[AUTH MODULE]\\n    C --> D2[BANK MODULE]\\n    C --> D3[STAKING MODULE]\\n    C --> D4[GOV MODULE]\\n    D1 -->|Handle message, Update state| E[\\\"Return result to CometBFT (0=Ok, 1=Err)\\\"]\\n    D2 -->|Handle message, Update state| E[\\\"Return result to CometBFT (0=Ok, 1=Err)\\\"]\\n    D3 -->|Handle message, Update state| E[\\\"Return result to CometBFT (0=Ok, 1=Err)\\\"]\\n    D4 -->|Handle message, Update state| E[\\\"Return result to CometBFT (0=Ok, 1=Err)\\\"]\\n\\n\"]",
            "additional_kwargs": {},
            "response_metadata": {},
            "type": "tool",
            "name": "SearchCosmosDocumentation",
            "id": "cc6d31b2-792f-44c1-aacc-c57973ad7c38",
            "tool_call_id": "call_9Bm0IvDdntoEAdmRJzB4n2Yx",
            "artifact": null,
            "status": "success"
        },
        {
            "content": "",
            "additional_kwargs": {
                "tool_calls": [
                    {
                        "id": "call_ifterLKWSxydzqpqLm8suPBU",
                        "function": {
                            "arguments": "{\"query\": \"personal_listAccounts cosmos\"}",
                            "name": "SearchCosmosDocumentation"
                        },
                        "type": "function"
                    }
                ],
                "refusal": null
            },
            "response_metadata": {
                "token_usage": {
                    "completion_tokens": 797,
                    "prompt_tokens": 58966,
                    "total_tokens": 59763,
                    "completion_tokens_details": {
                        "accepted_prediction_tokens": 0,
                        "audio_tokens": 0,
                        "reasoning_tokens": 768,
                        "rejected_prediction_tokens": 0
                    },
                    "prompt_tokens_details": {
                        "audio_tokens": 0,
                        "cached_tokens": 41728
                    }
                },
                "model_name": "o3-2025-04-16",
                "system_fingerprint": null,
                "id": "chatcmpl-CPw0MRvBKlYiY36IquDsOUBSjkWKo",
                "service_tier": "default",
                "finish_reason": "tool_calls",
                "logprobs": null
            },
            "type": "ai",
            "name": null,
            "id": "run--6b167b95-edf9-442d-b28a-9ccbdad69330-0",
            "example": false,
            "tool_calls": [
                {
                    "name": "SearchCosmosDocumentation",
                    "args": {
                        "query": "personal_listAccounts cosmos"
                    },
                    "id": "call_ifterLKWSxydzqpqLm8suPBU",
                    "type": "tool_call"
                }
            ],
            "invalid_tool_calls": [],
            "usage_metadata": {
                "input_tokens": 58966,
                "output_tokens": 797,
                "total_tokens": 59763,
                "input_token_details": {
                    "audio": 0,
                    "cache_read": 41728
                },
                "output_token_details": {
                    "audio": 0,
                    "reasoning": 768
                }
            }
        },
        {
            "content": "[\"Title: personal_listAccounts\\nLink: https://evm.cosmos.network/docs/evm/next/api-reference/ethereum-json-rpc/methods\\nContent: Private : Requires authentication. Returns a list of addresses for accounts this node manages.\\n\\nPrivate : Requires authentication. Returns a list of addresses for accounts this node manages. // Request\\ncurl -X POST --data '{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"method\\\":\\\"personal_listAccounts\\\",\\\"params\\\":[],\\\"id\\\":1}' -H \\\"Content-Type: application/json\\\" http://localhost:8545\\n// Result\\n{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"id\\\":1,\\\"result\\\":[\\\"0x3b7252d007059ffc82d16d022da3cbf9992d2f70\\\",\\\"0xddd64b4712f7c8f1ace3c145c950339eddaf221d\\\",\\\"0x0f54f47bf9b8e317b214ccd6a7c3e38b893cd7f0\\\"]}\\n\\npersonal_lockAccount\\nPrivate : Requires authentication. Removes the private key with given address from memory. The account can no longer be used to send transactions.\\n\\n\", \"Title: personal_listAccounts\\nLink: https://evm.cosmos.network/docs/evm/v0.4.x/api-reference/ethereum-json-rpc/methods\\nContent: Private : Requires authentication. Returns a list of addresses for accounts this node manages.\\n\\nPrivate : Requires authentication. Returns a list of addresses for accounts this node manages. // Request\\ncurl -X POST --data '{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"method\\\":\\\"personal_listAccounts\\\",\\\"params\\\":[],\\\"id\\\":1}' -H \\\"Content-Type: application/json\\\" http://localhost:8545\\n// Result\\n{\\\"jsonrpc\\\":\\\"2.0\\\",\\\"id\\\":1,\\\"result\\\":[\\\"0x3b7252d007059ffc82d16d022da3cbf9992d2f70\\\",\\\"0xddd64b4712f7c8f1ace3c145c950339eddaf221d\\\",\\\"0x0f54f47bf9b8e317b214ccd6a7c3e38b893cd7f0\\\"]}\\n\\npersonal_lockAccount\\nPrivate : Requires authentication. Removes the private key with given address from memory. The account can no longer be used to send transactions.\\n\\n\", \"Title: Cosmos Blockchain Simulator\\nLink: https://evm.cosmos.network/docs/sdk/v0.53/learn/advanced/simulation\\nContent: The Cosmos SDK offers a full fledged simulation framework to fuzz test every\\nmessage defined by a module. On the Cosmos SDK, this functionality is provided by SimApp , which is a\\nBaseapp application that is used for running the simulation module.\\nThis module defines all the simulation logic as well as the operations for\\nrandomized parameters like accounts, balances etc.\\n\\nThe Cosmos SDK offers a full fledged simulation framework to fuzz test every message defined by a module.\\n\\nUse simulation in your Cosmos SDK-based application\\nLearn how you can build the simulation into your Cosmos SDK-based application: Application Simulation Manager Building modules: Simulator Simulator tests\\n\\n\", \"Title: Cosmos Blockchain Simulator\\nLink: https://evm.cosmos.network/docs/sdk/v0.50/learn/advanced/simulation\\nContent: The Cosmos SDK offers a full fledged simulation framework to fuzz test every\\nmessage defined by a module. On the Cosmos SDK, this functionality is provided by SimApp , which is a\\nBaseapp application that is used for running the simulation module.\\nThis module defines all the simulation logic as well as the operations for\\nrandomized parameters like accounts, balances etc.\\n\\nThe Cosmos SDK offers a full fledged simulation framework to fuzz test every message defined by a module.\\n\\nUse simulation in your Cosmos SDK-based application\\nLearn how you can build the simulation into your Cosmos SDK-based application: Application Simulation Manager Building modules: Simulator Simulator tests\\n\\n\", \"Title: Cosmos Blockchain Simulator\\nLink: https://evm.cosmos.network/docs/sdk/v0.47/learn/advanced/simulation\\nContent: The Cosmos SDK offers a full fledged simulation framework to fuzz test every\\nmessage defined by a module. On the Cosmos SDK, this functionality is provided by SimApp , which is a\\nBaseapp application that is used for running the simulation module.\\nThis module defines all the simulation logic as well as the operations for\\nrandomized parameters like accounts, balances etc.\\n\\nThe Cosmos SDK offers a full fledged simulation framework to fuzz test every message defined by a module.\\n\\nUse simulation in your Cosmos SDK-based application\\nLearn how you can integrate the simulation into your Cosmos SDK-based application: Application Simulation Manager Building modules: Simulator Simulator tests\\n\\n\", \"Title: What is the Cosmos SDK\\nLink: https://evm.cosmos.network/docs/sdk/v0.47/learn/intro/overview\\nContent: The Cosmos SDK is an open-source framework for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains. We envision the Cosmos SDK as the npm-like framework to build secure blockchain applications on top of CometBFT . SDK-based blockchains are built out of composable modules , most of which are open-source and readily available for any developers to use. Anyone can create a module for the Cosmos SDK, and integrating already-built modules is as simple as importing them into your blockchain application. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model.\\n\\nWhat is the Cosmos SDK\\nThe Cosmos SDK is an open-source framework for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains. We envision the Cosmos SDK as the npm-like framework to build secure blockchain applications on top of CometBFT . SDK-based blockchains are built out of composable modules , most of which are open-source and readily available for any developers to use. Anyone can create a module for the Cosmos SDK, and integrating already-built modules is as simple as importing them into your blockchain application. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model.\\n\\nWhy the Cosmos SDK\\nThe Cosmos SDK is the most advanced framework for building custom application-specific blockchains today. Here are a few reasons why you might want to consider building your decentralized application with the Cosmos SDK: The default consensus engine available within the Cosmos SDK is CometBFT . CometBFT is the most (and only) mature BFT consensus engine in existence. It is widely used across the industry and is considered the gold standard consensus engine for building Proof-of-Stake systems. The Cosmos SDK is open-source and designed to make it easy to build blockchains out of composable modules . As the ecosystem of open-source Cosmos SDK modules grows, it will become increasingly easier to build complex decentralized platforms with it. The Cosmos SDK is inspired by capabilities-based security, and informed by years of wrestling with blockchain state-machines. This makes the Cosmos SDK a very secure environment to build blockchains. Most importantly, the Cosmos SDK has already been used to build many application-specific blockchains that are already in production. Among others, we can cite Cosmos Hub , IRIS Hub , Binance Chain , Terra or Kava . Many more are building on the Cosmos SDK.\\n\\n\", \"Title: What is the Cosmos SDK\\nLink: https://evm.cosmos.network/docs/sdk/v0.53/learn/intro/overview\\nContent: The Cosmos SDK is an open-source toolkit for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains.\\nWe further this modular approach by allowing developers to plug and play with different consensus engines this can range from the CometBFT or Rollkit. SDK-based blockchains have the choice to use the predefined modules or to build their own modules. What this means is that developers can build a blockchain that is tailored to their specific use case, without having to worry about the low-level details of building a blockchain from scratch. Predefined modules include staking, governance, and token issuance, among others. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model. How you can look at this is if we imagine that the SDK is like a lego kit. You can choose to build the basic house from the instructions or you can choose to modify your house and add more floors, more doors, more windows. The choice is yours.\\n\\nWhat is the Cosmos SDK\\nThe Cosmos SDK is an open-source toolkit for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains.\\nWe further this modular approach by allowing developers to plug and play with different consensus engines this can range from the CometBFT or Rollkit. SDK-based blockchains have the choice to use the predefined modules or to build their own modules. What this means is that developers can build a blockchain that is tailored to their specific use case, without having to worry about the low-level details of building a blockchain from scratch. Predefined modules include staking, governance, and token issuance, among others. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model. How you can look at this is if we imagine that the SDK is like a lego kit. You can choose to build the basic house from the instructions or you can choose to modify your house and add more floors, more doors, more windows. The choice is yours.\\n\\nWhy the Cosmos SDK\\nThe Cosmos SDK is the most advanced framework for building custom modular application-specific blockchains today. Here are a few reasons why you might want to consider building your decentralized application with the Cosmos SDK: It allows you to plug and play and customize your consensus layer. As above you can use Rollkit and Celestia as your consensus and data availability layer. This offers a lot of flexibility and customisation. Previously the default consensus engine available within the Cosmos SDK is CometBFT . CometBFT is the most (and only) mature BFT consensus engine in existence. It is widely used across the industry and is considered the gold standard consensus engine for building Proof-of-Stake systems. The Cosmos SDK is open-source and designed to make it easy to build blockchains out of composable modules . As the ecosystem of open-source Cosmos SDK modules grows, it will become increasingly easier to build complex decentralized platforms with it. The Cosmos SDK is inspired by capabilities-based security, and informed by years of wrestling with blockchain state-machines. This makes the Cosmos SDK a very secure environment to build blockchains. Most importantly, the Cosmos SDK has already been used to build many application-specific blockchains that are already in production. Among others, we can cite Cosmos Hub , IRIS Hub , Binance Chain , Terra or Kava . Many more are building on the Cosmos SDK.\\n\\n\", \"Title: What is the Cosmos SDK\\nLink: https://evm.cosmos.network/docs/sdk/v0.50/learn/intro/overview\\nContent: The Cosmos SDK is an open-source toolkit for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains.\\nWe further this modular approach by allowing developers to plug and play with different consensus engines this can range from the CometBFT or Rollkit. SDK-based blockchains have the choice to use the predefined modules or to build their own modules. What this means is that developers can build a blockchain that is tailored to their specific use case, without having to worry about the low-level details of building a blockchain from scratch. Predefined modules include staking, governance, and token issuance, among others. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model. How you can look at this is if we imagine that the SDK is like a lego kit. You can choose to build the basic house from the instructions or you can choose to modify your house and add more floors, more doors, more windows. The choice is yours.\\n\\nWhat is the Cosmos SDK\\nThe Cosmos SDK is an open-source toolkit for building multi-asset public Proof-of-Stake (PoS) blockchains , like the Cosmos Hub, as well as permissioned Proof-of-Authority (PoA) blockchains. Blockchains built with the Cosmos SDK are generally referred to as application-specific blockchains. The goal of the Cosmos SDK is to allow developers to easily create custom blockchains from scratch that can natively interoperate with other blockchains.\\nWe further this modular approach by allowing developers to plug and play with different consensus engines this can range from the CometBFT or Rollkit. SDK-based blockchains have the choice to use the predefined modules or to build their own modules. What this means is that developers can build a blockchain that is tailored to their specific use case, without having to worry about the low-level details of building a blockchain from scratch. Predefined modules include staking, governance, and token issuance, among others. What's more, the Cosmos SDK is a capabilities-based system that allows developers to better reason about the security of interactions between modules. For a deeper look at capabilities, jump to Object-Capability Model. How you can look at this is if we imagine that the SDK is like a lego kit. You can choose to build the basic house from the instructions or you can choose to modify your house and add more floors, more doors, more windows. The choice is yours.\\n\\nWhy the Cosmos SDK\\nThe Cosmos SDK is the most advanced framework for building custom modular application-specific blockchains today. Here are a few reasons why you might want to consider building your decentralized application with the Cosmos SDK: It allows you to plug and play and customize your consensus layer. As above you can use Rollkit and Celestia as your consensus and data availability layer. This offers a lot of flexibility and customisation. Previously the default consensus engine available within the Cosmos SDK is CometBFT . CometBFT is the most (and only) mature BFT consensus engine in existence. It is widely used across the industry and is considered the gold standard consensus engine for building Proof-of-Stake systems. The Cosmos SDK is open-source and designed to make it easy to build blockchains out of composable modules . As the ecosystem of open-source Cosmos SDK modules grows, it will become increasingly easier to build complex decentralized platforms with it. The Cosmos SDK is inspired by capabilities-based security, and informed by years of wrestling with blockchain state-machines. This makes the Cosmos SDK a very secure environment to build blockchains. Most importantly, the Cosmos SDK has already been used to build many application-specific blockchains that are already in production. Among others, we can cite Cosmos Hub , IRIS Hub , Binance Chain , Terra or Kava . Many more are building on the Cosmos SDK.\\n\\n\", \"Title: Main Components of the Cosmos SDK\\nLink: https://evm.cosmos.network/docs/sdk/v0.53/learn/intro/sdk-design\\nContent: The Cosmos SDK is a framework that facilitates the development of secure state-machines on top of CometBFT. At its core, the Cosmos SDK is a boilerplate implementation of the ABCI in Golang. It comes with a multistore to persist data and a router to handle transactions. Here is a simplified view of how transactions are handled by an application built on top of the Cosmos SDK when transferred from CometBFT via DeliverTx: Decode transactions received from the CometBFT consensus engine (remember that CometBFT only deals with []bytes ). Extract messages from transactions and do basic sanity checks. Route each message to the appropriate module so that it can be processed. Commit state changes.\\n\\nMain Components of the Cosmos SDK\\nThe Cosmos SDK is a framework that facilitates the development of secure state-machines on top of CometBFT. At its core, the Cosmos SDK is a boilerplate implementation of the ABCI in Golang. It comes with a multistore to persist data and a router to handle transactions. Here is a simplified view of how transactions are handled by an application built on top of the Cosmos SDK when transferred from CometBFT via DeliverTx: Decode transactions received from the CometBFT consensus engine (remember that CometBFT only deals with []bytes ). Extract messages from transactions and do basic sanity checks. Route each message to the appropriate module so that it can be processed. Commit state changes.\\n\\nModules\\nThe power of the Cosmos SDK lies in its modularity. Cosmos SDK applications are built by aggregating a collection of interoperable modules. Each module defines a subset of the state and contains its own message/transaction processor, while the Cosmos SDK is responsible for routing each message to its respective module. Here is a simplified view of how a transaction is processed by the application of each full-node when it is received in a valid block: flowchart TD\\n    A[Transaction relayed from the full-node's CometBFT engine to the node's application via DeliverTx] --> B[APPLICATION]\\n    B -->|\\\"Using baseapp's methods: Decode the Tx, extract and route the message(s)\\\"| C[Message routed to the correct module to be processed]\\n    C --> D1[AUTH MODULE]\\n    C --> D2[BANK MODULE]\\n    C --> D3[STAKING MODULE]\\n    C --> D4[GOV MODULE]\\n    D1 -->|Handle message, Update state| E[\\\"Return result to CometBFT (0=Ok, 1=Err)\\\"]\\n    D2 -->|Handle message, Update state| E[\\\"Return result to CometBFT (0=Ok, 1=Err)\\\"]\\n    D3 -->|Handle message, Update state| E[\\\"Return result to CometBFT (0=Ok, 1=Err)\\\"]\\n    D4 -->|Handle message, Update state| E[\\\"Return result to CometBFT (0=Ok, 1=Err)\\\"]\\n\\n\", \"Title: Main Components of the Cosmos SDK\\nLink: https://evm.cosmos.network/docs/sdk/v0.50/learn/intro/sdk-design\\nContent: The Cosmos SDK is a framework that facilitates the development of secure state-machines on top of CometBFT. At its core, the Cosmos SDK is a boilerplate implementation of the ABCI in Golang. It comes with a multistore to persist data and a router to handle transactions. Here is a simplified view of how transactions are handled by an application built on top of the Cosmos SDK when transferred from CometBFT via DeliverTx: Decode transactions received from the CometBFT consensus engine (remember that CometBFT only deals with []bytes ). Extract messages from transactions and do basic sanity checks. Route each message to the appropriate module so that it can be processed. Commit state changes.\\n\\nMain Components of the Cosmos SDK\\nThe Cosmos SDK is a framework that facilitates the development of secure state-machines on top of CometBFT. At its core, the Cosmos SDK is a boilerplate implementation of the ABCI in Golang. It comes with a multistore to persist data and a router to handle transactions. Here is a simplified view of how transactions are handled by an application built on top of the Cosmos SDK when transferred from CometBFT via DeliverTx: Decode transactions received from the CometBFT consensus engine (remember that CometBFT only deals with []bytes ). Extract messages from transactions and do basic sanity checks. Route each message to the appropriate module so that it can be processed. Commit state changes.\\n\\nModules\\nThe power of the Cosmos SDK lies in its modularity. Cosmos SDK applications are built by aggregating a collection of interoperable modules. Each module defines a subset of the state and contains its own message/transaction processor, while the Cosmos SDK is responsible for routing each message to its respective module. Here is a simplified view of how a transaction is processed by the application of each full-node when it is received in a valid block: Each module can be seen as a little state-machine. Developers need to define the subset of the state handled by the module, as well as custom message types that modify the state ( Note: messages are extracted from transactions by baseapp ). In general, each module declares its own KVStore in the multistore to persist the subset of the state it defines. Most developers will need to access other 3rd party modules when building their own modules. Given that the Cosmos SDK is an open framework, some of the modules may be malicious, which means there is a need for security principles to reason about inter-module interactions. These principles are based on object-capabilities . In practice, this means that instead of having each module keep an access control list for other modules, each module implements special objects called keepers that can be passed to other modules to grant a pre-defined set of capabilities. Cosmos SDK modules are defined in the x/ folder of the Cosmos SDK. Some core modules include: x/auth : Used to manage accounts and signatures. x/bank : Used to enable tokens and token transfers. x/staking + x/slashing : Used to build Proof-Of-Stake blockchains. In addition to the already existing modules in x/ , that anyone can use in their app, the Cosmos SDK lets you build your own custom modules. You can check an example of that in the tutorial.\\n\\n\"]",
            "additional_kwargs": {},
            "response_metadata": {},
            "type": "tool",
            "name": "SearchCosmosDocumentation",
            "id": "b8ab9990-fe33-456b-8acc-38ff08171c36",
            "tool_call_id": "call_ifterLKWSxydzqpqLm8suPBU",
            "artifact": null,
            "status": "success"
        },
        {
            "content": "[\n  {\n    \"intent\": \"Get an account Merkle proof at a specific block (eth_getProof)\",\n    \"workflow\": [\n      {\n        \"step\": 1,\n        \"tool\": \"validate_eth_address\",\n        \"description\": \"Confirm the supplied account address is a valid 0x-prefixed, 20-byte EVM address.\"\n      },\n      {\n        \"step\": 2,\n        \"tool\": \"validate_block_height\",\n        \"description\": \"Verify the given block number (e.g. 0x1) is \u2265 0x1, because Cosmos EVM rejects heights < 1.\"\n      },\n      {\n        \"step\": 3,\n        \"tool\": \"construct_json_rpc_payload\",\n        \"description\": \"Build the JSON-RPC body:\\n{\\n  \\\"jsonrpc\\\":\\\"2.0\\\",\\n  \\\"method\\\":\\\"eth_getProof\\\",\\n  \\\"params\\\":[\\\"<account>\\\",[],\\\"0x1\\\"],\\n  \\\"id\\\":1\\n}\"\n      },\n      {\n        \"step\": 4,\n        \"tool\": \"http_post_rpc\",\n        \"description\": \"POST the payload to the node\u2019s HTTP RPC endpoint (default http://localhost:8545).\"\n      },\n      {\n        \"step\": 5,\n        \"tool\": \"parse_rpc_response\",\n        \"description\": \"Decode the result, returning account proof fields (balance, nonce, storageHash, codeHash, and proof array).\"\n      }\n    ],\n    \"outcome_checks\": [\n      \"HTTP 200 status with a non-null result field.\",\n      \"Result.proof array length > 0 (Merkle proof present).\",\n      \"No error object in the JSON-RPC response.\"\n    ]\n  },\n  {\n    \"intent\": \"Create a new pending-transaction filter (eth_newPendingTransactionFilter)\",\n    \"workflow\": [\n      {\n        \"step\": 1,\n        \"tool\": \"construct_json_rpc_payload\",\n        \"description\": \"Create the JSON-RPC body:\\n{\\n  \\\"jsonrpc\\\":\\\"2.0\\\",\\n  \\\"method\\\":\\\"eth_newPendingTransactionFilter\\\",\\n  \\\"params\\\":[],\\n  \\\"id\\\":1\\n}\"\n      },\n      {\n        \"step\": 2,\n        \"tool\": \"http_post_rpc\",\n        \"description\": \"POST the payload to the HTTP RPC endpoint.\"\n      },\n      {\n        \"step\": 3,\n        \"tool\": \"parse_rpc_response\",\n        \"description\": \"Extract the returned filter ID (hex string).\"\n      },\n      {\n        \"step\": 4,\n        \"tool\": \"store_filter_id\",\n        \"description\": \"Persist the filter ID locally for later use with eth_getFilterChanges or eth_uninstallFilter.\"\n      }\n    ],\n    \"outcome_checks\": [\n      \"Response result starts with \\\"0x\\\" and is 32 hex chars (typical filter ID).\",\n      \"No error field present.\"\n    ]\n  },\n  {\n    \"intent\": \"Fetch changes for an existing pending-transaction filter (eth_getFilterChanges)\",\n    \"workflow\": [\n      {\n        \"step\": 1,\n        \"tool\": \"retrieve_filter_id\",\n        \"description\": \"Load the previously stored filter ID that tracks pending transactions.\"\n      },\n      {\n        \"step\": 2,\n        \"tool\": \"construct_json_rpc_payload\",\n        \"description\": \"Build the JSON-RPC body:\\n{\\n  \\\"jsonrpc\\\":\\\"2.0\\\",\\n  \\\"method\\\":\\\"eth_getFilterChanges\\\",\\n  \\\"params\\\":[\\\"<filterId>\\\"],\\n  \\\"id\\\":1\\n}\"\n      },\n      {\n        \"step\": 3,\n        \"tool\": \"http_post_rpc\",\n        \"description\": \"POST the payload to the node\u2019s HTTP RPC endpoint.\"\n      },\n      {\n        \"step\": 4,\n        \"tool\": \"parse_rpc_response\",\n        \"description\": \"Return an array of pending-transaction hashes that arrived since the last poll.\"\n      }\n    ],\n    \"outcome_checks\": [\n      \"Result is an array (possibly empty) of 0x-prefixed 32-byte hashes.\",\n      \"No error object present in the response.\"\n    ]\n  },\n  {\n    \"intent\": \"Unsubscribe from a WebSocket subscription (eth_unsubscribe)\",\n    \"workflow\": [\n      {\n        \"step\": 1,\n        \"tool\": \"websocket_connect\",\n        \"description\": \"Open (or reuse) a WebSocket connection to ws://<node>:8546.\"\n      },\n      {\n        \"step\": 2,\n        \"tool\": \"retrieve_subscription_id\",\n        \"description\": \"Fetch the active WebSocket subscription ID to cancel.\"\n      },\n      {\n        \"step\": 3,\n        \"tool\": \"send_ws_message\",\n        \"description\": \"Send the JSON-RPC frame:\\n{\\n  \\\"jsonrpc\\\":\\\"2.0\\\",\\n  \\\"method\\\":\\\"eth_unsubscribe\\\",\\n  \\\"params\\\":[\\\"<subscriptionId>\\\"],\\n  \\\"id\\\":1\\n}\"\n      },\n      {\n        \"step\": 4,\n        \"tool\": \"await_ws_response\",\n        \"description\": \"Wait for the confirmation message from the node.\"\n      }\n    ],\n    \"outcome_checks\": [\n      \"Response.result is true, indicating the subscription was removed.\",\n      \"No further events are received for that subscription ID.\"\n    ]\n  },\n  {\n    \"intent\": \"List personal accounts managed by the node (personal_listAccounts)\",\n    \"workflow\": [\n      {\n        \"step\": 1,\n        \"tool\": \"authenticate_rpc\",\n        \"description\": \"Attach HTTP basic auth header or JWT if the node\u2019s personal namespace requires authentication.\"\n      },\n      {\n        \"step\": 2,\n        \"tool\": \"construct_json_rpc_payload\",\n        \"description\": \"Create the JSON-RPC body:\\n{\\n  \\\"jsonrpc\\\":\\\"2.0\\\",\\n  \\\"method\\\":\\\"personal_listAccounts\\\",\\n  \\\"params\\\":[],\\n  \\\"id\\\":1\\n}\"\n      },\n      {\n        \"step\": 3,\n        \"tool\": \"http_post_rpc\",\n        \"description\": \"POST the payload to the HTTP RPC endpoint.\"\n      },\n      {\n        \"step\": 4,\n        \"tool\": \"parse_rpc_response\",\n        \"description\": \"Return the array of addresses the node controls.\"\n      }\n    ],\n    \"outcome_checks\": [\n      \"Result is an array (possibly empty) of valid 0x-prefixed addresses.\",\n      \"No error object; if authentication fails, the node should return an error which must be handled.\"\n    ]\n  }\n]",
            "additional_kwargs": {
                "refusal": null
            },
            "response_metadata": {
                "token_usage": {
                    "completion_tokens": 2106,
                    "prompt_tokens": 64432,
                    "total_tokens": 66538,
                    "completion_tokens_details": {
                        "accepted_prediction_tokens": 0,
                        "audio_tokens": 0,
                        "reasoning_tokens": 704,
                        "rejected_prediction_tokens": 0
                    },
                    "prompt_tokens_details": {
                        "audio_tokens": 0,
                        "cached_tokens": 58880
                    }
                },
                "model_name": "o3-2025-04-16",
                "system_fingerprint": null,
                "id": "chatcmpl-CPw0knGkpKIkfBFE1GKmY83tfSOB1",
                "service_tier": "default",
                "finish_reason": "stop",
                "logprobs": null
            },
            "type": "ai",
            "name": null,
            "id": "run--c7a16516-00b0-4814-834a-2da6029a536f-0",
            "example": false,
            "tool_calls": [],
            "invalid_tool_calls": [],
            "usage_metadata": {
                "input_tokens": 64432,
                "output_tokens": 2106,
                "total_tokens": 66538,
                "input_token_details": {
                    "audio": 0,
                    "cache_read": 58880
                },
                "output_token_details": {
                    "audio": 0,
                    "reasoning": 704
                }
            }
        }
    ]
}