{
    "label": "others",
    "workflow": [
        {
            "step": 1,
            "label": "backend",
            "introduction": "Step 1 defines a backend helper to resolve the 'republic' label into a concrete Republic chain configuration (REST/RPC/indexer endpoints) that later steps will reuse.",
            "code": "from dataclasses import dataclass\nfrom typing import Optional, Dict\nimport os\n\nclass NetworkResolutionError(Exception):\n    # Raised when a network label cannot be resolved to a configuration.\n    pass\n\n@dataclass\nclass NetworkConfig:\n    label: str\n    chain_id: str\n    rest_endpoint: str\n    rpc_endpoint: Optional[str] = None\n    indexer_endpoint: Optional[str] = None\n\n# Static mapping; endpoints are placeholders and should be overridden via environment variables in production.\n_DEFAULT_NETWORKS: Dict[str, NetworkConfig] = {\n    'republic': NetworkConfig(\n        label='republic',\n        chain_id=os.getenv('REPUBLIC_CHAIN_ID', 'republic-1'),\n        rest_endpoint=os.getenv(\n            'REPUBLIC_REST_ENDPOINT',\n            'https://api.republic.network',  # placeholder REST endpoint\n        ),\n        rpc_endpoint=os.getenv(\n            'REPUBLIC_RPC_ENDPOINT',\n            'https://rpc.republic.network',  # placeholder RPC endpoint\n        ),\n        indexer_endpoint=os.getenv(\n            'REPUBLIC_INDEXER_ENDPOINT',\n            'https://indexer.republic.network',  # optional indexer endpoint\n        ),\n    ),\n}\n\ndef resolve_network_from_label(label: str) -> NetworkConfig:\n    '''\n    Map a human-friendly network label (for example, 'republic') to a concrete\n    Republic chain configuration (REST/RPC endpoints and optional indexer).\n    '''\n    if not label:\n        raise NetworkResolutionError('Network label must be a non-empty string.')\n\n    normalized = label.strip().lower()\n    config = _DEFAULT_NETWORKS.get(normalized)\n    if not config:\n        raise NetworkResolutionError(\n            f'Unknown network label {label}. Extend _DEFAULT_NETWORKS or configure it dynamically.'\n        )\n\n    # Optionally, you could clone and override fields here if needed.\n    return config\n",
            "usage": "from your_module import resolve_network_from_label\n\nnetwork = resolve_network_from_label('republic')\nprint(network.rest_endpoint)"
        },
        {
            "step": 2,
            "label": "backend",
            "introduction": "Step 2 implements an async backend function that queries the Republic chain's staking module to fetch all validators with pagination.",
            "code": "import httpx\nfrom typing import Any, Dict, List, Optional\n\nclass RepublicQueryError(Exception):\n    # Raised when a query to the Republic REST API fails.\n    pass\n\nasync def query_republic_validators(\n    network: NetworkConfig,\n    status: str = 'BOND_STATUS_BONDED',\n    page_size: int = 100,\n) -> List[Dict[str, Any]]:\n    '''\n    Retrieve the complete set of validators from the Republic chain.\n\n    This function queries the Cosmos SDK staking module REST endpoint with\n    pagination until all validators are fetched.\n    '''\n    if not network.rest_endpoint:\n        raise RepublicQueryError('REST endpoint is not configured for this network.')\n\n    validators: List[Dict[str, Any]] = []\n    next_key: Optional[str] = None\n\n    try:\n        async with httpx.AsyncClient(base_url=network.rest_endpoint, timeout=10.0) as client:\n            while True:\n                params: Dict[str, Any] = {\n                    'status': status,\n                    'pagination.limit': str(page_size),\n                }\n                if next_key:\n                    params['pagination.key'] = next_key\n\n                resp = await client.get('/cosmos/staking/v1beta1/validators', params=params)\n                resp.raise_for_status()\n                data = resp.json()\n\n                page_validators = data.get('validators', [])\n                validators.extend(page_validators)\n\n                pagination = data.get('pagination', {}) or {}\n                next_key = pagination.get('next_key')\n                if not next_key:\n                    break\n    except httpx.HTTPError as e:\n        raise RepublicQueryError(f'Failed to query validators: {e}') from e\n    except Exception as e:\n        raise RepublicQueryError(f'Unexpected error while querying validators: {e}') from e\n\n    return validators\n",
            "usage": "import asyncio\n\nfrom your_module import resolve_network_from_label, query_republic_validators\n\nasync def main():\n    network = resolve_network_from_label('republic')\n    validators = await query_republic_validators(network)\n    print(f'Fetched {len(validators)} validators')\n\nasyncio.run(main())"
        },
        {
            "step": 3,
            "label": "backend",
            "introduction": "Step 3 adds a backend function that walks staking delegations for each validator and attaches a total_stake_urep (micro-REP) field.",
            "code": "import os\nimport httpx\nfrom typing import Any, Dict, List, Optional\n\nREP_DENOM = os.getenv('REPUBLIC_STAKE_DENOM', 'urep')\n\nasync def attach_validator_stake_totals(\n    network: NetworkConfig,\n    validators: List[Dict[str, Any]],\n    page_size: int = 100,\n) -> List[Dict[str, Any]]:\n    '''\n    For each validator, query staking data (self-bond plus delegations) and\n    attach a total delegated stake field in micro-REP (urep) under\n    the key 'total_stake_urep'.\n    '''\n    if not validators:\n        return validators\n\n    if not network.rest_endpoint:\n        raise RepublicQueryError('REST endpoint is not configured for this network.')\n\n    enriched: List[Dict[str, Any]] = []\n\n    async with httpx.AsyncClient(base_url=network.rest_endpoint, timeout=10.0) as client:\n        for validator in validators:\n            operator_address = validator.get('operator_address')\n            validator_copy = dict(validator)\n\n            if not operator_address:\n                # If we cannot identify the operator, set stake to zero and continue.\n                validator_copy['total_stake_urep'] = 0\n                enriched.append(validator_copy)\n                continue\n\n            total_stake = 0\n            next_key: Optional[str] = None\n\n            try:\n                while True:\n                    params: Dict[str, Any] = {\n                        'pagination.limit': str(page_size),\n                    }\n                    if next_key:\n                        params['pagination.key'] = next_key\n\n                    url = f'/cosmos/staking/v1beta1/validators/{operator_address}/delegations'\n                    resp = await client.get(url, params=params)\n                    resp.raise_for_status()\n                    data = resp.json()\n\n                    for delegation in data.get('delegation_responses', []) or []:\n                        balance = delegation.get('balance') or {}\n                        if balance.get('denom') != REP_DENOM:\n                            continue\n                        amount_str = balance.get('amount') or '0'\n                        try:\n                            total_stake += int(amount_str)\n                        except ValueError:\n                            # Skip malformed amounts rather than failing the whole request.\n                            continue\n\n                    pagination = data.get('pagination', {}) or {}\n                    next_key = pagination.get('next_key')\n                    if not next_key:\n                        break\n            except httpx.HTTPError as e:\n                raise RepublicQueryError(\n                    f'Failed to query delegations for validator {operator_address}: {e}'\n                ) from e\n            except Exception as e:\n                raise RepublicQueryError(\n                    f'Unexpected error while computing stake for validator {operator_address}: {e}'\n                ) from e\n\n            validator_copy['total_stake_urep'] = total_stake\n            enriched.append(validator_copy)\n\n    return enriched\n",
            "usage": "import asyncio\n\nfrom your_module import resolve_network_from_label, query_republic_validators, attach_validator_stake_totals\n\nasync def main():\n    network = resolve_network_from_label('republic')\n    validators = await query_republic_validators(network)\n    validators_with_stake = await attach_validator_stake_totals(network, validators)\n    print(validators_with_stake[0]['operator_address'], validators_with_stake[0]['total_stake_urep'])\n\nasyncio.run(main())"
        },
        {
            "step": 4,
            "label": "backend",
            "introduction": "Step 4 queries Republic's compute validation or benchmark registry to attach throughput, inference, and achieved FLOPs metrics to each validator.",
            "code": "import httpx\nfrom typing import Any, Dict, List, Optional\n\nasync def attach_compute_benchmarks(\n    network: NetworkConfig,\n    validators: List[Dict[str, Any]],\n) -> List[Dict[str, Any]]:\n    '''\n    Fetch each validator's latest compute benchmark results from Republic's\n    compute validation or benchmark registry and attach them under\n    a 'benchmarks' key.\n    '''\n    if not validators:\n        return validators\n\n    base_url = network.indexer_endpoint or network.rest_endpoint\n    if not base_url:\n        raise RepublicQueryError('No REST or indexer endpoint configured for this network.')\n\n    enriched: List[Dict[str, Any]] = []\n\n    async with httpx.AsyncClient(base_url=base_url, timeout=15.0) as client:\n        for validator in validators:\n            operator_address = validator.get('operator_address')\n            validator_copy = dict(validator)\n\n            if not operator_address:\n                validator_copy['benchmarks'] = {\n                    'throughput': None,\n                    'inference': None,\n                    'achieved_flops': None,\n                }\n                enriched.append(validator_copy)\n                continue\n\n            benchmarks: Dict[str, Optional[float]] = {\n                'throughput': None,\n                'inference': None,\n                'achieved_flops': None,\n            }\n\n            try:\n                # Assumed REST path for the compute benchmark registry.\n                path = f'/republic/compute/v1/validators/{operator_address}/benchmarks/latest'\n                resp = await client.get(path)\n                if resp.status_code == 404:\n                    # No benchmarks available yet for this validator.\n                    validator_copy['benchmarks'] = benchmarks\n                    enriched.append(validator_copy)\n                    continue\n\n                resp.raise_for_status()\n                data = resp.json() or {}\n\n                # The actual response shape may vary; try to be defensive.\n                payload = data.get('benchmark') or data\n\n                def _extract_metric(key: str) -> Optional[float]:\n                    value = payload.get(key)\n                    if isinstance(value, dict):\n                        value = value.get('score')\n                    if value is None:\n                        return None\n                    try:\n                        return float(value)\n                    except (TypeError, ValueError):\n                        return None\n\n                benchmarks['throughput'] = _extract_metric('throughput')\n                benchmarks['inference'] = _extract_metric('inference')\n                benchmarks['achieved_flops'] = _extract_metric('achieved_flops')\n\n            except httpx.HTTPError:\n                # For compute benchmarks we degrade gracefully instead of failing the request.\n                benchmarks = {\n                    'throughput': None,\n                    'inference': None,\n                    'achieved_flops': None,\n                }\n\n            validator_copy['benchmarks'] = benchmarks\n            enriched.append(validator_copy)\n\n    return enriched\n",
            "usage": "import asyncio\n\nfrom your_module import resolve_network_from_label, query_republic_validators, attach_validator_stake_totals, attach_compute_benchmarks\n\nasync def main():\n    network = resolve_network_from_label('republic')\n    validators = await query_republic_validators(network)\n    validators = await attach_validator_stake_totals(network, validators)\n    validators = await attach_compute_benchmarks(network, validators)\n    print(validators[0]['operator_address'], validators[0]['benchmarks'])\n\nasyncio.run(main())"
        },
        {
            "step": 5,
            "label": "backend",
            "introduction": "Step 5 provides a pure-Python backend utility that normalizes each validator's benchmark metrics and computes a scalar compute_performance_score.",
            "code": "from typing import Any, Dict, List, Optional\n\ndef compute_validator_compute_score(\n    validators: List[Dict[str, Any]],\n    weights: Optional[Dict[str, float]] = None,\n) -> List[Dict[str, Any]]:\n    '''\n    Aggregate raw benchmark metrics into a single compute_performance_score\n    for each validator.\n\n    The function performs a simple min-max normalization across validators\n    for each metric and then applies a weighted average.\n    '''\n    if not validators:\n        return validators\n\n    # Default weights: tune as needed.\n    if weights is None:\n        weights = {\n            'throughput': 0.4,\n            'inference': 0.3,\n            'achieved_flops': 0.3,\n        }\n\n    metrics = ['throughput', 'inference', 'achieved_flops']\n\n    # Collect all raw values per metric.\n    values_by_metric: Dict[str, List[float]] = {m: [] for m in metrics}\n    for v in validators:\n        bm = v.get('benchmarks') or {}\n        for m in metrics:\n            raw = bm.get(m)\n            try:\n                if raw is not None:\n                    values_by_metric[m].append(float(raw))\n            except (TypeError, ValueError):\n                # Ignore non-numeric values.\n                continue\n\n    # Compute min and max for each metric.\n    ranges: Dict[str, Dict[str, float]] = {}\n    for m in metrics:\n        values = values_by_metric[m]\n        if not values:\n            ranges[m] = {'min': 0.0, 'max': 0.0}\n        else:\n            ranges[m] = {'min': min(values), 'max': max(values)}\n\n    enriched: List[Dict[str, Any]] = []\n\n    for v in validators:\n        bm = v.get('benchmarks') or {}\n        score_sum = 0.0\n        weight_sum = 0.0\n\n        for m in metrics:\n            w = float(weights.get(m, 0.0))\n            if w <= 0.0:\n                continue\n\n            raw = bm.get(m)\n            try:\n                raw_val = float(raw) if raw is not None else None\n            except (TypeError, ValueError):\n                raw_val = None\n\n            if raw_val is None:\n                continue\n\n            r = ranges[m]\n            min_v = r['min']\n            max_v = r['max']\n\n            if max_v > min_v:\n                normalized = (raw_val - min_v) / (max_v - min_v)\n            else:\n                # All validators share the same value for this metric.\n                normalized = 0.5\n\n            score_sum += w * normalized\n            weight_sum += w\n\n        compute_score = score_sum / weight_sum if weight_sum > 0 else 0.0\n\n        v_copy = dict(v)\n        v_copy['compute_performance_score'] = compute_score\n        enriched.append(v_copy)\n\n    return enriched\n",
            "usage": "from your_module import compute_validator_compute_score\n\nvalidators_with_scores = compute_validator_compute_score(validators_with_benchmarks)\nprint(validators_with_scores[0]['operator_address'], validators_with_scores[0]['compute_performance_score'])"
        },
        {
            "step": 6,
            "label": "backend",
            "introduction": "Step 6 defines a backend helper to deterministically sort validators by stake, compute score, and operator address.",
            "code": "from typing import Any, Dict, List\n\ndef sort_validators(validators: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n    '''\n    Sort validators by total delegated stake (descending), then by\n    compute_performance_score (descending), and finally by operator address\n    (ascending) as a deterministic tie-breaker.\n    '''\n    def sort_key(v: Dict[str, Any]):\n        stake = int(v.get('total_stake_urep', 0) or 0)\n        score = float(v.get('compute_performance_score', 0.0) or 0.0)\n        address = v.get('operator_address') or ''\n        # Negative values for descending order on stake and score.\n        return (-stake, -score, address)\n\n    return sorted(validators, key=sort_key)\n",
            "usage": "from your_module import sort_validators\n\nsorted_validators = sort_validators(validators_with_scores)\nprint(sorted_validators[0]['operator_address'])"
        },
        {
            "step": 7,
            "label": "backend",
            "introduction": "Step 7 formats the sorted validator data into an API/UI-ready response object including operator address, moniker, stake, benchmark metrics, and the aggregate compute score.",
            "code": "from decimal import Decimal, ROUND_DOWN\nfrom typing import Any, Dict, List\n\nMICRO_REP = Decimal('1000000')\n\ndef _format_urep_to_rep(amount_urep: int) -> str:\n    '''\n    Convert an integer amount in micro-REP (urep) to a human-readable\n    REP string with 6 decimal places.\n    '''\n    rep = Decimal(amount_urep) / MICRO_REP\n    # Normalize and trim trailing zeros.\n    return format(rep.quantize(Decimal('0.000001'), rounding=ROUND_DOWN).normalize(), 'f')\n\ndef format_validator_list_response(\n    network: NetworkConfig,\n    validators: List[Dict[str, Any]],\n) -> Dict[str, Any]:\n    '''\n    Format the sorted validator list into an API or UI friendly response.\n    '''\n    formatted: List[Dict[str, Any]] = []\n\n    for rank, v in enumerate(validators, start=1):\n        total_urep = int(v.get('total_stake_urep', 0) or 0)\n        benchmarks = v.get('benchmarks') or {}\n\n        formatted.append(\n            {\n                'rank': rank,\n                'operator_address': v.get('operator_address'),\n                'moniker': (v.get('description') or {}).get('moniker'),\n                'total_delegated_stake': {\n                    'amount': str(total_urep),\n                    'denom': REP_DENOM,\n                    'display': _format_urep_to_rep(total_urep),\n                    'display_denom': 'REP',\n                },\n                'benchmarks': {\n                    'throughput': benchmarks.get('throughput'),\n                    'inference': benchmarks.get('inference'),\n                    'achieved_flops': benchmarks.get('achieved_flops'),\n                },\n                'compute_performance_score': float(\n                    v.get('compute_performance_score', 0.0) or 0.0\n                ),\n            }\n        )\n\n    return {\n        'network': {\n            'label': network.label,\n            'chain_id': network.chain_id,\n        },\n        'validators': formatted,\n    }\n",
            "usage": "import asyncio\n\nfrom your_module import (\n    resolve_network_from_label,\n    query_republic_validators,\n    attach_validator_stake_totals,\n    attach_compute_benchmarks,\n    compute_validator_compute_score,\n    sort_validators,\n    format_validator_list_response,\n)\n\nasync def main():\n    network = resolve_network_from_label('republic')\n    validators = await query_republic_validators(network)\n    validators = await attach_validator_stake_totals(network, validators)\n    validators = await attach_compute_benchmarks(network, validators)\n    validators = compute_validator_compute_score(validators)\n    validators = sort_validators(validators)\n    response = format_validator_list_response(network, validators)\n    print(response)\n\nasyncio.run(main())"
        }
    ]
}