{
    "label": "others",
    "workflow": [
        {
            "step": 1,
            "label": "backend",
            "introduction": "Step 1 defines a backend helper that derives an analysis epoch window from frontend request parameters, defaulting to a recent bounded range when the user provides no explicit window.",
            "code": "import os\nfrom typing import Any, Dict\n\nimport httpx\n\nANALYTICS_BASE_URL = os.getenv('REPUBLIC_ANALYTICS_BASE_URL', 'https://analytics.republic.local')\nDEFAULT_WINDOW_EPOCHS = 500\nMAX_WINDOW_EPOCHS = 2000\n\n\nclass AnalysisWindowError(Exception):\n    pass\n\n\nasync def fetch_latest_epoch() -> int:\n    '''\n    Query the Republic analytics service for the latest known epoch id.\n    '''\n    url = f'{ANALYTICS_BASE_URL}/epochs/latest'\n    try:\n        async with httpx.AsyncClient(timeout=10.0) as client:\n            response = await client.get(url)\n        response.raise_for_status()\n        data = response.json()\n    except httpx.HTTPError as exc:\n        raise AnalysisWindowError(f'Failed to fetch latest epoch from analytics service: {exc}') from exc\n\n    epoch_value = data.get('epoch_id')\n    if epoch_value is None:\n        raise AnalysisWindowError('Analytics response did not contain an epoch_id field')\n\n    try:\n        return int(epoch_value)\n    except (TypeError, ValueError) as exc:\n        raise AnalysisWindowError(f'Invalid epoch_id value in analytics response: {epoch_value}') from exc\n\n\nasync def derive_analysis_window_from_request(params: Dict[str, Any]) -> Dict[str, int]:\n    '''\n    Determine the epoch analysis window from frontend supplied parameters.\n\n    Supported parameters in params:\n      - start_epoch: optional int\n      - end_epoch: optional int\n      - window_size_epochs: optional int, number of epochs in the window\n\n    If no explicit window is given, the function defaults to the most recent\n    DEFAULT_WINDOW_EPOCHS, but will never exceed MAX_WINDOW_EPOCHS.\n    '''\n    requested_start = params.get('start_epoch')\n    requested_end = params.get('end_epoch')\n    window_size = params.get('window_size_epochs')\n\n    # Resolve end epoch if missing.\n    if requested_end is None:\n        latest_epoch = await fetch_latest_epoch()\n        requested_end = latest_epoch\n\n    # Resolve start epoch if missing.\n    if requested_start is None:\n        if window_size is None:\n            window_size = DEFAULT_WINDOW_EPOCHS\n        try:\n            window_size_int = int(window_size)\n        except (TypeError, ValueError) as exc:\n            raise AnalysisWindowError(f'Invalid window_size_epochs value: {window_size}') from exc\n\n        # Enforce upper bound.\n        window_size_int = max(1, min(window_size_int, MAX_WINDOW_EPOCHS))\n        requested_start = int(requested_end) - window_size_int + 1\n\n    # Clamp start_epoch to zero or above.\n    try:\n        start_epoch = max(0, int(requested_start))\n        end_epoch = int(requested_end)\n    except (TypeError, ValueError) as exc:\n        raise AnalysisWindowError('start_epoch and end_epoch must be integers') from exc\n\n    if start_epoch > end_epoch:\n        raise AnalysisWindowError(f'start_epoch {start_epoch} is greater than end_epoch {end_epoch}')\n\n    # Enforce maximum window length.\n    span = end_epoch - start_epoch + 1\n    if span > MAX_WINDOW_EPOCHS:\n        start_epoch = end_epoch - MAX_WINDOW_EPOCHS + 1\n        span = MAX_WINDOW_EPOCHS\n\n    return {\n        'start_epoch': start_epoch,\n        'end_epoch': end_epoch,\n        'total_epochs': span,\n    }",
            "usage": "window = await derive_analysis_window_from_request({'start_epoch': 1200, 'end_epoch': 1700})"
        },
        {
            "step": 2,
            "label": "backend",
            "introduction": "Step 2 implements a backend action that pulls, from a Republic analytics or indexer service, the committee membership and reputation snapshot for each epoch in the chosen window.",
            "code": "import asyncio\nimport os\nfrom typing import Any, Dict, List\n\nimport httpx\n\n\nANALYTICS_BASE_URL = os.getenv('REPUBLIC_ANALYTICS_BASE_URL', 'https://analytics.republic.local')\nMAX_CONCURRENT_REQUESTS = 10\n\n\nclass AnalyticsServiceError(Exception):\n    pass\n\n\nasync def _fetch_epoch_validator_snapshot(client: httpx.AsyncClient, epoch_id: int) -> List[Dict[str, Any]]:\n    '''\n    Fetch committee membership and reputation scores for all validators\n    for a single epoch from the Republic analytics service.\n    '''\n    url = f'{ANALYTICS_BASE_URL}/epochs/{epoch_id}/validators'\n    try:\n        response = await client.get(url, timeout=10.0)\n        response.raise_for_status()\n        data = response.json()\n    except httpx.HTTPError as exc:\n        raise AnalyticsServiceError(f'Failed to fetch validator snapshot for epoch {epoch_id}: {exc}') from exc\n\n    validators = data.get('validators')\n    if validators is None:\n        raise AnalyticsServiceError(f'Analytics response for epoch {epoch_id} did not contain validators field')\n\n    rows: List[Dict[str, Any]] = []\n    for item in validators:\n        try:\n            validator_id = item['validator_id']\n        except KeyError:\n            # Skip malformed records.\n            continue\n\n        in_committee = bool(item.get('in_committee', False))\n        rep_raw = item.get('reputation_score')\n        try:\n            reputation_score = float(rep_raw) if rep_raw is not None else 0.0\n        except (TypeError, ValueError):\n            reputation_score = 0.0\n\n        rows.append(\n            {\n                'epoch_id': int(epoch_id),\n                'validator_id': validator_id,\n                'in_committee_flag': in_committee,\n                'reputation_score': reputation_score,\n            }\n        )\n\n    return rows\n\n\nasync def backend_republic_get_committees_with_reputation_history(\n    start_epoch: int,\n    end_epoch: int,\n) -> List[Dict[str, Any]]:\n    '''\n    Fetch, for each epoch in the given range, committee membership and\n    reputation scores for validators, and flatten into a list of rows.\n\n    Each row has the shape:\n      {\n        'epoch_id': int,\n        'validator_id': str,\n        'in_committee_flag': bool,\n        'reputation_score': float,\n      }\n    '''\n    if start_epoch > end_epoch:\n        raise ValueError('start_epoch must be less than or equal to end_epoch')\n\n    epochs = list(range(start_epoch, end_epoch + 1))\n    all_rows: List[Dict[str, Any]] = []\n\n    async with httpx.AsyncClient() as client:\n        semaphore = asyncio.Semaphore(MAX_CONCURRENT_REQUESTS)\n\n        async def task(epoch: int) -> List[Dict[str, Any]]:\n            async with semaphore:\n                try:\n                    return await _fetch_epoch_validator_snapshot(client, epoch)\n                except AnalyticsServiceError as exc:\n                    # In production, you might log this and decide whether to abort or continue.\n                    print(f'Warning: skipping epoch {epoch} due to error: {exc}')\n                    return []\n\n        tasks = [task(epoch) for epoch in epochs]\n        per_epoch_results = await asyncio.gather(*tasks, return_exceptions=False)\n\n    for epoch_rows in per_epoch_results:\n        all_rows.extend(epoch_rows)\n\n    return all_rows",
            "usage": "rows = await backend_republic_get_committees_with_reputation_history(window['start_epoch'], window['end_epoch'])"
        },
        {
            "step": 3,
            "label": "backend",
            "introduction": "Step 3 aggregates the raw per epoch rows into per validator selection statistics, computing counts and basic reputation summaries.",
            "code": "from typing import Any, Dict, List\n\n\ndef aggregate_validator_selection_frequencies(\n    epoch_rows: List[Dict[str, Any]],\n) -> List[Dict[str, Any]]:\n    '''\n    Aggregate per epoch committee data into per validator selection statistics.\n\n    Input rows must include:\n      - epoch_id: int\n      - validator_id: str\n      - in_committee_flag: bool\n      - reputation_score: float\n    '''\n    stats: Dict[str, Dict[str, Any]] = {}\n\n    for row in epoch_rows:\n        try:\n            validator_id = row['validator_id']\n            epoch_id = int(row['epoch_id'])\n        except (KeyError, TypeError, ValueError):\n            # Skip malformed entries.\n            continue\n\n        in_committee = bool(row.get('in_committee_flag', False))\n\n        rep_raw = row.get('reputation_score', 0.0)\n        try:\n            rep_score = float(rep_raw)\n        except (TypeError, ValueError):\n            rep_score = 0.0\n\n        if validator_id not in stats:\n            stats[validator_id] = {\n                'validator_id': validator_id,\n                'total_epochs_in_sample': 0,\n                'epochs_in_committee': 0,\n                'reputation_scores': [],\n                'first_epoch_in_sample': epoch_id,\n                'last_epoch_in_sample': epoch_id,\n            }\n\n        record = stats[validator_id]\n        record['total_epochs_in_sample'] += 1\n        if in_committee:\n            record['epochs_in_committee'] += 1\n        record['reputation_scores'].append(rep_score)\n        if epoch_id < record['first_epoch_in_sample']:\n            record['first_epoch_in_sample'] = epoch_id\n        if epoch_id > record['last_epoch_in_sample']:\n            record['last_epoch_in_sample'] = epoch_id\n\n    aggregated: List[Dict[str, Any]] = []\n    for validator_id, record in stats.items():\n        total_epochs = record['total_epochs_in_sample']\n        epochs_in_committee = record['epochs_in_committee']\n        if total_epochs > 0:\n            selection_frequency = epochs_in_committee / total_epochs\n        else:\n            selection_frequency = 0.0\n\n        scores = sorted(record['reputation_scores'])\n        n_scores = len(scores)\n        avg_reputation = sum(scores) / n_scores if n_scores else 0.0\n        if n_scores == 0:\n            median_reputation = 0.0\n        elif n_scores % 2 == 1:\n            median_reputation = scores[n_scores // 2]\n        else:\n            lower = scores[n_scores // 2 - 1]\n            upper = scores[n_scores // 2]\n            median_reputation = 0.5 * (lower + upper)\n\n        aggregated.append(\n            {\n                'validator_id': validator_id,\n                'total_epochs_in_sample': total_epochs,\n                'epochs_in_committee': epochs_in_committee,\n                'selection_frequency': selection_frequency,\n                'avg_reputation_score': avg_reputation,\n                'median_reputation_score': median_reputation,\n                'first_epoch_in_sample': record['first_epoch_in_sample'],\n                'last_epoch_in_sample': record['last_epoch_in_sample'],\n            }\n        )\n\n    return aggregated",
            "usage": "per_validator_stats = aggregate_validator_selection_frequencies(rows)"
        },
        {
            "step": 4,
            "label": "backend",
            "introduction": "Step 4 computes Pearson and Spearman style correlation metrics between average reputation and committee selection frequency and optionally builds reputation buckets for robustness checks.",
            "code": "from math import sqrt\nfrom typing import Any, Dict, List, Optional\n\n\ndef _pearson_correlation(xs: List[float], ys: List[float]) -> Optional[float]:\n    '''\n    Compute the Pearson correlation coefficient between two equal length vectors.\n    Returns None if the correlation is undefined.\n    '''\n    n = len(xs)\n    if n != len(ys) or n < 2:\n        return None\n\n    mean_x = sum(xs) / n\n    mean_y = sum(ys) / n\n\n    cov = 0.0\n    var_x = 0.0\n    var_y = 0.0\n    for x_val, y_val in zip(xs, ys):\n        dx = x_val - mean_x\n        dy = y_val - mean_y\n        cov += dx * dy\n        var_x += dx * dx\n        var_y += dy * dy\n\n    if var_x <= 0.0 or var_y <= 0.0:\n        return None\n\n    return cov / sqrt(var_x * var_y)\n\n\ndef _rank_values(values: List[float]) -> List[float]:\n    '''\n    Assign ranks to a list of values, using average ranks for ties.\n    '''\n    indexed = list(enumerate(values))\n    indexed.sort(key=lambda pair: pair[1])\n\n    ranks = [0.0] * len(values)\n    i = 0\n    while i < len(indexed):\n        j = i\n        # Find tie group.\n        while j + 1 < len(indexed) and indexed[j + 1][1] == indexed[i][1]:\n            j += 1\n        # Average rank for indices i..j, ranks are 1 based.\n        rank_value = 0.5 * (i + j) + 1.0\n        for k in range(i, j + 1):\n            original_index = indexed[k][0]\n            ranks[original_index] = rank_value\n        i = j + 1\n\n    return ranks\n\n\ndef compute_reputation_selection_correlation(\n    validator_stats: List[Dict[str, Any]],\n    num_buckets: int = 4,\n) -> Dict[str, Any]:\n    '''\n    Given per validator selection statistics, compute correlation metrics\n    between reputation and selection frequency and optionally group\n    validators into reputation buckets.\n\n    validator_stats is expected to contain:\n      - avg_reputation_score: float\n      - selection_frequency: float\n    '''\n    reputations: List[float] = []\n    frequencies: List[float] = []\n\n    for row in validator_stats:\n        try:\n            rep = float(row.get('avg_reputation_score', 0.0))\n            freq = float(row.get('selection_frequency', 0.0))\n        except (TypeError, ValueError):\n            continue\n        reputations.append(rep)\n        frequencies.append(freq)\n\n    n_validators = len(reputations)\n    pearson = _pearson_correlation(reputations, frequencies)\n    if n_validators >= 2:\n        rep_ranks = _rank_values(reputations)\n        freq_ranks = _rank_values(frequencies)\n        spearman = _pearson_correlation(rep_ranks, freq_ranks)\n    else:\n        spearman = None\n\n    # Build reputation buckets for robustness checks.\n    buckets: List[Dict[str, Any]] = []\n    if n_validators > 0 and num_buckets > 0:\n        # Pair and sort by reputation.\n        paired = list(zip(reputations, frequencies))\n        paired.sort(key=lambda pair: pair[0])\n\n        for bucket_index in range(num_buckets):\n            start_index = int(bucket_index * n_validators / num_buckets)\n            end_index = int((bucket_index + 1) * n_validators / num_buckets)\n            if start_index >= end_index:\n                continue\n            bucket_vals = paired[start_index:end_index]\n            rep_min = bucket_vals[0][0]\n            rep_max = bucket_vals[-1][0]\n            mean_freq = sum(val[1] for val in bucket_vals) / len(bucket_vals)\n            buckets.append(\n                {\n                    'bucket_index': bucket_index,\n                    'reputation_min': rep_min,\n                    'reputation_max': rep_max,\n                    'validators_in_bucket': len(bucket_vals),\n                    'mean_selection_frequency': mean_freq,\n                }\n            )\n\n    return {\n        'pearson_correlation': pearson,\n        'spearman_correlation': spearman,\n        'num_validators': n_validators,\n        'num_buckets': len(buckets),\n        'buckets': buckets,\n    }",
            "usage": "correlation = compute_reputation_selection_correlation(per_validator_stats, num_buckets=4)"
        },
        {
            "step": 5,
            "label": "backend",
            "introduction": "Step 5 generates a structured summary object that includes human readable text, bucket level metrics, and scatter plot data for frontend visualisation.",
            "code": "from typing import Any, Dict, List\n\n\ndef generate_correlation_summary(\n    window_info: Dict[str, Any],\n    validator_stats: List[Dict[str, Any]],\n    correlation: Dict[str, Any],\n) -> Dict[str, Any]:\n    '''\n    Produce a summary payload that can be returned to frontends, including\n    human readable text and chart ready data.\n    '''\n    start_epoch = window_info.get('start_epoch')\n    end_epoch = window_info.get('end_epoch')\n    total_epochs = window_info.get('total_epochs')\n\n    num_validators = correlation.get('num_validators', len(validator_stats))\n    pearson = correlation.get('pearson_correlation')\n    spearman = correlation.get('spearman_correlation')\n    buckets = correlation.get('buckets', [])\n\n    lines: List[str] = []\n    lines.append(f'Analysis window: epochs {start_epoch} to {end_epoch} (total {total_epochs} epochs).')\n    lines.append(f'Validators included in sample: {num_validators}.')\n\n    if pearson is not None:\n        try:\n            lines.append(f'Pearson correlation between average reputation and committee selection frequency: {pearson:.3f}.')\n        except (TypeError, ValueError):\n            lines.append('Pearson correlation between average reputation and committee selection frequency is not a finite number.')\n    else:\n        lines.append('Pearson correlation could not be computed, likely due to insufficient sample size or zero variance.')\n\n    if spearman is not None:\n        try:\n            lines.append(f'Spearman rank correlation between reputation and selection frequency: {spearman:.3f}.')\n        except (TypeError, ValueError):\n            lines.append('Spearman rank correlation between reputation and selection frequency is not a finite number.')\n    else:\n        lines.append('Spearman rank correlation could not be computed.')\n\n    if buckets:\n        lines.append('Reputation bucket summary:')\n        for bucket in buckets:\n            bucket_index = bucket.get('bucket_index')\n            rep_min = bucket.get('reputation_min')\n            rep_max = bucket.get('reputation_max')\n            validators_in_bucket = bucket.get('validators_in_bucket')\n            mean_freq = bucket.get('mean_selection_frequency')\n            try:\n                lines.append(\n                    f'  Bucket {bucket_index}: reputation from {rep_min:.3f} to {rep_max:.3f}, '\n                    f'validators {validators_in_bucket}, mean selection frequency {mean_freq:.3f}.'\n                )\n            except (TypeError, ValueError):\n                lines.append(f'  Bucket {bucket_index}: could not format numeric values.')\n    else:\n        lines.append('No reputation buckets were produced for this sample.')\n\n    summary_text = ' '.join(lines)\n\n    # Prepare scatter plot data: one point per validator.\n    scatter_data: List[Dict[str, Any]] = []\n    for row in validator_stats:\n        try:\n            validator_id = row['validator_id']\n            avg_rep = float(row.get('avg_reputation_score', 0.0))\n            freq = float(row.get('selection_frequency', 0.0))\n        except (KeyError, TypeError, ValueError):\n            continue\n\n        scatter_data.append(\n            {\n                'validator_id': validator_id,\n                'avg_reputation_score': avg_rep,\n                'selection_frequency': freq,\n            }\n        )\n\n    return {\n        'window': window_info,\n        'metrics': {\n            'pearson_correlation': pearson,\n            'spearman_correlation': spearman,\n        },\n        'sample_sizes': {\n            'num_validators': num_validators,\n            'num_epochs': total_epochs,\n        },\n        'buckets': buckets,\n        'scatter': scatter_data,\n        'summary_text': summary_text,\n    }",
            "usage": "summary = generate_correlation_summary(window, per_validator_stats, correlation)"
        }
    ]
}