{
	"construct_param_change_proposal": "def construct_param_change_proposal(new_security_address: str, deposit: str = \"10000000untrn\", output_path: str = \"proposal.json\") -> str:\n    \"\"\"Generate a Param-Change proposal file that updates the Cron module's security_address parameter.\"\"\"\n\n    proposal = {\n        \"title\": \"Update Cron security_address\",\n        \"description\": f\"Updates Cron module security_address param to {new_security_address}.\",\n        \"changes\": [\n            {\n                \"subspace\": \"cron\",\n                \"key\": \"SecurityAddress\",\n                \"value\": f\"\\\"{new_security_address}\\\"\"\n            }\n        ],\n        \"deposit\": deposit\n    }\n\n    try:\n        with open(output_path, \"w\", encoding=\"utf-8\") as fp:\n            json.dump(proposal, fp, indent=2)\n    except IOError as err:\n        raise RuntimeError(f\"Could not write proposal file: {err}\") from err\n\n    return output_path",
	"submit_gov_proposal": "def submit_gov_proposal(proposal_file: str, from_key: str, chain_id: str = \"neutron-1\", node: str = \"https://rpc-kralum.neutron.org:443\", fees: str = \"2000untrn\", gas: str = \"400000\") -> str:\n    \"\"\"Submits the param-change proposal and extracts the proposal_id from the tx response.\"\"\"\n\n    cmd = [\n        \"neutrond\", \"tx\", \"gov\", \"submit-proposal\", \"param-change\", proposal_file,\n        \"--from\", from_key,\n        \"--chain-id\", chain_id,\n        \"--node\", node,\n        \"--fees\", fees,\n        \"--gas\", gas,\n        \"-y\",\n        \"--output\", \"json\"\n    ]\n\n    try:\n        completed = subprocess.run(cmd, check=True, capture_output=True, text=True)\n        tx_response = json.loads(completed.stdout)\n        proposal_id = None\n        for log in tx_response.get(\"logs\", []):\n            for event in log.get(\"events\", []):\n                if event.get(\"type\") == \"submit_proposal\":\n                    for attr in event.get(\"attributes\", []):\n                        if attr.get(\"key\") == \"proposal_id\":\n                            proposal_id = attr.get(\"value\")\n                            break\n        if not proposal_id:\n            raise RuntimeError(\"Proposal submitted but proposal_id not found in transaction logs.\")\n        return proposal_id\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"Failed to submit proposal: {err.stderr}\") from err",
	"wait_for_voting_result": "def wait_for_voting_result(proposal_id: str, chain_id: str = \"neutron-1\", node: str = \"https://rpc-kralum.neutron.org:443\", poll_interval: int = 15, max_attempts: int = 800) -> str:\n    \"\"\"Polls proposal status until finalised (PASSED/REJECTED) or timeout.\"\"\"\n\n    attempts = 0\n    while attempts < max_attempts:\n        attempts += 1\n        proc = subprocess.run([\n            \"neutrond\", \"query\", \"gov\", \"proposal\", str(proposal_id),\n            \"--chain-id\", chain_id,\n            \"--node\", node,\n            \"--output\", \"json\"\n        ], capture_output=True, text=True)\n\n        if proc.returncode != 0:\n            raise RuntimeError(proc.stderr)\n\n        status = json.loads(proc.stdout).get(\"status\")\n        print(f\"[poll] proposal {proposal_id} status: {status}\")\n\n        if status == \"PROPOSAL_STATUS_PASSED\":\n            return status\n        if status in (\"PROPOSAL_STATUS_REJECTED\", \"PROPOSAL_STATUS_FAILED\", \"PROPOSAL_STATUS_ABORTED\"):\n            raise RuntimeError(f\"Proposal {proposal_id} ended with status {status}\")\n\n        time.sleep(poll_interval)\n\n    raise TimeoutError(\"Exceeded maximum attempts while waiting for proposal to pass.\")",
	"query_cron_params": "def query_cron_params(chain_id: str = \"neutron-1\", node: str = \"https://rpc-kralum.neutron.org:443\") -> dict:\n    \"\"\"Fetches the current Cron module parameters.\"\"\"\n\n    proc = subprocess.run([\n        \"neutrond\", \"query\", \"cron\", \"params\",\n        \"--chain-id\", chain_id,\n        \"--node\", node,\n        \"--output\", \"json\"\n    ], capture_output=True, text=True)\n\n    if proc.returncode != 0:\n        raise RuntimeError(proc.stderr)\n\n    return json.loads(proc.stdout).get(\"params\", {})\n\n\ndef verify_security_address(expected: str, chain_id: str = \"neutron-1\", node: str = \"https://rpc-kralum.neutron.org:443\") -> bool:\n    \"\"\"Validates that security_address equals the expected value.\"\"\"\n\n    params = query_cron_params(chain_id, node)\n    actual = params.get(\"security_address\")\n    if actual == expected:\n        print(\"✅ Cron security_address updated successfully.\")\n        return True\n    raise ValueError(f\"security_address mismatch: expected {expected}, got {actual}\")",
	"_fetch_raw_tx": "def _fetch_raw_tx(tx_hash: str) -> dict:\n    \"\"\"Internal helper to retrieve raw tx data from the LCD\"\"\"\n    if not re.fullmatch(r'^(0x)?[0-9a-fA-F]{64}$', tx_hash):\n        raise ValueError('Invalid transaction hash')\n    # LCD expects plain hex (no 0x)\n    clean = tx_hash.lower().replace('0x', '')\n    url = f\"{LCD_ENDPOINT}/cosmos/tx/v1beta1/txs/{clean}\"\n    async with httpx.AsyncClient(timeout=10) as client:\n        resp = await client.get(url)\n        try:\n            resp.raise_for_status()\n        except httpx.HTTPStatusError as e:\n            raise HTTPException(status_code=resp.status_code, detail=str(e))\n        return resp.json()\n\n@router.get('/api/tx/{tx_hash}')\nasync def get_raw_tx_endpoint(tx_hash: str):\n    \"\"\"Public BFF route to obtain raw transaction JSON.\"\"\"\n    try:\n        return await _fetch_raw_tx(tx_hash)\n    except ValueError as err:\n        raise HTTPException(status_code=400, detail=str(err))",
	"get_formatted_tx": "def get_formatted_tx(tx_hash: str) -> Dict[str, Any]:\n    try:\n        raw = await _fetch_raw_tx(tx_hash)\n    except ValueError as err:\n        raise HTTPException(status_code=400, detail=str(err))\n\n    if 'tx_response' not in raw:\n        raise HTTPException(status_code=500, detail='Unexpected LCD response format')\n\n    r = raw['tx_response']\n    formatted = {\n        'height': r.get('height'),\n        'hash': r.get('txhash'),\n        'codespace': r.get('codespace'),\n        'code': r.get('code'),\n        'gas_wanted': r.get('gas_wanted'),\n        'gas_used': r.get('gas_used'),\n        'timestamp': r.get('timestamp'),\n        'fees': r.get('tx', {}).get('auth_info', {}).get('fee', {}),\n        'messages': r.get('tx', {}).get('body', {}).get('messages', []),\n        'raw_log': r.get('raw_log')\n    }\n    return formatted",
	"get_web3": "def get_web3():\n    rpc_url = os.getenv(\"RPC_URL\", \"http://localhost:8545\")\n    try:\n        w3 = Web3(Web3.HTTPProvider(rpc_url))\n        if not w3.isConnected():\n            raise ConnectionError(f\"Unable to connect to JSON-RPC at {rpc_url}\")\n        return w3\n    except Exception as e:\n        raise RuntimeError(f\"get_web3 error: {str(e)}\")",
	"eth_sign": "def eth_sign(from_address: str, message_hex: str) -> str:\n    rpc_url = os.getenv(\"RPC_URL\", \"http://localhost:8545\")\n    payload = {\n        \"jsonrpc\": \"2.0\",\n        \"id\": 1,\n        \"method\": \"eth_sign\",\n        \"params\": [from_address, message_hex]\n    }\n\n    try:\n        response = requests.post(rpc_url, json=payload, timeout=10)\n        response.raise_for_status()\n        data = response.json()\n        if 'error' in data:\n            raise RuntimeError(data['error'])\n        return data['result']  # 0x-signature\n    except Exception as e:\n        raise RuntimeError(f\"eth_sign failed: {e}\")",
	"verify_signature": "def verify_signature(message: str, signature: str, expected_address: str, w3: Web3 | None = None) -> bool:\n    try:\n        # Use existing Web3 instance or create a new one\n        if w3 is None:\n            w3 = Web3(HTTPProvider(os.getenv('RPC_URL', 'http://localhost:8545')))\n        msg = encode_defunct(text=message)\n        recovered = w3.eth.account.recover_message(msg, signature=signature)\n        return recovered.lower() == expected_address.lower()\n    except Exception as e:\n        raise RuntimeError(f\"verify_signature error: {e}\")",
	"get_sender_address": "def get_sender_address(wallet_alias: str = 'lender'):\n    \"\"\"Return the Bech32 address for a configured backend wallet.\"\"\"\n    env_key = f\"{wallet_alias.upper()}_ADDRESS\"\n    address = os.getenv(env_key)\n    if not address:\n        raise HTTPException(status_code=404, detail=f'Wallet alias {wallet_alias} not configured')\n    return {\"wallet\": wallet_alias, \"address\": address}",
	"check_token_balance": "def check_token_balance(address: str, cw20_contract: str):\n    \"\"\"Return the CW20 balance for a given address.\"\"\"\n    query = {\"balance\": {\"address\": address}}\n    encoded_query = base64.b64encode(json.dumps(query).encode()).decode()\n    url = f\"{REST_ENDPOINT}/cosmwasm/wasm/v1/contract/{cw20_contract}/smart/{encoded_query}\"\n    try:\n        resp = requests.get(url, timeout=10)\n        resp.raise_for_status()\n        balance = int(resp.json().get('data', {}).get('balance', '0'))\n        return {\"address\": address, \"cw20_contract\": cw20_contract, \"balance\": balance}\n    except requests.RequestException as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"construct_cw20_approve": "def construct_cw20_approve(spender: str, amount_micro: int) -> dict:\n    \"\"\"Build the CW20 increase_allowance message.\"\"\"\n    return {\n        'increase_allowance': {\n            'spender': spender,\n            'amount': str(amount_micro)\n        }\n    }",
	"sign_and_broadcast_approval": "def sign_and_broadcast_approval() -> dict:\n    \"\"\"Signs and broadcasts the CW20 approve (increase_allowance) transaction.\"\"\"\n    network = NetworkConfig(\n        chain_id='neutron-1',\n        url=os.getenv('NEUTRON_GRPC', 'grpc://grpc-kralum.neutron-1.neutron.org:443'),\n        fee_minimum_gas_price=0.025,\n        fee_denom='untrn'\n    )\n    client = LedgerClient(network)\n\n    private_key_hex = os.getenv('LENDER_PRIVKEY')\n    if not private_key_hex:\n        raise RuntimeError('Missing LENDER_PRIVKEY environment variable')\n    wallet = PrivateKey(bytes.fromhex(private_key_hex))\n\n    cw20_contract = os.getenv('SOLVBTC_CONTRACT')\n    spender = os.getenv('AMBER_MARKET_CONTRACT')\n    amount_micro = int(os.getenv('APPROVE_AMOUNT', '300000000'))  # 3 solvBTC * 1e8 (assuming 8 decimals)\n\n    # Build execute message\n    msg = MsgExecuteContract(\n        sender=wallet.address(),\n        contract=cw20_contract,\n        msg=json.dumps({'increase_allowance': {'spender': spender, 'amount': str(amount_micro)}}).encode(),\n        funds=[]\n    )\n\n    tx = (\n        Transaction()\n        .with_messages(msg)\n        .with_chain_id(network.chain_id)\n        .with_gas_estimate(client)\n        .sign(wallet)\n        .broadcast(client, mode='block')\n    )\n    return {'tx_hash': tx.tx_hash}\n\n\nif __name__ == '__main__':\n    print(sign_and_broadcast_approval())",
	"construct_amber_lend_tx": "def construct_amber_lend_tx(amount_micro: int) -> dict:\n    \"\"\"Build the lend (supply) message for Amber Finance market contract.\"\"\"\n    return {\n        'lend': {\n            'amount': str(amount_micro)\n        }\n    }",
	"sign_and_broadcast_lend": "def sign_and_broadcast_lend() -> dict:\n    \"\"\"Signs and broadcasts the lend (supply) transaction to Amber Finance.\"\"\"\n    network = NetworkConfig(\n        chain_id='neutron-1',\n        url=os.getenv('NEUTRON_GRPC', 'grpc://grpc-kralum.neutron-1.neutron.org:443'),\n        fee_minimum_gas_price=0.025,\n        fee_denom='untrn'\n    )\n    client = LedgerClient(network)\n\n    private_key_hex = os.getenv('LENDER_PRIVKEY')\n    if not private_key_hex:\n        raise RuntimeError('Missing LENDER_PRIVKEY environment variable')\n    wallet = PrivateKey(bytes.fromhex(private_key_hex))\n\n    amber_market_contract = os.getenv('AMBER_MARKET_CONTRACT')\n    amount_micro = int(os.getenv('LEND_AMOUNT', '300000000'))  # 3 solvBTC * 1e8\n\n    # Build execute message\n    msg = MsgExecuteContract(\n        sender=wallet.address(),\n        contract=amber_market_contract,\n        msg=json.dumps({'lend': {'amount': str(amount_micro)}}).encode(),\n        funds=[]\n    )\n\n    tx = (\n        Transaction()\n        .with_messages(msg)\n        .with_chain_id(network.chain_id)\n        .with_gas_estimate(client)\n        .sign(wallet)\n        .broadcast(client, mode='block')\n    )\n    return {'tx_hash': tx.tx_hash}\n\n\nif __name__ == '__main__':\n    print(sign_and_broadcast_lend())",
	"_b64": "def _b64(query: dict) -> str:\n    \"\"\"Base64-encode a JSON query for /smart/ LCD endpoints.\"\"\"\n    return base64.b64encode(json.dumps(query).encode()).decode()\n\nasync def _cw20_balance(contract: str, addr: str) -> int:\n    url = f\"{NODE_LCD}/cosmwasm/wasm/v1/contract/{contract}/smart/{_b64({'balance': {'address': addr}})}\"\n    async with httpx.AsyncClient(timeout=10) as client:\n        r = await client.get(url)\n        r.raise_for_status()\n        return int(r.json()['data']['balance'])\n\n@router.get('/api/validate_balances')\nasync def validate_balances(address: str):\n    required_wbtc = int(MIN_WBTC * 10 ** WBTC_DECIMALS)\n    required_usdc = int(MIN_USDC * 10 ** USDC_DECIMALS)\n\n    wbtc_balance = await _cw20_balance(WBTC_CONTRACT, address)\n    usdc_balance = await _cw20_balance(USDC_CONTRACT, address)\n\n    if wbtc_balance < required_wbtc or usdc_balance < required_usdc:\n        raise HTTPException(\n            status_code=400,\n            detail={\n                'wbtc_balance': wbtc_balance,\n                'usdc_balance': usdc_balance,\n                'message': 'Insufficient token balances for deposit.'\n            }\n        )\n\n    return {\n        'status': 'ok',\n        'wbtc_raw': wbtc_balance,\n        'usdc_raw': usdc_balance\n    }",
	"supervault_address": "def supervault_address():\n    \"\"\"Return the current WBTC/USDC Supervault address.\"\"\"\n    return {'address': SUPERVAULT_CONTRACT}",
	"construct_deposit_msg": "def construct_deposit_msg():\n    wbtc_raw = int(Decimal('0.2') * 10 ** WBTC_DECIMALS)      # 0.2 WBTC → 20 000 000 raw\n    usdc_raw = int(Decimal('12000') * 10 ** USDC_DECIMALS)    # 12 000 USDC → 12 000 000 000 raw\n\n    msg = {\n        'deposit': {\n            'assets': [\n                {\n                    'info': {'token': {'contract_addr': WBTC_CONTRACT}},\n                    'amount': str(wbtc_raw)\n                },\n                {\n                    'info': {'token': {'contract_addr': USDC_CONTRACT}},\n                    'amount': str(usdc_raw)\n                }\n            ]\n        }\n    }\n\n    return {'msg': msg}",
	"_build_deposit_msg": "def _build_deposit_msg(sender: str) -> MsgExecuteContract:\n    \"\"\"Create a MsgExecuteContract for the deposit.\"\"\"\n    deposit_msg = {\n        'deposit': {\n            'assets': [\n                {\n                    'info': {'token': {'contract_addr': WBTC_CONTRACT}},\n                    'amount': str(int(0.2 * 10 ** 8))\n                },\n                {\n                    'info': {'token': {'contract_addr': USDC_CONTRACT}},\n                    'amount': str(int(12000 * 10 ** 6))\n                }\n            ]\n        }\n    }\n    return MsgExecuteContract(\n        sender=sender,\n        contract=SUPERVAULT_CONTRACT,\n        msg=json.dumps(deposit_msg).encode(),\n        funds=[]\n    )\n\n@router.post('/api/sign_and_broadcast')\nasync def sign_and_broadcast_tx():\n    \"\"\"\n    WARNING: Exposes a signing flow on the backend. Use only for server-controlled\n    treasury accounts – never end-user keys.\n    \"\"\"\n    if not MNEMONIC:\n        raise HTTPException(status_code=500, detail='FUNDER_MNEMONIC env var not set.')\n\n    # 1. Instantiate the private key\n    key = PrivateKey.from_mnemonic(MNEMONIC)\n    sender_addr = str(key.to_address())\n\n    # 2. Build the transaction\n    network = NetworkConfig(chain_id=CHAIN_ID, url=RPC_ENDPOINT)\n    ledger = LedgerClient(network)\n    account = ledger.query_account(sender_addr)\n\n    tx = (\n        Transaction()\n        .with_chain_id(CHAIN_ID)\n        .with_account_num(account.account_number)\n        .with_sequence(account.sequence)\n        .with_gas(400_000)\n        .with_fee_limit('60000untrn')\n    )\n    tx.add_message(_build_deposit_msg(sender_addr))\n\n    # 3. Sign and broadcast\n    tx_signed = tx.sign(key)\n    tx_hash = ledger.broadcast_tx(tx_signed)\n\n    return {'tx_hash': tx_hash.hex()}",
	"construct_wasm_execute_msg": "def construct_wasm_execute_msg(sender: str, contract_address: str, shares_to_redeem: int) -> MsgExecuteContract:\n    \"\"\"Build a MsgExecuteContract for a Supervault `withdraw` call.\n\n    Args:\n        sender (str): The bech32 address initiating the transaction.\n        contract_address (str): The Supervault contract address.\n        shares_to_redeem (int): LP shares to redeem.\n\n    Returns:\n        MsgExecuteContract: Ready-to-sign protobuf message.\n    \"\"\"\n    withdraw_msg = {\"withdraw\": {\"amount\": str(shares_to_redeem)}}\n\n    msg = MsgExecuteContract(\n        sender=sender,\n        contract=contract_address,\n        msg=json.dumps(withdraw_msg).encode('utf-8'),\n        funds=[]  # No native coins sent along with the execute call\n    )\n    return msg",
	"sign_and_broadcast_tx": "def sign_and_broadcast_tx(execute_msg):\n    \"\"\"Signs and broadcasts the given execute message.\n\n    Args:\n        execute_msg (MsgExecuteContract): Message produced by `construct_wasm_execute_msg`.\n\n    Returns:\n        dict: `{ \"tx_hash\": \"...\" }` when successful.\n    \"\"\"\n    mnemonic = os.getenv(MNEMONIC_ENV)\n    if not mnemonic:\n        raise EnvironmentError(f\"Mnemonic not provided in env var {MNEMONIC_ENV}.\")\n\n    wallet = MnemonicWallet(mnemonic)\n    client = LedgerClient(NETWORK)\n\n    tx = Transaction()\n    tx.add_message(execute_msg)\n    tx.with_sender(wallet.address())\n\n    # Estimate gas & fees, sign, then broadcast\n    tx = tx.autofill(client)\n    tx = tx.sign(wallet)\n\n    response = client.broadcast_block(tx)\n    if response.is_ok():\n        return {\"tx_hash\": response.tx_hash}\n    else:\n        raise Exception(f\"Broadcast failed: {response.raw_log}\")",
	"export_passphrase_env": "def export_passphrase_env(passphrase: str, ttl: int = 60):\n    '''\n    Temporarily exports KEYRING_PASSPHRASE as an environment variable and\n    clears it after `ttl` seconds in a background thread.\n    '''\n    if not passphrase:\n        raise ValueError('Passphrase cannot be empty.')\n\n    # Export the variable so any subprocess (e.g., simd) will inherit it.\n    os.environ['KEYRING_PASSPHRASE'] = passphrase\n    print('KEYRING_PASSPHRASE exported. It will be cleared in', ttl, 'seconds.')\n\n    def _unset():\n        '''Waits for ttl seconds and removes the passphrase from env.'''\n        time.sleep(ttl)\n        os.environ.pop('KEYRING_PASSPHRASE', None)\n        print('KEYRING_PASSPHRASE cleared from environment.')\n\n    # Fire-and-forget the cleaner thread so the main program continues.\n    threading.Thread(target=_unset, daemon=True).start()\n",
	"run_timeboxed_script": "def run_timeboxed_script(cmd: List[str]):\n    '''\n    Executes a simd CLI transaction command (sign + broadcast) while the\n    KEYRING_PASSPHRASE env var is present.\n    '''\n    if 'KEYRING_PASSPHRASE' not in os.environ:\n        raise EnvironmentError('KEYRING_PASSPHRASE is not set. Call export_passphrase_env first.')\n\n    try:\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n        print('Transaction successfully broadcasted:')\n        print(result.stdout)\n        return result\n    except subprocess.CalledProcessError as err:\n        print('simd command failed:', err.stderr)\n        raise\n",
	"confirm_relock": "def confirm_relock(cmd: List[str]) -> bool:\n    '''\n    Attempts to execute a signing command after the KEYRING_PASSPHRASE TTL has\n    expired. Returns True if the CLI prompts for a passphrase, indicating\n    that the keyring is re-locked.\n    '''\n    # Ensure the passphrase env var is gone\n    if 'KEYRING_PASSPHRASE' in os.environ:\n        print('Waiting 1 s for passphrase to clear…')\n        time.sleep(1)\n\n    # Use --dry-run so we do not broadcast real transactions during the test\n    dry_cmd = cmd + ['--dry-run']\n\n    process = subprocess.Popen(\n        dry_cmd,\n        stdin=subprocess.PIPE,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True\n    )\n\n    # Give the CLI a moment to output its prompt\n    time.sleep(2)\n    try:\n        output = process.stdout.read()\n    finally:\n        process.kill()\n\n    relocked = any(kw in output for kw in ['Enter keyring passphrase', 'Passphrase:'])\n\n    if relocked:\n        print('Account is relocked. Passphrase prompt detected.')\n    else:\n        print('Account is still unlocked (NO passphrase prompt detected).')\n\n    return relocked\n",
	"get_ufw_status": "def get_ufw_status():\n    \"\"\"Check if UFW is active and return the raw output.\"\"\"\n    try:\n        proc = subprocess.run([\n            \"sudo\", \"ufw\", \"status\"\n        ], capture_output=True, text=True, check=True)\n        return {\n            \"active\": \"inactive\" not in proc.stdout.lower(),\n            \"output\": proc.stdout.strip()\n        }\n    except subprocess.CalledProcessError as err:\n        return {\n            \"active\": False,\n            \"error\": err.stderr.strip() if err.stderr else \"Failed to obtain UFW status.\"\n        }\n\n# Example direct usage:\n# result = get_ufw_status()\n# print(result)",
	"allow_ssh_via_ufw": "def allow_ssh_via_ufw():\n    \"\"\"Add a UFW rule to allow SSH on port 22/tcp with the comment 'Allow SSH'.\"\"\"\n    try:\n        proc = subprocess.run([\n            \"sudo\", \"ufw\", \"allow\", \"22/tcp\", \"comment\", \"Allow SSH\"\n        ], capture_output=True, text=True, check=True)\n        return {\n            \"success\": True,\n            \"output\": proc.stdout.strip() or \"Rule added\"\n        }\n    except subprocess.CalledProcessError as err:\n        return {\n            \"success\": False,\n            \"error\": err.stderr.strip() if err.stderr else \"Failed to add SSH rule.\"\n        }\n\n# Example direct usage:\n# response = allow_ssh_via_ufw()\n# print(response)",
	"reload_ufw": "def reload_ufw():\n    \"\"\"Reload the UFW ruleset to apply recent changes.\"\"\"\n    try:\n        proc = subprocess.run([\n            \"sudo\", \"ufw\", \"reload\"\n        ], capture_output=True, text=True, check=True)\n        return {\n            \"reloaded\": True,\n            \"output\": proc.stdout.strip() or \"UFW reloaded\"\n        }\n    except subprocess.CalledProcessError as err:\n        return {\n            \"reloaded\": False,\n            \"error\": err.stderr.strip() if err.stderr else \"Failed to reload UFW.\"\n        }\n\n# Example direct usage:\n# info = reload_ufw()\n# print(info)",
	"list_ufw_rules_numbered": "def list_ufw_rules_numbered() -> Dict[str, List[str]]:\n    \"\"\"Return UFW rules in numbered format for easy review.\"\"\"\n    try:\n        proc = subprocess.run([\n            \"sudo\", \"ufw\", \"status\", \"numbered\"\n        ], capture_output=True, text=True, check=True)\n        lines = [line.strip() for line in proc.stdout.strip().split(\"\\n\") if line.strip()]\n        return {\"rules\": lines}\n    except subprocess.CalledProcessError as err:\n        return {\n            \"error\": err.stderr.strip() if err.stderr else \"Unable to list UFW rules.\"\n        }\n\n# Example direct usage:\n# numbered = list_ufw_rules_numbered()\n# print(\"\\n\".join(numbered.get(\"rules\", [])))",
	"ensure_output_directory": "def ensure_output_directory(path: str) -> str:\n    \"\"\"Ensure the directory used for validator configs & genesis exists.\n\n    Args:\n        path (str): Relative or absolute path where `simd` will write files.\n\n    Returns:\n        str: An absolute, verified path.\n\n    Raises:\n        RuntimeError: If the directory cannot be created or accessed.\n    \"\"\"\n    try:\n        abs_path = os.path.abspath(os.path.expanduser(path))\n        os.makedirs(abs_path, exist_ok=True)  # idempotent: no error if it already exists\n        return abs_path\n    except Exception as err:\n        raise RuntimeError(f\"[ensure_output_directory] Failed for '{path}': {err}\")\n",
	"simd_testnet_init_files": "def simd_testnet_init_files(output_dir: str,\n                             chain_id: str = \"localnet-1\",\n                             validators: int = 1,\n                             keyring_backend: str = \"test\") -> None:\n    \"\"\"Bootstraps a local single- or multi-validator testnet.\n\n    Args:\n        output_dir (str): Directory created in Step 1.\n        chain_id  (str): Custom chain-id for the test chain.\n        validators (int): How many validator nodes to initialise.\n        keyring_backend (str): `simd` keyring backend (e.g. \"test\", \"os\").\n\n    Raises:\n        RuntimeError: If the `simd` command returns a non-zero exit code.\n    \"\"\"\n    home_arg = str(Path(output_dir).expanduser())\n    cmd = [\n        \"simd\", \"testnet\", \"init-files\",\n        \"--home\", home_arg,\n        \"--chain-id\", chain_id,\n        \"--v\", str(validators),\n        \"--keyring-backend\", keyring_backend,\n    ]\n\n    try:\n        completed = subprocess.run(cmd, capture_output=True, text=True, check=True)\n        # Optional: print or log stdout for user visibility\n        print(completed.stdout)\n    except subprocess.CalledProcessError as err:\n        print(err.stderr)\n        raise RuntimeError(\"[simd_testnet_init_files] `simd` exited with non-zero code\")\n",
	"verify_generated_artifacts": "def verify_generated_artifacts(output_dir: str, validators: int = 1) -> bool:\n    \"\"\"Sanity-check that Step 2 produced the expected files.\n\n    Args:\n        output_dir (str): Base directory used by `simd`.\n        validators (int): Number of validator folders expected.\n\n    Returns:\n        bool: `True` if every file is present.\n\n    Raises:\n        FileNotFoundError: When any required artifact is missing.\n    \"\"\"\n    base = Path(output_dir).expanduser().resolve()\n\n    # 1. Shared genesis.json\n    genesis = base / \"genesis.json\"\n    if not genesis.is_file():\n        raise FileNotFoundError(f\"Missing {genesis}\")\n\n    # 2. Per-validator checks\n    for idx in range(validators):\n        node_dir = base / f\"node{idx}\"\n        config_dir = node_dir / \"config\"\n        if not config_dir.is_dir():\n            raise FileNotFoundError(f\"Missing config dir: {config_dir}\")\n\n        node_key = config_dir / \"node_key.json\"\n        priv_val = config_dir / \"priv_validator_key.json\"\n        if not node_key.is_file():\n            raise FileNotFoundError(f\"Missing node_key for validator #{idx}: {node_key}\")\n        if not priv_val.is_file():\n            raise FileNotFoundError(f\"Missing priv_validator_key for validator #{idx}: {priv_val}\")\n\n    return True  # All good\n",
	"instantiate_wallet": "def instantiate_wallet():\n    \"\"\"Creates a wallet instance from PRIVATE_KEY and returns its address.\"\"\"\n    if not PRIVATE_KEY:\n        raise HTTPException(status_code=500, detail=\"PRIVATE_KEY is not set in environment variables\")\n    acct = w3.eth.account.from_key(PRIVATE_KEY)\n    return {\"address\": acct.address}",
	"fee_data": "def fee_data():\n    \"\"\"Returns baseFeePerGas, maxPriorityFeePerGas and a recommended maxFeePerGas.\"\"\"\n    try:\n        latest_block = w3.eth.get_block('latest')\n        base_fee = latest_block['baseFeePerGas']\n        max_priority_fee = w3.eth.max_priority_fee  # Recommended priority tip\n        # Heuristic: maxFeePerGas = baseFee + 2 * maxPriorityFee\n        max_fee_per_gas = base_fee + 2 * max_priority_fee\n        return {\n            \"baseFeePerGas\": base_fee,\n            \"maxPriorityFeePerGas\": max_priority_fee,\n            \"maxFeePerGas\": max_fee_per_gas\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"build_tx": "def build_tx(params: BuildTxParams):\n    \"\"\"Constructs an unsigned EIP-1559 transaction object.\"\"\"\n    try:\n        fee_info = await fee_data()          # Dynamic fee suggestions\n        wallet_info = await instantiate_wallet()\n        sender = wallet_info['address']\n\n        nonce = w3.eth.get_transaction_count(sender)\n        chain_id = w3.eth.chain_id\n\n        tx = {\n            \"to\": params.to,\n            \"value\": params.value,\n            \"data\": params.data,\n            \"gas\": params.gasLimit,\n            \"maxFeePerGas\": fee_info['maxFeePerGas'],\n            \"maxPriorityFeePerGas\": fee_info['maxPriorityFeePerGas'],\n            \"nonce\": nonce,\n            \"chainId\": chain_id,\n            \"type\": 2  # EIP-1559\n        }\n        return tx\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"sign_and_send": "def sign_and_send(tx: TxObject):\n    \"\"\"Signs an EIP-1559 tx using PRIVATE_KEY and broadcasts it, returning the tx hash.\"\"\"\n    if not PRIVATE_KEY:\n        raise HTTPException(status_code=500, detail=\"Server missing PRIVATE_KEY\")\n    try:\n        signed_tx = w3.eth.account.sign_transaction(tx.dict(), private_key=PRIVATE_KEY)\n        tx_hash = w3.eth.send_raw_transaction(signed_tx.rawTransaction)\n        return {\"txHash\": tx_hash.hex()}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"generate_key": "def generate_key(key_name: str, keyring_backend: str = 'test'):\n    \"\"\"Generate a new key pair using `simd` and persist it to the provided keyring backend.\"\"\"\n    cmd = [\n        'simd', 'keys', 'add', key_name,\n        '--keyring-backend', keyring_backend,\n        '--output', 'json'  # ensures machine-readable output\n    ]\n\n    try:\n        # Execute the CLI command and capture its output\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=True\n        )\n        key_info = json.loads(result.stdout)  # parse the JSON given by simd\n        return {\n            'message': 'Key generated successfully',\n            'data': key_info\n        }\n\n    except subprocess.CalledProcessError as e:\n        # When simd exits with a non-zero code we surface the error message\n        raise HTTPException(\n            status_code=500,\n            detail=f'Key generation failed: {e.stderr.strip()}'\n        )\n    except json.JSONDecodeError:\n        # simd did not return JSON despite --output=json flag\n        raise HTTPException(\n            status_code=500,\n            detail='Failed to parse simd output as JSON.'\n        )",
	"verify_key": "def verify_key(key_name: str, keyring_backend: str = 'test'):\n    \"\"\"Check whether a key exists in the requested keyring backend.\"\"\"\n    cmd = [\n        'simd', 'keys', 'show', key_name,\n        '--keyring-backend', keyring_backend,\n        '-a'  # address-only output (quieter, easier to parse)\n    ]\n\n    try:\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=True\n        )\n        address = result.stdout.strip()\n        if not address:\n            # simd printed nothing even though command succeeded\n            raise HTTPException(status_code=404, detail=f'Key `{key_name}` seems empty.')\n        return {\n            'key_name': key_name,\n            'address': address\n        }\n\n    except subprocess.CalledProcessError:\n        # simd returns non-zero when key isn't found\n        raise HTTPException(\n            status_code=404,\n            detail=f'Key `{key_name}` not found in `{keyring_backend}` keyring.'\n        )",
	"_ping": "def _ping(url: str, timeout: float = 1.5) -> float:\n    \"\"\"Return response-time in seconds (∞ if unreachable).\"\"\"\n    start = time.time()\n    try:\n        requests.head(url, timeout=timeout)\n        return time.time() - start\n    except requests.RequestException:\n        return float(\"inf\")\n\n\ndef select_data_provider(prefer_graphql: bool = True) -> Dict[str, str]:\n    \"\"\"Choose the fastest available provider and return a descriptor dict.\"\"\"\n    providers = [\n        {\n            \"name\": \"celatone\",\n            \"base_url\": \"https://celatone-api.neutron.org/v1/graphql\",\n            \"api_type\": \"graphql\",\n        },\n        {\n            \"name\": \"lcd\",\n            \"base_url\": \"https://lcd.neutron.org\",\n            \"api_type\": \"rest\",\n        },\n    ]\n\n    # If GraphQL is preferred, try it first.\n    if prefer_graphql:\n        graphql_providers = [p for p in providers if p[\"api_type\"] == \"graphql\"]\n        if graphql_providers and _ping(graphql_providers[0][\"base_url\"]) != float(\"inf\"):\n            return graphql_providers[0]\n\n    # Fallback: choose the provider with the lowest latency.\n    best = min(providers, key=lambda p: _ping(p[\"base_url\"]))\n    if _ping(best[\"base_url\"]) == float(\"inf\"):\n        raise RuntimeError(\"No data provider is reachable at the moment.\")\n    return best",
	"build_history_query": "def build_history_query(\n    provider: Dict[str, str],\n    address: str,\n    limit: int = 50,\n    cursor: Optional[str] = None,\n    offset: int = 0,\n) -> Tuple[str, Union[Dict[str, Any], None]]:\n    \"\"\"Return (query_or_endpoint, variables_or_params) ready for Step 3.\"\"\"\n    if provider[\"api_type\"] == \"graphql\":\n        # Celatone GraphQL query string with optional cursor for pagination.\n        gql_query = (\n            \"\"\"\n            query ($address: String!, $limit: Int!, $cursor: String) {\n              messages(\n                where: {sender: {_eq: $address}},\n                order_by: {block: {time: desc}},\n                limit: $limit,\n                %s\n              ) {\n                transaction_hash\n                block { height time }\n                type\n                success\n                fee { amount denom }\n              }\n              pageInfo: messages_aggregate(where: {sender: {_eq: $address}}) {\n                aggregate { count }\n              }\n            }\n            \"\"\"\n            % (\"offset: 0\" if cursor is None else \"cursor: $cursor\")\n        )\n        variables: Dict[str, Any] = {\"address\": address, \"limit\": limit}\n        if cursor:\n            variables[\"cursor\"] = cursor\n        return gql_query, variables\n\n    # ---------- REST / LCD ----------\n    endpoint = f\"{provider['base_url']}/cosmos/tx/v1beta1/txs\"\n    params: Dict[str, Any] = {\n        \"events\": f\"message.sender='{address}'\",\n        \"order_by\": \"ORDER_BY_DESC\",\n        \"pagination.limit\": str(limit),\n        \"pagination.offset\": str(offset),\n    }\n    return endpoint, params",
	"execute_query_request": "def execute_query_request(\n    provider: Dict[str, str],\n    query_or_url: str,\n    variables_or_params: Optional[Union[Dict[str, Any], None]] = None,\n    timeout: int = 10,\n) -> Tuple[List[Dict[str, Any]], Optional[str]]:\n    \"\"\"Return (raw_results, next_cursor_or_offset).\"\"\"\n    try:\n        if provider[\"api_type\"] == \"graphql\":\n            resp = requests.post(\n                provider[\"base_url\"],\n                json={\"query\": query_or_url, \"variables\": variables_or_params or {}},\n                timeout=timeout,\n            )\n            resp.raise_for_status()\n            data = resp.json()\n            if \"errors\" in data:\n                raise RuntimeError(f\"GraphQL error: {data['errors']}\")\n            results = data[\"data\"][\"messages\"]\n            # Cursor-based pagination (Celatone may not expose pageInfo directly − adjust if needed)\n            next_cursor = variables_or_params.get(\"cursor\") if variables_or_params else None\n            return results, next_cursor\n        # ---------------- REST / LCD ----------------\n        resp = requests.get(query_or_url, params=variables_or_params, timeout=timeout)\n        resp.raise_for_status()\n        data = resp.json()\n        results = data.get(\"txs\", []) or data.get(\"tx_responses\", [])\n        next_key = data.get(\"pagination\", {}).get(\"next_key\")\n        return results, next_key\n    except requests.RequestException as exc:\n        raise RuntimeError(f\"Failed to query {provider['name']}: {exc}\") from exc",
	"normalize_tx_results": "def normalize_tx_results(provider: Dict[str, str], raw_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:\n    \"\"\"Map each transaction to {hash, blockHeight, action, fee, success}.\"\"\"\n    normalized: List[Dict[str, Any]] = []\n\n    if provider[\"api_type\"] == \"graphql\":\n        for item in raw_results:\n            fee_obj = item.get(\"fee\", {}) or {}\n            fee_str = (\n                f\"{fee_obj.get('amount', '0')}{fee_obj.get('denom', '')}\"\n                if fee_obj else \"0\"\n            )\n            normalized.append(\n                {\n                    \"hash\": item.get(\"transaction_hash\"),\n                    \"blockHeight\": item.get(\"block\", {}).get(\"height\"),\n                    \"timestamp\": item.get(\"block\", {}).get(\"time\"),\n                    \"action\": item.get(\"type\"),\n                    \"fee\": fee_str,\n                    \"success\": bool(item.get(\"success\")),\n                }\n            )\n    else:  # REST / LCD\n        for tx in raw_results:\n            # Transaction hash and height\n            hash_ = tx.get(\"txhash\") or tx.get(\"hash\")\n            height = int(tx.get(\"height\", 0))\n            timestamp = tx.get(\"timestamp\")\n\n            # First message type as action indicator\n            first_msg = (\n                (tx.get(\"tx\", {}) or {}).get(\"body\", {}).get(\"messages\", [])\n            )\n            action = first_msg[0].get(\"@type\", \"\") if first_msg else \"\"\n\n            # Fee formatting\n            fee_info = (tx.get(\"tx\", {}) or {}).get(\"auth_info\", {}).get(\"fee\", {})\n            fee_amounts = fee_info.get(\"amount\", [])\n            fee_str = (\n                f\"{fee_amounts[0]['amount']}{fee_amounts[0]['denom']}\" if fee_amounts else \"0\"\n            )\n\n            success = tx.get(\"code\", 0) == 0  # code == 0 indicates success\n\n            normalized.append(\n                {\n                    \"hash\": hash_,\n                    \"blockHeight\": height,\n                    \"timestamp\": timestamp,\n                    \"action\": action,\n                    \"fee\": fee_str,\n                    \"success\": success,\n                }\n            )\n    return normalized",
	"wait_for_confirmations": "def wait_for_confirmations(tx_hash: str, confirmations: int = 12, poll: int = 15) -> Dict:\n    \"\"\"Blocks until `confirmations` are reached for `tx_hash`.\"\"\"\n    try:\n        receipt = None\n        while receipt is None:\n            try:\n                receipt = web3.eth.get_transaction_receipt(tx_hash)\n            except exceptions.TransactionNotFound:\n                time.sleep(poll)\n        tx_block = receipt.blockNumber\n        while (web3.eth.block_number - tx_block) < confirmations:\n            time.sleep(poll)\n        return {\"status\": \"confirmed\", \"txHash\": tx_hash, \"confirmations\": confirmations}\n    except Exception as e:\n        return {\"status\": \"error\", \"error\": str(e)}",
	"wait_for_ibc_transfer": "def wait_for_ibc_transfer(neutron_addr: str, source_tx: str, poll: int = 15, timeout: int = 1800) -> Dict:\n    \"\"\"Polls Neutron txs until an IBC transfer that correlates to `source_tx` is observed.\"\"\"\n    end_time = time.time() + timeout\n    page_key = None\n    while time.time() < end_time:\n        url = f\"{LCD}/cosmos/tx/v1beta1/txs?events=transfer.recipient='\" + neutron_addr + \"'\" + (f\"&pagination.key={page_key}\" if page_key else '')\n        resp = requests.get(url, timeout=10)\n        if resp.status_code == 200:\n            data = resp.json()\n            for tx in data.get('txs', []):\n                # Very naive correlation: search for the Ethereum tx-hash in memo / events\n                if source_tx.lower()[2:12] in str(tx):  # quick substring match\n                    return {\"status\": \"ibc_received\", \"neutron_txhash\": tx['txhash']}\n            page_key = data.get('pagination', {}).get('next_key')\n        time.sleep(poll)\n    return {\"status\": \"timeout\", \"message\": \"No IBC packet seen in allotted time.\"}",
	"query_wbtc_balance": "def query_wbtc_balance(neutron_addr: str, ibc_denom: str) -> Dict:\n    url = f\"{LCD}/cosmos/bank/v1beta1/balances/{neutron_addr}\"\n    resp = requests.get(url, timeout=10)\n    if resp.status_code != 200:\n        return {\"status\": \"error\", \"error\": resp.text}\n    balances = resp.json().get('balances', [])\n    for coin in balances:\n        if coin.get('denom') == ibc_denom:\n            amount = int(coin.get('amount', '0'))\n            return {\"status\": \"ok\", \"amount_sats\": amount}\n    return {\"status\": \"ok\", \"amount_sats\": 0}",
	"parse_cron_params": "def parse_cron_params(params_json: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"\n    Extract important fields from the raw Cron parameters response.\n\n    Args:\n        params_json (Dict[str, Any]): Raw JSON structure returned by `query_cron_params`.\n\n    Returns:\n        Dict[str, Any]: A simplified dictionary containing selected Cron parameters.\n\n    Raises:\n        KeyError: If the expected keys are not found.\n    \"\"\"\n    try:\n        params = params_json[\"params\"]\n        parsed = {\n            \"max_msg_length\": int(params.get(\"max_msg_length\", 0)),\n            \"min_period\": int(params.get(\"min_period\", 0)),\n            \"security_address\": params.get(\"security_address\", \"\"),\n            \"fee_currency\": params.get(\"fee_currency\", \"\"),\n            \"fee_amount\": params.get(\"fee_amount\", \"\")\n        }\n        return parsed\n    except KeyError as exc:\n        raise KeyError(f\"Expected key not found while parsing Cron params: {exc}\") from exc",
	"search_cosmos_docs": "def search_cosmos_docs(query: str, limit: int = 10) -> List[Dict[str, str]]:\n    '''\n    Simple wrapper around the public ReadTheDocs search endpoint used by the\n    Cosmos SDK documentation site.\n\n    Args:\n        query (str): search string, e.g. \"SetUpgradeHandler example\".\n        limit (int): maximum number of results to return.\n\n    Returns:\n        list[dict]: Each dict contains 'title' and 'link' keys.\n\n    Raises:\n        RuntimeError: if the request fails or the endpoint is unreachable.\n    '''\n    base_url = 'https://evm.cosmos.network/search'\n    try:\n        resp = requests.get(base_url, params={'q': query}, timeout=10)\n        resp.raise_for_status()\n    except Exception as e:\n        raise RuntimeError(f'Failed to search Cosmos docs: {e}') from e\n\n    # The HTML response contains <a class=\\\"result-link\\\" href=\\\"URL\\\">Title</a>\n    results = []\n    for line in resp.text.splitlines():\n        if 'class=\\\"result-link\\\"' in line:\n            try:\n                href_part = line.split('href=\\\"')[1]\n                link = href_part.split('\\\"')[0]\n                title = href_part.split('\\\">')[1].split('</a>')[0]\n                results.append({'title': title.strip(), 'link': link.strip()})\n                if len(results) >= limit:\n                    break\n            except IndexError:\n                continue\n    return results\n",
	"": "\n",
	"compile_wasm_contract": "def compile_wasm_contract(contract_dir: str) -> str:\n    \"\"\"Compile a CosmWasm contract and return the path to the optimised .wasm file.\"\"\"\n    try:\n        # 1. Compile to Wasm (un-optimised)\n        subprocess.run(['cargo', 'wasm'], cwd=contract_dir, check=True)\n        # 2. Run the optimiser (expects `cargo run-script optimize` set up by rust-optimizer)\n        subprocess.run(['cargo', 'run-script', 'optimize'], cwd=contract_dir, check=True)\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f'Contract compilation failed: {err}') from err\n\n    # Locate the optimised file (typically placed in <contract>/artifacts)\n    artifacts_dir = os.path.join(contract_dir, 'artifacts')\n    wasm_files = [f for f in os.listdir(artifacts_dir) if f.endswith('.wasm')]\n    if not wasm_files:\n        raise FileNotFoundError('Optimised wasm not found in artifacts directory.')\n    return os.path.join(artifacts_dir, wasm_files[0])",
	"get_local_chain_account": "def get_local_chain_account(key_name: str = 'cosmopark', faucet_url: str | None = 'http://localhost:4500/credit') -> dict:\n    \"\"\"Load or create a key and optionally request faucet funds.\"\"\"\n    try:\n        key_info_raw = subprocess.check_output([\n            'neutrond', 'keys', 'show', key_name,\n            '--output', 'json', '--keyring-backend', 'test'\n        ])\n    except subprocess.CalledProcessError:\n        # Key does not exist – create it\n        subprocess.run([\n            'neutrond', 'keys', 'add', key_name,\n            '--output', 'json', '--keyring-backend', 'test'\n        ], check=True)\n        key_info_raw = subprocess.check_output([\n            'neutrond', 'keys', 'show', key_name,\n            '--output', 'json', '--keyring-backend', 'test'\n        ])\n\n    key_info = json.loads(key_info_raw)\n    address = key_info['address']\n\n    # Ask faucet to top-up (optional / local-net only)\n    if faucet_url:\n        try:\n            requests.post(faucet_url, json={'address': address, 'denom': 'untrn'})\n        except Exception as faucet_err:\n            print(f'Faucet funding skipped/failed: {faucet_err}')\n\n    return {'name': key_name, 'address': address}",
	"construct_tx_wasm_store": "def construct_tx_wasm_store(wasm_path: str, wallet, chain_id: str, gas: int = 2_000_000, fee: int = 300_000):\n    \"\"\"Return an unsigned `Transaction` containing `MsgStoreCode`.\"\"\"\n    with open(wasm_path, 'rb') as wasm_file:\n        wasm_bytes = wasm_file.read()\n\n    msg = MsgStoreCode(\n        sender=wallet.address(),\n        wasm_byte_code=wasm_bytes\n    )\n\n    tx = (\n        Transaction()\n        .with_messages(msg)\n        .with_chain_id(chain_id)\n        .with_gas(gas)\n        .with_fee(fee)\n    )\n    return tx",
	"parse_code_id_from_receipt": "def parse_code_id_from_receipt(tx_response) -> int:\n    \"\"\"Search TxResponse logs for the `store_code` event and return its `code_id`.\"\"\"\n    logs = tx_response.logs if hasattr(tx_response, 'logs') else tx_response['logs']\n    for event in logs[0]['events']:\n        if event['type'] == 'store_code':\n            for attr in event['attributes']:\n                if attr['key'] in ('code_id', 'codeID'):\n                    return int(attr['value'])\n    raise ValueError('code_id not found in transaction logs.')",
	"construct_tx_wasm_instantiate": "def construct_tx_wasm_instantiate(code_id: int, init_msg: dict, label: str, wallet, chain_id: str, admin: str | None = None, gas: int = 500_000, fee: int = 150_000):\n    \"\"\"Return an unsigned instantiate transaction.\"\"\"\n    msg = MsgInstantiateContract(\n        sender=wallet.address(),\n        admin=admin or '',\n        code_id=code_id,\n        label=label,\n        msg=json.dumps(init_msg).encode('utf-8'),\n        funds=[]  # Provide coins if the contract expects them\n    )\n\n    tx = (\n        Transaction()\n        .with_messages(msg)\n        .with_chain_id(chain_id)\n        .with_gas(gas)\n        .with_fee(fee)\n    )\n    return tx",
	"broadcast_instantiate_tx": "def broadcast_instantiate_tx(instantiate_tx, wallet, client):\n    \"\"\"Helper that re-uses `sign_and_broadcast_tx` for the instantiate step.\"\"\"\n    return sign_and_broadcast_tx(instantiate_tx, wallet, client)",
	"parse_contract_address_from_receipt": "def parse_contract_address_from_receipt(tx_response) -> str:\n    \"\"\"Fetch `_contract_address` from the instantiate event.\"\"\"\n    logs = tx_response.logs if hasattr(tx_response, 'logs') else tx_response['logs']\n    for event in logs[0]['events']:\n        if event['type'] == 'instantiate':\n            for attr in event['attributes']:\n                if attr['key'] == '_contract_address':\n                    return attr['value']\n    raise ValueError('Contract address not found in instantiate logs.')",
	"query_contract_state": "def query_contract_state(client: LedgerClient, contract_address: str, query_msg: dict):\n    \"\"\"Query the contract’s state using a custom query message.\"\"\"\n    try:\n        return client.wasm_query(contract_address, query_msg)\n    except Exception as err:\n        raise RuntimeError(f'Contract query failed: {err}') from err",
	"validate_key_name": "def validate_key_name(name: str):\n    \"\"\"Return `{ available: bool }` indicating whether the key name is free.\"\"\"\n    try:\n        cmd = [\n            'simd',\n            'keys',\n            'list',\n            '--keyring-backend', 'file',\n            '--output', 'json'\n        ]\n        proc = subprocess.run(cmd, capture_output=True, text=True, check=False)\n        if proc.returncode != 0:\n            raise HTTPException(status_code=500, detail=proc.stderr.strip())\n\n        existing = json.loads(proc.stdout) if proc.stdout else []\n        existing_names = {entry.get('name') for entry in existing}\n        return {\"available\": name not in existing_names}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"add_key": "def add_key(payload: dict):\n    \"\"\"Create a key and return `{ address, mnemonic }`. Payload must contain `name` and `passphrase`.\"\"\"\n    name = payload.get('name')\n    passphrase = payload.get('passphrase')\n\n    if not name or not passphrase:\n        raise HTTPException(status_code=400, detail='Both `name` and `passphrase` are required.')\n\n    try:\n        cmd = [\n            'simd',\n            'keys', 'add', name,\n            '--keyring-backend', 'file',\n            '--output', 'json'\n        ]\n\n        # Feed passphrase twice via STDIN (create + confirm)\n        proc = subprocess.run(\n            cmd,\n            input=f\"{passphrase}\\n{passphrase}\\n\",\n            capture_output=True,\n            text=True,\n            check=False,\n        )\n\n        if proc.returncode != 0:\n            raise HTTPException(status_code=500, detail=proc.stderr.strip())\n\n        key_info = json.loads(proc.stdout)\n        return {\n            'address': key_info.get('address'),\n            'mnemonic': key_info.get('mnemonic')\n        }\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"_fetch_balance": "def _fetch_balance(address: str, denom: str) -> int:\n    \"\"\"Query /cosmos/bank/v1beta1/balances/{address}/{denom}\"\"\"\n    url = f\"{REST_ENDPOINT}/cosmos/bank/v1beta1/balances/{address}/{denom}\"\n    async with httpx.AsyncClient(timeout=10) as client:\n        resp = await client.get(url)\n    if resp.status_code != 200:\n        raise HTTPException(status_code=resp.status_code, detail=\"Bank API error\")\n    amount = int(resp.json().get(\"balance\", {}).get(\"amount\", 0))\n    return amount\n\n# --- Route -----------------------------------------------------------------\n@app.get(\"/api/check-balance\")\nasync def check_token_balance(address: str, wbtc_needed: int = 1, usdc_needed: int = 60000):\n    \"\"\"Verify that the provided address owns ≥ required WBTC & USDC.\"\"\"\n    wbtc_balance = await _fetch_balance(address, WBTC_DENOM)\n    usdc_balance = await _fetch_balance(address, USDC_DENOM)\n\n    sufficient = (wbtc_balance >= wbtc_needed) and (usdc_balance >= usdc_needed)\n\n    return {\n        \"address\": address,\n        \"wbtc_balance\": wbtc_balance,\n        \"usdc_balance\": usdc_balance,\n        \"sufficient\": sufficient\n    }",
	"query_supervault_details": "def query_supervault_details():\n    return {\n        \"contract_address\": SUPER_VAULT_CONTRACT_ADDRESS,\n        \"tokens\": [\n            {\"denom\": WBTC_DENOM, \"symbol\": \"WBTC\"},\n            {\"denom\": USDC_DENOM, \"symbol\": \"USDC\"}\n        ]\n    }",
	"construct_supervault_deposit_tx": "def construct_supervault_deposit_tx(req: ConstructTxRequest = Body(...)):\n    # 1. Compose execute message expected by Supervault contract\n    exec_msg = {\n        \"deposit\": {\n            \"assets\": [\n                {\n                    \"info\": {\"native_token\": {\"denom\": WBTC_DENOM}},\n                    \"amount\": str(req.wbtc_amount)\n                },\n                {\n                    \"info\": {\"native_token\": {\"denom\": USDC_DENOM}},\n                    \"amount\": str(req.usdc_amount)\n                }\n            ]\n        }\n    }\n\n    # 2. Create Tx object\n    tx = Transaction()\n    tx.add_message(\n        ledger.execute_contract(\n            sender=req.address,\n            contract_address=SUPER_VAULT_CONTRACT,\n            msg=exec_msg,\n            funds=[]  # Contract pulls tokens from user’s balance; no explicit Coin[] required\n        )\n    )\n\n    # 3. Gas estimate (rough – add a safety buffer client-side if needed)\n    gas_estimate = ledger.estimate_gas(tx)\n    tx.set_gas(gas_estimate)\n\n    # 4. Return unsigned tx bytes for the next step\n    unsigned_bytes = tx.serialize()\n    return {\n        \"tx_base64\": base64.b64encode(unsigned_bytes).decode(),\n        \"gas_estimate\": gas_estimate\n    }",
	"execute_opt_in_airdrops": "def execute_opt_in_airdrops(req: ExecuteRequest):\n    \"\"\"Signs and broadcasts `{ opt_in_airdrops: { partner_id } }`\"\"\"\n    try:\n        # Create a wallet from the provided mnemonic\n        wallet = LocalWallet.from_mnemonic(req.mnemonic)\n        sender_addr = wallet.address()\n\n        # Create the execute message\n        wasm_msg = {\n            \"opt_in_airdrops\": {\n                \"partner_id\": req.partner_id\n            }\n        }\n\n        # Build transaction\n        tx = Transaction()\n        tx.add_execute_contract(\n            sender_addr,\n            req.contract_address,\n            wasm_msg,\n            gas_limit=req.gas_limit,\n        )\n        tx.with_chain_id(NETWORK.chain_id)\n        tx.with_fee(req.fee_denom)\n\n        # Sign\n        signed_tx = tx.sign(wallet)\n\n        # Broadcast\n        client = LedgerClient(NETWORK)\n        resp = client.broadcast_tx(signed_tx)\n\n        if resp.is_error():\n            raise HTTPException(status_code=400, detail=f\"Broadcast failed: {resp.raw_log}\")\n\n        return {\"txhash\": resp.tx_hash}\n\n    except Exception as e:\n        # Surface any unexpected error\n        raise HTTPException(status_code=500, detail=str(e))",
	"check_foundry": "def check_foundry():\n    \"\"\"\n    Returns `{ installed: bool, version: str }`.\n    Raises HTTP 500 if the `cast` binary is missing or mis-configured.\n    \"\"\"\n    try:\n        # `cast --version` is a quick way to test availability\n        result = subprocess.run([\"cast\", \"--version\"], capture_output=True, text=True, check=True)\n        return {\"installed\": True, \"version\": result.stdout.strip()}\n    except FileNotFoundError:\n        raise HTTPException(status_code=500, detail=\"Foundry not installed (`cast` binary not found).\")\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=f\"Error running cast: {err.stderr.strip()}\")",
	"estimate_gas": "def estimate_gas(body: EstimateRequest):\n    \"\"\"Executes `cast estimate` and returns `{ gas_units: int }`.\"\"\"\n    cmd = [\n        \"cast\",\n        \"estimate\",\n        \"--rpc-url\",\n        body.rpc_url,\n        body.contract_address,\n        body.function_signature,\n    ] + body.args\n\n    try:\n        completed = subprocess.run(cmd, capture_output=True, text=True, check=True)\n        gas_units_str = completed.stdout.strip()\n        gas_units = int(gas_units_str, 0)  # auto-detect base (0x…, decimal, etc.)\n        return {\"gas_units\": gas_units}\n    except FileNotFoundError:\n        raise HTTPException(status_code=500, detail=\"`cast` binary not found on server.\")\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=f\"cast error: {err.stderr.strip()}\")\n    except ValueError:\n        raise HTTPException(status_code=500, detail=\"Unexpected output from cast estimate.\")",
	"__init__": "def __init__(self, endpoint: str | None = None):\n        # Allow the endpoint to be configured via env-var or default to localhost\n        self.endpoint = endpoint or os.getenv(\"ETH_RPC_ENDPOINT\", \"http://localhost:8545\")\n\n    def _post(self, method: str, params: List[Any] | None = None) -> Any:\n        payload = {\n            \"jsonrpc\": \"2.0\",\n            \"id\": 1,\n            \"method\": method,\n            \"params\": params or []\n        }\n        try:\n            resp = requests.post(self.endpoint, json=payload, timeout=10)\n            resp.raise_for_status()\n        except requests.RequestException as exc:\n            raise ConnectionError(f\"Unable to reach JSON-RPC endpoint {self.endpoint}: {exc}\") from exc\n\n        data = resp.json()\n        if \"error\" in data and data[\"error\"]:\n            raise RuntimeError(f\"JSON-RPC error: {data['error']}\")\n        return data.get(\"result\")\n\n    # Convenience wrappers\n    def get_transaction_by_hash(self, tx_hash: str) -> Any:\n        return self._post(\"eth_getTransactionByHash\", [tx_hash])\n\n    def get_transaction_receipt(self, tx_hash: str) -> Any:\n        return self._post(\"eth_getTransactionReceipt\", [tx_hash])",
	"get_transaction": "def get_transaction(tx_hash: str = Query(..., description=\"0x-prefixed transaction hash\")):\n    try:\n        tx = client.get_transaction_by_hash(tx_hash)\n        if tx is None:\n            # Ethereum returns null when the hash is unknown\n            raise HTTPException(status_code=404, detail=\"Transaction not found\")\n        return {\"transaction\": tx}\n    except (ConnectionError, RuntimeError) as exc:\n        raise HTTPException(status_code=502, detail=str(exc)) from exc",
	"get_receipt": "def get_receipt(tx_hash: str = Query(..., description=\"0x-prefixed transaction hash\")):\n    try:\n        receipt = client.get_transaction_receipt(tx_hash)\n        if receipt is None:\n            raise HTTPException(status_code=404, detail=\"Receipt unavailable – the transaction may be pending or unknown\")\n        return {\"receipt\": receipt}\n    except (ConnectionError, RuntimeError) as exc:\n        raise HTTPException(status_code=502, detail=str(exc)) from exc",
	"list_gpg_keys": "def list_gpg_keys() -> List[str]:\n    \"\"\"Return a list of available GPG key IDs that exist on the host.\n\n    This helper runs `gpg --list-keys --with-colons` and parses the\n    machine-readable output (colon-separated fields).  The 5th column holds\n    the long key ID.\n    \"\"\"\n    try:\n        completed = subprocess.run(\n            [\"gpg\", \"--list-keys\", \"--with-colons\"],\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n    except FileNotFoundError:\n        # The `gpg` binary is not present on the system.\n        raise RuntimeError(\"`gpg` command is missing. Please install GnuPG and try again.\")\n    except subprocess.CalledProcessError as exc:\n        # The command executed but returned a non-zero exit status.\n        raise RuntimeError(f\"Failed to list GPG keys: {exc.stderr.strip()}\")\n\n    # Parse keys from command output.\n    key_ids = [\n        row.split(\":\")[4]\n        for row in completed.stdout.splitlines()\n        if row.startswith(\"pub\") and len(row.split(\":\")) > 4\n    ]\n    return key_ids\n\n@app.get(\"/api/gpg/keys\")\nasync def get_gpg_keys():\n    \"\"\"HTTP endpoint: GET /api/gpg/keys\n    Returns a JSON object with the available GPG key IDs so the frontend can\n    let the user choose which one to use for `pass init`.\n    \"\"\"\n    try:\n        keys = list_gpg_keys()\n    except RuntimeError as e:\n        # Convert Python errors to proper HTTP errors for the client.\n        raise HTTPException(status_code=500, detail=str(e))\n    return {\"keys\": keys}",
	"init_pass_store": "def init_pass_store(key_id: str) -> None:\n    \"\"\"Initialise the `pass` password store with the supplied `key_id`.\"\"\"\n    try:\n        subprocess.run(\n            [\"pass\", \"init\", key_id],\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n    except FileNotFoundError:\n        raise RuntimeError(\"`pass` CLI not found. Install 'pass' and ensure it is on $PATH.\")\n    except subprocess.CalledProcessError as exc:\n        raise RuntimeError(f\"`pass init` failed: {exc.stderr.strip()}\")\n\n@app.post(\"/api/pass/init\")\nasync def api_init_pass_store(req: InitRequest):\n    \"\"\"HTTP endpoint: POST /api/pass/init {\"key_id\": \"<GPG_KEY_ID>\"}.\n    It runs `pass init` on the server and returns status back to the caller.\n    \"\"\"\n    try:\n        init_pass_store(req.key_id)\n    except RuntimeError as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    return {\"status\": \"initialised\", \"key_id\": req.key_id}",
	"verify_pass_store": "def verify_pass_store() -> List[str]:\n    \"\"\"Return list of entries in the password store (empty list if none).\n\n    Returns an empty list when the store is freshly initialised.\n    \"\"\"\n    try:\n        completed = subprocess.run(\n            [\"pass\", \"ls\"],\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n    except FileNotFoundError:\n        raise RuntimeError(\"`pass` CLI not found. Install 'pass' and ensure it is on $PATH.\")\n    except subprocess.CalledProcessError as exc:\n        raise RuntimeError(f\"`pass ls` failed: {exc.stderr.strip()}\")\n\n    # Clean up and flatten the textual tree output.\n    entries = [line.strip() for line in completed.stdout.splitlines() if line.strip()]\n    return entries\n\n@app.get(\"/api/pass/verify\")\nasync def api_verify_pass_store():\n    \"\"\"HTTP endpoint: GET /api/pass/verify.\n    Returns the current list of passwords in the store. If the list is empty\n    the store is valid but has no secrets yet.\n    \"\"\"\n    try:\n        entries = verify_pass_store()\n    except RuntimeError as e:\n        raise HTTPException(status_code=500, detail=str(e))\n    return {\"entries\": entries}",
	"get_dao_authority_address": "def get_dao_authority_address(rpc_endpoint: str, chain_id: str, dao_contract: str) -> str:\n    \"\"\"Return the address that has Main-DAO authority.\n\n    Args:\n        rpc_endpoint (str): Full RPC URL, e.g. \"https://rpc-kralum.neutron.org:443\".\n        chain_id (str): The on-chain ID, e.g. \"neutron-1\".\n        dao_contract (str): Bech-32 address of the DAO WASM contract.\n\n    Returns:\n        str: Address with delete-schedule permissions.\n    \"\"\"\n    try:\n        cfg = NetworkConfig(chain_id=chain_id, url=rpc_endpoint, fee_minimum_gas_price=0)\n        client = LedgerClient(cfg)\n\n        # The DAO contract is expected to support `{ \"authority\": {} }` query.\n        query_msg = {\"authority\": {}}\n        res = client.wasm.contract_query(dao_contract, query_msg)\n        authority_addr = res.get(\"authority\")\n        if not authority_addr:\n            raise ValueError(\"DAO contract did not return an authority address.\")\n        return authority_addr\n    except (CosmPyException, ValueError) as err:\n        raise RuntimeError(f\"Unable to fetch DAO authority address: {err}\")\n",
	"build_msg_delete_schedule": "def build_msg_delete_schedule(authority: str, schedule_name: str = \"protocol_update\") -> dict:\n    \"\"\"Return an amino/JSON-encoded MsgDeleteSchedule body ready for packing.\n\n    Args:\n        authority (str): Address returned from Step 1.\n        schedule_name (str): Name of the schedule to delete.\n\n    Returns:\n        dict: Properly-typed MsgDeleteSchedule for inclusion in gov proposal.\n    \"\"\"\n    if not authority:\n        raise ValueError(\"Authority address is required to build MsgDeleteSchedule.\")\n\n    msg = {\n        \"@type\": \"/neutron.admin.MsgDeleteSchedule\",\n        \"authority_address\": authority,\n        \"name\": schedule_name\n    }\n    # quick validation\n    json.dumps(msg)  # will raise if non-serialisable\n    return msg\n",
	"package_into_gov_proposal": "def package_into_gov_proposal(authority: str, delete_msg: dict, deposit_amount: str = \"10000000\", denom: str = \"untrn\") -> dict:\n    \"\"\"Embed the delete-schedule message into a MsgSubmitProposal.\n\n    Args:\n        authority (str): DAO authority address (will be listed as proposer).\n        delete_msg (dict): Message from Step 2.\n        deposit_amount (str): Minimum deposit in micro-denom (10 NTRN default).\n        denom (str): Denomination for deposit.\n\n    Returns:\n        dict: MsgSubmitProposal ready for signing.\n    \"\"\"\n    title = \"Remove obsolete cron schedule: protocol_update\"\n    description = (\n        \"This proposal deletes the `protocol_update` cron schedule, which is no longer \"\n        \"needed after the successful upgrade executed on \" + datetime.utcnow().strftime(\"%Y-%m-%d\") + \".\"\n    )\n\n    proposal_msg = {\n        \"@type\": \"/cosmos.gov.v1beta1.MsgSubmitProposal\",\n        \"proposer\": authority,\n        \"initial_deposit\": [{\"denom\": denom, \"amount\": deposit_amount}],\n        \"content\": {\n            \"@type\": \"/cosmos.gov.v1beta1.TextProposal\",\n            \"title\": title,\n            \"description\": description\n        },\n        \"messages\": [delete_msg]  # custom message list supported by Neutron-gov\n    }\n\n    # Ensure JSON validity\n    json.dumps(proposal_msg)\n    return proposal_msg\n",
	"open_config_file": "def open_config_file(daemon_name: str):\n    \"\"\"Return (path, config_dict) for $HOME/.<daemon>/config/app.toml.\n\n    Parameters\n    ----------\n    daemon_name : str\n        The binary/service name (e.g. 'gaiad', 'junod').\n    \"\"\"\n    home_dir = os.path.expanduser('~')\n    path = os.path.join(home_dir, f'.{daemon_name}', 'config', 'app.toml')\n\n    if not os.path.isfile(path):\n        raise FileNotFoundError(f'Config file not found at {path}')\n\n    try:\n        with open(path, 'r', encoding='utf-8') as fh:\n            raw_toml = fh.read()\n        config_dict = toml.loads(raw_toml)  # `pip install toml` on Python < 3.11\n        return path, config_dict\n    except Exception as err:\n        # Surface additional context while preserving the original traceback\n        raise RuntimeError(f'Unable to open or parse {path}: {err}') from err",
	"update_mempool_max_txs": "def update_mempool_max_txs(config_dict: dict, new_value: int = -1):\n    \"\"\"Return an updated copy of the TOML config with mempool.max_txs replaced.\"\"\"\n    updated = copy.deepcopy(config_dict)\n    mempool_cfg = updated.get('mempool', {})\n    mempool_cfg['max_txs'] = new_value\n    updated['mempool'] = mempool_cfg\n    return updated",
	"save_config_file": "def save_config_file(path: str, config_dict: dict):\n    \"\"\"Write the provided config_dict back to the original file atomically.\"\"\"\n    try:\n        toml_str = toml.dumps(config_dict)\n        tmp_path = f\"{path}.tmp\"\n        with open(tmp_path, 'w', encoding='utf-8') as fh:\n            fh.write(toml_str)\n        os.replace(tmp_path, path)  # atomic move on POSIX\n    except Exception as err:\n        raise RuntimeError(f'Failed to write config file {path}: {err}') from err",
	"restart_node_service": "def restart_node_service(daemon_name: str, wait_seconds: int = 60):\n    \"\"\"Restart <daemon> with systemctl and wait until it's active.\n\n    This function assumes the current user can invoke `sudo systemctl` without\n    interactive password prompts (e.g. via sudoers configuration).\n    \"\"\"\n    service_name = daemon_name\n\n    # Restart the service\n    try:\n        subprocess.run(['sudo', 'systemctl', 'restart', service_name], check=True)\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f'Failed to restart service {service_name}: {err}') from err\n\n    # Poll until the service is active or timeout is reached\n    start_time = time.time()\n    while time.time() - start_time < wait_seconds:\n        result = subprocess.run(['systemctl', 'is-active', service_name], capture_output=True, text=True)\n        if result.stdout.strip() == 'active':\n            print(f'Service {service_name} is active again.')\n            return\n        time.sleep(2)\n\n    raise TimeoutError(f'Service {service_name} did not become active within {wait_seconds} seconds.')",
	"gas_price": "def gas_price():\n    \"\"\"Return baseFee and suggested priority fee from the last 5 blocks.\"\"\"\n    cmd = [\"cast\", \"gas-price\", \"--blocks\", \"5\", \"--json\"]\n    try:\n        raw = subprocess.check_output(cmd, text=True)\n        info = json.loads(raw)\n        return jsonify({\n            \"baseFee\": int(info[\"baseFeePerGas\"]),\n            \"priorityFee\": int(info[\"maxPriorityFeePerGas\"])\n        })\n    except subprocess.CalledProcessError as err:\n        return jsonify({\"error\": err.output}), 500\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", port=8000, debug=True)",
	"_calc_total_fee": "def _calc_total_fee(estimated_gas: int, base_fee: int, priority_fee: int, max_fee_per_gas: int):\n    \"\"\"Compute effectiveGasPrice and totalFee as per EIP-1559.\"\"\"\n    effective_gas_price = min(base_fee + priority_fee, max_fee_per_gas)\n    total_fee = estimated_gas * effective_gas_price\n    return {\n        \"effectiveGasPrice\": effective_gas_price,\n        \"totalFee\": total_fee\n    }\n\n@app.route(\"/api/calculate_total_fee\", methods=[\"POST\"])\ndef calculate_total_fee():\n    data = request.get_json(force=True)\n    try:\n        result = _calc_total_fee(\n            estimated_gas = int(data[\"estimatedGas\"]),\n            base_fee       = int(data[\"baseFee\"]),\n            priority_fee   = int(data[\"priorityFee\"]),\n            max_fee_per_gas= int(data[\"maxFeePerGas\"])\n        )\n        return jsonify(result)\n    except (KeyError, ValueError) as err:\n        return jsonify({\"error\": str(err)}), 422\n\nif __name__ == \"__main__\":\n    app.run(host=\"0.0.0.0\", port=8000, debug=True)",
	"stop_evmd_node": "def stop_evmd_node() -> Dict[str, str]:\n    \"\"\"Stop the running `evmd` instance.\"\"\"\n    try:\n        # Attempt a graceful shutdown via systemd\n        result = subprocess.run(\n            [\"systemctl\", \"stop\", \"evmd\"],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,\n            check=False,\n        )\n\n        # Fallback for non-systemd or failure cases\n        if result.returncode != 0:\n            subprocess.run([\"pkill\", \"-f\", \"evmd\"], check=False)\n\n        return {\"status\": \"evmd stopped\"}\n\n    except Exception as e:\n        # Capture and return any error information\n        return {\"error\": str(e)}",
	"load_app_toml": "def load_app_toml() -> dict:\n    \"\"\"Read ~/.evmd/config/app.toml into a Python dictionary.\"\"\"\n    if not APP_TOML_PATH.exists():\n        raise FileNotFoundError(f\"{APP_TOML_PATH} does not exist.\")\n    return toml.load(APP_TOML_PATH)",
	"set_json_rpc_timeout": "def set_json_rpc_timeout(cfg: dict, timeout: str = \"5s\") -> dict:\n    \"\"\"Mutate the `cfg` dict to enforce a 5-second JSON-RPC EVM timeout.\"\"\"\n    json_rpc_block = cfg.setdefault(\"json-rpc\", {})\n\n    # Prefer the modern key, fall back if not present\n    if \"evm-timeout\" in json_rpc_block or \"rpc-evm-timeout\" not in json_rpc_block:\n        json_rpc_block[\"evm-timeout\"] = timeout\n    else:\n        json_rpc_block[\"rpc-evm-timeout\"] = timeout\n\n    return cfg",
	"save_app_toml": "def save_app_toml(cfg: dict) -> None:\n    \"\"\"Write the updated configuration back to ~/.evmd/config/app.toml.\"\"\"\n    with open(APP_TOML_PATH, \"w\", encoding=\"utf-8\") as fp:\n        toml.dump(cfg, fp)",
	"start_evmd_node": "def start_evmd_node() -> dict:\n    \"\"\"Start (or restart) the `evmd` service so it picks up the new configuration.\"\"\"\n    try:\n        # Systemd path (preferred)\n        subprocess.run([\"systemctl\", \"start\", \"evmd\"], check=True)\n    except subprocess.CalledProcessError:\n        # Fallback: spawn the process directly if systemd is unavailable\n        subprocess.Popen([\"evmd\", \"start\"], stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n    return {\"status\": \"evmd started\"}",
	"get_rpc_auth_header": "def get_rpc_auth_header():\n    # Build Basic-Auth header from RPC_USER and RPC_PASS environment variables.\n    username = os.getenv('RPC_USER')\n    password = os.getenv('RPC_PASS')\n    if not username or not password:\n        raise EnvironmentError('RPC_USER or RPC_PASS is not set in environment variables.')\n\n    token_bytes = f'{username}:{password}'.encode()\n    token_b64 = base64.b64encode(token_bytes).decode()\n    return {'Authorization': f'Basic {token_b64}'}\n",
	"enable_mutex_profiling": "def enable_mutex_profiling():\n    # Enable mutex contention sampling by calling debug_setMutexProfileFraction(1).\n    headers = get_rpc_auth_header()\n    headers['Content-Type'] = 'application/json'\n\n    payload = {\n        'jsonrpc': '2.0',\n        'id': str(uuid.uuid4()),\n        'method': 'debug_setMutexProfileFraction',\n        'params': [1]\n    }\n\n    try:\n        resp = requests.post(RPC_URL, json=payload, headers=headers, timeout=10)\n        resp.raise_for_status()\n        data = resp.json()\n        if 'error' in data:\n            return jsonify({'status': 'error', 'message': data['error']}), 500\n        return jsonify({'status': 'success', 'result': data.get('result')})\n    except requests.exceptions.RequestException as e:\n        return jsonify({'status': 'error', 'message': str(e)}), 500\n",
	"query_bank_balance": "def query_bank_balance(contract_addr: str, denom: str = 'untrn') -> str:\n    \"\"\"Query the bank balance for a given contract address via Neutrond CLI.\"\"\"\n    try:\n        cmd = [\n            'neutrond', 'q', 'bank', 'balances', contract_addr,\n            '--denom', denom,\n            '--output', 'json',\n        ]\n        completed = subprocess.run(\n            cmd,\n            check=True,\n            capture_output=True,\n            text=True,\n        )\n        return completed.stdout\n    except FileNotFoundError:\n        raise RuntimeError('The neutrond binary is not in PATH. Please install the Neutrond CLI.')\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f'Failed to query balance: {err.stderr or err}')\n",
	"parse_balance_response": "def parse_balance_response(raw_json: str, denom: str = 'untrn') -> Dict[str, str]:\n    \"\"\"Extracts the balance for the specified denom and formats it for display.\"\"\"\n    try:\n        data = json.loads(raw_json)\n        balances = data.get('balances', [])\n        micro_amount = 0\n        for coin in balances:\n            if coin.get('denom') == denom:\n                micro_amount = int(coin.get('amount', '0'))\n                break\n        human_amount = Decimal(micro_amount) / Decimal(1_000_000)  # 1e6 micro = 1 NTRN\n        return {\n            'denom': denom,\n            'micro_amount': str(micro_amount),\n            'amount': f'{human_amount.normalize()} NTRN'\n        }\n    except (json.JSONDecodeError, ValueError) as err:\n        raise ValueError('Invalid JSON supplied to parser: ' + str(err))\n",
	"gather_gentx_files": "def gather_gentx_files(source_dirs: List[str], target_dir: str = \"config/gentx\") -> List[str]:\n    \"\"\"Gather all validator gentx JSON files into the chain's `config/gentx/` folder.\n\n    Parameters\n    ----------\n    source_dirs : List[str]\n        A list of directories where gentx files can be found.\n    target_dir : str, optional\n        Destination directory for the gentx files, by default \"config/gentx\".\n\n    Returns\n    -------\n    List[str]\n        Absolute paths of all gentx files that were copied.\n    \"\"\"\n    # Ensure the destination exists.\n    if not os.path.isdir(target_dir):\n        os.makedirs(target_dir, exist_ok=True)\n\n    copied: List[str] = []\n\n    for src in source_dirs:\n        if not os.path.isdir(src):\n            raise FileNotFoundError(f\"Source directory '{src}' does not exist.\")\n\n        # Copy every .json file found in that directory.\n        for file_path in glob.glob(os.path.join(src, \"*.json\")):\n            destination = os.path.join(target_dir, os.path.basename(file_path))\n            shutil.copy2(file_path, destination)\n            copied.append(os.path.abspath(destination))\n\n    if not copied:\n        raise RuntimeError(\"No gentx JSON files were discovered in the supplied directories.\")\n\n    return copied\n\n# Stand-alone usage example\nif __name__ == \"__main__\":\n    files_moved = gather_gentx_files([\"./gentx_inputs\"])\n    print(f\"Successfully gathered {len(files_moved)} gentx files → {os.path.abspath('config/gentx')}\")",
	"collect_gentxs": "def collect_gentxs(chain_binary: str = os.getenv(\"CHAIN_BINARY\", \"mychaind\"), home: str = \".\") -> str:\n    \"\"\"Execute `<chain_binary> collect-gentxs` and return the final genesis path.\n\n    Parameters\n    ----------\n    chain_binary : str, optional\n        The binary to execute, defaults to the `CHAIN_BINARY` env var or `mychaind`.\n    home : str, optional\n        The node's home directory (where the `config/` folder lives), defaults to `.`.\n\n    Returns\n    -------\n    str\n        Absolute path to the resulting genesis.json file.\n    \"\"\"\n    cmd = [chain_binary, \"collect-gentxs\", \"--home\", home]\n    result = subprocess.run(cmd, text=True, capture_output=True)\n\n    if result.returncode != 0:\n        raise RuntimeError(\n            \"collect-gentxs failed!\\n\" +\n            f\"stdout:\\n{result.stdout}\\n\" +\n            f\"stderr:\\n{result.stderr}\"\n        )\n\n    genesis_path = Path(home) / \"config\" / \"genesis.json\"\n    if not genesis_path.is_file():\n        raise FileNotFoundError(\"genesis.json was not created — please check the logs above.\")\n\n    return str(genesis_path.resolve())\n\n# Stand-alone usage example\nif __name__ == \"__main__\":\n    genesis_file = collect_gentxs()\n    print(f\"Genesis generated at → {genesis_file}\")",
	"validate_genesis": "def validate_genesis(chain_binary: str = os.getenv(\"CHAIN_BINARY\", \"mychaind\"), home: str = \".\") -> bool:\n    \"\"\"Run `<chain_binary> validate-genesis` to ensure the genesis file is valid.\n\n    Parameters\n    ----------\n    chain_binary : str, optional\n        The chain binary to run, default comes from `CHAIN_BINARY` env var.\n    home : str, optional\n        Node's home directory (where the `config/` folder is), defaults to `.`.\n\n    Returns\n    -------\n    bool\n        True if validation passes; raises otherwise.\n    \"\"\"\n    cmd = [chain_binary, \"validate-genesis\", \"--home\", home]\n    result = subprocess.run(cmd, text=True, capture_output=True)\n\n    if result.returncode != 0:\n        raise RuntimeError(\n            \"Genesis validation failed!\\n\" +\n            f\"stdout:\\n{result.stdout}\\n\" +\n            f\"stderr:\\n{result.stderr}\"\n        )\n\n    # Success — echo whatever the binary output plus confirm.\n    print(result.stdout or \"Genesis validation passed ✅\")\n    return True\n\n# Stand-alone usage example\nif __name__ == \"__main__\":\n    validate_genesis()\n    print(\"Genesis file is valid and the chain is ready to start 🚀\")",
	"verify_protoc_plugins": "def verify_protoc_plugins() -> Dict[str, str]:\n    \"\"\"Check presence & version of each required protobuf tool.\"\"\"\n    missing = []\n    versions = {}\n    for tool in REQUIRED_TOOLS:\n        path = shutil.which(tool)\n        if path is None:\n            missing.append(tool)\n            continue\n        try:\n            res = subprocess.run([tool, \"--version\"], capture_output=True, text=True, check=False)\n            versions[tool] = res.stdout.strip() or res.stderr.strip() or f\"found at {path}\"\n        except Exception as e:\n            versions[tool] = f\"found at {path} (version check failed: {e})\"\n    if missing:\n        raise EnvironmentError(f\"Missing required protobuf tools: {', '.join(missing)}\")\n    return versions\n\nif __name__ == \"__main__\":\n    try:\n        info = verify_protoc_plugins()\n        print(\"✅ Protobuf environment looks good:\")\n        for name, ver in info.items():\n            print(f\"  - {name}: {ver}\")\n    except EnvironmentError as err:\n        print(f\"❌ {err}\")\n        sys.exit(1)",
	"ensure_proto_files": "def ensure_proto_files():\n    \"\"\"Generate stub .proto files if they are not present.\"\"\"\n    PROTO_BASE.mkdir(parents=True, exist_ok=True)\n    created = []\n    if not MSG_PROTO.exists():\n        MSG_PROTO.write_text(MSG_TEMPLATE)\n        created.append(str(MSG_PROTO))\n    if not QUERY_PROTO.exists():\n        QUERY_PROTO.write_text(QUERY_TEMPLATE)\n        created.append(str(QUERY_PROTO))\n    return {\"created\": created or \"none\", \"location\": str(PROTO_BASE)}\n\nif __name__ == \"__main__\":\n    print(ensure_proto_files())",
	"buf_generate": "def buf_generate(repo_root: str = \".\") -> str:\n    \"\"\"Execute `buf generate` inside the repo root.\"\"\"\n    root = Path(repo_root).resolve()\n    if not root.joinpath(\"buf.yaml\").exists():\n        raise FileNotFoundError(f\"buf.yaml not found in {root}\")\n    proc = subprocess.run([\"buf\", \"generate\"], cwd=root, capture_output=True, text=True)\n    if proc.returncode != 0:\n        raise RuntimeError(f\"buf generate failed:\\n{proc.stderr}\")\n    return proc.stdout\n\nif __name__ == \"__main__\":\n    try:\n        print(buf_generate())\n    except Exception as e:\n        print(f\"❌ {e}\")\n        sys.exit(1)",
	"compile_generated_code": "def compile_generated_code(repo_root: str = \".\") -> str:\n    \"\"\"Run `go vet ./...` and `go test ./...` to validate compilation.\"\"\"\n    root = Path(repo_root).resolve()\n    commands = [\n        [\"go\", \"vet\", \"./...\"],\n        [\"go\", \"test\", \"./...\"]\n    ]\n    for cmd in commands:\n        proc = subprocess.run(cmd, cwd=root, capture_output=True, text=True)\n        if proc.returncode != 0:\n            raise RuntimeError(f\"{' '.join(cmd)} failed:\\n{proc.stderr}\")\n    return \"Go vet and go test executed successfully.\"\n\nif __name__ == \"__main__\":\n    try:\n        print(compile_generated_code())\n    except Exception as e:\n        print(f\"❌ {e}\")\n        sys.exit(1)",
	"verify_generated_services": "def verify_generated_services(module_path: str = \"x/mymodule/types\") -> str:\n    \"\"\"Ensure generated gRPC files exist after code-gen.\"\"\"\n    expected = [\n        \"tx.pb.go\",\n        \"tx_grpc.pb.go\",\n        \"query.pb.go\",\n        \"query_grpc.pb.go\",\n    ]\n    base = Path(module_path).resolve()\n    missing = [f for f in expected if not base.joinpath(f).exists()]\n    if missing:\n        raise FileNotFoundError(f\"Missing generated files: {', '.join(missing)}\")\n    return \"All required gRPC stubs are present.\"\n\nif __name__ == \"__main__\":\n    try:\n        print(verify_generated_services())\n    except Exception as e:\n        print(f\"❌ {e}\")\n        sys.exit(1)",
	"get_node_home": "def get_node_home(env_var='SIMD_HOME', default_path='~/.simd'):\n    # Return absolute path to the simd home directory.\n    home = os.getenv(env_var, default_path)\n    return os.path.abspath(os.path.expanduser(home))\n",
	"list_snapshots": "def list_snapshots(home_dir):\n    '''Return a list of snapshot dictionaries: {'id': str, 'height': int}.'''\n    cmd = ['simd', 'snapshot', 'list', f'--home={home_dir}']\n    try:\n        result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f'Error listing snapshots: {e.stderr}')\n\n    snapshots = []\n    for line in result.stdout.splitlines():\n        parts = line.strip().split()\n        if len(parts) >= 2 and parts[0].isdigit():\n            snapshots.append({'id': parts[0], 'height': int(parts[1])})\n    return snapshots\n",
	"stop_simd_service": "def stop_simd_service(service_name='simd'):\n    '''Stop the simd daemon via systemctl or pkill.'''\n    try:\n        subprocess.run(['systemctl', 'stop', service_name], check=True)\n        return 'Stopped via systemctl'\n    except Exception:\n        pass\n    try:\n        subprocess.run(['pkill', '-f', service_name], check=True)\n        return 'Stopped via pkill'\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f'Failed to stop simd: {e}')\n",
	"backup_and_clear_data": "def backup_and_clear_data(home_dir, data_subdir='data'):\n    '''Back up the current data directory to <home>/backup/data_<timestamp>.'''\n    data_path = os.path.join(home_dir, data_subdir)\n    if not os.path.isdir(data_path):\n        raise FileNotFoundError(f'Data dir not found: {data_path}')\n    timestamp = datetime.datetime.utcnow().strftime('%Y%m%d%H%M%S')\n    backup_root = os.path.join(home_dir, 'backup')\n    os.makedirs(backup_root, exist_ok=True)\n    backup_path = os.path.join(backup_root, f'data_{timestamp}')\n    shutil.move(data_path, backup_path)\n    return backup_path\n",
	"restore_snapshot": "def restore_snapshot(home_dir, snapshot_id):\n    '''Run simd snapshot restore for the provided snapshot ID.'''\n    cmd = ['simd', 'snapshot', 'restore', f'--home={home_dir}', snapshot_id]\n    try:\n        subprocess.run(cmd, check=True)\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f'Snapshot restore failed: {e}')\n",
	"build_simd_start_cmd": "def build_simd_start_cmd(home_dir, additional_flags=''):\n    '''Return a ready-to-run simd start command string.'''\n    return f'simd start --home={home_dir} {additional_flags}'.strip()\n",
	"start_simd": "def start_simd(home_dir, additional_flags='', detach=True):\n    '''Start simd in foreground or background based on `detach`.'''\n    cmd = ['simd', 'start', f'--home={home_dir}'] + additional_flags.split()\n    if detach:\n        subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n        return 'Started simd in background'\n    subprocess.run(cmd, check=True)\n    return 'Started simd in foreground'\n",
	"check_node_sync": "def check_node_sync(expected_height, rpc_url='http://localhost:26657', timeout=300):\n    '''Wait until the node's block height is >= expected_height.'''\n    start_time = time.time()\n    while time.time() - start_time < timeout:\n        try:\n            resp = requests.get(f'{rpc_url}/status', timeout=5)\n            resp.raise_for_status()\n            height = int(resp.json()['result']['sync_info']['latest_block_height'])\n            if height >= expected_height:\n                print(f'Node synced at height {height}')\n                return True\n            print(f'Current height {height}; waiting for {expected_height}...')\n        except Exception as err:\n            print('RPC error:', err)\n        time.sleep(5)\n    raise TimeoutError('Node did not reach expected height within timeout.')\n",
	"modify_minimum_gas_prices": "def modify_minimum_gas_prices(lines: list[str], new_value: str = \"0stake\") -> list[str]:\n    \"\"\"Update—or insert—the `minimum-gas-prices` parameter.\n\n    Args:\n        lines: Original list of lines from app.toml.\n        new_value: The desired gas-price string, e.g. `\"0stake\"`.\n\n    Returns:\n        A new list of lines reflecting the change.\n    \"\"\"\n    target_line = f'minimum-gas-prices = \"{new_value}\"\\n'\n    updated = False\n\n    for idx, line in enumerate(lines):\n        if line.strip().startswith(\"minimum-gas-prices\"):\n            lines[idx] = target_line\n            updated = True\n            break\n\n    if not updated:\n        # If the key wasn’t found, append it to the end of the [baseapp] section or file.\n        lines.append(\"\\n# Added automatically by script\\n\" + target_line)\n\n    return lines",
	"save_and_close_file": "def save_and_close_file(lines: list[str], config_path: str | None = None) -> str:\n    \"\"\"Persist the updated app.toml to disk and keep a backup.\n\n    Args:\n        lines: The modified list of lines to write.\n        config_path: Optional custom path to the app.toml file.\n\n    Returns:\n        The path to the file that was written.\n    \"\"\"\n    path = config_path or CONFIG_PATH\n\n    if not os.path.exists(path):\n        raise FileNotFoundError(f\"Config file not found at: {path}\")\n\n    # Create a backup before overwriting\n    backup_path = path + \".bak\"\n    shutil.copy(path, backup_path)\n\n    with open(path, \"w\", encoding=\"utf-8\") as fp:\n        fp.writelines(lines)\n\n    return path",
	"validate_file_change": "def validate_file_change(config_path: str | None = None, expected_value: str = \"0stake\") -> bool:\n    \"\"\"Verify `minimum-gas-prices` now equals the expected string.\n\n    Args:\n        config_path: Optional custom path to the app.toml file.\n        expected_value: Expected gas-price value (default: \"0stake\").\n\n    Returns:\n        True if the parameter is set correctly, else False.\n    \"\"\"\n    path = config_path or CONFIG_PATH\n    expected_line = f'minimum-gas-prices = \"{expected_value}\"'\n\n    if not os.path.exists(path):\n        raise FileNotFoundError(f\"Config file not found at: {path}\")\n\n    with open(path, \"r\", encoding=\"utf-8\") as fp:\n        for line in fp:\n            if line.strip() == expected_line:\n                return True\n\n    return False",
	"detect_profile": "def detect_profile() -> Path:\n    \"\"\"Infer which shell profile should be modified.\"\"\"\n    shell = os.environ.get(\"SHELL\", \"\")\n    if shell.endswith(\"zsh\"):\n        return Path.home() / \".zshrc\"\n    return Path.home() / \".bashrc\"\n\n\ndef add_cast_alias(rpc_url: str, profile_path: Path | None = None) -> None:\n    \"\"\"Append (or skip if present) the alias line to the profile file.\"\"\"\n    if not rpc_url:\n        raise ValueError(\"rpc_url is required\")\n\n    profile_path = profile_path or detect_profile()\n    alias_line = f'alias cast=\"cast --rpc-url {rpc_url}\"'\n\n    # Skip if alias already exists\n    if profile_path.exists() and alias_line in profile_path.read_text():\n        print(\"Alias already present; nothing to do.\")\n        return\n\n    with profile_path.open(\"a\", encoding=\"utf-8\") as fp:\n        fp.write(\"\\n# Added by Cosmos EVM setup script\\n\")\n        fp.write(alias_line + \"\\n\")\n\n    print(f\"Alias successfully written to {profile_path}\")\n\n\nif __name__ == \"__main__\":\n    rpc_url = os.environ.get(\"COSMOS_RPC_URL\") or input(\"Enter the RPC URL: \").strip()\n    add_cast_alias(rpc_url)",
	"reload_shell": "def reload_shell() -> None:\n    shell_path = os.environ.get(\"SHELL\", \"/bin/bash\")\n    print(f\"Spawning a fresh login shell ({shell_path} -l)...\")\n    print(\"After this command finishes, verify the alias with `type cast`.\")\n    try:\n        subprocess.run([shell_path, \"-l\"], check=True)\n    except subprocess.CalledProcessError as exc:\n        print(f\"Failed to reload shell: {exc}\", file=sys.stderr)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    reload_shell()",
	"init_genesis": "def init_genesis(moniker: str, chain_id: str = \"my-test-chain\") -> Dict[str, str]:\n    \"\"\"Initialise a new chain by executing `simd init`.\n\n    Args:\n        moniker (str): A human-readable name for your node.\n        chain_id (str, optional): The desired chain-ID. Defaults to \"my-test-chain\".\n\n    Returns:\n        Dict[str, str]: Captured stdout/stderr for logging purposes.\n    \"\"\"\n    cmd = [\"simd\", \"init\", moniker, \"--chain-id\", chain_id]\n\n    try:\n        # Run the command and capture output for debugging/logging.\n        completed = subprocess.run(\n            cmd,\n            check=True,\n            capture_output=True,\n            text=True,\n        )\n        return {\"stdout\": completed.stdout, \"stderr\": completed.stderr}\n    except FileNotFoundError:\n        raise RuntimeError(\n            \"`simd` binary not found. Make sure the Cosmos SDK binary is installed and in $PATH.\"\n        )\n    except subprocess.CalledProcessError as exc:\n        raise RuntimeError(\n            f\"simd init failed with exit code {exc.returncode}: {exc.stderr.strip()}\"\n        )\n",
	"verify_genesis_file": "def verify_genesis_file(\n    genesis_path: str = os.path.expanduser(\"~/.simapp/config/genesis.json\"),\n    expected_chain_id: str = \"my-test-chain\",\n) -> bool:\n    \"\"\"Verify that the genesis file contains the expected chain-ID.\n\n    Args:\n        genesis_path (str, optional): Path to genesis.json. Defaults to standard simd location.\n        expected_chain_id (str, optional): The chain-ID we expect. Defaults to \"my-test-chain\".\n\n    Returns:\n        bool: True if verification succeeds, raises otherwise.\n    \"\"\"\n    if not os.path.isfile(genesis_path):\n        raise FileNotFoundError(\n            f\"Genesis file not found at {genesis_path}. Did you run `simd init`?\"\n        )\n\n    with open(genesis_path, \"r\", encoding=\"utf-8\") as fp:\n        data = json.load(fp)\n\n    actual_chain_id = data.get(\"chain_id\")\n\n    if actual_chain_id != expected_chain_id:\n        raise ValueError(\n            f\"chain_id mismatch: expected '{expected_chain_id}', found '{actual_chain_id}'\"\n        )\n\n    return True\n",
	"_query_wasm_smart": "def _query_wasm_smart(contract_addr: str, query_msg: dict):\n    \"\"\"Low-level helper that hits the LCD `/smart/` endpoint.\"\"\"\n    msg_b64 = base64.b64encode(json.dumps(query_msg).encode()).decode()\n    url = f\"{NEUTRON_LCD}/cosmwasm/wasm/v1/contract/{contract_addr}/smart/{msg_b64}\"\n    async with httpx.AsyncClient(timeout=10) as client:\n        r = await client.get(url)\n        if r.status_code != 200:\n            raise HTTPException(status_code=r.status_code, detail=r.text)\n        # LCD wraps contract results inside a `data` or `result` field depending on version.\n        data = r.json()\n        return data.get('data') or data.get('result') or data\n\n@app.get('/api/amber_positions')\nasync def amber_positions(address: str):\n    \"\"\"Public route => `/api/amber_positions?address=<bech32>`\"\"\"\n    try:\n        query_msg = {\"positions_by_owner\": {\"owner\": address}}\n        positions = await _query_wasm_smart(AMBER_CONTRACT_ADDR, query_msg)\n        return positions  # Forward raw contract JSON back to the caller.\n    except HTTPException:\n        raise  # Re-throw FastAPI HTTP errors untouched.\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=f\"Amber query failed: {exc}\")",
	"lock_tokens": "def lock_tokens(req: LockRequest):\n    try:\n        # Defensive checks ----------------------------------------------------\n        if WALLET.address() != req.sender:\n            raise HTTPException(\n                status_code=400,\n                detail=\"Backend wallet address does not match provided sender.\"\n            )\n\n        # Build MsgExecuteContract -------------------------------------------\n        wasm_msg_bytes = json.dumps(req.msg).encode()\n        execute_msg = MsgExecuteContract(\n            sender=req.sender,\n            contract=req.contract_address,\n            msg=wasm_msg_bytes,\n            funds=[\n                {\n                    \"denom\": f.denom,\n                    \"amount\": f.amount,\n                }\n                for f in req.funds\n            ],\n        )\n\n        # Create & sign TX ----------------------------------------------------\n        tx = Transaction()\n        tx.add_message(execute_msg)\n        tx.with_sequence(LedgerClient(NETWORK).get_sequence(req.sender))\n        tx.with_chain_id(NETWORK.chain_id)\n        tx.with_gas(250_000)  # empirical gas; adjust if necessary\n        tx.with_memo(\"Lock 2K NTRN for 90d\")\n\n        # Sign using backend wallet\n        tx_signed = tx.sign(WALLET)\n\n        # Broadcast -----------------------------------------------------------\n        client = LedgerClient(NETWORK)\n        tx_response = client.broadcast_tx(tx_signed)\n\n        return {\n            \"tx_hash\": tx_response.tx_hash.hex(),\n            \"height\": tx_response.height,\n            \"raw_log\": tx_response.raw_log,\n        }\n\n    except HTTPException:\n        raise  # re-throw fastapi exceptions unchanged\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"enable_block_profiling": "def enable_block_profiling() -> Dict[str, str]:\n    \"\"\"Restart the node with block profiling turned on (pprof exposed on :6060).\"\"\"\n    # 1. Stop any running instance of the node (ignore errors if none running)\n    subprocess.run([\"pkill\", \"-f\", NODE_BINARY], check=False)\n\n    # 2. Prepare the new environment with profiling enabled\n    env = os.environ.copy()\n    env[\"GODEBUG\"] = \"blockprofilerate=1\"  # Instruct Go runtime to collect blocking events\n\n    # 3. Start the node\n    cmd = [NODE_BINARY, \"start\", \"--home\", NODE_HOME]\n    log_handle = open(LOG_FILE, \"w\")\n    try:\n        proc = subprocess.Popen(cmd, env=env, stdout=log_handle, stderr=subprocess.STDOUT)\n    except FileNotFoundError:\n        raise RuntimeError(f\"{NODE_BINARY} not found. Check COSMOS_NODE_BINARY environment variable.\")\n\n    return {\n        \"pid\": str(proc.pid),\n        \"log_file\": LOG_FILE,\n        \"message\": f\"Node restarted with block profiling. PID {proc.pid}. Logs at {LOG_FILE}.\"\n    }",
	"wait_runtime": "def wait_runtime(seconds: int = 30) -> Dict[str, str]:\n    \"\"\"Pause execution for `seconds` to let the node gather block-profile samples.\"\"\"\n    if seconds <= 0:\n        raise ValueError(\"seconds must be positive\")\n    await asyncio.sleep(seconds)\n    return {\"status\": \"ok\", \"waited_seconds\": seconds}",
	"fetch_block_profile": "def fetch_block_profile(url: str = PPROF_URL, output_path: str = OUTPUT_FILE) -> Dict[str, str]:\n    \"\"\"Retrieve the block profile and write it to `output_path`.\"\"\"\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n    except requests.RequestException as err:\n        raise RuntimeError(f\"Failed to fetch block profile: {err}\")\n\n    with open(output_path, \"wb\") as fp:\n        fp.write(response.content)\n\n    return {\n        \"output_path\": output_path,\n        \"size_bytes\": len(response.content),\n        \"message\": f\"Block profile saved to {output_path} ({len(response.content)} bytes)\"\n    }",
	"verify_profile_file": "def verify_profile_file(profile_path: str = PROFILE_PATH) -> Dict[str, str]:\n    \"\"\"Check that `profile_path` exists and its size is greater than zero.\"\"\"\n    if not os.path.isfile(profile_path):\n        return {\"exists\": False, \"size_bytes\": 0, \"message\": f\"{profile_path} not found.\"}\n\n    size = os.path.getsize(profile_path)\n    if size == 0:\n        return {\"exists\": True, \"size_bytes\": 0, \"message\": f\"{profile_path} is empty.\"}\n\n    return {\"exists\": True, \"size_bytes\": size, \"message\": f\"{profile_path} verified with {size} bytes.\"}",
	"query_position_status": "def query_position_status(address: str):\n    \"\"\"Returns the address’ Amber position (if any).\"\"\"\n    try:\n        async with LedgerClient(RPC_ENDPOINT) as client:\n            query_msg = {\"position_status\": {\"address\": address}}\n            # Amber is a CosmWasm contract; `wasm_query` expects bytes\n            result = await client.wasm_query(\n                AMBER_CONTRACT,\n                json.dumps(query_msg).encode()\n            )\n            return result\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=f\"Position query failed: {exc}\")",
	"close_position_sign_doc": "def close_position_sign_doc(req: ClosePosRequest):\n    \"\"\"Returns `sign_doc`, `body_bytes`, and `auth_info_bytes` (all base-64) for Keplr’s signDirect.\"\"\"\n    try:\n        async with LedgerClient(RPC_ENDPOINT) as client:\n            # Look-up account info (account number & sequence)\n            acct = await client.query_auth_account(req.address)\n            acct = acct[\"base_account\"] if \"base_account\" in acct else acct\n            account_number = int(acct[\"account_number\"])\n            sequence       = int(acct[\"sequence\"])\n\n            # Build the execute message\n            close_msg = {\"close_position\": {\"id\": req.position_id}}\n            exec_msg  = MsgExecuteContract(\n                sender   = req.address,\n                contract = AMBER_CONTRACT,\n                msg      = close_msg,\n                funds    = []\n            )\n\n            # Prepare the Tx\n            tx = Transaction()\n            tx.add_message(exec_msg)\n            tx.with_gas(req.gas_limit)\n            tx.with_fee(req.fee_amount, req.fee_denom)\n            tx.with_chain_id(req.chain_id)\n            tx.with_memo(\"close Amber position\")\n\n            sign_doc = tx.get_sign_doc(account_number, sequence)\n\n            return {\n                \"sign_doc\":        base64.b64encode(sign_doc.SerializeToString()).decode(),\n                \"body_bytes\":      base64.b64encode(tx.body.SerializeToString()).decode(),\n                \"auth_info_bytes\": base64.b64encode(tx.auth_info.SerializeToString()).decode()\n            }\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=f\"Failed to build sign-doc: {exc}\")",
	"confirm_position_closed": "def confirm_position_closed(address: str):\n    \"\"\"Returns `{closed: true}` once the address has no outstanding debt.\"\"\"\n    try:\n        data = await query_position_status(address)\n        debt = data.get(\"position\", {}).get(\"debt\", 0)\n        return {\"closed\": int(debt) == 0, \"raw\": data}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=f\"Confirmation failed: {exc}\")",
	"ensure_cosmopark_installed": "def ensure_cosmopark_installed() -> None:\n    \"\"\"Ensure that CosmoPark CLI and its Docker images are available.\"\"\"\n    # 1. Check CosmoPark binary\n    if shutil.which(\"cosmopark\") is None:\n        print(\"CosmoPark CLI not found. Attempting installation via pip…\")\n        try:\n            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"cosmopark-cli\"])\n        except subprocess.CalledProcessError as err:\n            raise RuntimeError(\"Automatic installation of CosmoPark CLI failed.\") from err\n    else:\n        print(\"CosmoPark CLI detected ✅\")\n\n    # 2. Verify Docker is installed – required by CosmoPark\n    if shutil.which(\"docker\") is None:\n        raise RuntimeError(\"Docker is required but not installed or not in PATH.\")\n\n    # 3. Pull (or update) all CosmoPark Docker images\n    try:\n        subprocess.check_call([\"cosmopark\", \"pull\", \"--all\"])\n        print(\"CosmoPark Docker images pulled ✅\")\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(\"Failed to pull CosmoPark Docker images.\") from err\n\n\nif __name__ == \"__main__\":\n    try:\n        ensure_cosmopark_installed()\n        print(\"CosmoPark environment is ready 🟢\")\n    except Exception as e:\n        print(f\"❌ {e}\")\n        sys.exit(1)",
	"run_cosmopark_init": "def run_cosmopark_init(workspace_path: str = \"./localnet\") -> None:\n    \"\"\"Run `cosmopark init` inside the chosen workspace directory.\"\"\"\n    workspace = Path(workspace_path).expanduser().resolve()\n    workspace.mkdir(parents=True, exist_ok=True)\n\n    cmd = [\"cosmopark\", \"init\"]\n    try:\n        subprocess.check_call(cmd, cwd=str(workspace))\n        print(f\"Workspace initialised at {workspace} ✅\")\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(\"`cosmopark init` failed.\") from err\n\n\nif __name__ == \"__main__\":\n    path = sys.argv[1] if len(sys.argv) > 1 else \"./localnet\"\n    try:\n        run_cosmopark_init(path)\n    except Exception as e:\n        print(f\"❌ {e}\")\n        sys.exit(1)",
	"run_cosmopark_start": "def run_cosmopark_start(workspace_path: str = \"./localnet\") -> None:\n    \"\"\"Run `cosmopark start` inside the workspace to spin up the chain.\"\"\"\n    cmd = [\"cosmopark\", \"start\"]\n    try:\n        subprocess.check_call(cmd, cwd=workspace_path)\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(\"`cosmopark start` failed.\") from err\n\n\nif __name__ == \"__main__\":\n    path = sys.argv[1] if len(sys.argv) > 1 else \"./localnet\"\n    try:\n        run_cosmopark_start(path)\n    except Exception as e:\n        print(f\"❌ {e}\")\n        sys.exit(1)",
	"verify_local_chain_running": "def verify_local_chain_running(rpc_url: str = \"http://localhost:26657/status\", timeout: int = 60) -> int:\n    \"\"\"Wait until the RPC endpoint returns a status with a block height or raise on timeout.\"\"\"\n    start = time.time()\n    while True:\n        try:\n            resp = requests.get(rpc_url, timeout=3)\n            if resp.status_code == 200:\n                data = resp.json()\n                height = int(data[\"result\"][\"sync_info\"][\"latest_block_height\"])\n                print(f\"Local chain is up ✅  (latest height={height})\")\n                return height\n        except Exception:\n            # Ignore and retry until timeout\n            pass\n\n        if time.time() - start > timeout:\n            raise RuntimeError(f\"Local chain did not start within {timeout} seconds.\")\n\n        print(\"⏳ Waiting for local chain…\")\n        time.sleep(3)\n\n\nif __name__ == \"__main__\":\n    url = sys.argv[1] if len(sys.argv) > 1 else \"http://localhost:26657/status\"\n    try:\n        verify_local_chain_running(url)\n    except Exception as e:\n        print(f\"❌ {e}\")\n        sys.exit(1)",
	"build_msg_add_schedule": "def build_msg_add_schedule(authority: str,\n                           monitoring_contract: str,\n                           gas_limit: int = 500_000) -> MsgAddSchedule:\n    \"\"\"Compose a MsgAddSchedule ready for inclusion in a Tx.\"\"\"\n    try:\n        # 1. Build the inner MsgExecuteContract that will be executed by Cron\n        exec_msg = MsgExecuteContract(\n            sender=authority,\n            contract=monitoring_contract,\n            msg=json.dumps({\"perform_checks\": {}}).encode(),\n            funds=[],\n        )\n\n        # 2. Wrap everything into MsgAddSchedule\n        add_schedule_msg = MsgAddSchedule(\n            authority=authority,\n            name=\"health_check\",\n            period=300,\n            msgs=[exec_msg.SerializeToString()],  # list[bytes]\n            gas_limit=gas_limit,\n        )\n        return add_schedule_msg\n    except Exception as err:\n        raise RuntimeError(f\"Unable to build MsgAddSchedule: {err}\")",
	"check_chain_home": "def check_chain_home(home_path: str = os.path.expanduser(\"~/.simapp\")) -> dict:\n    \"\"\"Validate that the simd home directory has a readable genesis.json and config.toml.\"\"\"\n    result = {\n        \"home\": home_path,\n        \"genesis_exists\": False,\n        \"genesis_valid_json\": False,\n        \"config_exists\": False,\n        \"valid\": False,\n        \"errors\": []\n    }\n\n    genesis_path = os.path.join(home_path, \"config\", \"genesis.json\")\n    config_toml_path = os.path.join(home_path, \"config\", \"config.toml\")\n\n    try:\n        # Check for genesis.json\n        if os.path.isfile(genesis_path):\n            result[\"genesis_exists\"] = True\n            with open(genesis_path, \"r\") as f:\n                json.load(f)  # Raises if the JSON is malformed\n            result[\"genesis_valid_json\"] = True\n        else:\n            result[\"errors\"].append(f\"Missing {genesis_path}\")\n\n        # Check for config.toml\n        if os.path.isfile(config_toml_path):\n            result[\"config_exists\"] = True\n        else:\n            result[\"errors\"].append(f\"Missing {config_toml_path}\")\n\n        # All checks must pass\n        result[\"valid\"] = result[\"genesis_exists\"] and result[\"genesis_valid_json\"] and result[\"config_exists\"]\n    except Exception as e:\n        result[\"errors\"].append(str(e))\n        result[\"valid\"] = False\n\n    return result",
	"start_node": "def start_node(home_path: str = os.path.expanduser(\"~/.simapp\")) -> dict:\n    \"\"\"Start `simd start` as a background subprocess and return its PID or an error.\"\"\"\n    global NODE_PROCESS\n\n    if NODE_PROCESS and NODE_PROCESS.poll() is None:\n        return {\"status\": \"already_running\", \"pid\": NODE_PROCESS.pid}\n\n    cmd = [\"simd\", \"start\"]\n\n    # Supply --home if user chose a custom directory\n    if home_path != os.path.expanduser(\"~/.simapp\"):\n        cmd.extend([\"--home\", home_path])\n\n    try:\n        NODE_PROCESS = subprocess.Popen(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True  # decode bytes -> str automatically\n        )\n        return {\"status\": \"started\", \"pid\": NODE_PROCESS.pid, \"cmd\": \" \".join(cmd)}\n    except FileNotFoundError:\n        return {\"status\": \"error\", \"error\": \"`simd` binary not found in PATH.\"}\n    except Exception as e:\n        return {\"status\": \"error\", \"error\": str(e)}",
	"health_check": "def health_check(max_attempts: int = 30, interval_sec: int = 2) -> dict:\n    \"\"\"Poll http://localhost:26657/status until the node reports a positive block height or times out.\"\"\"\n    url = \"http://localhost:26657/status\"\n    for attempt in range(1, max_attempts + 1):\n        try:\n            resp = requests.get(url, timeout=2)\n            if resp.status_code == 200:\n                data = resp.json()\n                height = int(data[\"result\"][\"sync_info\"][\"latest_block_height\"])\n                if height > 0:\n                    return {\"healthy\": True, \"latest_block_height\": height}\n        except Exception:\n            # Ignored: transient connection errors expected while node boots up\n            pass\n\n        time.sleep(interval_sec)\n\n    return {\"healthy\": False, \"error\": \"Node did not reach a non-zero block height within the allotted time.\"}",
	"get_chain_home": "def get_chain_home(chain_id: str = \"simd\") -> dict:\n    \"\"\"Resolve and validate the chain's home directory.\"\"\"\n    env_var = f\"{chain_id.upper()}_HOME\"       # e.g.  SIMD_HOME\n    home_dir = os.getenv(env_var) or Path.home() / f\".{chain_id}\"\n\n    # Cast Path object to str to keep JSON-serialisable output\n    home_dir = str(home_dir)\n\n    if not os.path.isdir(home_dir):\n        raise FileNotFoundError(f\"Chain home directory not found at {home_dir}\")\n\n    return {\"chain_home\": home_dir}",
	"locate_genesis": "def locate_genesis(chain_home: str) -> dict:\n    \"\"\"Locate and load config/genesis.json from the provided home directory.\"\"\"\n    genesis_path = Path(chain_home) / \"config\" / \"genesis.json\"\n\n    if not genesis_path.exists():\n        raise FileNotFoundError(f\"genesis.json not found at {genesis_path}\")\n\n    with genesis_path.open(\"r\", encoding=\"utf-8\") as f:\n        genesis_data = json.load(f)\n\n    return {\"genesis_path\": str(genesis_path), \"genesis_data\": genesis_data}",
	"backup_genesis": "def backup_genesis(genesis_path: str) -> dict:\n    \"\"\"Copy genesis.json to genesis.json.bak.<timestamp>.\"\"\"\n    src = Path(genesis_path)\n    timestamp = datetime.utcnow().strftime(\"%Y%m%d%H%M%S\")\n    backup_path = src.with_suffix(f\".json.bak.{timestamp}\")\n    shutil.copy2(src, backup_path)  # copy2 keeps file metadata\n    return {\"backup_path\": str(backup_path)}",
	"update_inflation": "def update_inflation(genesis_data: dict, new_inflation: str = \"0.300000000000000000\") -> dict:\n    \"\"\"Set app_state.mint.params.inflation to a new value.\"\"\"\n    try:\n        genesis_data[\"app_state\"][\"mint\"][\"params\"][\"inflation\"] = new_inflation\n    except KeyError as err:\n        raise KeyError(\"Unable to locate mint.params.inflation in genesis.json\") from err\n\n    return {\"updated_genesis\": genesis_data}",
	"save_genesis": "def save_genesis(genesis_path: str, updated_genesis: dict) -> dict:\n    \"\"\"Persist the updated genesis data to disk.\"\"\"\n    path = Path(genesis_path)\n    with path.open(\"w\", encoding=\"utf-8\") as f:\n        json.dump(updated_genesis, f, indent=2, ensure_ascii=False)\n        f.write(\"\\n\")  # POSIX-friendly newline at EOF\n\n    return {\"status\": \"saved\", \"path\": str(path)}",
	"update_log_level": "def update_log_level(config_dict: dict, desired_level: str | None = None):\n    \"\"\"Mutates and returns the provided config dict with an updated log_level.\n\n    Args:\n        config_dict: Parsed TOML dictionary returned from `open_config_file`.\n        desired_level: Custom log level string (defaults to the recommended value).\n    Returns:\n        dict: The same dictionary instance, now with the new log level set.\n    \"\"\"\n    desired_level = desired_level or \"state:info,p2p:info,consensus:info,*:error\"\n\n    # The `log_level` key lives at the top level of config.toml for most Cosmos SDK daemons.\n    # If your daemon nests the setting, update the path accordingly.\n    config_dict[\"log_level\"] = desired_level\n\n    return config_dict",
	"create_bignumber": "def create_bignumber(req: CreateRequest):\n    '''Instantiate a BigNumber from a given string, int, or float.'''\n    try:\n        bn = BigNumber(req.value)\n    except (TypeError, ValueError) as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    return {'big_number': str(bn)}\n",
	"operate": "def operate(req: OperateRequest):\n    '''Perform arithmetic operations between BigNumber values or exponentiation.'''\n    try:\n        a_bn = BigNumber(req.a)\n        if req.operation == Operation.pow:\n            if req.exponent is None:\n                raise HTTPException(status_code=400, detail='Missing exponent for pow operation')\n            result_bn = a_bn.pow(req.exponent)\n        else:\n            if req.b is None:\n                raise HTTPException(status_code=400, detail='Parameter b is required for the selected operation')\n            b_bn = BigNumber(req.b)\n            if req.operation == Operation.add:\n                result_bn = a_bn.add(b_bn)\n            elif req.operation == Operation.sub:\n                result_bn = a_bn.sub(b_bn)\n            elif req.operation == Operation.mul:\n                result_bn = a_bn.mul(b_bn)\n            elif req.operation == Operation.div:\n                result_bn = a_bn.div(b_bn)\n            else:\n                raise HTTPException(status_code=400, detail='Unsupported operation')\n    except (TypeError, ValueError, ZeroDivisionError) as e:\n        raise HTTPException(status_code=400, detail=str(e))\n\n    return {'result': str(result_bn)}\n",
	"format_bignumber": "def format_bignumber(value: str = Query(..., description='Raw big number value as string'),\n                           decimals: int = Query(18, description='Number of token decimals')):\n    '''Convert a raw integer amount into a human-readable decimal representation.'''\n    try:\n        raw_bn = BigNumber(value)\n        divisor_bn = BigNumber(10 ** decimals)\n        human_value = raw_bn.div(divisor_bn)\n        # Ensure fixed decimal places without scientific notation\n        quantize_str = '1.' + '0' * decimals\n        formatted = Decimal(str(human_value)).quantize(Decimal(quantize_str), rounding=ROUND_DOWN).normalize()\n    except (TypeError, ValueError, ZeroDivisionError) as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    return {'formatted': format(formatted, 'f')}\n",
	"_get_client": "def _get_client():\n    \"\"\"Instantiate a LedgerClient for each request.\"\"\"\n    return LedgerClient(NETWORK)\n\n@app.get('/api/points')\nasync def get_user_points(address: str):\n    \"\"\"Return the caller's current point total from the Points contract.\"\"\"\n    try:\n        client = _get_client()\n        query_msg = {'points': {'address': address}}\n        response = client.query_contract_smart(CONTRACT_ADDRESS, query_msg)\n        # Expected shape: {'points': '12345'}\n        points = int(response.get('points', 0))\n        return {'address': address, 'points': points}\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"get_reward_params": "def get_reward_params():\n    \"\"\"Return constants used for reward calculations.\"\"\"\n    try:\n        return REWARD_PARAMS\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"projected_rewards": "def projected_rewards(address: str):\n    \"\"\"Compute and return projected NTRN rewards for the supplied address.\"\"\"\n    try:\n        # 1. Query the user’s point total (reuse logic from Step 2)\n        client = _get_client()\n        query_msg = {'points': {'address': address}}\n        points_response = client.query_contract_smart(CONTRACT_ADDRESS, query_msg)\n        points = int(points_response.get('points', 0))\n\n        # 2. Fetch campaign parameters (from Step 3 constant)\n        per_point_rate = REWARD_PARAMS['per_point_rate']  # micro-NTRN per point\n\n        # 3. Apply multipliers (if any). For now, multiplier = 1.\n        multiplier = 1\n        projected_untrn = points * per_point_rate * multiplier\n        projected_ntrn = projected_untrn / 1_000_000  # convert micro-denom → denom\n\n        return {\n            'address': address,\n            'points': points,\n            'projected_reward_untrn': projected_untrn,\n            'projected_reward_ntrn': projected_ntrn,\n            'assumptions': {\n                **REWARD_PARAMS,\n                'multiplier': multiplier\n            }\n        }\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"validate_token_balance": "def validate_token_balance(address: str, min_offer: int = 1_000_000, min_fee: int = 50_000) -> dict:\n    \"\"\"Verify that `address` owns\n    · `min_offer` micro-eBTC (1 eBTC = 1_000_000 micro-eBTC)\n    · `min_fee`  micro-NTRN for network fees.\n    Returns `{valid: True}` on success or `{valid: False, error: '...'}` otherwise.\n    \"\"\"\n    offer_denom = 'eBTC'\n    fee_denom = 'untrn'\n    try:\n        url = f\"{REST_ENDPOINT}/cosmos/bank/v1beta1/balances/{address}\"\n        resp = requests.get(url, timeout=10)\n        resp.raise_for_status()\n        balances = resp.json().get('balances', [])\n\n        def amount_of(denom: str) -> int:\n            for coin in balances:\n                if coin.get('denom') == denom:\n                    return int(coin.get('amount', '0'))\n            return 0\n\n        if amount_of(offer_denom) < min_offer:\n            raise ValueError('Insufficient eBTC balance.')\n        if amount_of(fee_denom) < min_fee:\n            raise ValueError('Insufficient untrn balance for fees.')\n\n        return {\"valid\": True}\n    except Exception as err:\n        return {\"valid\": False, \"error\": str(err)}",
	"query_dex_pool": "def query_dex_pool(offer_denom: str = 'eBTC', ask_denom: str = 'uniBTC') -> dict:\n    \"\"\"Returns raw pool data for the requested trading pair.\"\"\"\n    query_msg = {\n        \"pool\": {\n            \"pair\": {\n                \"asset_infos\": [\n                    {\"native_token\": {\"denom\": offer_denom}},\n                    {\"native_token\": {\"denom\": ask_denom}}\n                ]\n            }\n        }\n    }\n\n    try:\n        b64 = base64.b64encode(json.dumps(query_msg).encode()).decode()\n        url = f\"{REST_ENDPOINT}/cosmwasm/wasm/v1/contract/{PAIR_CONTRACT}/smart/{b64}\"\n        resp = requests.get(url, timeout=10)\n        resp.raise_for_status()\n        return resp.json()  # contains liquidity, price, etc.\n    except Exception as err:\n        return {\"error\": str(err)}",
	"construct_msg_update_params": "def construct_msg_update_params(authority: str, schedules_per_block: int = 30) -> dict:\n    \"\"\"Return a dict that represents `/neutron.cron.MsgUpdateParams`.\n\n    Args:\n        authority (str): The DAO (gov) address that is allowed to change chain params.\n        schedules_per_block (int): Desired value for the `schedules_per_block` param.\n\n    Returns:\n        dict: JSON-serialisable message ready to be embedded in a proposal.\n    \"\"\"\n    # Basic validation -------------------------------------------------------\n    if not authority.startswith(\"neutron\"):\n        raise ValueError(\"`authority` must be a valid Neutron bech32 address\")\n    if schedules_per_block <= 0:\n        raise ValueError(\"`schedules_per_block` must be > 0\")\n\n    # Build the message ------------------------------------------------------\n    msg = {\n        \"@type\": \"/neutron.cron.MsgUpdateParams\",\n        \"authority\": authority,\n        \"params\": {\n            \"schedules_per_block\": schedules_per_block\n        }\n    }\n    return msg\n\n# OPTIONAL: pretty-print for audit / persistence\nif __name__ == \"__main__\":\n    DAO_ADDR = \"neutron1...\"  # <- replace with real address\n    print(json.dumps(construct_msg_update_params(DAO_ADDR), indent=2))",
	"_encode_cosmos_msg": "def _encode_cosmos_msg(msg: Dict) -> Dict:\n    \"\"\"Helper: builds a `CosmosMsg::Gov`-compatible JSON envelope.\n\n    Because cosmpy (and most clients) accept raw JSON in place of protobuf\n    for Custom messages, we simply return the dict itself. If your DAO core\n    requires base64-encoded `wasm/MsgExecuteContract`, encode as shown below.\n    \"\"\"\n    return msg  # no additional wrapping needed for most cw-dao versions\n\n\ndef build_dao_proposal(msg_update_params: Dict,\n                       title: str = \"Update Cron schedules_per_block to 30\",\n                       description: str = \"Set cron.schedules_per_block param to 30 via governance.\",\n                       deposit: str = \"1000000untrn\",\n                       proposer: str | None = None) -> Dict:\n    \"\"\"Return the message to execute against the DAO core contract.\"\"\"\n\n    if proposer is not None and not proposer.startswith(\"neutron\"):\n        raise ValueError(\"Invalid proposer address\")\n\n    proposal = {\n        \"propose\": {\n            \"title\": title,\n            \"description\": description,\n            \"msgs\": [\n                {\"custom\": _encode_cosmos_msg(msg_update_params)}\n            ],\n            \"deposit\": deposit\n        }\n    }\n    # Some DAO cores support an explicit `proposer` field\n    if proposer:\n        proposal[\"propose\"][\"proposer\"] = proposer\n\n    return proposal\n\nif __name__ == \"__main__\":\n    dao_contract_addr = \"neutron1dao...\"  # <- your DAO core address\n    cron_msg = construct_msg_update_params(authority=dao_contract_addr, schedules_per_block=30)\n    proposal_msg = build_dao_proposal(cron_msg)\n    print(json.dumps(proposal_msg, indent=2))",
	"monitor_proposal_status": "def monitor_proposal_status(dao_contract: str, proposal_id: int,\n                                  rpc: str = RPC,\n                                  chain_id: str = CHAIN_ID,\n                                  interval: int = 15):\n    \"\"\"Continuously poll DAO contract for proposal status until finalised.\"\"\"\n    client = LedgerClient(NetworkConfig(chain_id=chain_id, url=rpc))\n    try:\n        while True:\n            try:\n                result = client.query_contract_state(dao_contract, {\"proposal\": {\"proposal_id\": proposal_id}})\n                status = result[\"proposal\"].get(\"status\", \"unknown\")\n                print(f\"Proposal {proposal_id} ➜ {status}\")\n                if status.lower() in {\"executed\", \"rejected\", \"failed\"}:\n                    return status\n            except Exception as err:\n                print(f\"query error: {err}\")\n            await asyncio.sleep(interval)\n    finally:\n        client.close()\n\n# Usage example --------------------------------------------------------------\n# final_status = await monitor_proposal_status(DAO_CORE_ADDR, PROPOSAL_ID)",
	"broadcast_tx": "def broadcast_tx(req: BroadcastRequest):\n    \"\"\"Broadcast a signed tx and return the txhash.\"\"\"\n    lcd = req.lcd_url or LCD_URL\n    payload = {\"tx_bytes\": req.tx_bytes, \"mode\": req.mode}\n\n    async with httpx.AsyncClient(timeout=15.0) as client:\n        try:\n            res = await client.post(f\"{lcd}/cosmos/tx/v1beta1/txs\", json=payload)\n            res.raise_for_status()\n        except httpx.HTTPError as e:\n            raise HTTPException(status_code=502, detail=f\"Failed to broadcast tx: {e}\")\n\n    data = res.json()\n    txhash = data.get(\"tx_response\", {}).get(\"txhash\")\n    if not txhash:\n        raise HTTPException(status_code=500, detail=\"Broadcast response missing txhash\")\n\n    return {\"txhash\": txhash, \"raw_response\": data}",
	"wait_tx": "def wait_tx(\n    txhash: str,\n    lcd_url: Optional[str] = None,\n    timeout: int = 60,           # seconds before giving up\n    interval: float = 2.0        # seconds between polls\n):\n    \"\"\"Poll /cosmos/tx/v1beta1/txs/{txhash} until it appears in a block.\"\"\"\n    lcd = lcd_url or LCD_URL\n    deadline = asyncio.get_event_loop().time() + timeout\n\n    async with httpx.AsyncClient(timeout=10.0) as client:\n        while True:\n            try:\n                res = await client.get(f\"{lcd}/cosmos/tx/v1beta1/txs/{txhash}\")\n                if res.status_code == 200:\n                    data = res.json()\n                    height = int(data.get(\"tx_response\", {}).get(\"height\", \"0\"))\n                    if height > 0:\n                        return data  # Success!\n            except httpx.HTTPError:\n                # Network hiccup; ignore and retry\n                pass\n\n            if asyncio.get_event_loop().time() >= deadline:\n                raise HTTPException(status_code=504, detail=\"Timed out waiting for transaction to be included in a block\")\n\n            await asyncio.sleep(interval)",
	"install_slither": "def install_slither():\n    \"\"\"\n    Ensure that the Slither static-analysis tool is installed on the host.\n    Preferred installer is `pipx`; we gracefully fall back to `pip` if pipx\n    is not present.  Returns a JSON payload describing the outcome.\n    \"\"\"\n    # Early-exit if Slither already exists in $PATH\n    if shutil.which(\"slither\"):\n        return {\"message\": \"Slither is already installed.\"}\n\n    try:\n        # Decide which installer to use\n        if shutil.which(\"pipx\"):\n            cmd = [\"pipx\", \"install\", \"slither-analyzer\"]\n        else:\n            cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"slither-analyzer\"]\n\n        completed = subprocess.run(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            check=True,\n        )\n        return {\n            \"message\": \"Slither installed successfully.\",\n            \"stdout\": completed.stdout,\n        }\n    except subprocess.CalledProcessError as exc:\n        # Surface installer stderr so the caller can debug easily\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to install Slither: {exc.stderr}\",\n        )",
	"compile_project_for_slither": "def compile_project_for_slither():\n    \"\"\"\n    Trigger Solidity compilation for the current project directory.  The\n    function prefers Hardhat (if `hardhat.config.*` files and `npx` are\n    available); otherwise, it attempts a bare-bones `solc` compilation.\n    \"\"\"\n    try:\n        if shutil.which(\"npx\") and (\n            os.path.isfile(\"hardhat.config.js\") or os.path.isfile(\"hardhat.config.ts\")\n        ):\n            cmd = [\"npx\", \"hardhat\", \"compile\"]\n        elif shutil.which(\"solc\"):\n            # Example fallback: compile every .sol file under ./contracts\n            cmd = [\n                \"solc\",\n                \"--bin\",\n                \"--abi\",\n                \"--overwrite\",\n                \"-o\",\n                \"build\",\n                \"contracts/*.sol\",\n            ]\n        else:\n            raise HTTPException(\n                status_code=500,\n                detail=\"Neither Hardhat nor solc found in PATH; cannot compile project.\",\n            )\n\n        completed = subprocess.run(\n            \" \".join(cmd),\n            shell=True,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            check=True,\n        )\n        return {\"message\": \"Compilation completed.\", \"stdout\": completed.stdout}\n    except subprocess.CalledProcessError as exc:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Compilation failed: {exc.stderr}\",\n        )",
	"run_slither": "def run_slither():\n    \"\"\"\n    Execute `slither .` in the project root and stream the textual\n    vulnerability report back to the caller.\n    \"\"\"\n    try:\n        completed = subprocess.run(\n            [\"slither\", \".\"],\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            check=True,\n        )\n        return {\n            \"message\": \"Slither analysis completed.\",\n            \"stdout\": completed.stdout,\n        }\n    except subprocess.CalledProcessError as exc:\n        raise HTTPException(status_code=500, detail=f\"Slither run failed: {exc.stderr}\")",
	"generate_slither_report": "def generate_slither_report():\n    \"\"\"\n    Run `slither . --json slither-report.json` and verify that the report\n    file exists before returning.  The JSON contents are *not* inlined in the\n    HTTP response to avoid large payloads; only the filepath is returned.\n    \"\"\"\n    report_file = \"slither-report.json\"\n    try:\n        cmd = [\"slither\", \".\", \"--json\", report_file]\n        completed = subprocess.run(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            check=True,\n        )\n        if not os.path.isfile(report_file):\n            raise HTTPException(\n                status_code=500,\n                detail=\"Slither did not produce the expected JSON report.\",\n            )\n        return {\n            \"message\": \"JSON report generated successfully.\",\n            \"stdout\": completed.stdout,\n            \"report_file\": report_file,\n        }\n    except subprocess.CalledProcessError as exc:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"Failed to generate Slither JSON report: {exc.stderr}\",\n        )",
	"construct_delegate_tx": "def construct_delegate_tx(delegator: str, validator: str, amount: int) -> Transaction:\n    \"\"\"Return an unsigned Transaction object carrying MsgDelegate.\"\"\"\n    coin = {\"denom\": DENOM, \"amount\": str(amount)}\n    msg = MsgDelegate(\n        delegator_address = delegator,\n        validator_address = validator,\n        amount            = coin,\n    )\n\n    # Pack into protobuf Any so the tx can hold heterogeneous messages\n    any_msg = Any()\n    any_msg.Pack(msg, type_url_prefix='/')\n\n    tx = Transaction()\n    tx.add_message(any_msg)\n    tx.seal_network_info(network_cfg)  # embeds chain-id etc.\n    return tx",
	"delegate": "def delegate(req: DelegateRequest):\n    try:\n        pk_hex = os.getenv('DELEGATOR_PRIVATE_KEY_HEX')\n        if not pk_hex:\n            raise ValueError('Backend mis-configuration: set DELEGATOR_PRIVATE_KEY_HEX env var')\n\n        priv_key = PrivateKey.from_hex(pk_hex)\n        tx = construct_delegate_tx(req.delegator, req.validator, req.amount)\n\n        # Sign & broadcast in one go\n        result = prepare_and_broadcast(lcd, tx, priv_key)\n\n        if result.code != 0:\n            raise RuntimeError(f\"Tx failed (code {result.code}): {result.raw_log}\")\n\n        return {\"tx_hash\": result.txhash}\n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))",
	"prepare_simulation_env": "def prepare_simulation_env(random_seed: Optional[int] = None) -> Dict[str, Optional[str]]:\n    \"\"\"\n    Sets environment variables required for Cosmos SDK simulation tests.\n\n    Args:\n        random_seed (Optional[int]): Fixed seed to reproduce a run. If None, any\n            previously-set SIMAPP_RANDOM_SEED is removed so the test harness can\n            choose a random seed.\n\n    Returns:\n        Dict[str, Optional[str]]: Snapshot of key environment variables after\n            mutation so callers can log them.\n    \"\"\"\n    try:\n        # Ensure $GOFLAGS is completely unset – it can change go-test behaviour.\n        os.environ.pop(\"GOFLAGS\", None)\n\n        if random_seed is not None:\n            os.environ[\"SIMAPP_RANDOM_SEED\"] = str(random_seed)\n        else:\n            os.environ.pop(\"SIMAPP_RANDOM_SEED\", None)\n\n        return {\n            \"SIMAPP_RANDOM_SEED\": os.getenv(\"SIMAPP_RANDOM_SEED\"),\n            \"GOFLAGS\": os.getenv(\"GOFLAGS\"),\n        }\n    except Exception as e:\n        raise RuntimeError(f\"Failed to prepare simulation environment: {e}\") from e",
	"run_simulation_tests": "def run_simulation_tests(command: str = \"make test-sim-nondeterminism\") -> Tuple[int, List[str]]:\n    \"\"\"\n    Runs Cosmos SDK simulation tests and captures stdout/stderr.\n\n    Args:\n        command (str): Shell command to run. Defaults to the Make target that\n            wraps `go test ./sim/... -run TestFullAppSimulation -v`.\n\n    Returns:\n        Tuple[int, List[str]]: (exit_code, list_of_output_lines)\n    \"\"\"\n    try:\n        process = subprocess.Popen(\n            shlex.split(command),\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            env=os.environ,     # inherits SIMAPP_RANDOM_SEED, GOFLAGS unset\n            text=True,\n            bufsize=1,\n        )\n\n        output_lines: List[str] = []\n        for line in process.stdout:\n            print(line, end=\"\")           # realtime feedback in CI/logs\n            output_lines.append(line.rstrip(\"\\n\"))\n\n        process.wait()\n        return process.returncode, output_lines\n    except FileNotFoundError as e:\n        raise RuntimeError(f\"Simulation command not found: {e}\") from e\n    except Exception as e:\n        raise RuntimeError(f\"Error running simulation tests: {e}\") from e",
	"parse_simulation_output": "def parse_simulation_output(output_lines: List[str]) -> List[Dict[str, int]]:\n    \"\"\"\n    Extracts seed and block-height information printed by the test runner.\n\n    Looks for lines such as:\n        --- RUN   TestFullAppSimulation_Seed=169314843_Blocks=500\n    or separate `Seed:` / `Block height:` lines.\n\n    Args:\n        output_lines (List[str]): Captured stdout/stderr lines.\n\n    Returns:\n        List[Dict[str, int]]: One dict per simulation, e.g. [{\"seed\": 169314843,\n            \"blocks\": 500}].\n    \"\"\"\n    pattern = re.compile(r\".*Seed[=:\\s](\\d+).*(?:Blocks?|Block height)[=:\\s](\\d+)\")\n    results: List[Dict[str, int]] = []\n\n    for line in output_lines:\n        match = pattern.match(line)\n        if match:\n            seed = int(match.group(1))\n            blocks = int(match.group(2))\n            results.append({\"seed\": seed, \"blocks\": blocks})\n\n    return results",
	"verify_simulation_results": "def verify_simulation_results(exit_code: int, output_lines: list) -> None:\n    \"\"\"\n    Verifies success criteria for Cosmos SDK simulations.\n\n    Raises RuntimeError if any check fails.\n    \"\"\"\n    if exit_code != 0:\n        raise RuntimeError(f\"Simulation tests terminated with exit code {exit_code}.\")\n\n    log_blob = \"\\n\".join(output_lines).lower()\n\n    # Fail fast if any panic occurred.\n    if \"panic\" in log_blob:\n        raise RuntimeError(\"'panic' detected in simulation logs.\")\n\n    # Check invariants: allow either explicit success line or absence of failures.\n    if \"invariants broken\" in log_blob and \"invariants broken: 0\" not in log_blob:\n        raise RuntimeError(\"Invariants were broken during simulation.\")\n\n    print(\"✅ All simulations passed without panics and with invariants intact.\")",
	"allow_cosmos_p2p_port": "def allow_cosmos_p2p_port() -> dict:\n    \"\"\"Allow TCP/26656 through UFW with the comment 'Cosmos P2P'.\n    NOTE: This function must be executed with root privileges (e.g. the\n    backend process itself runs as root or via sudo in a privileged\n    execution environment).\"\"\"\n\n    cmd = [\n        \"sudo\",          # ensure the command runs with elevated privileges\n        \"ufw\",\n        \"allow\",\n        \"26656/tcp\",\n        \"comment\",\n        \"Cosmos P2P\"\n    ]\n\n    try:\n        # capture_output=True lets us read stdout/stderr for debugging\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=True  # raises CalledProcessError when return code != 0\n        )\n        return {\n            \"status\": \"success\",\n            \"message\": result.stdout.strip() or \"Port 26656 opened successfully.\"\n        }\n\n    except subprocess.CalledProcessError as err:\n        # Standardized error structure for the frontend to consume\n        raise RuntimeError(\n            f\"Failed to add UFW rule: {err.stderr.strip()}\"\n        )",
	"grpc_bank_all_balances": "def grpc_bank_all_balances(address: str, height: Optional[int] = None) -> dict:\n    \"\"\"Return the gRPC QueryAllBalancesResponse as a plain Python dict.\"\"\"\n    channel = grpc.insecure_channel(GRPC_ENDPOINT)\n    stub = bank_query_grpc.QueryStub(channel)\n\n    request = bank_query_pb2.QueryAllBalancesRequest(address=address)\n\n    metadata = []\n    if height is not None:\n        metadata.append(('x-cosmos-block-height', str(height)))\n\n    try:\n        response_proto = stub.AllBalances(request, metadata=metadata, timeout=10)\n        return MessageToDict(response_proto, preserving_proto_field_name=True)\n    except grpc.RpcError as rpc_err:\n        # Convert low-level gRPC errors into generic exceptions for the HTTP layer\n        raise RuntimeError(f'gRPC query failed: {rpc_err.details()} (code={rpc_err.code()})') from rpc_err\n\n# -----------------------------------------------------------------------------\n# FastAPI wrapper so the frontend can fetch with a simple HTTP call\n# -----------------------------------------------------------------------------\nfrom fastapi import FastAPI, HTTPException, Query\n\napp = FastAPI()\n\n@app.get('/api/balances')\ndef api_all_balances(\n    address: str = Query(..., description='Bech32 account address'),\n    height: Optional[int] = Query(None, description='Optional block height')):\n    try:\n        return grpc_bank_all_balances(address, height)\n    except RuntimeError as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"parse_balances_response": "def parse_balances_response(response: dict):\n    \"\"\"Extracts a simple list of {denom, amount} from the gRPC response dict.\"\"\"\n    try:\n        balances = response.get('balances', [])\n        return [{'denom': coin['denom'], 'amount': coin['amount']} for coin in balances]\n    except (AttributeError, KeyError, TypeError) as err:\n        raise ValueError('Malformed balances response') from err",
	"_evmos_network_config": "def _evmos_network_config() -> dict:\n    \"\"\"Return a dict that follows MetaMask’s `wallet_addEthereumChain` spec.\"\"\"\n    return {\n        \"chainId\": \"0x2329\",  # 9001 in hex\n        \"chainName\": \"Evmos\",\n        \"nativeCurrency\": {\n            \"name\": \"Evmos\",\n            \"symbol\": \"EVMOS\",\n            \"decimals\": 18\n        },\n        \"rpcUrls\": [\n            \"https://eth.bd.evmos.org:8545\"\n        ],\n        \"blockExplorerUrls\": [\n            \"https://escan.live\"\n        ]\n    }\n\n\n@app.get(\"/api/network/evmos\")\nasync def get_network_config():\n    \"\"\"GET /api/network/evmos → JSON network parameters.\"\"\"\n    try:\n        return JSONResponse(_evmos_network_config())\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"get_cron_authority": "def get_cron_authority(lcd_endpoint: str) -> str:\n    \"\"\"Return the Cron module authority address (e.g. the Main DAO address).\"\"\"\n    try:\n        url = f\"{lcd_endpoint}/neutron/cron/v1/params\"\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        # The expected JSON shape is: {\"params\": {\"authority\": \"neutron1...\"}}\n        return response.json()[\"params\"][\"authority\"]\n    except (requests.RequestException, KeyError) as err:\n        raise RuntimeError(f\"Unable to fetch Cron authority: {err}\")",
	"validate_contract": "def validate_contract(address: str, lcd_endpoint: str) -> bool:\n    \"\"\"Return True when the contract exists and is instantiated.\"\"\"\n    try:\n        url = f\"{lcd_endpoint}/cosmwasm/wasm/v1/contract/{address}\"\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        info = response.json().get(\"contract_info\", {})\n        # Minimal sanity-check: the endpoint echoes back the queried address\n        return info.get(\"address\") == address\n    except requests.RequestException:\n        return False",
	"build_msg_execute_contract": "def build_msg_execute_contract(staking_contract: str, cron_sender: str = \"cron\") -> dict:\n    \"\"\"Return a MsgExecuteContract dict compatible with protobuf/CLI JSON.\"\"\"\n    inner_msg = {\"distribute_rewards\": {}}\n    return {\n        \"@type\": \"/cosmwasm.wasm.v1.MsgExecuteContract\",\n        \"sender\": cron_sender,\n        \"contract\": staking_contract,\n        \"msg\": base64.b64encode(json.dumps(inner_msg).encode()).decode(),  # base64-encoded\n        \"funds\": []\n    }",
	"write_proposal_file": "def write_proposal_file(msg_add_schedule: dict, filename: str = \"proposal.json\") -> str:\n    \"\"\"Write the governance proposal to disk and return the file name.\"\"\"\n    proposal = {\n        \"title\": \"Add weekly staking-reward cron\",\n        \"description\": \"Distribute staking rewards every week automatically\",\n        \"messages\": [msg_add_schedule]\n    }\n    with open(filename, \"w\", encoding=\"utf-8\") as fp:\n        json.dump(proposal, fp, indent=2)\n    return filename",
	"submit_proposal": "def submit_proposal(file_path: str, from_key: str, chain_id: str, node: str) -> None:\n    \"\"\"Call neutrond CLI to submit the proposal for voting.\"\"\"\n    cmd = [\n        \"neutrond\", \"tx\", \"wasm\", \"submit-proposal\", file_path,\n        \"--from\", from_key,\n        \"--chain-id\", chain_id,\n        \"--node\", node,\n        \"--gas\", \"auto\",\n        \"--gas-adjustment\", \"1.3\",\n        \"-y\"\n    ]\n    try:\n        subprocess.run(cmd, check=True)\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"Proposal submission failed: {err}\")",
	"wait_for_proposal_passage": "def wait_for_proposal_passage(proposal_id: int, lcd_endpoint: str, poll: int = 15, timeout: int = 3600) -> None:\n    \"\"\"Block until the proposal is PASSED or raise if REJECTED/EXPIRED/timeout.\"\"\"\n    deadline = time.time() + timeout\n    gov_url = f\"{lcd_endpoint}/cosmos/gov/v1/proposals/{proposal_id}\"\n    while time.time() < deadline:\n        response = requests.get(gov_url, timeout=10)\n        response.raise_for_status()\n        status = int(response.json()[\"proposal\"][\"status\"])\n        if status == 3:  # PASSED\n            print(f\"✅  Proposal {proposal_id} PASSED\")\n            return\n        if status in (4, 5):  # REJECTED or FAILED\n            raise RuntimeError(f\"❌  Proposal {proposal_id} failed with status {status}\")\n        print(f\"⏳  Waiting... current status = {status}\")\n        time.sleep(poll)\n    raise TimeoutError(\"Timed out waiting for proposal to pass\")",
	"query_cron_schedule": "def query_cron_schedule(name: str, lcd_endpoint: str) -> dict:\n    \"\"\"Return the on-chain definition of the given Cron schedule name.\"\"\"\n    url = f\"{lcd_endpoint}/neutron/cron/v1/schedule/{name}\"\n    response = requests.get(url, timeout=10)\n    response.raise_for_status()\n    return response.json()",
	"stop_evmd_service": "def stop_evmd_service(service_name: str = \"evmd\") -> dict:\n    \"\"\"Stops the evmd (systemd) service gracefully.\"\"\"\n    try:\n        # Attempt to stop the service\n        subprocess.run([\"systemctl\", \"stop\", service_name], check=True)\n        return {\"service\": service_name, \"status\": \"stopped\"}\n    except subprocess.CalledProcessError as e:\n        # Convert the low-level error into a clearer Python exception\n        raise RuntimeError(f\"Failed to stop {service_name}: {e}\")",
	"_replace_or_add": "def _replace_or_add(pattern: str, replacement: str, text: str) -> str:\n    \"\"\"Replace a line that matches pattern or add replacement inside [json-rpc] section.\"\"\"\n    if re.search(pattern, text, flags=re.MULTILINE):\n        return re.sub(pattern, replacement, text, flags=re.MULTILINE)\n\n    # If the key is missing, insert it after the [json-rpc] header\n    lines = text.splitlines()\n    updated_lines = []\n    in_json_rpc = False\n\n    for idx, line in enumerate(lines):\n        updated_lines.append(line)\n        if line.strip().startswith(\"[json-rpc]\"):\n            in_json_rpc = True\n            continue\n        # Insert when we exit the [json-rpc] section\n        if in_json_rpc and line.strip().startswith(\"[\") and not line.strip().startswith(\"[json-rpc]\"):\n            updated_lines.insert(len(updated_lines) - 1, replacement)\n            in_json_rpc = False\n    return \"\\n\".join(updated_lines)\n\n\ndef update_app_toml_parameter(config_path: str = \"~/.evmd/config/app.toml\") -> dict:\n    \"\"\"Mutates app.toml in-place to enable JSON-RPC & txpool along with indexing.\"\"\"\n    path = Path(config_path).expanduser()\n    if not path.exists():\n        raise FileNotFoundError(f\"{path} does not exist.\")\n\n    raw = path.read_text(encoding=\"utf-8\")\n\n    # Apply the required replacements or insertions\n    updated = raw\n    updated = _replace_or_add(r\"^enable\\s*=.*$\", \"enable = true\", updated)\n    updated = _replace_or_add(r\"^api\\s*=.*$\", \"api = \\\"eth,net,web3,txpool,debug\\\"\", updated)\n    updated = _replace_or_add(r\"^enable-indexer\\s*=.*$\", \"enable-indexer = true\", updated)\n\n    # Write only if something changed\n    changed = updated != raw\n    if changed:\n        path.write_text(updated, encoding=\"utf-8\")\n\n    return {\"path\": str(path), \"changed\": changed}",
	"verify_app_toml": "def verify_app_toml(config_path: str = \"~/.evmd/config/app.toml\") -> bool:\n    \"\"\"Returns True if enable=true, txpool exists in api, and enable-indexer=true.\"\"\"\n    path = Path(config_path).expanduser()\n    text = path.read_text(encoding=\"utf-8\")\n    return all([\n        \"enable = true\" in text,\n        \"txpool\" in text,\n        \"enable-indexer = true\" in text,\n    ])",
	"start_evmd_service": "def start_evmd_service(service_name: str = \"evmd\") -> dict:\n    \"\"\"Starts evmd and returns the latest logs to confirm successful boot.\"\"\"\n    try:\n        subprocess.run([\"systemctl\", \"start\", service_name], check=True)\n        logs = subprocess.check_output([\n            \"journalctl\", \"-u\", service_name, \"-n\", \"20\", \"--no-pager\"\n        ], text=True)\n        return {\"service\": service_name, \"status\": \"started\", \"logs\": logs}\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f\"Failed to start {service_name}: {e}\")",
	"json_rpc_call": "def json_rpc_call(method: str = \"txpool_status\", params: list | None = None, endpoint: str = \"http://localhost:8545\") -> dict:\n    \"\"\"Executes a JSON-RPC call and returns the result payload.\"\"\"\n    if params is None:\n        params = []\n\n    payload = {\n        \"jsonrpc\": \"2.0\",\n        \"method\": method,\n        \"params\": params,\n        \"id\": 1,\n    }\n\n    try:\n        response = requests.post(endpoint, json=payload, timeout=5)\n        response.raise_for_status()\n        data = response.json()\n        if \"error\" in data:\n            raise RuntimeError(f\"RPC Error: {data['error']}\")\n        return data.get(\"result\")\n    except (requests.RequestException, ValueError) as e:\n        raise RuntimeError(f\"Failed to perform JSON-RPC call: {e}\")",
	"locate_genesis_file": "def locate_genesis_file(chain_home: str) -> str:\n    \"\"\"Return the absolute path to config/genesis.json and verify its existence.\"\"\"\n    genesis_path = os.path.join(chain_home, \"config\", \"genesis.json\")\n    if not os.path.isfile(genesis_path):\n        raise FileNotFoundError(f\"genesis.json not found at {genesis_path}\")\n    return genesis_path\n",
	"update_voting_period": "def update_voting_period(genesis_path: str, new_period: str = \"600s\") -> Dict:\n    \"\"\"\n    Modify `voting_period` in-place within the genesis JSON structure.\n    Handles both:\n      • app_state.gov.params.voting_period  (newer SDK)\n      • app_state.gov.voting_params.voting_period  (older SDK)\n    Returns the updated Python dict (not yet persisted).\n    \"\"\"\n    with open(genesis_path, \"r\", encoding=\"utf-8\") as fp:\n        genesis = json.load(fp)\n\n    app_state = genesis.get(\"app_state\", {})\n    gov_state = app_state.get(\"gov\", {})\n    updated = False\n\n    # Newer SDK layout\n    params = gov_state.get(\"params\", {})\n    if \"voting_period\" in params:\n        params[\"voting_period\"] = new_period\n        updated = True\n\n    # Older SDK layout\n    voting_params = gov_state.get(\"voting_params\", {})\n    if \"voting_period\" in voting_params:\n        voting_params[\"voting_period\"] = new_period\n        updated = True\n\n    if not updated:\n        raise KeyError(\"voting_period field not found in genesis.json\")\n\n    return genesis\n",
	"fork_mint_module": "def fork_mint_module(project_root: str, new_module_name: str = 'custommint') -> str:\n    # Copy Cosmos-SDK mint module into x/<new_module_name> and rename packages\n    mint_src = Path(project_root) / 'x' / 'mint'\n    mint_dst = Path(project_root) / 'x' / new_module_name\n\n    if not mint_src.exists():\n        raise FileNotFoundError(f'Original mint module not found at {mint_src}')\n\n    if mint_dst.exists():\n        logging.warning('Destination %s already exists. Overwriting...', mint_dst)\n        shutil.rmtree(mint_dst)\n\n    shutil.copytree(mint_src, mint_dst)\n\n    # Update package declarations inside .go files\n    for go_file in mint_dst.rglob('*.go'):\n        content = go_file.read_text()\n        content = content.replace('package mint', f'package {new_module_name}')\n        go_file.write_text(content)\n\n    logging.info('Forked mint module into %s', mint_dst)\n    return str(mint_dst)\n\n\nif __name__ == '__main__':\n    import argparse\n    parser = argparse.ArgumentParser(description='Fork Cosmos-SDK mint module')\n    parser.add_argument('--project_root', required=True, help='Path to the chain source root')\n    parser.add_argument('--module_name', default='custommint')\n    args = parser.parse_args()\n    fork_mint_module(args.project_root, args.module_name)\n",
	"implement_custom_inflation_logic": "def implement_custom_inflation_logic(project_root: str, new_module_name: str = 'custommint') -> None:\n    # Inject a new exponential-decay inflation model into x/<new_module_name>/inflation.go\n    inflation_file = Path(project_root) / 'x' / new_module_name / 'inflation.go'\n    if not inflation_file.exists():\n        raise FileNotFoundError(inflation_file)\n\n    content = inflation_file.read_text()\n    pattern = r'func\\s+CalculateInflation[\\s\\S]*?\\}'\n    custom_logic = (\n        '// CalculateInflation replaces the default Cosmos-SDK logic with an exponential\\n'\n        '// decay model.\\n\\n'\n        'func CalculateInflation(params types.Params, firstBlockTime time.Time, blockTime time.Time) sdk.Dec {\\n'\n        '    epochs := int(blockTime.Sub(firstBlockTime).Hours() / (24 * 365))\\n'\n        '    initialInflation := sdk.NewDecWithPrec(20, 2) // 0.20\\n'\n        '    decayFactor := sdk.NewDecWithPrec(98, 2)      // 0.98\\n\\n'\n        '    pow := sdk.OneDec()\\n'\n        '    for i := 0; i < epochs; i++ {\\n'\n        '        pow = pow.Mul(decayFactor)\\n'\n        '    }\\n'\n        '    return initialInflation.Mul(pow)\\n'\n        '}')\n\n    new_content = re.sub(pattern, custom_logic, content, flags=re.MULTILINE)\n    inflation_file.write_text(new_content)\n    logging.info('Custom inflation logic written to %s', inflation_file)\n\n\nif __name__ == '__main__':\n    import argparse\n    parser = argparse.ArgumentParser(description='Inject custom inflation logic')\n    parser.add_argument('--project_root', required=True)\n    parser.add_argument('--module_name', default='custommint')\n    args = parser.parse_args()\n    implement_custom_inflation_logic(args.project_root, args.module_name)\n",
	"register_custom_module": "def register_custom_module(project_root: str, new_module_name: str = 'custommint', go_module_path: str = 'github.com/my/app') -> None:\n    # Wire the custom mint module into app.go, replacing the default mint module\n    app_file = Path(project_root) / 'app.go'\n    if not app_file.exists():\n        raise FileNotFoundError(app_file)\n\n    content = app_file.read_text()\n\n    # Replace import path for mint module\n    default_import = '\"github.com/cosmos/cosmos-sdk/x/mint\"'\n    custom_import = f'\"{go_module_path}/x/{new_module_name}\"'\n    if default_import in content and custom_import not in content:\n        content = content.replace(default_import, custom_import)\n\n    # Replace keeper and module registration references\n    content = content.replace('mint.NewKeeper(', f'{new_module_name}.NewKeeper(')\n    content = content.replace('mintmodule.NewAppModule', f'{new_module_name}.NewAppModule')\n\n    app_file.write_text(content)\n    logging.info('app.go updated to use %s module', new_module_name)\n\n\nif __name__ == '__main__':\n    import argparse\n    parser = argparse.ArgumentParser(description='Register custom mint module')\n    parser.add_argument('--project_root', required=True)\n    parser.add_argument('--module_name', default='custommint')\n    parser.add_argument('--go_module_path', default='github.com/my/app')\n    args = parser.parse_args()\n    register_custom_module(args.project_root, args.module_name, args.go_module_path)\n",
	"create_inflation_test": "def create_inflation_test(project_root: str, new_module_name: str = 'custommint') -> None:\n    test_dir = Path(project_root) / 'x' / new_module_name\n    test_file = test_dir / 'inflation_test.go'\n    if test_file.exists():\n        return\n\n    lines = [\n        f'package {new_module_name}',\n        '',\n        'import (',\n        '    \"testing\"',\n        '    \"time\"',\n        ')',\n        '',\n        'func TestCalculateInflation(t *testing.T) {',\n        '    params := DefaultParams()',\n        '    now := time.Now()',\n        '',\n        '    infStart := CalculateInflation(params, now, now)',\n        '    infNextYear := CalculateInflation(params, now, now.AddDate(1, 0, 0))',\n        '',\n        '    if !infNextYear.LT(infStart) {',\n        '        t.Fatalf(\"expected inflation to decay: got %s >= %s\", infNextYear, infStart)',\n        '    }',\n        '}',\n    ]\n    test_file.write_text('\\n'.join(lines))\n    logging.info('Created %s', test_file)\n\n\ndef go_build_and_unit_test(project_root: str) -> None:\n    create_inflation_test(project_root)\n\n    logging.info('Running go test ./...')\n    result = subprocess.run(['go', 'test', './...'], cwd=project_root)\n    if result.returncode != 0:\n        raise SystemExit('Go tests failed')\n\n    logging.info('Building binaries')\n    result2 = subprocess.run(['go', 'build', './...'], cwd=project_root)\n    if result2.returncode != 0:\n        raise SystemExit('Go build failed')\n\n\nif __name__ == '__main__':\n    import argparse\n    parser = argparse.ArgumentParser(description='Run build and unit tests')\n    parser.add_argument('--project_root', required=True)\n    args = parser.parse_args()\n    go_build_and_unit_test(args.project_root)\n",
	"launch_devnet_and_monitor": "def launch_devnet_and_monitor(project_root: str, home: str = './sim_home') -> None:\n    logging.basicConfig(level=logging.INFO)\n    node_cmd = ['simd', 'start', '--home', home]\n    env = os.environ.copy()\n    env['DAEMON_HOME'] = home\n\n    proc = subprocess.Popen(node_cmd, cwd=project_root, stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)\n    try:\n        rpc = 'http://localhost:1317'\n        # Wait until REST server is up\n        for _ in range(60):\n            try:\n                r = requests.get(f'{rpc}/node_info', timeout=2)\n                if r.status_code == 200:\n                    break\n            except requests.exceptions.RequestException:\n                pass\n            time.sleep(1)\n        else:\n            raise RuntimeError('REST API did not start in time')\n\n        logging.info('Node is running. Waiting for a few blocks...')\n        time.sleep(10)\n\n        inflation = requests.get(f'{rpc}/cosmos/mint/v1beta1/inflation').json()\n        provisions = requests.get(f'{rpc}/cosmos/mint/v1beta1/annual_provisions').json()\n        logging.info('Current inflation: %s', inflation)\n        logging.info('Annual provisions: %s', provisions)\n    finally:\n        logging.info('Terminating node')\n        proc.send_signal(signal.SIGINT)\n        proc.wait()\n\n\nif __name__ == '__main__':\n    import argparse\n    parser = argparse.ArgumentParser(description='Run local devnet and monitor inflation values')\n    parser.add_argument('--project_root', required=True)\n    parser.add_argument('--home', default='./sim_home')\n    args = parser.parse_args()\n    launch_devnet_and_monitor(args.project_root, args.home)\n",
	"set_json_rpc_enable": "def set_json_rpc_enable(config: dict, enable: bool = True) -> dict:\n    \"\"\"Set the `enable` flag in the `[json-rpc]` section.\"\"\"\n    # Create the section if it does not yet exist\n    config.setdefault(\"json-rpc\", {})\n\n    # Update the flag\n    config[\"json-rpc\"][\"enable\"] = enable\n\n    return config",
	"set_json_rpc_address": "def set_json_rpc_address(config: dict, address: str = \"0.0.0.0:8545\") -> dict:\n    \"\"\"Set the HTTP address where the JSON-RPC server will listen.\"\"\"\n    config.setdefault(\"json-rpc\", {})\n    config[\"json-rpc\"][\"address\"] = address\n    return config",
	"set_ws_address_optional": "def set_ws_address_optional(\n    config: dict,\n    ws_address: str = \"0.0.0.0:8546\",\n    enable_ws: bool = True,\n) -> dict:\n    \"\"\"Add or remove the `ws-address` key inside `[json-rpc]`.\"\"\"\n    config.setdefault(\"json-rpc\", {})\n\n    if enable_ws:\n        config[\"json-rpc\"][\"ws-address\"] = ws_address\n    else:\n        # Remove the key if present and WebSocket is disabled\n        config[\"json-rpc\"].pop(\"ws-address\", None)\n\n    return config",
	"restart_node": "def restart_node(service_name: str = \"evmd\") -> None:\n    \"\"\"Restart the node process via systemctl (or fall back to a manual command).\"\"\"\n    try:\n        # Attempt a systemd restart\n        subprocess.run([\"systemctl\", \"restart\", service_name], check=True)\n        print(f\"Service '{service_name}' restarted successfully.\")\n\n    except FileNotFoundError:\n        # systemctl not available (e.g. macOS or containers)\n        raise EnvironmentError(\n            \"systemctl not found. Please restart the node manually or adapt this function.\"\n        )\n\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(\n            f\"Failed to restart '{service_name}'. Systemctl returned: {err}\"\n        )",
	"get_block_number": "def get_block_number(rpc_url: str = Query(..., description=\"Full HTTP(S) JSON-RPC endpoint\")):\n    \"\"\"Return the latest block number from a JSON-RPC endpoint.\"\"\"\n    payload = {\n        \"jsonrpc\": \"2.0\",\n        \"id\": 1,\n        \"method\": \"eth_blockNumber\",\n        \"params\": []\n    }\n    try:\n        async with httpx.AsyncClient(timeout=10) as client:\n            response = await client.post(rpc_url, json=payload)\n            response.raise_for_status()\n            data = response.json()\n            # Validate JSON-RPC structure\n            if \"result\" not in data:\n                raise ValueError(\"Malformed JSON-RPC response: 'result' key missing\")\n            # Convert hex string (e.g., '0x10d4f') to int\n            block_number = int(data[\"result\"], 16)\n            return {\"block_number\": block_number}\n    except (httpx.HTTPError, ValueError) as exc:\n        # Propagate a clean API error to the caller\n        raise HTTPException(status_code=500, detail=str(exc))",
	"build_msg_update_params": "def build_msg_update_params(authority: str, *, max_schedules: int | None = None, default_gas_limit: int | None = None) -> MsgUpdateParams:\n    \"\"\"Constructs MsgUpdateParams with only the fields that need updating.\n\n    Args:\n        authority: Address allowed to perform the update (DAO address).\n        max_schedules: New maximum number of active cron schedules.\n        default_gas_limit: Optional default gas limit per cron execution.\n    \"\"\"\n    params = Params()\n    if max_schedules is not None:\n        params.max_schedules = max_schedules\n    if default_gas_limit is not None:\n        params.default_gas_limit = default_gas_limit\n\n    return MsgUpdateParams(authority=authority, params=params)",
	"create_preblocker_fn": "def create_preblocker_fn(app_dir: str) -> None:\n    \"\"\"\n    Inserts a PreBlocker function in app/app.go that updates consensus params\n    at the beginning of every block.\n    \"\"\"\n    app_go_path = os.path.join(app_dir, \"app\", \"app.go\")\n    if not os.path.exists(app_go_path):\n        raise FileNotFoundError(f\"{app_go_path} not found\")\n\n    preblocker_code = textwrap.dedent('''\n\n// -------------------------- PreBlocker ----------------------------------\n// PreBlocker updates consensus parameters before every block is processed.\n//\n// Required imports (add to the import block in app/app.go):\n//   \"github.com/cosmos/cosmos-sdk/types\"\n//   abci \"github.com/cometbft/cometbft/abci/types\"\n//   tmtypes \"github.com/cometbft/cometbft/proto/tendermint/types\"\n//   \"time\"\nfunc PreBlocker(ctx sdk.Context, req abci.RequestPreBlock) {\n    // Example mutation: increase MaxGas every block\n    newParams := &tmtypes.ConsensusParams{\n        Block: &tmtypes.BlockParams{\n            MaxBytes: 22020096, // 21 MB\n            MaxGas:   10000000,\n        },\n        Evidence: &tmtypes.EvidenceParams{\n            MaxAgeDuration: 48 * time.Hour,\n            MaxAgeNumBlocks: 100000,\n        },\n        Validator: &tmtypes.ValidatorParams{\n            PubKeyTypes: []string{\"ed25519\"},\n        },\n    }\n\n    if err := app.BaseApp.UpdateConsensusParams(ctx, newParams); err != nil {\n        ctx.Logger().Error(\"failed to update consensus params\", \"err\", err)\n    }\n}\n// ------------------------------------------------------------------------\n''')\n\n    with open(app_go_path, \"r+\") as f:\n        content = f.read()\n        if \"func PreBlocker(\" in content:\n            print(\"PreBlocker already exists in file, skipping.\")\n            return\n        f.write(preblocker_code)\n    print(\"✅ PreBlocker function added to app/app.go\")\n\n\nif __name__ == \"__main__\":\n    # Usage: python create_preblocker_fn.py /absolute/path/to/your/app\n    target = sys.argv[1] if len(sys.argv) > 1 else \".\"\n    create_preblocker_fn(os.path.abspath(target))",
	"register_preblocker": "def register_preblocker(app_dir: str) -> None:\n    \"\"\"\n    Adds app.SetPreBlocker(PreBlocker) to the NewApp constructor so the PreBlocker executes every block.\n    \"\"\"\n    app_go_path = os.path.join(app_dir, \"app\", \"app.go\")\n    if not os.path.exists(app_go_path):\n        raise FileNotFoundError(f\"{app_go_path} not found\")\n\n    with open(app_go_path, \"r+\") as f:\n        content = f.read()\n        if \"SetPreBlocker(PreBlocker)\" in content:\n            print(\"PreBlocker already registered, skipping.\")\n            return\n\n        # Insert right before the final return statement inside NewApp\n        pattern = r\"func\\s+NewApp[\\s\\S]+?return\\s+app\"\n        match = re.search(pattern, content)\n        if not match:\n            print(\"Could not locate NewApp function; please register manually.\")\n            return\n\n        insert_idx = match.end() - len(\"return app\")\n        insertion = \"\\n    // Register the PreBlocker\\n    app.SetPreBlocker(PreBlocker)\\n\"\n        new_content = content[:insert_idx] + insertion + content[insert_idx:]\n\n        f.seek(0)\n        f.write(new_content)\n        f.truncate()\n\n    print(\"✅ PreBlocker registered in NewApp\")\n\n\nif __name__ == \"__main__\":\n    target = sys.argv[1] if len(sys.argv) > 1 else \".\"\n    register_preblocker(os.path.abspath(target))",
	"compile_binary": "def compile_binary(app_dir: str = \".\") -> None:\n    \"\"\"\n    Compiles the modified binary and installs it to $GOBIN.\n    \"\"\"\n    print(\"🔨 Compiling the blockchain binary …\")\n    proc = subprocess.run([\"go\", \"install\", \"./...\"], cwd=app_dir, capture_output=True, text=True)\n    if proc.returncode != 0:\n        print(proc.stderr)\n        raise RuntimeError(\"Compilation failed\")\n    print(\"✅ Compilation successful. Binary available in your GOPATH/bin directory.\")\n\n\nif __name__ == \"__main__\":\n    compile_binary(sys.argv[1] if len(sys.argv) > 1 else \".\")",
	"start_local_chain": "def start_local_chain(home: str = \"./data\", chain_id: str = \"localnet\", binary: str = \"appd\") -> None:\n    \"\"\"\n    Starts a single-node chain using the rebuilt binary.\n    \"\"\"\n    if not os.path.exists(home):\n        print(\"🔧 Initializing home directory\")\n        subprocess.run([binary, \"init\", \"validator\", \"--chain-id\", chain_id, \"--home\", home], check=True)\n        subprocess.run([binary, \"config\", \"chain-id\", chain_id, \"--home\", home], check=True)\n\n    print(\"⛓️  Starting node … (Ctrl+C to stop)\")\n    try:\n        subprocess.run([binary, \"start\", \"--home\", home], check=True)\n    except KeyboardInterrupt:\n        print(\"Node stopped by user\")\n\n\nif __name__ == \"__main__\":\n    # Usage: python start_local_chain.py [home_dir] [chain_id] [binary]\n    start_local_chain(*(sys.argv[1:]))",
	"query_consensus_params": "def query_consensus_params(height: int, binary: str = \"appd\") -> None:\n    \"\"\"\n    Queries consensus parameters for a given block height.\n    \"\"\"\n    cmd = [\n        binary,\n        \"query\",\n        \"params\",\n        \"subspace\",\n        \"consensus\",\n        \"1\",\n        \"--height\",\n        str(height),\n        \"--output\",\n        \"json\",\n    ]\n    result = subprocess.run(cmd, capture_output=True, text=True)\n    if result.returncode != 0:\n        print(result.stderr)\n        raise RuntimeError(\"Query failed\")\n    print(result.stdout)\n\n\nif __name__ == \"__main__\":\n    height = int(sys.argv[1]) if len(sys.argv) > 1 else 1\n    query_consensus_params(height)",
	"get_governance_authority": "def get_governance_authority(rest_endpoint: str = 'https://rest-kralum.neutron.org') -> str:\n    '''\n    Fetch the current Main DAO address from the cron params endpoint.\n    Fallback to the MAIN_DAO_ADDRESS environment variable if the\n    endpoint is unavailable or the field is missing.\n    '''\n    try:\n        resp = requests.get(f'{rest_endpoint}/neutron/cron/v1/params', timeout=10)\n        resp.raise_for_status()\n        data = resp.json()\n        # Try multiple likely field names for robustness.\n        authority = (\n            data.get('params', {}).get('governance_account')\n            or data.get('params', {}).get('authority')\n        )\n        if authority:\n            return authority\n        raise ValueError('Authority field not found in response.')\n    except Exception as err:\n        # Log and fall back to env var so the workflow can continue.\n        print(f'[WARN] Unable to fetch authority from REST API: {err}')\n        fallback = os.getenv('MAIN_DAO_ADDRESS')\n        if not fallback:\n            raise RuntimeError('MAIN_DAO_ADDRESS env var is not set.') from err\n        return fallback\n",
	"build_execute_msg": "def build_execute_msg(sender: str, contract: str, msg: dict, funds: List[dict] | None = None) -> wasm_tx.MsgExecuteContract:\n    '''\n    Converts a Python dict into the binary-encoded message required by\n    MsgExecuteContract and optionally attaches funds.\n    '''\n    try:\n        execute = wasm_tx.MsgExecuteContract(\n            sender=sender,\n            contract=contract,\n            msg=json.dumps(msg).encode('utf-8'),  # CosmWasm expects binary JSON\n        )\n        if funds:\n            for coin in funds:\n                execute.funds.add(denom=coin['denom'], amount=str(coin['amount']))\n        return execute\n    except Exception as err:\n        raise ValueError(f'Failed to build MsgExecuteContract: {err}')\n\n\n# ---------------------------------------------------------------------\n# Example placeholder calls\n# ---------------------------------------------------------------------\n\ndef build_placeholder_calls(authority: str):\n    call_1 = build_execute_msg(\n        sender=authority,\n        contract='neutron1contractaddr1...',\n        msg={'update_config': {'param': 42}},\n    )\n    call_2 = build_execute_msg(\n        sender=authority,\n        contract='neutron1contractaddr2...',\n        msg={'set_admin': {'new_admin': authority}},\n    )\n    call_3 = build_execute_msg(\n        sender=authority,\n        contract='neutron1contractaddr3...',\n        msg={'migrate': {'code_id': 99}},\n    )\n    return call_1, call_2, call_3\n",
	"build_add_schedule": "def build_add_schedule(authority: str, name: str, period: int, msgs: List) -> cron_tx.MsgAddSchedule:\n    '''Create a MsgAddSchedule for the Cron module.'''\n    if not msgs:\n        raise ValueError('Msgs list cannot be empty')\n    try:\n        schedule = cron_tx.MsgAddSchedule(\n            authority=authority,\n            name=name,\n            period=period,\n            msgs=msgs,\n        )\n        return schedule\n    except Exception as err:\n        raise RuntimeError(f'Unable to build MsgAddSchedule: {err}')\n",
	"wrap_into_submit_proposal": "def wrap_into_submit_proposal(schedule_msg, proposer: str, deposit: List[dict]):\n    '''Pack the MsgAddSchedule into a MsgSubmitProposal.'''    \n    try:\n        any_msg = Any()\n        any_msg.Pack(schedule_msg, type_url_prefix='/')\n\n        submit = gov_tx.MsgSubmitProposal(\n            messages=[any_msg],\n            initial_deposit=[base_coin.Coin(denom=c['denom'], amount=str(c['amount'])) for c in deposit],\n            proposer=proposer,\n            title='Register Cron schedule: protocol_update',\n            summary='Adds a cron schedule that executes three contract calls every 100,800 blocks.',\n        )\n        return submit\n    except Exception as err:\n        raise RuntimeError(f'Unable to create MsgSubmitProposal: {err}')\n",
	"keccak_hash": "def keccak_hash(req: KeccakRequest):\n    \"\"\"Return Keccak-256 hash for the given input.\"\"\"\n    data_str = req.data\n\n    # Detect hex vs text\n    try:\n        if data_str.startswith((\"0x\", \"0X\")):\n            hex_body = data_str[2:]\n            # If hex has odd length, left-pad with a zero\n            if len(hex_body) % 2:\n                hex_body = \"0\" + hex_body\n            raw_bytes = binascii.unhexlify(hex_body)\n        else:\n            raw_bytes = data_str.encode(\"utf-8\")\n    except (binascii.Error, ValueError) as exc:\n        raise HTTPException(status_code=400, detail=f\"Invalid hex input: {exc}\") from exc\n\n    digest = keccak_256(raw_bytes).hexdigest()\n    return {\"hash\": \"0x\" + digest}",
	"get_rpc_endpoint": "def get_rpc_endpoint(chain_id: str):\n    \"\"\"Return the RPC endpoint for a given EVM-compatible Cosmos chain.\"\"\"\n    env_key = CHAIN_RPC_ENV_MAP.get(chain_id.lower())\n    if env_key is None:\n        raise HTTPException(status_code=404, detail=f\"Unsupported chain_id '{chain_id}'.\")\n\n    endpoint = os.getenv(env_key)\n    if not endpoint:\n        raise HTTPException(status_code=500, detail=f\"Environment variable '{env_key}' is not set.\")\n\n    return {\"chain_id\": chain_id, \"rpc_endpoint\": endpoint}",
	"validate_address": "def validate_address(address: str):\n    \"\"\"Verify that `address` is a valid EVM address and return its checksum version.\"\"\"\n    if not Web3.isAddress(address):\n        raise HTTPException(status_code=400, detail=\"Address is not a valid hex EVM address.\")\n\n    checksum_address = Web3.toChecksumAddress(address)\n    return {\"checksum_address\": checksum_address}",
	"download_abi": "def download_abi(req: AbiRequest):\n    \"\"\"Download and persist the ABI JSON so other endpoints can reuse it.\"\"\"\n    try:\n        res = requests.get(req.source_url)\n        res.raise_for_status()\n        abi_json = res.json()\n    except Exception as err:\n        raise HTTPException(status_code=400, detail=f\"Failed to fetch/parse ABI: {err}\")\n\n    file_path = os.path.join(ABI_DIR, f\"{req.contract_name}.abi.json\")\n    with open(file_path, \"w\") as fp:\n        json.dump(abi_json, fp, indent=2)\n\n    return {\"saved_to\": file_path}",
	"fetch_logs": "def fetch_logs(req: LogRequest):\n    \"\"\"Return raw logs for the requested filter; decode can be done client-side if desired.\"\"\"\n    env_key = CHAIN_RPC_ENV_MAP.get(req.chain_id.lower())\n    if env_key is None:\n        raise HTTPException(status_code=404, detail=f\"Unsupported chain_id '{req.chain_id}'.\")\n\n    rpc_endpoint = os.getenv(env_key)\n    if not rpc_endpoint:\n        raise HTTPException(status_code=500, detail=f\"Environment variable '{env_key}' is not set.\")\n\n    w3 = Web3(Web3.HTTPProvider(rpc_endpoint))\n    if not w3.isConnected():\n        raise HTTPException(status_code=502, detail=\"Could not connect to RPC endpoint.\")\n\n    if not Web3.isAddress(req.address):\n        raise HTTPException(status_code=400, detail=\"Invalid contract address.\")\n    checksum_address = Web3.toChecksumAddress(req.address)\n\n    # Ensure ABI exists (even if we don’t decode here, caller likely uploaded it)\n    abi_path = os.path.join(ABI_DIR, f\"{req.contract_name}.abi.json\")\n    if not os.path.exists(abi_path):\n        raise HTTPException(status_code=400, detail=f\"ABI file not found: {abi_path}\")\n\n    filter_params = {\n        \"fromBlock\": req.from_block,\n        \"toBlock\":   req.to_block,\n        \"address\":   checksum_address,\n        \"topics\":    req.topics if req.topics else None\n    }\n\n    try:\n        raw_logs = w3.eth.get_logs(filter_params)\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=f\"get_logs failed: {err}\")\n\n    # Transform HexBytes → hex strings for JSON friendliness\n    parsed_logs = []\n    for log in raw_logs:\n        parsed_logs.append({\n            \"blockNumber\": log.blockNumber,\n            \"transactionHash\": log.transactionHash.hex(),\n            \"address\": log.address,\n            \"data\": log.data,\n            \"topics\": [t.hex() for t in log.topics]\n        })\n\n    return {\"total\": len(parsed_logs), \"logs\": parsed_logs}",
	"ensure_key_exists": "def ensure_key_exists(key_name: str, keyring_backend: str = \"test\") -> Dict[str, str]:\n    \"\"\"Return basic key information if the key exists, otherwise raise an error.\"\"\"\n    try:\n        # --output json yields a machine-readable response we can parse\n        result = subprocess.run(\n            [\n                \"cosmos\",\n                \"keys\",\n                \"show\",\n                key_name,\n                \"--keyring-backend\",\n                keyring_backend,\n                \"--output\",\n                \"json\",\n            ],\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n        key_info = json.loads(result.stdout)\n        return {\n            \"key_name\": key_info.get(\"name\", key_name),\n            \"address\": key_info.get(\"address\"),\n        }\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(\n            f\"Key '{key_name}' was not found in key-ring '{keyring_backend}'. CLI stderr: {err.stderr}\"\n        ) from err\n\n\n# Example FastAPI route (optional, integrate into your BFF of choice)\n# from fastapi import APIRouter, HTTPException\n# router = APIRouter()\n#\n# @router.get(\"/api/keys/show\")\n# async def api_key_show(key_name: str):\n#     try:\n#         return ensure_key_exists(key_name)\n#     except Exception as exc:\n#         raise HTTPException(status_code=400, detail=str(exc))",
	"sign_transaction": "def sign_transaction(\n    unsigned_tx_path: str,\n    from_key: str,\n    chain_id: str,\n    output_tx_path: str = \"tx_signed.json\",\n    keyring_backend: str = \"test\",\n) -> Dict[str, str]:\n    \"\"\"Sign an existing transaction file via the Cosmos CLI and return the output path.\"\"\"\n    unsigned_tx = Path(unsigned_tx_path).expanduser()\n    output_tx = Path(output_tx_path).expanduser()\n\n    if not unsigned_tx.exists():\n        raise FileNotFoundError(f\"Unsigned tx file not found: {unsigned_tx}\")\n\n    cmd = [\n        \"cosmos\",\n        \"tx\",\n        \"sign\",\n        str(unsigned_tx),\n        \"--from\",\n        from_key,\n        \"--chain-id\",\n        chain_id,\n        \"--keyring-backend\",\n        keyring_backend,\n        \"--output-document\",\n        str(output_tx),\n    ]\n\n    try:\n        subprocess.run(cmd, check=True, capture_output=True, text=True)\n        return {\"signed_tx_path\": str(output_tx)}\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"Failed to sign transaction. CLI stderr: {err.stderr}\") from err\n\n\n# Example FastAPI route (optional)\n# @router.post(\"/api/tx/sign\")\n# async def api_tx_sign(body: dict):\n#     return sign_transaction(**body)",
	"verify_signed_tx": "def verify_signed_tx(signed_tx_path: str = \"tx_signed.json\") -> Dict[str, bool]:\n    \"\"\"Validate that the signed transaction file contains a signature.\"\"\"\n    tx_file = Path(signed_tx_path).expanduser()\n    if not tx_file.exists():\n        raise FileNotFoundError(f\"Signed transaction file not found: {tx_file}\")\n\n    with tx_file.open() as fp:\n        tx_data = json.load(fp)\n\n    signatures = tx_data.get(\"signatures\", [])\n    if not signatures or not signatures[0]:\n        raise ValueError(\"Signature array is empty — transaction appears unsigned.\")\n\n    return {\"valid\": True, \"signature_count\": len(signatures)}\n\n\n# Example FastAPI route (optional)\n# @router.get(\"/api/tx/verify\")\n# async def api_tx_verify(path: str = \"tx_signed.json\"):\n#     return verify_signed_tx(path)",
	"ensure_foundry_installed": "def ensure_foundry_installed() -> bool:\n    \"\"\"Check for Foundry and install it if absent.\n\n    Returns:\n        bool: True when the tooling is confirmed present.\n    Raises:\n        RuntimeError: if installation fails.\n    \"\"\"\n    logger = logging.getLogger(__name__)\n\n    # Fast-exit when Foundry is already on PATH\n    if shutil.which(\"cast\") is not None:\n        logger.info(\"Foundry detected—skipping installation.\")\n        return True\n\n    try:\n        logger.info(\"Foundry not detected. Bootstrapping via official script…\")\n        # Download & run installer\n        subprocess.run(\n            \"curl -L https://foundry.paradigm.xyz | bash\",\n            shell=True,\n            check=True,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n        )\n        # Pull latest binaries\n        subprocess.run(\"foundryup\", shell=True, check=True)\n        logger.info(\"Foundry installation completed successfully.\")\n        return True\n    except subprocess.CalledProcessError as exc:\n        logger.error(\"Foundry installation failed: %s\", exc)\n        raise RuntimeError(\"Unable to install Foundry. Consult logs for details.\")",
	"cast_from_bin": "def cast_from_bin(file: UploadFile = File(...)):\n    # Make sure Foundry exists before proceeding\n    ensure_foundry_installed()\n\n    tmp_path = None\n    try:\n        # Persist request body to a temp file\n        with tempfile.NamedTemporaryFile(delete=False) as tmp:\n            tmp.write(await file.read())\n            tmp_path = tmp.name\n\n        # Run the conversion using Foundry’s cast\n        hex_output = subprocess.check_output(\n            ['cast', 'from-bin', tmp_path],\n            text=True,\n        ).strip()\n\n        return {'hex': hex_output}\n    except subprocess.CalledProcessError as exc:\n        raise HTTPException(status_code=500, detail=f'cast failed: {exc}')\n    finally:\n        # House-keeping: delete the temp file (if created)\n        if tmp_path and os.path.exists(tmp_path):\n            os.remove(tmp_path)",
	"query_cron_show_schedule": "def query_cron_show_schedule(schedule_name: str, node: str = \"https://rpc.neutron.org:26657\") -> Dict:\n    \"\"\"Fetch cron schedule metadata from a Neutron node.\n\n    Args:\n        schedule_name (str): The name of the cron schedule to query.\n        node (str): Optional RPC node URL. Defaults to a public Neutron RPC.\n\n    Returns:\n        Dict: Parsed JSON data describing the schedule.\n\n    Raises:\n        RuntimeError: If the neutrond binary is missing or the command fails.\n    \"\"\"\n    # Construct neutrond CLI command\n    cmd = [\n        \"neutrond\", \"query\", \"cron\", \"show-schedule\", schedule_name,\n        \"--node\", node,\n        \"--output\", \"json\"\n    ]\n\n    try:\n        completed = subprocess.run(cmd, check=True, capture_output=True, text=True)\n    except FileNotFoundError as err:\n        raise RuntimeError(\"'neutrond' CLI not found. Install it and ensure it is in your PATH.\") from err\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"CLI returned error while querying schedule '{schedule_name}': {err.stderr}\") from err\n\n    # Parse the JSON output\n    try:\n        return json.loads(completed.stdout)\n    except json.JSONDecodeError as err:\n        raise RuntimeError(\"Failed to decode neutrond JSON output.\") from err\n\n\nif __name__ == \"__main__\":\n    # Example invocation\n    schedule_meta = query_cron_show_schedule(\"protocol_update\")\n    print(json.dumps(schedule_meta, indent=2))",
	"get_code": "def get_code(address: str):\n    \"\"\"Proxy eth_getCode to the configured Cosmos-EVM JSON-RPC endpoint.\"\"\"\n    # Basic server-side validation (defense-in-depth)\n    if not address or not address.startswith(\"0x\") or len(address) != 42:\n        raise HTTPException(status_code=400, detail=\"Invalid EVM address supplied.\")\n\n    payload = {\n        \"jsonrpc\": \"2.0\",\n        \"method\": \"eth_getCode\",\n        \"params\": [address, \"latest\"],\n        \"id\": 1,\n    }\n\n    try:\n        async with httpx.AsyncClient() as client:\n            rpc_resp = await client.post(EVM_NODE_URL, json=payload, timeout=10)\n            rpc_resp.raise_for_status()\n    except Exception as exc:\n        # Bubble up networking / RPC errors to the caller\n        raise HTTPException(status_code=502, detail=f\"RPC request failed: {exc}\")\n\n    rpc_json = rpc_resp.json()\n\n    # The RPC node may return its own error structure\n    if \"error\" in rpc_json:\n        raise HTTPException(status_code=502, detail=rpc_json[\"error\"].get(\"message\", \"Unknown RPC error\"))\n\n    return {\n        \"address\": address,\n        \"bytecode\": rpc_json.get(\"result\", \"0x\")  # Empty contracts return \"0x\"\n    }",
	"_get_env_or_raise": "def _get_env_or_raise(var_name: str) -> str:\n    \"\"\"Return the value of an env-var or raise an explicit error.\"\"\"\n    value = os.getenv(var_name)\n    if value is None:\n        raise EnvironmentError(f\"Environment variable '{var_name}' is not set.\")\n    return value\n\n\ndef get_authenticated_session() -> requests.Session:\n    \"\"\"Instantiate a requests.Session configured with Basic-Auth creds.\"\"\"\n    session = requests.Session()\n\n    # Credentials are loaded from environment variables so secrets never\n    # leave the backend.\n    rpc_user = _get_env_or_raise(\"RPC_ADMIN_USER\")\n    rpc_pass = _get_env_or_raise(\"RPC_ADMIN_PASSWORD\")\n    session.auth = (rpc_user, rpc_pass)\n\n    # JSON-RPC always uses application/json.\n    session.headers.update({\"Content-Type\": \"application/json\"})\n\n    return session\n\n\n# A module-level session & endpoint can be shared across requests.\nRPC_ENDPOINT = os.getenv(\"RPC_ADMIN_URL\", \"http://127.0.0.1:8545\")\nSESSION = get_authenticated_session()\n\n\ndef rpc_call(method: str, params=None, id_: str | None = None):\n    \"\"\"Utility that performs a JSON-RPC request and returns `result`.\"\"\"\n    payload = {\n        \"jsonrpc\": \"2.0\",\n        \"id\": id_ or str(uuid.uuid4()),\n        \"method\": method,\n        \"params\": params or [],\n    }\n\n    # Perform HTTP POST with a 30-second timeout for safety.\n    resp = SESSION.post(RPC_ENDPOINT, json=payload, timeout=30)\n    resp.raise_for_status()  # Raises on non-200 HTTP codes.\n\n    data = resp.json()\n    if \"error\" in data:\n        raise RuntimeError(f\"RPC error: {data['error']}\")\n\n    return data.get(\"result\")",
	"debug_mutex_profile": "def debug_mutex_profile(payload: dict):\n    \"\"\"Invoke the node's `debug_mutexProfile` RPC method.\"\"\"\n    duration = payload.get('duration', 10)\n    output_path = payload.get('outputPath', 'mutex.prof')\n\n    try:\n        # In geth, the parameter order is [fileName, durationSeconds].\n        result = rpc_call('debug_mutexProfile', [output_path, duration])\n        return {\n            'status': 'ok',\n            'file': output_path,\n            'rpc_result': result  # Typically `null` if everything went fine.\n        }\n    except Exception as exc:\n        # Convert any Python/requests errors into an HTTP 500 for the client.\n        raise HTTPException(status_code=500, detail=str(exc))",
	"ensure_msg_execute": "def ensure_msg_execute(cls, v):\n        if v != '/cosmwasm.wasm.v1.MsgExecuteContract':\n            raise ValueError('Only MsgExecuteContract is supported by this endpoint.')\n        return v\n\n\n@router.post('/api/set_target')\nasync def set_target(payload: ExecutePayload):\n    \"\"\"Signs and broadcasts a MsgExecuteContract built on the frontend\"\"\"\n    try:\n        # Prepare LCD/RPC client\n        config = NetworkConfig(\n            chain_id=CHAIN_ID,\n            url=RPC,\n            fee_minimum_gas_price=GAS_PRICE,\n            fee_denom='untrn',\n        )\n        client = LedgerClient(config)\n\n        # Load server wallet\n        mnemonic = os.getenv('DEPLOYER_MNEMONIC')\n        if not mnemonic:\n            raise HTTPException(500, 'DEPLOYER_MNEMONIC environment variable not set.')\n        wallet = LocalWallet.from_mnemonic(mnemonic)\n\n        # Re-create the message\n        msg_execute = MsgExecuteContract(\n            sender=Address(payload.value.sender),\n            contract=Address(payload.value.contract),\n            msg=bytes(payload.value.msg),\n            funds=[],\n        )\n\n        # Build and sign the tx\n        tx = (\n            Transaction()\n            .with_messages(msg_execute)\n            .with_chain_id(CHAIN_ID)\n            .with_sender(wallet)\n            .with_fee(gas_limit=200_000, fee_amount=5000, fee_denom='untrn')\n            .with_memo('Update boost target')\n        )\n        signed_tx = tx.sign(wallet)\n\n        # Broadcast\n        tx_response = client.broadcast_tx(signed_tx)\n        if tx_response.is_err():\n            raise HTTPException(500, f'Broadcast failed: {tx_response.tx_response.raw_log}')\n\n        return {'tx_hash': tx_response.tx_hash}\n\n    except HTTPException:\n        raise\n    except Exception as exc:\n        raise HTTPException(500, str(exc))",
	"open_or_create_foundry_config": "def open_or_create_foundry_config() -> Path:\n    \"\"\"Ensure ~/.foundry/foundry.toml exists and return its Path object.\"\"\"\n    home_dir = Path.home()\n    foundry_dir = home_dir / \".foundry\"\n    foundry_dir.mkdir(parents=True, exist_ok=True)  # Create ~/.foundry if it doesn't exist\n\n    config_path = foundry_dir / \"foundry.toml\"\n    if not config_path.exists():\n        config_path.touch()  # Create an empty file\n        print(f\"Created new Foundry config at {config_path}\")\n    else:\n        print(f\"Found Foundry config at {config_path}\")\n\n    return config_path",
	"edit_toml_key_value": "def edit_toml_key_value(key: str, value: str, config_path: Path) -> bool:\n    \"\"\"Insert or update a \"key = \\\"value\\\"\" line in a TOML file.\n\n    Args:\n        key:    The TOML key to add or update, e.g. \"rpc_endpoint\".\n        value:  The value to associate with the key, e.g. \"https://my.rpc.node:8545\".\n        config_path: Path to the target foundry.toml file.\n\n    Returns:\n        True when the file was modified successfully.\n    \"\"\"\n    key_line = f\"{key} = \\\"{value}\\\"\\n\"\n\n    # Read current contents (if any)\n    try:\n        existing_lines = config_path.read_text().splitlines(keepends=True)\n    except FileNotFoundError:\n        existing_lines = []\n\n    updated = False\n    new_lines: list[str] = []\n    for line in existing_lines:\n        if line.strip().startswith(f\"{key} =\"):\n            new_lines.append(key_line)\n            updated = True\n        else:\n            new_lines.append(line)\n\n    if not updated:\n        # Key not present; append it.\n        new_lines.append(key_line)\n\n    # Persist changes.\n    config_path.write_text(\"\".join(new_lines))\n    print(f\"{'Updated' if updated else 'Added'} '{key}' in {config_path}\")\n    return True",
	"validate_configuration": "def validate_configuration(key: str = 'rpc_endpoint', expected_value: str | None = None) -> bool:\n    \"\"\"Run `forge config --json` and confirm `key` exists (and equals `expected_value` if provided).\"\"\"\n    try:\n        result = subprocess.run([\n            'forge', 'config', '--json'\n        ], capture_output=True, text=True, check=True)\n    except FileNotFoundError as err:\n        raise RuntimeError(\"`forge` CLI not found. Is Foundry installed?\") from err\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"`forge config` failed: {err.stderr}\") from err\n\n    # Try JSON parsing first.\n    try:\n        cfg = json.loads(result.stdout)\n        current_value = cfg.get(key)\n    except json.JSONDecodeError:\n        # Fallback to plain-text parsing.\n        current_value = None\n        for ln in result.stdout.splitlines():\n            if ln.strip().startswith(key):\n                current_value = ln.split('=')[-1].strip().strip('\"')\n                break\n\n    if current_value is None:\n        raise ValueError(f\"`{key}` not found in Forge configuration output.\")\n\n    if expected_value and current_value != expected_value:\n        raise ValueError(\n            f\"`{key}` mismatch: expected '{expected_value}', got '{current_value}'.\")\n\n    print(f\"Forge is configured with {key} = {current_value}\")\n    return True",
	"wasm_query": "def wasm_query(contract_address: str, query_msg: dict):\n    \"\"\"Utility function that performs a CosmWasm smart-query via the public LCD.\"\"\"\n    try:\n        msg_b64 = base64.b64encode(json.dumps(query_msg).encode()).decode()\n        url     = f\"{LCD_ENDPOINT}/cosmwasm/wasm/v1/contract/{contract_address}/smart/{msg_b64}\"\n        resp    = requests.get(url, timeout=10)\n        resp.raise_for_status()\n        return resp.json().get('data', {})\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f'Smart-query failed: {e}')\n\n@app.get('/api/active_phase')\ndef fetch_current_campaign_phase():\n    \"\"\"Returns the ID of the currently active campaign phase.\"\"\"\n    query_msg = {\"get_current_phase\": {}}\n    data      = wasm_query(CAMPAIGN_CONTRACT, query_msg)\n    if 'phase_id' not in data:\n        raise HTTPException(status_code=500, detail=\"Invalid contract response: 'phase_id' missing\")\n    return {\"phase_id\": data['phase_id']}",
	"stop_node": "def stop_node(service_name: str = \"evmd\") -> None:\n    \"\"\"Gracefully stop a running evmd node.\n    1. Try the `evmd stop` CLI.\n    2. Fallback to `systemctl stop evmd` if the CLI is unavailable or fails.\n    Raises an exception if both methods fail.\n    \"\"\"\n    try:\n        # First attempt: `evmd stop`\n        result = subprocess.run([\"evmd\", \"stop\"], capture_output=True, text=True)\n        if result.returncode == 0:\n            print(\"Node stopped with `evmd stop`.\")\n            return\n        else:\n            print(\"`evmd stop` returned non-zero exit code – trying systemd fallback…\\n\", result.stderr)\n    except FileNotFoundError:\n        # evmd binary not found – will try systemd next\n        pass\n\n    # Second attempt: systemd service\n    if shutil.which(\"systemctl\") is None:\n        raise RuntimeError(\"Neither `evmd stop` nor systemctl is available to stop the node.\")\n\n    systemd = subprocess.run([\"systemctl\", \"stop\", service_name], capture_output=True, text=True)\n    if systemd.returncode != 0:\n        raise RuntimeError(systemd.stderr.strip())\n\n    print(\"Node successfully stopped via systemd.\")",
	"open_app_toml": "def open_app_toml(path: Path = CONFIG_PATH) -> dict:\n    \"\"\"Open and parse the TOML file, caching it globally.\"\"\"\n    global config_cache\n    if not path.exists():\n        raise FileNotFoundError(f\"app.toml not found at: {path}\")\n\n    with path.open(\"r\", encoding=\"utf-8\") as fp:\n        config_cache = toml.load(fp)\n\n    print(\"Configuration loaded into memory.\")\n    return config_cache",
	"modify_json_rpc_field": "def modify_json_rpc_field(gas_cap: int = 20_000_000) -> dict:\n    \"\"\"Update (or create) the `gas-cap` inside the `[json-rpc]` section.\"\"\"\n    global config_cache\n    if not config_cache:\n        raise RuntimeError(\"Configuration not loaded. Run open_app_toml() first.\")\n\n    json_rpc_cfg = config_cache.setdefault(\"json-rpc\", {})\n    json_rpc_cfg[\"gas-cap\"] = gas_cap\n\n    print(f\"Set [json-rpc].gas-cap = {gas_cap}\")\n    return config_cache",
	"get_controller_address": "def get_controller_address(env: str = \"mainnet\"):\n    \"\"\"Return the controller/lens contract address used to query market data.\"\"\"\n    address = AMBER_CONTROLLER_ADDRESSES.get(env)\n    if not address:\n        raise HTTPException(status_code=400, detail=\"Unsupported environment\")\n    return {\"env\": env, \"controller_address\": address}",
	"_query_smart": "def _query_smart(contract_address: str, query_msg: dict):\n    \"\"\"Helper to perform a CosmWasm smart-query using the LCD REST interface.\"\"\"\n    encoded_msg = base64.b64encode(json.dumps(query_msg).encode()).decode()\n    url = f\"{LCD_ENDPOINT}/cosmwasm/wasm/v1/contract/{contract_address}/smart/{encoded_msg}\"\n    async with httpx.AsyncClient() as client:\n        resp = await client.get(url, timeout=10)\n        try:\n            resp.raise_for_status()\n        except httpx.HTTPStatusError as exc:\n            raise HTTPException(status_code=exc.response.status_code, detail=str(exc))\n        return resp.json().get(\"data\") or resp.json()\n\n@app.get(\"/api/amber/markets\")\nasync def get_markets(env: str = \"mainnet\"):\n    from amber_api import AMBER_CONTROLLER_ADDRESSES  # reuse mapping from step 1\n    controller = AMBER_CONTROLLER_ADDRESSES.get(env)\n    if not controller:\n        raise HTTPException(status_code=400, detail=\"Unsupported environment\")\n    markets = await _query_smart(controller, {\"markets\": {}})\n    return markets",
	"get_market_state": "def get_market_state(market_id: str, env: str = \"mainnet\"):\n    from amber_api import AMBER_CONTROLLER_ADDRESSES\n    controller = AMBER_CONTROLLER_ADDRESSES.get(env)\n    if not controller:\n        raise HTTPException(status_code=400, detail=\"Unsupported environment\")\n    state = await _query_smart(controller, {\"market_state\": {\"market_id\": market_id}})\n    return state",
	"lock_account": "def lock_account():\n    \"\"\"HTTP endpoint → personal_lockAccount JSON-RPC call.\"\"\"\n    data = request.get_json(force=True, silent=True) or {}\n    address = data.get(\"address\")\n\n    if not address or not isinstance(address, str):\n        return jsonify({\"error\": \"Missing or invalid 'address' field\"}), 400\n\n    try:\n        result = rpc_request(\"personal_lockAccount\", [address])\n        # Geth returns 'true' if the account was successfully removed from memory\n        return jsonify({\"address\": address, \"locked\": bool(result)})\n    except RPCError as rpc_err:\n        return jsonify({\"error\": str(rpc_err), \"code\": rpc_err.code}), 500\n    except Exception as exc:\n        return jsonify({\"error\": str(exc)}), 500\n\nif __name__ == \"__main__\":\n    port = int(os.getenv(\"PORT\", 5000))\n    app.run(host=\"0.0.0.0\", port=port)",
	"run_tests": "def run_tests():\n    \"\"\"Run the project's Hardhat test suite and return stdout or an error.\"\"\"\n    command = \"npx hardhat test\"  # Assumes Hardhat is installed and in PATH\n    try:\n        # Run the command with a 15-minute timeout to prevent hanging.\n        process = subprocess.run(\n            shlex.split(command),\n            capture_output=True,\n            text=True,\n            timeout=900,\n            check=False  # We'll handle non-zero exit codes ourselves.\n        )\n\n        # If tests failed, surface the stderr so the caller can debug.\n        if process.returncode != 0:\n            raise HTTPException(status_code=400, detail=process.stderr)\n\n        # Tests passed; return the captured stdout.\n        return {\"output\": process.stdout}\n\n    except subprocess.TimeoutExpired:\n        raise HTTPException(status_code=408, detail=\"Test execution timed out.\")\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"stop_cosmos_service": "def stop_cosmos_service(service_name: str = \"cosmosd\") -> None:\n    \"\"\"Gracefully stop a running Cosmos systemd service.\"\"\"\n    import subprocess\n\n    try:\n        # Use systemd to stop the validator\n        subprocess.run([\"sudo\", \"systemctl\", \"stop\", service_name], check=True, text=True)\n        print(f\"Successfully stopped {service_name}.\")\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"Failed to stop {service_name}: {err}\")",
	"verify_file_exists": "def verify_file_exists(file_path: str) -> None:\n    \"\"\"Raise FileNotFoundError if a required file is missing.\"\"\"\n    import os\n\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(f\"Required file not found: {file_path}\")\n    print(f\"Verified file exists: {file_path}\")",
	"backup_priv_val_state": "def backup_priv_val_state(node_home: str, backup_dir: str = \"/var/backups\") -> str:\n    \"\"\"Return the absolute path of the created backup file.\"\"\"\n    import os, shutil, datetime\n\n    src_path = os.path.join(node_home, \"data\", \"priv_val_state.json\")\n    timestamp = datetime.datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n    backup_name = f\"priv_val_state_{timestamp}.json\"\n    dst_path = os.path.join(backup_dir, backup_name)\n\n    os.makedirs(backup_dir, exist_ok=True)\n    shutil.copy2(src_path, dst_path)  # preserves metadata\n    print(f\"Backup created at: {dst_path}\")\n    return dst_path",
	"_sha256": "def _sha256(file_path: str) -> str:\n    import hashlib\n    h = hashlib.sha256()\n    with open(file_path, \"rb\") as f:\n        for chunk in iter(lambda: f.read(8192), b\"\"):\n            h.update(chunk)\n    return h.hexdigest()\n\n\ndef compare_checksums(original: str, backup: str) -> bool:\n    \"\"\"Return True when both files share an identical SHA-256 digest.\"\"\"\n    orig_hash = _sha256(original)\n    backup_hash = _sha256(backup)\n    print(f\"Original SHA-256: {orig_hash}\\nBackup   SHA-256: {backup_hash}\")\n    return orig_hash == backup_hash",
	"secure_offsite_copy": "def secure_offsite_copy(local_path: str, remote_user: str, remote_host: str, remote_dir: str) -> None:\n    \"\"\"SCP the backup to an off-site server.\"\"\"\n    import os, subprocess\n\n    remote_target = f\"{remote_user}@{remote_host}:{remote_dir}/{os.path.basename(local_path)}\"\n    try:\n        subprocess.run([\"scp\", \"-p\", local_path, remote_target], check=True, text=True)\n        print(f\"Successfully copied to {remote_target}\")\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"Secure copy failed: {err}\")",
	"start_cosmos_service": "def start_cosmos_service(service_name: str = \"cosmosd\") -> None:\n    \"\"\"Restart the Cosmos validator systemd unit.\"\"\"\n    import subprocess\n\n    try:\n        subprocess.run([\"sudo\", \"systemctl\", \"start\", service_name], check=True, text=True)\n        print(f\"Successfully started {service_name}.\")\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"Failed to start {service_name}: {err}\")",
	"format_amount": "def format_amount(raw_balance: int) -> str:\n    \"\"\"Convert micro-denom (`untrn`) to a formatted NTRN string.\"\"\"\n    try:\n        micro = int(raw_balance)\n    except (TypeError, ValueError):\n        raise ValueError(\"raw_balance must be an integer-compatible value\")\n\n    ntrn_value = micro / 1_000_000  # 1 NTRN = 1,000,000 untrn\n    return f\"{ntrn_value:,.6f} NTRN\"",
	"backup_file": "def backup_file(file_path: str) -> str:\n    \"\"\"Copy <file_path> to <file_path>.bak, preserving metadata.\"\"\"\n    if not os.path.isfile(file_path):\n        raise FileNotFoundError(file_path)\n    backup_path = file_path + '.bak'\n    shutil.copy2(file_path, backup_path)\n    return backup_path\n",
	"enable_rest_api": "def enable_rest_api(app_toml_path: str) -> None:\n    \"\"\"Sets api.enable = true and api.swagger = true inside app.toml.\"\"\"\n    # Load current config\n    try:\n        config = toml.load(app_toml_path)\n    except toml.TomlDecodeError as err:\n        raise ValueError(f'Failed to parse TOML file: {err}') from err\n\n    # Ensure the api table exists and toggle the desired flags\n    api_cfg = config.get('api', {})\n    api_cfg['enable'] = True\n    api_cfg['swagger'] = True\n    config['api'] = api_cfg\n\n    # Persist changes atomically via temporary file replacement\n    tmp_path = app_toml_path + '.tmp'\n    with open(tmp_path, 'w') as tmp_file:\n        toml.dump(config, tmp_file)\n    os.replace(tmp_path, app_toml_path)\n",
	"restart_simd": "def restart_simd(home_dir: str, start_command: str = 'simd start') -> None:\n    \"\"\"Restarts the simd process using a best-effort cross-platform approach.\"\"\"\n    try:\n        # Attempt to gracefully stop any running simd instance\n        subprocess.run(['pkill', '-f', 'simd'], check=False, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n        time.sleep(2)  # brief pause to ensure the process has terminated\n\n        # Start the node in a detached process so the Python script can exit\n        cmd = start_command.split() + ['--home', home_dir]\n        subprocess.Popen(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n    except Exception as e:\n        raise RuntimeError(f'Failed to restart simd: {e}') from e\n",
	"wait_for_swagger": "def wait_for_swagger(url: str = 'http://localhost:1317/swagger', timeout: int = 30) -> bool:\n    \"\"\"Poll <url> until it returns HTTP 200 or raise TimeoutError after <timeout> seconds.\"\"\"\n    end_time = time.time() + timeout\n    while time.time() < end_time:\n        try:\n            resp = requests.get(url, timeout=3)\n            if resp.status_code == 200:\n                return True\n        except requests.RequestException:\n            pass  # keep trying until timeout\n        time.sleep(1)\n    raise TimeoutError(f'Swagger endpoint did not become available within {timeout} seconds')\n",
	"_is_endpoint_alive": "def _is_endpoint_alive(url: str) -> bool:\n    \"\"\"Return True if the endpoint responds successfully to eth_chainId.\"\"\"\n    try:\n        payload = {\"jsonrpc\": \"2.0\", \"method\": \"eth_chainId\", \"params\": [], \"id\": 1}\n        r = requests.post(url, json=payload, timeout=5)\n        return r.status_code == 200 and 'result' in r.json()\n    except Exception:\n        return False\n\n\n@router.get('/api/get_rpc_endpoint')\nasync def get_rpc_endpoint():\n    \"\"\"Pick the first healthy RPC endpoint from the list and return it.\"\"\"\n    for url in RPC_ENDPOINTS:\n        if _is_endpoint_alive(url):\n            return {\"endpoint\": url}\n    raise HTTPException(status_code=503, detail='No healthy RPC endpoint found')",
	"_broadcast": "def _broadcast(endpoint: str, raw_tx: str) -> str:\n    \"\"\"Attempt to broadcast the raw transaction.\"\"\"\n    payload = {\n        \"jsonrpc\": \"2.0\",\n        \"method\": \"eth_sendRawTransaction\",\n        \"params\": [raw_tx],\n        \"id\": 1\n    }\n    response = requests.post(endpoint, json=payload, timeout=20)\n\n    # HTTP-level errors\n    if response.status_code != 200:\n        raise HTTPException(status_code=response.status_code, detail=f'RPC status code {response.status_code}')\n\n    data = response.json()\n\n    # JSON-RPC-level errors\n    if 'error' in data:\n        raise HTTPException(status_code=400, detail=data['error'])\n\n    # Successful path returns the 0x-prefixed tx hash\n    return data['result']\n\n@router.post('/api/broadcast_raw_tx')\nasync def broadcast_raw_tx(payload: TxPayload):\n    \"\"\"Try each configured endpoint until the tx is accepted, then return its hash.\"\"\"\n    endpoints = os.getenv('EVM_RPC_ENDPOINTS', 'https://rpc-evmos.cosmos.network,https://json-rpc.ethermint.org').split(',')\n    for endpoint in endpoints:\n        try:\n            tx_hash = _broadcast(endpoint, payload.raw_tx)\n            return {\"tx_hash\": tx_hash, \"endpoint\": endpoint}\n        except HTTPException:\n            # Allow the next endpoint a chance\n            continue\n    raise HTTPException(status_code=503, detail='Failed to broadcast transaction on all endpoints')",
	"get_web3_provider": "def get_web3_provider() -> Web3:\n    # Connects to an Ethereum JSON-RPC endpoint based on ETH_RPC_URL environment variable.\n    rpc_url = os.getenv(\"ETH_RPC_URL\", \"https://mainnet.infura.io/v3/YOUR_API_KEY\")\n    w3 = Web3(Web3.HTTPProvider(rpc_url, request_kwargs={\"timeout\": 60}))\n\n    # Verify connectivity\n    if not w3.isConnected():\n        raise ConnectionError(f\"Unable to connect to Ethereum node at {rpc_url}\")\n\n    return w3",
	"load_signer": "def load_signer(web3: Web3):\n    # Loads the private key from the PRIVATE_KEY environment variable and returns an Account object.\n    private_key = os.getenv(\"PRIVATE_KEY\")\n    if not private_key:\n        raise ValueError(\"PRIVATE_KEY environment variable is not set.\")\n\n    if not private_key.startswith(\"0x\"):\n        private_key = \"0x\" + private_key\n\n    account = web3.eth.account.from_key(private_key)\n    return account",
	"get_liquid_staking_vault_contract": "def get_liquid_staking_vault_contract(web3: Web3):\n    # Instantiates the LiquidStakingVault contract using its address and ABI.\n    contract_address = os.getenv(\"VAULT_CONTRACT_ADDRESS\")\n    if not contract_address:\n        raise ValueError(\"VAULT_CONTRACT_ADDRESS environment variable is not set.\")\n    contract_address = Web3.toChecksumAddress(contract_address)\n\n    abi_path = os.getenv(\"VAULT_CONTRACT_ABI_PATH\", \"backend/abis/LiquidStakingVault.abi.json\")\n\n    try:\n        with open(abi_path, \"r\") as abi_file:\n            abi = json.load(abi_file)\n    except FileNotFoundError as err:\n        raise FileNotFoundError(f\"Unable to locate ABI file at {abi_path}\") from err\n\n    contract = web3.eth.contract(address=contract_address, abi=abi)\n    return contract",
	"build_stake_tx": "def build_stake_tx(web3: Web3, contract, signer, amount_eth: float, recipient_address: str):\n    # Builds an unsigned stake transaction for vault.stake(amount, recipient).\n    try:\n        amount_wei = web3.to_wei(Decimal(str(amount_eth)), \"ether\")\n    except Exception as err:\n        raise ValueError(f\"Invalid staking amount: {err}\") from err\n\n    recipient_address = Web3.toChecksumAddress(recipient_address)\n\n    nonce = web3.eth.get_transaction_count(signer.address)\n\n    tx = contract.functions.stake(amount_wei, recipient_address).build_transaction({\n        \"from\": signer.address,\n        \"nonce\": nonce\n    })\n\n    return tx",
	"finalize_gas_and_chain_id": "def finalize_gas_and_chain_id(web3: Web3, tx: dict) -> dict:\n    # Estimates gas, sets gas price, and fills in chainId.\n    try:\n        tx[\"gas\"] = web3.eth.estimate_gas(tx)\n    except Exception as err:\n        raise ValueError(f\"Gas estimation failed: {err}\") from err\n\n    try:\n        tx[\"gasPrice\"] = web3.eth.gas_price\n    except Exception:\n        tx[\"gasPrice\"] = web3.to_wei(3, \"gwei\")\n\n    tx[\"chainId\"] = web3.eth.chain_id\n\n    return tx",
	"sign_and_send_tx": "def sign_and_send_tx(web3: Web3, signer, tx: dict) -> str:\n    # Signs the provided transaction and broadcasts it to the network.\n    try:\n        signed_tx = signer.sign_transaction(tx)\n    except Exception as err:\n        raise ValueError(f\"Failed to sign transaction: {err}\") from err\n\n    try:\n        tx_hash = web3.eth.send_raw_transaction(signed_tx.rawTransaction)\n    except Exception as err:\n        raise ConnectionError(f\"Broadcast failed: {err}\") from err\n\n    return tx_hash.hex()",
	"get_admin_wallet": "def get_admin_wallet() -> LocalWallet:\n    \"\"\"Return the admin LocalWallet defined by the ADMIN_MNEMONIC env-var.\"\"\"\n    mnemonic = os.getenv(\"ADMIN_MNEMONIC\")\n    if not mnemonic:\n        raise EnvironmentError(\"ADMIN_MNEMONIC environment variable is not set.\")\n\n    try:\n        wallet = LocalWallet.from_mnemonic(mnemonic)\n    except Exception as err:\n        raise ValueError(f\"Failed to create wallet from mnemonic: {err}\") from err\n\n    return wallet\n\n\ndef get_admin_address() -> str:\n    \"\"\"A small helper that wraps get_admin_wallet() and only returns the Bech32 address.\"\"\"\n    return str(get_admin_wallet().address())",
	"get_contract_address": "def get_contract_address() -> str:\n    \"\"\"Return the contract address defined by CONTRACT_ADDRESS env-var.\"\"\"\n    contract_addr = os.getenv(\"CONTRACT_ADDRESS\") or \"\"\n    if not _BECH32_RE.match(contract_addr):\n        raise ValueError(\"CONTRACT_ADDRESS env-var is missing or not a valid Neutron bech32 address.\")\n    return contract_addr",
	"construct_tx_execute_contract": "def construct_tx_execute_contract(contract_addr: str, wallet, gas: int = 200000) -> Transaction:\n    \"\"\"Create an unsigned Transaction carrying the reset execute message.\"\"\"\n    execute_msg = {\"reset\": {}}\n\n    # Build protobuf MsgExecuteContract using the helper (encodes & sets funds = [])\n    msg = create_msg_execute_contract(\n        sender=str(wallet.address()),\n        contract=contract_addr,\n        msg=json.dumps(execute_msg).encode(),\n        funds=[],\n    )\n\n    tx = Transaction()\n    tx.add_message(msg)\n    tx.with_chain_id(NETWORK_CFG.chain_id)\n    tx.with_sender(wallet.address())\n    tx.with_gas(gas)\n    # Fee is automatically derived from gas*gas_price if not specified explicitly\n    return tx",
	"query_wasm_contract_state": "def query_wasm_contract_state(contract_addr: str) -> int:\n    \"\"\"Query `{ \"get_count\": {} }` from the counter contract and return the integer count.\"\"\"\n    query_msg = {\"get_count\": {}}\n    try:\n        response = LEDGER.query_contract_smart(contract_addr, query_msg)\n    except Exception as err:\n        raise RuntimeError(f\"Smart-contract query failed: {err}\") from err\n\n    if \"count\" not in response:\n        raise ValueError(f\"Unexpected response shape: {response}\")\n    return int(response[\"count\"])",
	"find_network_config": "def find_network_config(root_dir: str = \".\") -> Optional[str]:\n    \"\"\"Recursively search *root_dir* for a probable network configuration file.\n\n    A file is considered a match if it:\n      • Has a JSON extension **and** contains keys like `chainId`, `rpc`, `explorer`, or `chain_name`.\n      • OR (for *.js, *.ts, *.yaml, *.yml, *.env*) contains the strings `chain-registry`, `walletConnect`, or `explorer`.\n\n    Returns the full path of the first match, or *None* if nothing is found.\n    \"\"\"\n    for dirpath, _, filenames in os.walk(root_dir):\n        for filename in filenames:\n            ext = os.path.splitext(filename)[1].lower()\n            if ext not in {\".json\", \".js\", \".ts\", \".yaml\", \".yml\", \".env\"}:\n                continue\n            full_path = os.path.join(dirpath, filename)\n            try:\n                if ext == \".json\":\n                    with open(full_path, \"r\", encoding=\"utf-8\") as f:\n                        data = json.load(f)\n                    if isinstance(data, dict) and any(k in data for k in (\"chainId\", \"rpc\", \"explorer\", \"chain_name\")):\n                        return full_path\n                else:\n                    with open(full_path, \"r\", encoding=\"utf-8\") as f:\n                        content = f.read()\n                    if any(keyword in content for keyword in (\"chain-registry\", \"walletConnect\", \"explorer\", \"rpc\")):\n                        return full_path\n            except Exception:\n                # Ignore parse errors and keep searching\n                continue\n    return None\n\n\nif __name__ == \"__main__\":\n    path = find_network_config()\n    if path:\n        print(f\"Found network config file at: {path}\")\n    else:\n        print(\"No network config file found.\")",
	"insert_blockscout_url": "def insert_blockscout_url(config_path: Union[str, Path], blockscout_url: str = DEFAULT_BLOCKSCOUT_URL) -> None:\n    \"\"\"Add or update an `explorer` key in a JSON config file.\n\n    A *.bak* backup is written before overwriting the original file.\n    \"\"\"\n    config_path = Path(config_path)\n    if not config_path.exists():\n        raise FileNotFoundError(f\"{config_path} not found\")\n\n    # Backup original\n    backup = config_path.with_suffix(config_path.suffix + \".bak\")\n    shutil.copyfile(config_path, backup)\n    print(f\"Backup created at {backup}\")\n\n    # Load JSON and mutate\n    with open(config_path, \"r\", encoding=\"utf-8\") as f:\n        data = json.load(f)\n\n    if not isinstance(data, dict):\n        raise ValueError(\"Expected top-level JSON object in config file\")\n\n    previous = data.get(\"explorer\")\n    data[\"explorer\"] = blockscout_url\n\n    with open(config_path, \"w\", encoding=\"utf-8\") as f:\n        json.dump(data, f, indent=2)\n\n    action = \"updated\" if previous else \"inserted\"\n    print(f\"`explorer` field {action} -> {blockscout_url}\")\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) < 2:\n        print(\"Usage: python update_blockscout_url.py <config_path> [blockscout_url]\")\n        sys.exit(1)\n\n    cfg = sys.argv[1]\n    url = sys.argv[2] if len(sys.argv) > 2 else DEFAULT_BLOCKSCOUT_URL\n    insert_blockscout_url(cfg, url)",
	"verify_cast": "def verify_cast():\n    \"\"\"Endpoint that returns the installed version of `cast` or raises an error if it is not found.\"\"\"\n    try:\n        version = subprocess.check_output(['cast', '--version'], text=True).strip()\n        return {'installed': True, 'version': version}\n    except FileNotFoundError:\n        raise HTTPException(status_code=500, detail='Foundry `cast` CLI is not installed or not found in PATH.')\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=f'Error executing cast --version: {err}')",
	"check_private_key": "def check_private_key():\n    \"\"\"Verifies that the server has a PRIVATE_KEY env variable configured.\"\"\"\n    if not os.getenv('PRIVATE_KEY'):\n        raise HTTPException(status_code=500, detail='PRIVATE_KEY environment variable is missing.')\n    return {'loaded': True}",
	"send_tx": "def send_tx(params: TxParams):\n    \"\"\"Signs & broadcasts a transaction using Foundry's `cast send`.\"\"\"\n    private_key = os.getenv('PRIVATE_KEY')\n    if not private_key:\n        raise HTTPException(status_code=500, detail='PRIVATE_KEY environment variable is not set on the server.')\n\n    # Build the command\n    cmd = [\n        'cast', 'send', params.recipient, params.amount,\n        '--rpc-url', params.rpc_url,\n        '--private-key', private_key,\n        '--gas-price', str(params.gas_price),\n        '--gas-limit', str(params.gas_limit)\n    ]\n    if params.data:\n        cmd.extend(['--data', params.data])\n\n    try:\n        # `cast send` prints the transaction hash on success\n        tx_hash = subprocess.check_output(cmd, text=True).strip().split()[-1]\n        return {'tx_hash': tx_hash}\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=f'Error sending transaction: {err.output}')",
	"wait_for_confirmation": "def wait_for_confirmation(params: WaitParams):\n    \"\"\"Waits until the transaction is mined or the timeout is hit.\"\"\"\n    w3 = Web3(Web3.HTTPProvider(params.rpc_url))\n    if not w3.isConnected():\n        raise HTTPException(status_code=500, detail='Unable to connect to the provided RPC URL.')\n\n    elapsed = 0\n    while elapsed < params.timeout:\n        try:\n            receipt = w3.eth.get_transaction_receipt(params.tx_hash)\n            if receipt and receipt.blockNumber:\n                return {\n                    'confirmed': True,\n                    'blockNumber': receipt.blockNumber,\n                    'status': receipt.status,\n                    'tx_hash': params.tx_hash\n                }\n        except Exception:\n            # Transaction not yet mined; ignore and continue polling\n            pass\n        await asyncio.sleep(params.poll_interval)\n        elapsed += params.poll_interval\n\n    raise HTTPException(status_code=504, detail='Timed out waiting for transaction confirmation.')",
	"query_balance": "def query_balance(address: str, denom: str = 'untrn'):\n    # Returns the balance for a given Neutron address in micro-denom units (untrn)\n    try:\n        balance = client.query_bank_balance(address, denom=denom)\n        return {\n            'address': address,\n            'denom': denom,\n            'amount': int(balance),\n        }\n    except Exception as e:\n        raise HTTPException(status_code=400, detail=str(e))",
	"build_stake_and_mint_tx": "def build_stake_and_mint_tx(sender_address: str, contract_address: str, amount: int = 250000000, denom: str = 'untrn', duration: str = '12_months'):\n    # Build the JSON message expected by the Boost contract\n    execute_msg = {\n        'stake_and_mint_nft': {\n            'amount': f'{amount}{denom}',\n            'duration': duration,\n        }\n    }\n\n    # Funds that accompany the execute call\n    funds = [{ 'denom': denom, 'amount': str(amount) }]\n\n    # Construct the MsgExecuteContract protobuf wrapper\n    msg = MsgExecuteContract(\n        sender=sender_address,\n        contract=contract_address,\n        msg=execute_msg,\n        funds=funds,\n    )\n\n    # Wrap inside a Transaction for later signing\n    tx = Transaction()\n    tx.add_message(msg)\n    tx.with_sender(sender_address)\n    return tx",
	"sign_and_broadcast": "def sign_and_broadcast(tx, client: LedgerClient):\n    # Sign the provided Transaction using the mnemonic in the MNEMONIC env variable and broadcast it.\n    mnemonic = os.getenv('MNEMONIC')\n    if not mnemonic:\n        raise ValueError('MNEMONIC environment variable is not set.')\n\n    pk = PrivateKey.from_mnemonic(mnemonic)\n    signed_tx = tx.sign(pk)\n    resp = client.broadcast_transaction(signed_tx)\n\n    if resp.is_successful():\n        return { 'tx_hash': resp.tx_hash }\n    else:\n        raise RuntimeError(f'Broadcast failed with code {resp.code}: {resp.raw_log}')",
	"wait_for_tx_commit": "def wait_for_tx_commit(tx_hash: str, client: LedgerClient, timeout: int = 120, poll: float = 2.0):\n    # Poll the chain for the transaction result\n    deadline = time.time() + timeout\n    while time.time() < deadline:\n        tx_info = client.query_tx(tx_hash)\n        if tx_info is not None:\n            return {\n                'status': 'confirmed',\n                'height': tx_info.height,\n                'raw_log': tx_info.raw_log,\n            }\n        time.sleep(poll)\n    raise TimeoutError('Timed out waiting for transaction commitment.')",
	"query_nft_tokens": "def query_nft_tokens(client: LedgerClient, contract_address: str, owner_address: str):\n    query = { 'tokens': { 'owner': owner_address } }\n    try:\n        result = client.query_contract_smart(contract_address, query)\n        # The exact shape depends on the contract; assume `{ tokens: [id1,id2,...] }` is returned\n        return result.get('tokens', [])\n    except Exception as e:\n        raise RuntimeError(f'Contract query failed: {e}')",
	"get_neutron_client": "def get_neutron_client() -> LedgerClient:\n    \"\"\"Initialises a LedgerClient pointed at Pion-1.\n\n    Raises:\n        EnvironmentError: If an RPC endpoint is missing.\n    \"\"\"\n    rpc_url = os.getenv(\"PION_RPC\", \"https://rpc.pion-1.ntrn.tech:443\")\n\n    if not rpc_url:\n        raise EnvironmentError(\"RPC endpoint for Pion-1 is not set.\")\n\n    cfg = NetworkConfig(\n        chain_id=\"pion-1\",\n        url=rpc_url,\n        fee_minimum_gas_price=0.025,  # 0.025 NTRN / gas\n        fee_denomination=\"untrn\",\n        staking_denomination=\"untrn\",\n        bech32_hrp=\"neutron\"\n    )\n\n    return LedgerClient(cfg)\n\n# Optional: load a signing key once so future steps can re-use it\n# NOTE: store your mnemonic securely – this is *just* for local testing!\n_SIGNING_KEY: PrivateKey | None = None\n\ndef load_signing_key() -> PrivateKey:\n    \"\"\"Loads (or creates) a PrivateKey from a MNEMONIC env-var.\"\"\"\n    global _SIGNING_KEY\n    if _SIGNING_KEY is None:\n        mnemonic = os.getenv(\"NEUTRON_MNEMONIC\")\n        if not mnemonic:\n            raise EnvironmentError(\"Please export NEUTRON_MNEMONIC before running.\")\n        _SIGNING_KEY = PrivateKey.from_mnemonic(mnemonic)\n    return _SIGNING_KEY",
	"get_code_id": "def get_code_id(client: LedgerClient, uploader: str, explicit_code_id: Optional[int] = None) -> int:\n    \"\"\"Determine the code_id to instantiate.\n\n    Args:\n        client:   The LedgerClient from Step 1.\n        uploader: Address that stored the code (usually our wallet).\n        explicit_code_id: Optional override (e.g. via CLI flag).\n\n    Returns:\n        int: The wasm `code_id`.\n\n    Raises:\n        ValueError: If we cannot discover a code_id.\n    \"\"\"\n    # Highest priority: explicit argument / env-var\n    if explicit_code_id is None:\n        env_code_id = os.getenv(\"CODE_ID\")\n        explicit_code_id = int(env_code_id) if env_code_id else None\n\n    if explicit_code_id is not None:\n        return explicit_code_id\n\n    # Fallback: query the chain for all codes uploaded by `uploader`\n    response = client.query(\"/cosmwasm/wasm/v1/code\")  # REST path for all codes\n    codes = json.loads(response)[\"code_infos\"]\n\n    # Filter codes by creator and pick the latest\n    user_codes = [int(c[\"code_id\"]) for c in codes if c.get(\"creator\") == uploader]\n    if not user_codes:\n        raise ValueError(\"No code_id found for uploader – pass CODE_ID env-var or argument.\")\n    return max(user_codes)",
	"build_instantiate_tx": "def build_instantiate_tx(client: LedgerClient,\n                         signer: PrivateKey,\n                         code_id: int,\n                         init_msg: dict | None = None,\n                         admin: str | None = None,\n                         label: str = \"counter\") -> Transaction:\n    \"\"\"Create an unsigned instantiate transaction.\"\"\"\n\n    if init_msg is None:\n        init_msg = {\"count\": 0}\n\n    msg = MsgInstantiateContract(\n        sender=signer.address(),\n        admin=admin or \"\",\n        code_id=code_id,\n        label=label,\n        init_msg=init_msg,\n        funds=[]  # no initial funds\n    )\n\n    tx = (Transaction()\n           .with_messages(msg)\n           .with_sender(signer.address())\n           .with_chain_id(client.network_config.chain_id)\n           .with_gas(300_000)  # enough for small contracts\n           .with_fee(client.network_config.fee_denomination, 300_000 * client.network_config.fee_minimum_gas_price))\n\n    return tx",
	"extract_contract_address_from_tx": "def extract_contract_address_from_tx(tx_response):\n    \"\"\"Returns the contract address emitted by the instantiate event.\"\"\"\n    try:\n        logs = json.loads(tx_response.raw_log)\n        for event in logs[0].get(\"events\", []):\n            if event.get(\"type\") in (\"instantiate\", \"wasm\"):\n                for attr in event.get(\"attributes\", []):\n                    if attr.get(\"key\") == \"_contract_address\" or attr.get(\"key\") == \"contract_address\":\n                        return attr.get(\"value\")\n        raise RuntimeError(\"Contract address not found in tx events.\")\n    except (KeyError, ValueError, IndexError) as e:\n        raise RuntimeError(f\"Error parsing tx log: {e}\") from e",
	"add_genesis_account": "def add_genesis_account(payload: AddAccountPayload):\n    '''Invoke the chain binary to add an account to the genesis file.'''\n    chain_binary = os.getenv(\"CHAIN_BINARY\", \"gaiad\")\n    cmd = [chain_binary, \"add-genesis-account\", payload.address, f\"{payload.amount}{payload.denom}\"]\n    try:\n        result = subprocess.run(cmd, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)\n        return {\"success\": True, \"stdout\": result.stdout}\n    except subprocess.CalledProcessError as e:\n        raise HTTPException(status_code=500, detail=e.stderr)",
	"query_vesting_contract": "def query_vesting_contract(address: str):\n    \"\"\"Return the claimable rewards for a given address.\"\"\"\n    try:\n        query_msg = {\"claimable_rewards\": {\"address\": address}}\n        query_b64 = base64.b64encode(json.dumps(query_msg).encode()).decode()\n        url = f\"{NEUTRON_LCD}/cosmwasm/wasm/v1/contract/{VESTING_CONTRACT}/smart/{query_b64}\"\n        async with httpx.AsyncClient(timeout=10) as client:\n            resp = await client.get(url)\n            resp.raise_for_status()\n        data = resp.json()\n        # Expected format: {\"data\": {\"amount\": \"123456\"}}\n        amount = int(data.get(\"data\", {}).get(\"amount\", 0))\n        return {\"claimable\": amount}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"validate_claimable_amount": "def validate_claimable_amount(amount: int):\n    \"\"\"Raise an HTTP 400 if amount == 0.\"\"\"\n    if int(amount) == 0:\n        raise HTTPException(status_code=400, detail=\"No claimable rewards for this address.\")\n    return {\"ok\": True}",
	"construct_execute_msg": "def construct_execute_msg():\n    \"\"\"Return the execute message required to start vesting.\"\"\"\n    execute_msg = {\"start_standard_vesting\": {}}\n    return execute_msg",
	"query_vesting_schedule": "def query_vesting_schedule(address: str):\n    \"\"\"Return the latest vesting schedule for the provided address.\"\"\"\n    query = {\"vesting_schedule\": {\"address\": address}}\n    query_b64 = base64.b64encode(json.dumps(query).encode()).decode()\n    url = f\"{NEUTRON_LCD}/cosmwasm/wasm/v1/contract/{VESTING_CONTRACT}/smart/{query_b64}\"\n\n    try:\n        async with httpx.AsyncClient(timeout=10) as client:\n            resp = await client.get(url)\n            resp.raise_for_status()\n        return resp.json().get(\"data\", {})\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"construct_update_admin_tx": "def construct_update_admin_tx(\n    sender_address: str,\n    contract_address: str,\n    new_admin_address: str,\n) -> Tuple[Transaction, LedgerClient]:\n    \"\"\"Create an unsigned Transaction containing a MsgUpdateAdmin message.\n\n    Args:\n        sender_address: Current admin / governance address signing the tx.\n        contract_address: Address of the CosmWasm contract.\n        new_admin_address: Address that will become the new admin.\n\n    Returns:\n        A tuple of (tx, ledger_client) ready for signing & broadcasting.\n    \"\"\"\n    # Initialize client\n    network_cfg = NetworkConfig(\n        chain_id=CHAIN_ID,\n        url=RPC_ENDPOINT,\n    )\n    client = LedgerClient(network_cfg)\n\n    # Build the MsgUpdateAdmin protobuf message\n    msg = MsgUpdateAdmin(\n        sender=sender_address,\n        contract=contract_address,\n        new_admin=new_admin_address,\n    )\n\n    # Pack into Any type\n    any_msg = Any()\n    any_msg.Pack(msg, type_url_prefix='')  # cosmpy handles type_url internally\n\n    # Create transaction and add message\n    tx = Transaction()\n    tx.add_message(any_msg)\n\n    # Set a placeholder fee & gas (will be adjusted when we sign)\n    tx.set_fee(FEE_DENOM, amount=5000, gas_limit=DEFAULT_GAS_LIMIT)\n\n    return tx, client",
	"construct_json_rpc_request": "def construct_json_rpc_request(contract_address: str, slot: str = \"0x0\", request_id: int = 1) -> dict:\n    \"\"\"\n    Construct a JSON-RPC request body for eth_getStorageAt.\n\n    Args:\n        contract_address (str): Target contract address (0x-prefixed).\n        slot (str): Storage slot to read, default is \"0x0\" (slot 0).\n        request_id (int): Arbitrary JSON-RPC id.\n\n    Returns:\n        dict: A JSON-serialisable request object.\n    \"\"\"\n    if not contract_address.startswith(\"0x\"):\n        raise ValueError(\"contract_address must start with 0x\")\n\n    return {\n        \"jsonrpc\": \"2.0\",\n        \"method\": \"eth_getStorageAt\",\n        \"params\": [contract_address, slot, \"latest\"],\n        \"id\": request_id\n    }\n",
	"send_http_post": "def send_http_post(request_body: dict, endpoint: str = \"http://localhost:8545\", timeout: int = 10) -> dict:\n    \"\"\"\n    Send a JSON-RPC POST request to an Ethereum node.\n\n    Args:\n        request_body (dict): JSON-RPC request created in Step 1.\n        endpoint (str): URL of the JSON-RPC server.\n        timeout (int): Network timeout (seconds).\n\n    Returns:\n        dict: Parsed JSON response from the node.\n\n    Raises:\n        RuntimeError: For network or HTTP-status errors.\n        ValueError:  For malformed JSON responses.\n    \"\"\"\n    headers = {\"Content-Type\": \"application/json\"}\n    try:\n        resp = requests.post(endpoint, headers=headers, json=request_body, timeout=timeout)\n        resp.raise_for_status()\n    except requests.RequestException as e:\n        raise RuntimeError(f\"Failed to POST to {endpoint}: {e}\") from e\n\n    try:\n        return resp.json()\n    except ValueError as e:\n        raise ValueError(f\"Response is not valid JSON: {e}\") from e\n",
	"parse_json_rpc_response": "def parse_json_rpc_response(response_json: dict) -> str:\n    \"\"\"\n    Parse eth_getStorageAt response and return the storage value.\n\n    Args:\n        response_json (dict): JSON returned by Step 2.\n\n    Returns:\n        str: 32-byte hex string (e.g., \"0x000...42\").\n\n    Raises:\n        RuntimeError: If the node returned an error.\n        KeyError:     If the 'result' field is missing.\n        ValueError:   If the result format looks wrong.\n    \"\"\"\n    if \"error\" in response_json:\n        raise RuntimeError(f\"JSON-RPC error: {response_json['error']}\")\n\n    if \"result\" not in response_json:\n        raise KeyError(\"'result' field missing in response\")\n\n    result = response_json[\"result\"]\n    if not (isinstance(result, str) and result.startswith(\"0x\")):\n        raise ValueError(\"Unexpected 'result' format\")\n\n    return result\n",
	"install_hardhat_coverage": "def install_hardhat_coverage():\n    '''\n    Installs the hardhat-coverage plugin as a development dependency.\n    '''\n    try:\n        result = subprocess.run(\n            ['npm', 'install', '--save-dev', 'hardhat-coverage'],\n            check=True,\n            capture_output=True,\n            text=True\n        )\n        return {'stdout': result.stdout, 'stderr': result.stderr}\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f'Failed to install hardhat-coverage: {err.stderr}') from err",
	"configure_hardhat": "def configure_hardhat():\n    '''\n    Adds require('hardhat-coverage'); to hardhat.config.js if not already present.\n    '''\n    config_path = pathlib.Path('hardhat.config.js')\n    if not config_path.exists():\n        raise FileNotFoundError('hardhat.config.js not found.')\n\n    content = config_path.read_text()\n    require_line = \"require('hardhat-coverage');\"\n\n    if require_line not in content:\n        config_path.write_text(f'{require_line}\\n{content}')\n        return {'status': 'updated', 'path': str(config_path)}\n\n    return {'status': 'already_configured', 'path': str(config_path)}",
	"run_hardhat_coverage": "def run_hardhat_coverage():\n    '''\n    Executes the Hardhat coverage task.\n    '''\n    try:\n        result = subprocess.run(\n            ['npx', 'hardhat', 'coverage'],\n            check=True,\n            capture_output=True,\n            text=True\n        )\n        return {'stdout': result.stdout}\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f'Coverage run failed: {err.stderr}') from err",
	"open_coverage_report": "def open_coverage_report():\n    '''\n    Opens coverage/lcov-report/index.html in the default browser if it exists.\n    '''\n    report_path = pathlib.Path('coverage/lcov-report/index.html').resolve()\n    if not report_path.exists():\n        raise FileNotFoundError('Coverage report not found; please run coverage first.')\n\n    webbrowser.open(report_path.as_uri())\n    return {'status': 'opened', 'report': str(report_path)}",
	"build_release_tokens_msg": "def build_release_tokens_msg(sender: str, vesting_contract: str) -> MsgExecuteContract:\n    \"\"\"Constructs a MsgExecuteContract that triggers the `release_tokens` method of the vesting contract.\"\"\"\n    try:\n        execute_msg = {\"release_tokens\": {}}\n        msg = MsgExecuteContract(\n            sender=sender,\n            contract=vesting_contract,\n            msg=json.dumps(execute_msg).encode(),\n            funds=[]  # No funds sent with the call\n        )\n        return msg\n    except Exception as e:\n        raise ValueError(f\"Failed to build MsgExecuteContract: {e}\")",
	"build_add_schedule_msg": "def build_add_schedule_msg(authority: str, release_msg, period: int = 216000, name: str = \"token_unlock\") -> MsgAddSchedule:\n    \"\"\"Constructs a MsgAddSchedule message for the Cron module.\"\"\"\n    try:\n        schedule_msg = MsgAddSchedule(\n            authority=authority,\n            name=name,\n            period=period,\n            msgs=[release_msg]\n        )\n        return schedule_msg\n    except Exception as e:\n        raise ValueError(f\"Failed to build MsgAddSchedule: {e}\")",
	"wrap_into_gov_proposal": "def wrap_into_gov_proposal(schedule_msg, title: str = \"Add token_unlock schedule\", summary: str = \"Adds periodic token unlock via Cron\", deposit: str = \"10000000untrn\") -> str:\n    \"\"\"Serialises the schedule message into a governance proposal JSON string.\"\"\"\n    try:\n        schedule_dict = MessageToDict(schedule_msg, preserving_proto_field_name=True)\n        schedule_dict[\"@type\"] = \"/neutron.cron.MsgAddSchedule\"\n\n        proposal = {\n            \"messages\": [schedule_dict],\n            \"metadata\": \"\",\n            \"deposit\": deposit,\n            \"title\": title,\n            \"summary\": summary\n        }\n        return json.dumps(proposal, indent=2)\n    except Exception as e:\n        raise ValueError(f\"Failed to wrap proposal JSON: {e}\")",
	"validate_tx": "def validate_tx(payload: TxBytes):\n    \"\"\"Validate that the provided base64 string decodes to a *signed* TxRaw.\"\"\"\n    # 1. Decode base64\n    try:\n        raw_bytes = base64.b64decode(payload.tx_bytes)\n    except (TypeError, ValueError) as e:\n        raise HTTPException(status_code=400, detail=\"tx_bytes is not valid base64\") from e\n\n    # 2. Parse protobuf TxRaw to ensure it is well-formed\n    try:\n        tx_raw = cosmos_tx_pb2.TxRaw()\n        tx_raw.ParseFromString(raw_bytes)\n    except message.DecodeError as e:\n        raise HTTPException(status_code=400, detail=\"Decoded bytes are not a valid TxRaw message\") from e\n\n    # 3. Confirm the transaction is signed\n    if len(tx_raw.signatures) == 0:\n        raise HTTPException(status_code=400, detail=\"TxRaw contains no signatures\")\n\n    return {\"is_valid\": True, \"signature_count\": len(tx_raw.signatures)}",
	"_simulate_tx": "def _simulate_tx(base64_tx_bytes: str) -> dict:\n    \"\"\"Internal helper: hits cosmos.tx.v1beta1.Service/Simulate and returns the response as a dict.\"\"\"\n    tx_bytes = base64.b64decode(base64_tx_bytes)\n    with grpc.insecure_channel(GRPC_ENDPOINT) as channel:\n        stub = tx_service_grpc.ServiceStub(channel)\n        request = tx_service_pb2.SimulateRequest(tx_bytes=tx_bytes)\n        response = stub.Simulate(request)\n    return MessageToDict(response, preserving_proto_field_name=True)\n\n@app.post(\"/api/simulate_tx\")\nasync def simulate_tx(payload: TxBytes):\n    \"\"\"HTTP wrapper that forwards signed tx bytes to the gRPC Simulate endpoint.\"\"\"\n    try:\n        result = _simulate_tx(payload.tx_bytes)\n        return result\n    except grpc.RpcError as e:\n        raise HTTPException(status_code=400, detail=f\"Simulation failed: {e.details()}\")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"encode_tx": "def encode_tx(req: EncodeRequest):\n    \"\"\"Encode a signed JSON tx into protobuf bytes using the Cosmos CLI.\"\"\"\n    if not os.path.isfile(req.input_json_path):\n        raise HTTPException(status_code=404, detail=\"input_json_path does not exist\")\n\n    cmd = [\"cosmos\", \"tx\", \"encode\", req.input_json_path]\n    try:\n        # Run the CLI command and capture stdout (base64 string)\n        result = subprocess.run(cmd, check=True, capture_output=True)\n        base64_tx = result.stdout.decode().strip()\n\n        # Optionally persist the raw protobuf bytes to disk\n        if req.output_pb_path:\n            with open(req.output_pb_path, \"wb\") as f:\n                f.write(base64.b64decode(base64_tx))\n\n        return {\n            \"base64_tx\": base64_tx,\n            \"output_pb_path\": req.output_pb_path\n        }\n    except subprocess.CalledProcessError as err:\n        # Surface any CLI errors back to the caller\n        err_msg = err.stderr.decode() if err.stderr else \"Unknown CLI error\"\n        raise HTTPException(status_code=500, detail=err_msg)",
	"decode_tx": "def decode_tx(req: DecodeRequest):\n    \"\"\"Decode protobuf bytes back into JSON using the Cosmos CLI.\"\"\"\n    if not os.path.isfile(req.pb_file_path):\n        raise HTTPException(status_code=404, detail=\"pb_file_path does not exist\")\n\n    cmd = [\"cosmos\", \"tx\", \"decode\", req.pb_file_path]\n    try:\n        result = subprocess.run(cmd, check=True, capture_output=True)\n        json_tx = result.stdout.decode()\n        return { \"decoded_tx_json\": json_tx }\n    except subprocess.CalledProcessError as err:\n        err_msg = err.stderr.decode() if err.stderr else \"Unknown CLI error\"\n        raise HTTPException(status_code=500, detail=err_msg)",
	"ensure_foundryup": "def ensure_foundryup():\n    \"\"\"Ensure that the Foundry tool-chain is installed and current.\"\"\"\n    try:\n        # 1. Check whether `foundryup` is already on PATH\n        foundryup_path = shutil.which(\"foundryup\")\n        if foundryup_path is None:\n            # 2. Install Foundry non-interactively (adds binaries under $HOME/.foundry/bin)\n            install_cmd = \"curl -L https://foundry.paradigm.xyz | bash\"\n            subprocess.run(install_cmd, shell=True, check=True)\n            # 3. Add the bin directory to PATH for the life-time of this process\n            os.environ[\"PATH\"] += f\":{Path.home()}/.foundry/bin\"\n        # 4. Update (or finish installing) the tool-chain\n        subprocess.run(\"foundryup\", shell=True, check=True)\n        return {\"status\": \"success\", \"message\": \"Foundry is installed and up to date.\"}\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=f\"Foundry installation failed: {err}\")",
	"create_foundry_toml": "def create_foundry_toml():\n    \"\"\"Generate the global Foundry TOML configuration file.\"\"\"\n    try:\n        # Preferred path: let Forge initialise the file for us\n        subprocess.run([\"forge\", \"config\", \"--global\"], check=True)\n        return {\"status\": \"success\", \"message\": \"Global foundry.toml created/updated by Forge.\"}\n    except FileNotFoundError:\n        # Fallback: Forge not on PATH yet – create an empty file manually\n        cfg_path = Path.home() / \".foundry\" / \"foundry.toml\"\n        cfg_path.parent.mkdir(parents=True, exist_ok=True)\n        cfg_path.touch(exist_ok=True)\n        return {\"status\": \"success\", \"message\": f\"Created empty config at {cfg_path}.\"}\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=f\"`forge config --global` failed: {err}\")",
	"edit_foundry_toml": "def edit_foundry_toml():\n    \"\"\"Inject recommended defaults into the global Foundry config.\"\"\"\n    try:\n        cfg_path = Path.home() / \".foundry\" / \"foundry.toml\"\n        cfg_path.parent.mkdir(parents=True, exist_ok=True)\n        if not cfg_path.exists():\n            cfg_path.touch()\n\n        # Desired key/value lines\n        desired = [\n            'rpc_endpoints = { cosmos_evm = \"https://rpc.my-chain.com\" }',\n            'default_rpc_endpoint = \"cosmos_evm\"',\n            'optimizer = true',\n            'optimizer_runs = 200'\n        ]\n\n        existing_lines = cfg_path.read_text().splitlines()\n        with cfg_path.open(\"a\") as fp:\n            for line in desired:\n                # Avoid duplicate keys on successive calls\n                key = line.split(\"=\")[0].strip()\n                if not any(key == l.split(\"=\")[0].strip() for l in existing_lines):\n                    fp.write(line + \"\\n\")\n        return {\"status\": \"success\", \"message\": \"foundry.toml updated with standard settings.\"}\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=f\"Unable to update foundry.toml: {err}\")",
	"validate_foundry_config": "def validate_foundry_config():\n    \"\"\"Return the current global Foundry configuration as plain text.\"\"\"\n    try:\n        output = subprocess.check_output(\n            [\"forge\", \"config\", \"--show\", \"--global\"],\n            text=True\n        )\n        return {\"status\": \"success\", \"config\": output}\n    except FileNotFoundError:\n        raise HTTPException(status_code=404, detail=\"Forge binary not found on PATH. Have you run /api/ensure_foundryup?\")\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=f\"Unable to display config: {err}\")",
	"query_contract_info": "def query_contract_info(contract_address: str, lcd: str = REST_ENDPOINT) -> Dict:\n    \"\"\"Request contract metadata from the LCD endpoint.\n\n    Args:\n        contract_address (str): Bech32 contract address.\n        lcd (str): Base URL for the LCD server.\n\n    Returns:\n        Dict: Parsed JSON with contract metadata.\n    \"\"\"\n    url = f\"{lcd}/cosmwasm/wasm/v1/contract/{contract_address}\"\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        data = response.json()\n        return data.get(\"contract_info\", {})\n    except requests.RequestException as exc:\n        raise ContractQueryError(f\"LCD request failed: {exc}\") from exc\n    except ValueError:\n        raise ContractQueryError(\"LCD returned malformed JSON\")",
	"extract_code_id": "def extract_code_id(contract_info: Dict) -> Union[int, str]:\n    \"\"\"Pull `code_id` out of the contract-info payload.\n\n    Args:\n        contract_info (Dict): Output from `query_contract_info`.\n\n    Returns:\n        int | str: The numeric (or string) code ID.\n    \"\"\"\n    try:\n        code_id = contract_info[\"code_id\"]\n        if code_id in (None, \"\"):\n            raise KeyError\n        return code_id\n    except KeyError:\n        raise CodeIdExtractionError(\"`code_id` not found in contract info payload\")",
	"query_code_info": "def query_code_info(code_id: str, lcd: str = REST_ENDPOINT) -> Dict:\n    \"\"\"Retrieve code-info (including `code_hash`) from the LCD.\n\n    Args:\n        code_id (str): The code ID extracted in Step 3.\n        lcd (str): Base URL for the LCD server.\n\n    Returns:\n        Dict: JSON payload containing code-info.\n    \"\"\"\n    url = f\"{lcd}/cosmwasm/wasm/v1/code/{code_id}\"\n    try:\n        response = requests.get(url, timeout=10)\n        response.raise_for_status()\n        return response.json().get(\"code_info\", {})\n    except requests.RequestException as exc:\n        raise CodeInfoQueryError(f\"LCD request failed: {exc}\") from exc\n    except ValueError:\n        raise CodeInfoQueryError(\"Malformed JSON in LCD response\")",
	"extract_code_hash": "def extract_code_hash(code_info: Dict) -> str:\n    \"\"\"Safely extract the `code_hash` value.\n\n    Args:\n        code_info (Dict): Output from `query_code_info`.\n\n    Returns:\n        str: The hexadecimal code hash.\n    \"\"\"\n    try:\n        code_hash = code_info[\"data_hash\"] or code_info[\"code_hash\"]  # field name may differ\n        if not code_hash:\n            raise KeyError\n        return code_hash\n    except KeyError:\n        raise CodeHashExtractionError(\"`code_hash` not present in code-info payload\")",
	"construct_and_sign": "def construct_and_sign(req: ConstructTxRequest):\n    try:\n        # Restore private key & derive sender address\n        pk = PrivateKey(bytes.fromhex(req.sender_privkey_hex))\n        sender_addr = pk.public_key().address()\n\n        client = LedgerClient(RPC_ENDPOINT)\n        onchain_account = await client.query_account(sender_addr)\n\n        # ----- Build bank MsgSend -----\n        send_msg = bank_tx.MsgSend(\n            from_address=sender_addr,\n            to_address=req.recipient,\n            amount=[{\"denom\": req.amount_denom, \"amount\": str(req.amount)}],\n        )\n\n        # ----- Create Tx wrapper -----\n        tx = Transaction()\n        tx.add_message(send_msg)\n        tx.with_sequence(onchain_account.sequence)\n        tx.with_account_num(onchain_account.account_number)\n        tx.with_chain_id(CHAIN_ID)\n        tx.with_gas(req.gas_limit)\n        tx.with_fee(req.fee_amount, req.fee_denom)\n\n        signed_tx = tx.get_tx_data(pk)\n        return {\"signed_tx_hex\": signed_tx.hex()}\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"broadcast_signed_tx": "def broadcast_signed_tx(req: BroadcastRequest):\n    try:\n        client = LedgerClient(RPC_ENDPOINT)\n        tx_bytes = bytes.fromhex(req.signed_tx_hex)\n        res = await client.broadcast_tx_sync(tx_bytes)\n\n        if res.code != 0:\n            raise TxCommitError(f\"Tx failed: code={res.code} log={res.raw_log}\")\n\n        return {\"tx_hash\": res.txhash, \"height\": res.height}\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"query_balances": "def query_balances(address: str):\n    \"\"\"Fetch bank balances for a bech32 address and return only the relevant JSON payload.\"\"\"\n    url = f\"{REST_ENDPOINT}/cosmos/bank/v1beta1/balances/{address}\"\n    try:\n        async with httpx.AsyncClient(timeout=5.0) as client:\n            resp = await client.get(url)\n            resp.raise_for_status()\n            data = resp.json()\n    except httpx.RequestError as exc:\n        # Network-level failure\n        raise HTTPException(status_code=502, detail=f\"Cannot reach REST endpoint: {exc}\")\n    except httpx.HTTPStatusError as exc:\n        # Non-200 response from node\n        raise HTTPException(status_code=exc.response.status_code, detail=exc.response.text)\n\n    # Return a trimmed response to the frontend\n    return {\n        \"address\": address,\n        \"balances\": data.get(\"balances\", [])\n    }",
	"txpool_proxy": "def txpool_proxy(request: Request):\n    \"\"\"Proxy any txpool_* JSON-RPC request to the configured RPC_ENDPOINT.\"\"\"\n    try:\n        payload = await request.json()\n    except ValueError:\n        raise HTTPException(status_code=400, detail=\"Invalid JSON body\")\n\n    # Basic sanity-check that the user is only allowed to call txpool_* methods\n    if not payload.get(\"method\", \"\").startswith(\"txpool_\"):\n        raise HTTPException(status_code=400, detail=\"Only txpool_* methods are allowed\")\n\n    try:\n        async with httpx.AsyncClient(timeout=10) as client:\n            rpc_response = await client.post(RPC_ENDPOINT, json=payload)\n            rpc_response.raise_for_status()\n            return rpc_response.json()\n    except httpx.HTTPStatusError as he:\n        # Bubble up node-side HTTP errors\n        raise HTTPException(status_code=he.response.status_code, detail=str(he))\n    except Exception as e:\n        # Catch-all to ensure the client always receives a clean error structure\n        raise HTTPException(status_code=500, detail=f\"txpool_proxy internal error: {e}\")",
	"parse_txpool_response": "def parse_txpool_response(rpc_response: Dict[str, Any]) -> Union[List[str], Dict[str, Any]]:\n    \"\"\"Normalise the JSON-RPC `result` field.\n\n    Args:\n        rpc_response (dict): Raw response from an EVM JSON-RPC node.\n\n    Returns:\n        Union[List[str], Dict[str, Any]]: A simplified representation.\n\n    Raises:\n        TxpoolParsingError: If the response is malformed or contains an error.\n    \"\"\"\n    # Check for JSON-RPC errors first\n    if \"error\" in rpc_response:\n        raise TxpoolParsingError(rpc_response[\"error\"].get(\"message\", \"Unknown RPC error\"))\n\n    result = rpc_response.get(\"result\")\n    if result is None:\n        raise TxpoolParsingError(\"Missing 'result' field in RPC response\")\n\n    # Heuristically decide which method was used based on the payload format\n    if isinstance(result, str):\n        # This should be the `txpool_inspect` response (a big string). Split by lines.\n        # Each line looks like: \"0xAccount:nonce   tx_hash   {tx details...}\"\n        return [line.strip() for line in result.splitlines() if line.strip()]\n    elif isinstance(result, dict):\n        # Likely `txpool_content`: keep the full structure (pending / queued)\n        return result\n    else:\n        raise TxpoolParsingError(\"Unrecognised txpool response format\")",
	"_run_cmd": "def _run_cmd(cmd: list[str]) -> subprocess.CompletedProcess:\n    \"\"\"Helper that executes an external command and raises if it fails.\"\"\"\n    proc = subprocess.run(cmd, capture_output=True, text=True)\n    if proc.returncode != 0:\n        raise RuntimeError(f\"Command failed: {' '.join(cmd)}\\n{proc.stderr}\")\n    return proc\n\ndef ensure_testnet_files(home_dir: str | None = None,\n                          auto_init: bool = False,\n                          validators: int = 2) -> dict:\n    \"\"\"Checks (and optionally creates) test-net files for simd.\"\"\"\n    # Resolve the directory (default: $HOME/.simapp )\n    if home_dir is None:\n        home_dir = str(Path.home() / \".simapp\")\n    home_path = Path(home_dir)\n\n    # Very light-weight existence test – looks for any genesis.json file.\n    config_exists = any(home_path.glob(\"**/genesis.json\"))\n\n    # If everything is in place, just return the positive status.\n    if config_exists:\n        return {\"exists\": True, \"path\": home_dir}\n\n    # Files are missing – either tell the caller or create them.\n    if not auto_init:\n        return {\n            \"exists\": False,\n            \"requires_init\": True,\n            \"path\": home_dir,\n            \"hint\": \"POST again with auto_init=true or run `simd testnet init-files` manually.\"\n        }\n\n    # Initialise the directory.\n    cmd = [\n        \"simd\", \"testnet\", \"init-files\",\n        \"--v\", str(validators),            # number of validators\n        \"--output-dir\", home_dir\n    ]\n    proc = _run_cmd(cmd)\n    return {\n        \"exists\": True,\n        \"init_performed\": True,\n        \"path\": home_dir,\n        \"stdout\": proc.stdout\n    }\n\n@app.post(\"/api/ensure-testnet-files\")\nasync def api_ensure_testnet_files(home_dir: str | None = None,\n                                   auto_init: bool = False,\n                                   validators: int = 2):\n    \"\"\"HTTP wrapper around ensure_testnet_files.\"\"\"\n    try:\n        return ensure_testnet_files(home_dir, auto_init, validators)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"start_testnet": "def start_testnet(home_dir: str) -> dict:\n    \"\"\"Launch `simd testnet start --home <dir>` as a managed background process.\"\"\"\n    if not Path(home_dir).exists():\n        raise FileNotFoundError(f\"The directory {home_dir} does not exist; run Step 1 first.\")\n\n    # If a process is already running, avoid spawning another one.\n    existing = _processes.get(home_dir)\n    if existing and existing.poll() is None:\n        return {\"started\": False, \"message\": \"Test-net is already running.\", \"pid\": existing.pid}\n\n    cmd = [\"simd\", \"testnet\", \"start\", \"--home\", home_dir]\n    proc = subprocess.Popen(\n        cmd,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True,\n        bufsize=1  # line-buffered so we can stream logs\n    )\n    _processes[home_dir] = proc\n    return {\"started\": True, \"pid\": proc.pid, \"home_dir\": home_dir}\n\n\n@app.post(\"/api/start-testnet\")\nasync def api_start_testnet(home_dir: str):\n    \"\"\"HTTP endpoint that starts the test-net process.\"\"\"\n    try:\n        return start_testnet(home_dir)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"api_testnet_logs": "def api_testnet_logs(home_dir: str):\n    \"\"\"Streams stdout from the running `simd testnet start` process.\"\"\"\n    proc = _processes.get(home_dir)\n    if not proc or proc.poll() is not None:\n        raise HTTPException(status_code=400, detail=\"No running test-net for the given home_dir\")\n\n    async def log_generator():\n        \"\"\"Asynchronously yield lines from the process output.\"\"\"\n        # Use the underlying file-descriptor in non-blocking mode.\n        while True:\n            line = proc.stdout.readline()\n            if line:\n                yield line\n            elif proc.poll() is not None:\n                break  # process ended\n            else:\n                await asyncio.sleep(0.1)  # avoid busy-loop\n\n    return StreamingResponse(log_generator(), media_type=\"text/plain\")",
	"build_withdraw_tx": "def build_withdraw_tx(req: BuildTxRequest):\n    try:\n        rpc = os.getenv('RPC_ENDPOINT', 'https://rpc-kralum.neutron-1.neutron.org')\n        client = LedgerClient(rpc)\n        account = client.query_account(req.delegator_address)\n\n        tx = Transaction()\n        # A MsgWithdrawDelegatorReward message per validator\n        for r in req.rewards:\n            tx.add_msg(\n                MsgWithdrawDelegatorReward(\n                    delegator_address=req.delegator_address,\n                    validator_address=r.validator_address,\n                )\n            )\n\n        # Basic fee / gas; adjust to your needs\n        tx.set_fee(2000, 'untrn')\n        tx.set_gas(200000 * len(req.rewards))\n\n        tx.set_account_num(account.account_number)\n        tx.set_sequence(account.sequence)\n        tx.set_chain_id(client.chain_id)\n\n        sign_doc = tx.get_sign_doc()\n\n        return SignDocResponse(\n            body_bytes=base64.b64encode(sign_doc.body_bytes).decode(),\n            auth_info_bytes=base64.b64encode(sign_doc.auth_info_bytes).decode(),\n            account_number=account.account_number,\n            chain_id=client.chain_id,\n        )\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"check_foundryup_installation": "def check_foundryup_installation():\n    \"\"\"Verify that `foundryup` is on the PATH and return its version.\"\"\"\n    try:\n        result = subprocess.run([\n            \"foundryup\",\n            \"--version\"\n        ], check=True, capture_output=True, text=True)\n        version = result.stdout.strip()\n        return {\"foundryup_version\": version}\n    except FileNotFoundError:\n        raise RuntimeError(\"`foundryup` binary not found. Please install Foundry or add it to your PATH.\")\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"Error while checking `foundryup --version`: {err.stderr.strip()}\")",
	"run_foundryup_nightly": "def run_foundryup_nightly():\n    \"\"\"Install the latest nightly version of Foundry toolchain.\"\"\"\n    try:\n        result = subprocess.run(\n            [\"foundryup\", \"nightly\"],\n            check=True,\n            capture_output=True,\n            text=True\n        )\n        return {\"output\": result.stdout.strip()}\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"`foundryup nightly` failed: {err.stderr.strip()}\")",
	"verify_foundry_version": "def verify_foundry_version():\n    \"\"\"Confirm that `forge` is on a nightly build.\"\"\"\n    try:\n        result = subprocess.run([\n            \"forge\",\n            \"--version\"\n        ], check=True, capture_output=True, text=True)\n        version = result.stdout.strip()\n        if \"nightly\" not in version.lower():\n            raise RuntimeError(f\"Forge version does not appear to be nightly: {version}\")\n        return {\"forge_version\": version}\n    except FileNotFoundError:\n        raise RuntimeError(\"`forge` binary not found. Ensure Foundry installation succeeded.\")\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"Error while checking `forge --version`: {err.stderr.strip()}\")",
	"check_dependencies": "def check_dependencies():\n    \"\"\"Make sure the backend has the libraries we need.\"\"\"\n    try:\n        import web3  # noqa: F401\n        import dotenv  # noqa: F401\n    except ImportError as err:\n        raise ImportError(\n            f\"Missing dependency: {err.name}. Install with `pip install web3 python-dotenv`.\"\n        )",
	"create_json_rpc_provider": "def create_json_rpc_provider(rpc_url: str) -> Web3:\n    \"\"\"Return a connected `Web3` instance or raise if the RPC is unreachable.\"\"\"\n    provider = Web3(Web3.HTTPProvider(rpc_url, request_kwargs={\"timeout\": 60}))\n    if not provider.isConnected():\n        raise ConnectionError(f\"Unable to connect to RPC endpoint at {rpc_url}\")\n    return provider",
	"initialize_wallet": "def initialize_wallet(provider: Web3, private_key: str | None = None):\n    \"\"\"Return an `Account` object that will sign transactions.\"\"\"\n    pk = private_key or os.getenv(\"PRIVATE_KEY\")\n    if not pk:\n        raise ValueError(\"Private key not provided. Pass it explicitly or set the PRIVATE_KEY env var.\")\n    account = Account.from_key(pk)\n    return account",
	"build_transaction": "def build_transaction(account, to_address: str, value_ether: float, provider: Web3, gas_limit: int | None = None):\n    \"\"\"Prepare an unsigned transaction.\"\"\"\n    nonce = provider.eth.get_transaction_count(account.address)\n    chain_id = provider.eth.chain_id\n    value_wei = Web3.toWei(value_ether, \"ether\")\n\n    tx = {\n        \"nonce\": nonce,\n        \"to\": Web3.to_checksum_address(to_address),\n        \"value\": value_wei,\n        \"chainId\": chain_id,\n    }\n    if gas_limit:\n        tx[\"gas\"] = gas_limit  # will be replaced during estimation if omitted\n    return tx",
	"estimate_gas_with_web3": "def estimate_gas_with_web3(tx: dict, provider: Web3) -> dict:\n    \"\"\"Populate `gas`, `maxFeePerGas` & `maxPriorityFeePerGas` OR `gasPrice`.\"\"\"\n    gas_estimate = provider.eth.estimate_gas(tx)\n    tx[\"gas\"] = gas_estimate\n\n    try:\n        # Prefer EIP-1559 style if supported\n        base_fee = provider.eth.fee_history(1, \"latest\")[\"baseFeePerGas\"][-1]\n        max_priority = Web3.toWei(2, \"gwei\")  # configurable tip\n        tx[\"maxFeePerGas\"] = base_fee + max_priority\n        tx[\"maxPriorityFeePerGas\"] = max_priority\n    except Exception:\n        # Fallback to legacy `gasPrice`\n        tx[\"gasPrice\"] = provider.eth.gas_price\n\n    return tx",
	"sign_and_send_transaction": "def sign_and_send_transaction(account, tx: dict, provider: Web3) -> str:\n    \"\"\"Sign the transaction and return its hash.\"\"\"\n    signed_tx = account.sign_transaction(tx)\n    tx_hash = provider.eth.send_raw_transaction(signed_tx.rawTransaction)\n    return tx_hash.hex()",
	"await_transaction_receipt": "def await_transaction_receipt(provider: Web3, tx_hash: str, confirmations: int = 1, poll_interval: int = 5, timeout: int = 300):\n    \"\"\"Block until the txn is mined + `confirmations` blocks and return its receipt.\"\"\"\n    receipt = provider.eth.wait_for_transaction_receipt(tx_hash, timeout=timeout)\n\n    if confirmations > 1:\n        target_block = receipt.blockNumber + confirmations - 1\n        while provider.eth.block_number < target_block:\n            time.sleep(poll_interval)\n    return dict(receipt)",
	"construct_msg_remove_schedule": "def construct_msg_remove_schedule(schedule_name: str, authority: str) -> dict:\n    \"\"\"Return a MsgRemoveSchedule ready for inclusion in a proposal.\"\"\"\n    return {\n        \"@type\": \"/neutron.cron.MsgRemoveSchedule\",\n        \"authority\": authority,\n        \"name\": schedule_name,\n    }",
	"construct_msg_add_schedule": "def construct_msg_add_schedule(schedule_name: str, period: int, msgs: list, authority: str) -> dict:\n    \"\"\"Return a MsgAddSchedule that runs at BEGIN_BLOCKER.\"\"\"\n    return {\n        \"@type\": \"/neutron.cron.MsgAddSchedule\",\n        \"authority\": authority,\n        \"name\": schedule_name,\n        \"period\": str(period),              # protobuf JSON expects strings for integers\n        \"execution_stages\": [\"BEGIN_BLOCKER\"],\n        \"msgs\": msgs,\n    }",
	"create_json_proposal_file": "def create_json_proposal_file(msgs: list, title: str, description: str, deposit: str, outfile: str = \"proposal.json\") -> str:\n    \"\"\"Writes a Neutron governance proposal JSON to disk.\"\"\"\n    proposal = {\n        \"title\": title,\n        \"description\": description,\n        \"deposit\": deposit,           # e.g. \"1000000untrn\"\n        \"messages\": msgs,\n    }\n    with open(outfile, \"w\", encoding=\"utf-8\") as fp:\n        json.dump(proposal, fp, indent=2)\n    return outfile",
	"vote_and_wait_for_passage": "def vote_and_wait_for_passage(rpc_endpoint: str, proposal_id: int, voter_priv_hex: str, chain_id: str, poll: int = 15):\n    \"\"\"Casts a YES vote, then waits until the proposal status is PASSED (or fails).\"\"\"\n    key = PrivateKey.from_hex(voter_priv_hex)\n    cfg = NetworkConfig(\n        chain_id=chain_id,\n        url=rpc_endpoint,\n        fee_denomination=\"untrn\",\n        fee_minimum_gas_price=0.025,\n    )\n    client = LedgerClient(cfg)\n\n    # VoteOptionYes = 1\n    client.gov_vote(proposal_id, key.address(), 1)\n    print(f\"YES vote submitted from {key.address()} on proposal {proposal_id}\")\n\n    while True:\n        status = client.gov_proposal(proposal_id)[\"status\"]\n        print(\"Current status:\", status)\n        if status == \"PROPOSAL_STATUS_PASSED\":\n            print(\"🎉 Proposal PASSED\")\n            return True\n        if status in (\"PROPOSAL_STATUS_REJECTED\", \"PROPOSAL_STATUS_FAILED\"):\n            raise RuntimeError(f\"Proposal ended with status {status}\")\n        time.sleep(poll)",
	"confirm_execution_stage": "def confirm_execution_stage(rest_endpoint: str, schedule_name: str) -> bool:\n    \"\"\"Returns True if the cron job now runs at BEGIN_BLOCKER.\"\"\"\n    schedule = query_cron_schedule(rest_endpoint, schedule_name)\n    return schedule.get(\"execution_stage\") == \"BEGIN_BLOCKER\"",
	"_get_network": "def _get_network() -> NetworkConfig:\n    return NetworkConfig(\n        chain_id=os.getenv(\"CHAIN_ID\", \"cosmoshub-4\"),\n        url=os.getenv(\"GRPC_ENDPOINT\", \"grpc+https://cosmoshub.grpc.polkachu.com:443\"),\n    )\n\ndef _get_wallet() -> LocalWallet:\n    mnemonic = os.getenv(\"PROPOSER_MNEMONIC\")\n    if not mnemonic:\n        raise RuntimeError(\"PROPOSER_MNEMONIC env var is missing\")\n    return LocalWallet.from_mnemonic(mnemonic)\n\n# ---------- Route ---------- #\n@router.post(\"/submit\")\nasync def submit_text_proposal(body: SubmitProposalBody):\n    try:\n        # 1. Init network + wallet\n        network = _get_network()\n        client = LedgerClient(network)\n        wallet = _get_wallet()\n\n        if wallet.address() != body.proposer_address:\n            raise HTTPException(status_code=400, detail=\"Server wallet address ≠ proposer address.\")\n\n        # 2. Build TextProposal content\n        text_content = TextProposal(title=body.title, description=body.description)\n        any_content = Any_pb2()\n        any_content.Pack(text_content)\n        any_content.type_url = \"/cosmos.gov.v1beta1.TextProposal\"\n\n        # 3. Build MsgSubmitProposal\n        msg = MsgSubmitProposal(\n            content=any_content,\n            proposer=wallet.address(),\n            initial_deposit=[Coin(amount=body.deposit_amount, denom=body.deposit_denom)],\n        )\n\n        # 4. Create & sign tx\n        tx = Transaction()\n        tx.add_message(msg)\n        tx.with_gas(200000)  # heuristic; adjust as needed\n        tx.with_fee(3000)    # micro-denom fee\n        tx.with_memo(body.summary)\n\n        signed_tx = wallet.sign_transaction(tx)\n\n        # 5. Broadcast and wait for inclusion\n        result = client.broadcast_tx_block(signed_tx)\n        if result.code != 0:\n            logger.error(\"Broadcast failed %s\", result.raw_log)\n            raise HTTPException(status_code=500, detail=f\"Broadcast error: {result.raw_log}\")\n\n        # Extract proposal ID from logs (gov module emits it)\n        proposal_id = None\n        for event in result.events:\n            if event[\"type\"] == \"submit_proposal\":\n                for attr in event[\"attributes\"]:\n                    if attr[\"key\"] == \"proposal_id\":\n                        proposal_id = int(attr[\"value\"])\n                        break\n        if proposal_id is None:\n            raise HTTPException(status_code=500, detail=\"Unable to parse proposal_id from tx logs\")\n\n        return {\n            \"tx_hash\": result.tx_hash,\n            \"proposal_id\": proposal_id\n        }\n    except HTTPException:\n        raise\n    except Exception as err:\n        logger.exception(\"submit_text_proposal failed\")\n        raise HTTPException(status_code=500, detail=str(err))",
	"get_proposal_status": "def get_proposal_status(proposal_id: int):\n    try:\n        url = f\"{REST_ENDPOINT}/cosmos/gov/v1beta1/proposals/{proposal_id}\"\n        r = requests.get(url, timeout=10)\n        if r.status_code != 200:\n            raise HTTPException(status_code=r.status_code, detail=r.text)\n        json_data = r.json()\n        status = json_data[\"proposal\"][\"status\"]\n        return {\n            \"proposal_id\": proposal_id,\n            \"status\": status,\n            \"raw\": json_data\n        }\n    except HTTPException:\n        raise\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"extract_last_execution_height": "def extract_last_execution_height(schedule_data: dict) -> int:\n    \"\"\"Return the most recent execution height from schedule JSON.\n\n    Supports both possible proto field names: `last_execution_height` (preferred)\n    or the legacy `last_executed_height`.\n    \"\"\"\n    for key in (\"last_execution_height\", \"last_executed_height\"):\n        value = schedule_data.get(key)\n        if value is not None:\n            try:\n                return int(value)\n            except (TypeError, ValueError):\n                raise ValueError(f\"Field '{key}' is not an integer: {value}\")\n\n    raise KeyError(\"Neither 'last_execution_height' nor 'last_executed_height' were found in the schedule data.\")",
	"construct_unsigned_tx_cli": "def construct_unsigned_tx_cli(tx_args: List[str], chain_id: str, node: str = 'tcp://localhost:26657', home_path: Optional[str] = None) -> Dict:\n    '''\n    Generate an unsigned transaction via `<appd> tx ... --generate-only`.\n\n    Parameters\n    ----------\n    tx_args : list[str]\n        Portion after `appd tx`, e.g. ['bank', 'send', '{from}', '{to}', '100uatom'].\n    chain_id : str\n        Target chain-id.\n    node : str\n        RPC endpoint of the node (defaults to local node).\n    home_path : str | None\n        Optional `$HOME` for the CLI.\n\n    Returns\n    -------\n    dict\n        Parsed JSON of the unsigned transaction.\n    '''\n    cmd = ['appd', 'tx'] + tx_args + ['--generate-only', '--chain-id', chain_id, '--node', node, '--output', 'json']\n    if home_path:\n        cmd += ['--home', home_path]\n\n    try:\n        completed = subprocess.run(cmd, capture_output=True, text=True, check=True)\n        return json.loads(completed.stdout)\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f'Failed to construct unsigned tx: {e.stderr}') from e",
	"sign_tx_cli": "def sign_tx_cli(unsigned_tx: Dict, signer_key: str, chain_id: str, home_path: Optional[str] = None) -> str:\n    '''Sign an unsigned transaction using `<appd> tx sign` and return base64 `tx_bytes`.'''\n    with NamedTemporaryFile('w', delete=False, suffix='.json') as tmp:\n        json.dump(unsigned_tx, tmp)\n        tmp.flush()\n        tmp_name = tmp.name\n\n    cmd = ['appd', 'tx', 'sign', tmp_name, '--from', signer_key, '--chain-id', chain_id, '--output', 'json']\n    if home_path:\n        cmd += ['--home', home_path]\n\n    try:\n        completed = subprocess.run(cmd, capture_output=True, text=True, check=True)\n        signed_tx = json.loads(completed.stdout)\n        tx_bytes = signed_tx.get('tx_bytes') or signed_tx.get('body', {}).get('tx_bytes')\n        if not tx_bytes:\n            raise KeyError('tx_bytes not found in signing output')\n        return tx_bytes\n    finally:\n        os.remove(tmp_name)",
	"broadcast_tx_rest": "def broadcast_tx_rest(tx_bytes_b64: str, rest_endpoint: str = 'http://localhost:1317', mode: str = 'BROADCAST_MODE_SYNC') -> Dict:\n    '''Broadcast the signed transaction using the REST (gRPC-gateway) endpoint.'''    \n    url = f'{rest_endpoint}/cosmos/tx/v1beta1/txs'\n    payload = {'tx_bytes': tx_bytes_b64, 'mode': mode}\n    resp = requests.post(url, json=payload, timeout=10)\n    if not resp.ok:\n        raise RuntimeError(f'REST broadcast failed: {resp.status_code} {resp.text}')\n    return resp.json()\n\n\ndef broadcast_tx_grpcurl(tx_bytes_b64: str, grpc_host: str = 'localhost:9090', mode: str = 'BROADCAST_MODE_SYNC') -> Dict:\n    '''Alternative: broadcast the signed transaction via the low-level gRPC method using `grpcurl`.'''\n    data = json.dumps({'tx_bytes': tx_bytes_b64, 'mode': mode})\n    cmd = ['grpcurl', '-plaintext', '-d', data, grpc_host, 'cosmos.tx.v1beta1.Service/BroadcastTx']\n    completed = subprocess.run(cmd, capture_output=True, text=True, check=True)\n    return json.loads(completed.stdout)",
	"_exec": "def _exec(cmd: List[str]) -> str:\n    \"\"\"Execute a CLI command and return stdout; raise an HTTPException on error.\"\"\"\n    try:\n        completed = subprocess.run(cmd, check=True, capture_output=True, text=True)\n        return completed.stdout\n    except FileNotFoundError:\n        raise HTTPException(status_code=500, detail=f\"Binary '{cmd[0]}' not found on server.\")\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=err.stderr or err.stdout)\n\n\n@app.get('/api/snapshots', response_model=dict)\nasync def list_snapshots():\n    \"\"\"GET /api/snapshots — returns a JSON array of available snapshots.\"\"\"\n    raw_output = _exec([APPD_BINARY, 'snapshots', 'list'])\n    lines = [line.strip() for line in raw_output.splitlines() if line.strip()]\n    # Remove header row if present (e.g., \"Height   Format   ...\")\n    if lines and lines[0].lower().startswith('height'):\n        lines = lines[1:]\n    return {'snapshots': lines}",
	"check_pprof_port": "def check_pprof_port(host: str = \"localhost\", port: int = 6060, timeout: int = 2):\n    '''\n    Check whether the Cosmos node was started with pprof enabled.\n\n    Args:\n        host (str): Hostname where the node is running.\n        port (int): Port where pprof is expected to listen (default 6060).\n        timeout (int): Timeout in seconds for the HTTP request.\n\n    Returns:\n        dict: Dictionary containing 'pprof_running' (bool) and 'message' (str).\n    '''\n    import http.client\n\n    conn = http.client.HTTPConnection(host, port, timeout=timeout)\n    try:\n        # '/debug/pprof/' returns 200 if pprof is enabled.\n        conn.request(\"GET\", \"/debug/pprof/\")\n        resp = conn.getresponse()\n\n        if resp.status == 200:\n            return {\n                \"pprof_running\": True,\n                \"message\": f\"pprof is active at http://{host}:{port}/debug/pprof/\"\n            }\n        return {\n            \"pprof_running\": False,\n            \"message\": f\"HTTP {resp.status} received; pprof might not be enabled.\"\n        }\n    except Exception as exc:\n        return {\n            \"pprof_running\": False,\n            \"message\": f\"Unable to connect to {host}:{port}. Error: {str(exc)}\"\n        }\n    finally:\n        conn.close()",
	"capture_cpu_profile": "def capture_cpu_profile(seconds: int = 30, host: str = \"localhost\", port: int = 6060, output_file: str = \"cpu.prof\"):\n    '''\n    Capture a CPU profile from the running Cosmos node via the pprof HTTP endpoint.\n\n    The call blocks for `seconds` while profiling is active, then writes the binary\n    profile to `output_file`.\n    '''\n    import http.client\n\n    path = f\"/debug/pprof/profile?seconds={seconds}\"\n    conn = http.client.HTTPConnection(host, port, timeout=seconds + 5)\n    try:\n        conn.request(\"GET\", path)\n        resp = conn.getresponse()\n\n        if resp.status != 200:\n            return {\"ok\": False, \"error\": f\"pprof returned HTTP {resp.status} {resp.reason}\"}\n\n        with open(output_file, \"wb\") as fp:\n            # Stream the response body to disk.\n            while True:\n                data = resp.read(8192)\n                if not data:\n                    break\n                fp.write(data)\n\n        return {\"ok\": True, \"output_file\": output_file, \"message\": f\"CPU profile captured to {output_file}\"}\n    except Exception as exc:\n        return {\"ok\": False, \"error\": str(exc)}\n    finally:\n        conn.close()",
	"init_hardhat_project": "def init_hardhat_project(project_name: str):\n    \"\"\"Initialize a Hardhat project inside a server-side working directory.\"\"\"\n    try:\n        project_path = os.path.abspath(project_name)\n        if os.path.exists(project_path):\n            raise HTTPException(status_code=400, detail='Directory already exists')\n        os.makedirs(project_path, exist_ok=True)\n\n        # 1. Generate package.json\n        subprocess.run(['npm', 'init', '-y'], cwd=project_path, check=True)\n\n        # 2. Install Hardhat locally\n        subprocess.run(['npm', 'install', '--save-dev', 'hardhat'], cwd=project_path, check=True)\n\n        # 3. Scaffold Hardhat boilerplate (–yes answers all prompts)\n        subprocess.run(['npx', 'hardhat', '--yes'], cwd=project_path, check=True)\n\n        return {\"status\": \"success\", \"project_path\": project_path}\n    except subprocess.CalledProcessError as e:\n        raise HTTPException(status_code=500, detail=f'Command failed: {e}')",
	"install_solidity_dependencies": "def install_solidity_dependencies(project_path: str):\n    \"\"\"Add @nomicfoundation/hardhat-toolbox and @evmos/hardhat-evmos to the project.\"\"\"\n    try:\n        if not os.path.isdir(project_path):\n            raise HTTPException(status_code=404, detail='Project directory not found')\n        packages = ['@nomicfoundation/hardhat-toolbox', '@evmos/hardhat-evmos']\n        subprocess.run(['npm', 'install', '--save-dev', *packages], cwd=project_path, check=True)\n        return {\"status\": \"success\", \"installed\": packages}\n    except subprocess.CalledProcessError as e:\n        raise HTTPException(status_code=500, detail=f'Install failed: {e}')",
	"configure_hardhat_network": "def configure_hardhat_network(project_path: str, network_name: str, rpc_url: str, chain_id: int, gas_price: str, private_key: str):\n    \"\"\"Write or overwrite hardhat.config.js with network values sent from the client side.\"\"\"\n    try:\n        if not os.path.isdir(project_path):\n            raise HTTPException(status_code=404, detail='Project directory not found')\n        config_path = os.path.join(project_path, 'hardhat.config.js')\n        with open(config_path, 'w', encoding='utf-8') as fh:\n            fh.write(NETWORK_TEMPLATE.format(\n                network_name=network_name,\n                rpc_url=rpc_url,\n                chain_id=chain_id,\n                gas_price=gas_price,\n                private_key=private_key\n            ))\n        return {\"status\": \"success\", \"config_path\": config_path}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"hardhat_compile": "def hardhat_compile(project_path: str):\n    \"\"\"Run `npx hardhat compile` inside the project directory.\"\"\"\n    try:\n        if not os.path.isdir(project_path):\n            raise HTTPException(status_code=404, detail='Project directory not found')\n        subprocess.run(['npx', 'hardhat', 'compile'], cwd=project_path, check=True)\n        return {\"status\": \"success\", \"message\": \"Compilation finished\"}\n    except subprocess.CalledProcessError as e:\n        raise HTTPException(status_code=500, detail=f'Compile failed: {e}')",
	"create_deployment_script": "def create_deployment_script(project_path: str, contract_name: str, constructor_args: str = ''):\n    \"\"\"Create `scripts/deploy.js` with the supplied contract name and constructor args.\"\"\"\n    try:\n        if not os.path.isdir(project_path):\n            raise HTTPException(status_code=404, detail='Project directory not found')\n        scripts_dir = os.path.join(project_path, 'scripts')\n        os.makedirs(scripts_dir, exist_ok=True)\n        deploy_script_path = os.path.join(scripts_dir, 'deploy.js')\n        with open(deploy_script_path, 'w', encoding='utf-8') as fh:\n            fh.write(DEPLOY_TEMPLATE.format(contract_name=contract_name, constructor_args=constructor_args))\n        return {\"status\": \"success\", \"deploy_script\": deploy_script_path}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"hardhat_run_deployment": "def hardhat_run_deployment(project_path: str, network_name: str):\n    \"\"\"Execute `npx hardhat run scripts/deploy.js --network <network>` and parse stdout for contract address.\"\"\"\n    try:\n        if not os.path.isdir(project_path):\n            raise HTTPException(status_code=404, detail='Project directory not found')\n        completed = subprocess.run(['npx', 'hardhat', 'run', 'scripts/deploy.js', '--network', network_name], cwd=project_path, check=True, capture_output=True, text=True)\n        match = DEPLOY_REGEX.search(completed.stdout)\n        address = match.group(1) if match else None\n        return {\"status\": \"success\", \"stdout\": completed.stdout, \"contract_address\": address}\n    except subprocess.CalledProcessError as e:\n        raise HTTPException(status_code=500, detail=f'Deployment failed: {e}\\n{e.stdout}\\n{e.stderr}')",
	"hardhat_verify_contract": "def hardhat_verify_contract(project_path: str, network_name: str, contract_address: str, constructor_args: str = ''):\n    \"\"\"Invoke `npx hardhat verify` with the given parameters.\"\"\"\n    try:\n        if not os.path.isdir(project_path):\n            raise HTTPException(status_code=404, detail='Project directory not found')\n        cmd = ['npx', 'hardhat', 'verify', '--network', network_name, contract_address]\n        if constructor_args:\n            cmd.extend(constructor_args.split())\n        subprocess.run(cmd, cwd=project_path, check=True)\n        return {\"status\": \"success\", \"verified\": contract_address}\n    except subprocess.CalledProcessError as e:\n        raise HTTPException(status_code=500, detail=f'Verification failed: {e}')",
	"parse_json_response": "def parse_json_response(raw: Dict[str, Any]) -> ParsedSchedule:\n    \"\"\"Parse required fields from cron schedule JSON.\n\n    Args:\n        raw: The raw JSON dict returned by query_cron_schedule.\n\n    Returns:\n        A TypedDict containing the requested fields.\n\n    Raises:\n        KeyError: If any expected field is missing.\n        ValueError: If a field has an unexpected type/format.\n    \"\"\"\n    try:\n        schedule = raw[\"schedule\"]  # LCD nests data under the `schedule` key\n        parsed: ParsedSchedule = {\n            \"name\": schedule[\"name\"],\n            \"period\": schedule[\"period\"],\n            \"msgs\": schedule[\"msgs\"],\n            \"last_execution_height\": int(schedule[\"last_execution_height\"]),\n        }\n        return parsed\n    except KeyError as exc:\n        raise KeyError(f\"Expected key not found in response: {exc}\") from exc\n    except (TypeError, ValueError) as exc:\n        raise ValueError(f\"Malformed field in cron schedule response: {exc}\") from exc",
	"get_eth_balance": "def get_eth_balance(\n    address: str = Query(..., description='0x-prefixed Ethereum address'),\n    rpc_endpoint: str = Query(DEFAULT_RPC_ENDPOINT, description='Optional JSON-RPC endpoint')\n):\n    \"\"\"Returns the latest ETH balance in Wei (hex encoded).\"\"\"\n    # Safety check on backend as well\n    if not ETH_ADDRESS_REGEX.fullmatch(address):\n        raise HTTPException(status_code=400, detail='Invalid Ethereum address')\n\n    payload = {\n        'jsonrpc': '2.0',\n        'method': 'eth_getBalance',\n        'params': [address, 'latest'],\n        'id': 1\n    }\n\n    try:\n        async with httpx.AsyncClient(timeout=10) as client:\n            resp = await client.post(rpc_endpoint, json=payload)\n            resp.raise_for_status()\n            data = resp.json()\n    except httpx.HTTPError as e:\n        raise HTTPException(status_code=502, detail=f'Upstream RPC error: {e}')\n\n    if data.get('error'):\n        raise HTTPException(status_code=500, detail=data['error'])\n\n    return {\n        'address': address,\n        'balance_hex': data.get('result', '0x0')\n    }",
	"wrap_in_dao_proposal": "def wrap_in_dao_proposal(\n    dao_contract: str,\n    proposer_addr: str,\n    schedule_msg: Dict,\n    title: str = \"Add daily_rewards cron schedule\",\n    description: str = \"Creates a cron job that distributes daily rewards at END_BLOCKER every 7200 blocks.\",\n) -> Dict:\n    \"\"\"Return a MsgExecuteContract that submits a `propose` call to a cw-dao-single contract.\"\"\"\n    if not dao_contract or not proposer_addr or not schedule_msg:\n        raise ProposalBuildError(\"dao_contract, proposer_addr, and schedule_msg are mandatory\")\n\n    # cw-dao expects its internal Cosmos messages to be passed as base64-encoded binary Anys.\n    # For simplicity we send the raw JSON (accepted by cosmjs), letting the chain pack it.\n    proposal_msg = {\n        \"propose\": {\n            \"title\": title,\n            \"description\": description,\n            \"msgs\": [\n                {\n                    \"stargate\": {\n                        \"type_url\": \"/neutron.cron.MsgAddSchedule\",\n                        \"value\": base64.b64encode(json.dumps(schedule_msg).encode()).decode()\n                    }\n                }\n            ],\n            \"latest\": None\n        }\n    }\n\n    return {\n        \"@type\": \"/cosmwasm.wasm.v1.MsgExecuteContract\",\n        \"sender\": proposer_addr,\n        \"contract\": dao_contract,\n        \"msg\": base64.b64encode(json.dumps(proposal_msg).encode()).decode(),\n        \"funds\": []\n    }\n",
	"search_docs": "def search_docs(query: str = Query(..., min_length=3)):\n    \"\"\"\n    Searches Cosmos-related documentation. This example uses DuckDuckGo’s open API\n    to keep the implementation simple while avoiding CORS issues for the frontend.\n    \"\"\"\n    try:\n        search_url = f\"https://duckduckgo.com/?q={query}&format=json\"\n        response = requests.get(search_url, timeout=10)\n        response.raise_for_status()\n        data = response.json()\n        # Return the first five hits to keep payloads small.\n        results = data.get(\"RelatedTopics\", [])[:5]\n        return {\"query\": query, \"results\": results}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Search failed: {e}\")",
	"export_state": "def export_state(height: int, home: str, output_path: str = \"state.json\", binary: str = os.getenv(\"COSMOS_BINARY\", \"cosmosd\")):\n    \"\"\"\n    Executes `<binary> export --home <home> --height <height>` and saves the\n    output to `output_path`.\n    \"\"\"\n    try:\n        cmd = f\"{binary} export --home {home} --height {height}\"\n        proc = await asyncio.create_subprocess_shell(\n            cmd,\n            stdout=asyncio.subprocess.PIPE,\n            stderr=asyncio.subprocess.PIPE,\n        )\n        stdout, stderr = await proc.communicate()\n        if proc.returncode != 0:\n            raise RuntimeError(stderr.decode())\n        Path(output_path).write_text(stdout.decode())\n        return {\"output_file\": output_path, \"height\": height}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Export failed: {e}\")",
	"validate_state": "def validate_state(file_path: str = \"state.json\"):\n    \"\"\"\n    Confirms that `app_state` and `validators` exist at the top level of the\n    exported JSON file.\n    \"\"\"\n    try:\n        if not Path(file_path).is_file():\n            raise FileNotFoundError(f\"{file_path} not found\")\n        with open(file_path, \"r\", encoding=\"utf-8\") as fp:\n            data = json.load(fp)\n        missing = [k for k in (\"app_state\", \"validators\") if k not in data]\n        return {\"valid\": len(missing) == 0, \"missing\": missing}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Validation failed: {e}\")",
	"get_latest_block_height": "def get_latest_block_height(rpc_url: str = \"http://localhost:26657\") -> int:\n    \"\"\"Return the latest block height from the node's RPC `/status` endpoint.\"\"\"\n    try:\n        response = requests.get(f\"{rpc_url}/status\", timeout=10)\n        response.raise_for_status()\n        data = response.json()\n        height = int(data[\"result\"][\"sync_info\"][\"latest_block_height\"])\n        return height\n    except Exception as err:\n        raise RuntimeError(f\"Unable to fetch latest block height: {err}\") from err",
	"create_snapshot": "def create_snapshot(home: str) -> None:\n    \"\"\"Create a snapshot via `simd snapshot create`. Raises on failure.\"\"\"\n    cmd = [\n        \"simd\",\n        \"snapshot\",\n        \"create\",\n        f\"--home={home}\"\n    ]\n    process = subprocess.run(cmd, capture_output=True, text=True)\n    if process.returncode != 0:\n        raise RuntimeError(\n            f\"Snapshot creation failed (exit {process.returncode}): {process.stderr.strip()}\"\n        )\n    # Log stdout for debugging purposes\n    print(process.stdout.strip())",
	"_list_snapshots_raw": "def _list_snapshots_raw(home: str) -> list[str]:\n    \"\"\"Internal helper to call `simd snapshot list`. Returns raw line output.\"\"\"\n    cmd = [\"simd\", \"snapshot\", \"list\", f\"--home={home}\"]\n    proc = subprocess.run(cmd, capture_output=True, text=True)\n    if proc.returncode != 0:\n        raise RuntimeError(f\"Snapshot list failed: {proc.stderr.strip()}\")\n    return [ln.strip() for ln in proc.stdout.splitlines() if ln.strip()]\n\n\ndef wait_for_snapshot(home: str, expected_height: int, timeout: int = 300, poll_interval: int = 5) -> str:\n    \"\"\"Wait until a snapshot containing `expected_height` appears or raise TimeoutError.\"\"\"\n    deadline = time.time() + timeout\n    while time.time() < deadline:\n        for line in _list_snapshots_raw(home):\n            if str(expected_height) in line:\n                return line  # Return snapshot identifier / line\n        time.sleep(poll_interval)\n    raise TimeoutError(\n        f\"Snapshot at height {expected_height} not found within {timeout} seconds.\"\n    )",
	"extract_tx_bytes": "def extract_tx_bytes(signed_path: str = \"signed.json\") -> str:\n    \"\"\"Extract the `tx_bytes` field from the signed transaction JSON.\n\n    Args:\n        signed_path: Path to the signed JSON produced in Step 2.\n\n    Returns:\n        Base-64 encoded transaction bytes.\n    \"\"\"\n    try:\n        data = json.loads(Path(signed_path).read_text(encoding=\"utf-8\"))\n        tx_bytes = data.get(\"tx_bytes\")\n        if not tx_bytes:\n            raise ValueError(\"`tx_bytes` not found in signed JSON.\")\n        return tx_bytes\n    except (json.JSONDecodeError, FileNotFoundError, ValueError) as e:\n        raise RuntimeError(f\"Failed to extract tx_bytes: {str(e)}\") from e",
	"convert_wei": "def convert_wei(req: WeiRequest):\n    wei = req.wei_amount.strip()\n\n    # Validate ---------------------------------------------------------------\n    if not wei.isdigit():\n        raise HTTPException(\n            status_code=400,\n            detail=\"Wei amount must be a positive integer represented as a string.\"\n        )\n\n    # Prefer the `cast` CLI if available ------------------------------------\n    cast_path = shutil.which(\"cast\")\n    if cast_path:\n        try:\n            result = subprocess.run(\n                [cast_path, \"from-wei\", wei],\n                capture_output=True,\n                text=True,\n                check=True\n            )\n            ether_value = result.stdout.strip()\n        except subprocess.CalledProcessError as err:\n            # Fall back in case cast exits with non-zero status\n            ether_value = str(Decimal(wei) / Decimal(10 ** 18))\n    else:\n        # Fallback: pure-Python conversion ---------------------------------\n        ether_value = str(Decimal(wei) / Decimal(10 ** 18))\n\n    return JSONResponse({\n        \"wei\": wei,\n        \"ether\": ether_value\n    })",
	"get_web3_client": "def get_web3_client(rpc_url: str, chain_id: int) -> Web3:\n    '''Return a configured Web3 HTTP provider.'''\n    if not rpc_url.startswith(('http://', 'https://')):\n        raise ValueError('RPC URL must start with http or https.')\n\n    w3 = Web3(Web3.HTTPProvider(rpc_url, request_kwargs={'timeout': 10}))\n    if not w3.isConnected():\n        raise ConnectionError(f'Unable to connect to RPC endpoint {rpc_url}')\n\n    # Many Cosmos EVM chains use the same header layout as POA networks\n    w3.middleware_onion.inject(geth_poa_middleware, layer=0)\n    w3.chain_id = chain_id\n    return w3",
	"read_contract": "def read_contract(req: ReadContractRequest):\n    try:\n        contract = w3.eth.contract(address=req.contractAddress, abi=req.abi)\n        try:\n            fn = getattr(contract.functions, req.functionName)\n        except AttributeError:\n            raise ABIFunctionNotFound(f'{req.functionName} not found in provided ABI')\n\n        data = fn(*req.args).call()\n        return {'data': data}\n    except Exception as e:\n        # Convert all errors to HTTP 400s so the frontend can handle them uniformly\n        raise HTTPException(status_code=400, detail=str(e))",
	"validate_new_code_id": "def validate_new_code_id(contract_address: str, new_code_id: int, rpc_url: str = \"https://rpc-kralum.neutron-1.neutron.org\") -> bool:\n    \"\"\"Validate that `new_code_id` exists and differs from the contract's current code ID.\n\n    Args:\n        contract_address (str): Address of the contract to migrate.\n        new_code_id (int): The code ID to migrate to.\n        rpc_url (str): RPC endpoint for Neutron.\n    Returns:\n        bool: True if the validation succeeds, otherwise an exception is raised.\n    \"\"\"\n    try:\n        cfg = NetworkConfig(\n            chain_id=\"neutron-1\",\n            url=rpc_url,\n            fee_minimum_gas_price=\"0.025untrn\",\n            fee_denomination=\"untrn\",\n        )\n        client = LedgerClient(cfg)\n\n        # Ensure the new code ID exists\n        code_info = client.query.wasm.get_code_info(new_code_id)\n        if code_info is None:\n            raise ValueError(f\"Code ID {new_code_id} does not exist on-chain.\")\n\n        # Fetch current contract info\n        contract_info = client.query.wasm.get_contract_info(contract_address)\n        if int(contract_info[\"code_id\"]) == new_code_id:\n            raise ValueError(\"Contract already instantiated with this code ID.\")\n\n        return True\n    except (QueryError, Exception) as err:\n        raise RuntimeError(f\"Validation failed: {err}\") from err",
	"get_rpc_session": "def get_rpc_session() -> requests.Session:\n    \"\"\"Return a requests.Session pre-configured with basic-auth headers.\"\"\"\n    session = requests.Session()\n    session.headers.update({'Content-Type': 'application/json'})\n\n    # Attach Basic-Auth only when credentials exist\n    if RPC_USERNAME and RPC_PASSWORD:\n        auth_pair = f'{RPC_USERNAME}:{RPC_PASSWORD}'.encode()\n        session.headers.update({\n            'Authorization': f'Basic {base64.b64encode(auth_pair).decode()}'\n        })\n\n    # Non-standard helper attribute for convenience\n    session.base_url = RPC_ENDPOINT  # type: ignore[attr-defined]\n    return session\n\n# Optional quick self-test when the file is executed directly\nif __name__ == '__main__':\n    try:\n        s = get_rpc_session()\n        resp = s.post(s.base_url, json={'jsonrpc': '2.0', 'method': 'health', 'params': [], 'id': 1}, timeout=5)\n        resp.raise_for_status()\n        print('RPC health check succeeded')\n    except Exception as err:\n        print(f'RPC health check failed: {err}')",
	"query_all_cron_schedules": "def query_all_cron_schedules(limit: int = 1000) -> List[Dict]:\n    \"\"\"Return every cron schedule on-chain.\n\n    Args:\n        limit: Max items per page (must be ≤ CLI max-limit).\n\n    Returns:\n        A list with all schedule objects.\n    \"\"\"\n    schedules: List[Dict] = []\n    next_key: str | None = \"\"\n\n    try:\n        while True:\n            # Build CLI command\n            cmd = [\n                \"neutrond\", \"query\", \"cron\", \"schedules\",\n                \"--limit\", str(limit), \"--output\", \"json\"\n            ]\n            if next_key:\n                cmd += [\"--page-key\", next_key]\n\n            # Execute the command and parse stdout\n            raw = subprocess.check_output(cmd, text=True)\n            data = json.loads(raw)\n\n            # Merge current page\n            schedules.extend(data.get(\"schedules\", []))\n\n            # Prepare for the next loop\n            next_key = data.get(\"pagination\", {}).get(\"next_key\")\n            if not next_key:\n                break\n    except FileNotFoundError:\n        raise RuntimeError(\"`neutrond` CLI not found – please install or add to PATH.\")\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"CLI call failed: {err.stderr or err}\")\n    except json.JSONDecodeError as err:\n        raise RuntimeError(f\"Unexpected CLI output – JSON decode error: {err}\")\n\n    return schedules",
	"count_array_elements": "def count_array_elements(items: list) -> int:\n    \"\"\"Safely count array length with a sanity check.\"\"\"\n    if items is None:\n        raise ValueError(\"Input is None – expected a list.\")\n    if not isinstance(items, list):\n        raise TypeError(f\"Expected list, got {type(items)}\")\n    return len(items)",
	"display_result": "def display_result(count: int) -> None:\n    \"\"\"Print the final schedule count in the required format.\"\"\"\n    if count < 0:\n        raise ValueError(\"Count cannot be negative.\")\n    print(f\"Active schedules: {count}\")",
	"_build_rpc_url": "def _build_rpc_url(rpc_endpoint: str, limit: int) -> str:\n    \"\"\"Helper that assembles the final RPC URL without double slashes.\"\"\"\n    return f\"{rpc_endpoint.rstrip('/')}/unconfirmed_txs?limit={limit}\"\n\n\n@router.get('/api/unconfirmed_txs')\ndef fetch_unconfirmed_txs(\n    limit: int = Query(50, ge=1, le=1000),\n    rpc_endpoint: str = Query('http://localhost:26657')\n):\n    \"\"\"Fetch raw unconfirmed transactions from a CometBFT node.\"\"\"\n    url = _build_rpc_url(rpc_endpoint, limit)\n    try:\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n        return response.json()\n    except requests.RequestException as exc:\n        # Surface networking problems as a clean 502 to the caller\n        raise HTTPException(status_code=502, detail=f'Unable to reach RPC endpoint: {exc}')",
	"parse_unconfirmed_txs": "def parse_unconfirmed_txs(raw_response: dict = Body(...)):\n    \"\"\"Extract `n_txs` and `txs` from the raw RPC response.\"\"\"\n    try:\n        result = raw_response.get('result', {})\n        n_txs = int(result.get('n_txs', 0))\n        txs = result.get('txs', [])\n        return {\n            'n_txs': n_txs,\n            'txs': txs  # still base64-encoded per CometBFT spec\n        }\n    except (ValueError, AttributeError) as exc:\n        raise HTTPException(status_code=400, detail=f'Malformed RPC response: {exc}')",
	"generate_deposit_address": "def generate_deposit_address(payload: dict):\n    \"\"\"\n    Obtain a unique solvBTC deposit address bound to the user’s EVM address.\n    \"\"\"\n    evm_address = payload.get('evm_address')\n    if not evm_address:\n        raise HTTPException(status_code=400, detail='`evm_address` field is required.')\n\n    async with httpx.AsyncClient() as client:\n        try:\n            resp = await client.post(f'{SOLV_GATEWAY_URL}/deposit-address', json={'evm_address': evm_address})\n            resp.raise_for_status()\n            data = resp.json()\n            return {'deposit_address': data['deposit_address']}\n        except httpx.HTTPError as exc:\n            raise HTTPException(status_code=502, detail=f'SolvBTC gateway error: {exc}')",
	"fee_positive": "def fee_positive(cls, v):\n        if v <= 0:\n            raise ValueError('fee_sat_per_byte must be positive')\n        return v\n\n@router.post('/api/btc/construct-tx')\ndef construct_and_sign_btc_tx(payload: ConstructTxPayload):\n    \"\"\"\n    Build & sign a Bitcoin transaction for 1 BTC (100 000 000 sats). Returns raw hex.\n    WARNING: The WIF is sensitive; keep this endpoint protected.\n    \"\"\"\n    try:\n        pk = PrivateKey(payload.wif)\n        outputs = [(payload.destination, Decimal('1'), 'btc')]  # 1 BTC exactly\n        raw_tx_hex = pk.create_transaction(outputs, fee=payload.fee_sat_per_byte)\n        return {'raw_tx_hex': raw_tx_hex}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"broadcast_btc_tx": "def broadcast_btc_tx(payload: dict):\n    \"\"\"Broadcast raw BTC TX and return the resulting txid.\"\"\"\n    raw_tx_hex = payload.get('raw_tx_hex')\n    if not raw_tx_hex:\n        raise HTTPException(status_code=400, detail='raw_tx_hex is required.')\n\n    try:\n        async with httpx.AsyncClient() as client:\n            resp = await client.post('https://blockstream.info/api/tx', content=raw_tx_hex)\n            resp.raise_for_status()\n            txid = resp.text.strip()\n            return {'txid': txid}\n    except httpx.HTTPError as exc:\n        raise HTTPException(status_code=502, detail=f'Broadcast error: {exc}')",
	"attest_and_mint": "def attest_and_mint(payload: dict):\n    btc_txid = payload.get('btc_txid')\n    btc_destination = payload.get('btc_destination')\n    evm_address = payload.get('evm_address')\n    if not all([btc_txid, btc_destination, evm_address]):\n        raise HTTPException(status_code=400, detail='btc_txid, btc_destination, and evm_address are required.')\n\n    try:\n        w3 = Web3(Web3.HTTPProvider(ETH_RPC_URL))\n        acct = w3.eth.account.from_key(BACKEND_PRIVATE_KEY)\n        contract = w3.eth.contract(address=Web3.to_checksum_address(MINT_CONTRACT_ADDRESS), abi=MINT_ABI)\n        tx = contract.functions.mint(btc_txid, btc_destination, evm_address).build_transaction({\n            'from': acct.address,\n            'nonce': w3.eth.get_transaction_count(acct.address),\n            'gas': 500000,\n            'gasPrice': w3.to_wei('30', 'gwei'),\n        })\n        signed_tx = acct.sign_transaction(tx)\n        tx_hash = w3.eth.send_raw_transaction(signed_tx.rawTransaction)\n        return {'eth_tx_hash': tx_hash.hex()}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"bridge_to_neutron": "def bridge_to_neutron(payload: dict):\n    evm_tx_hash = payload.get('eth_tx_hash')\n    neutron_address = payload.get('neutron_address')\n    amount_wei = payload.get('amount_wei', '1000000000000000000')  # 1 solvBTC (18 decimals)\n    if not all([evm_tx_hash, neutron_address]):\n        raise HTTPException(status_code=400, detail='eth_tx_hash and neutron_address are required.')\n\n    request_body = {\n        'source_chain': 'Ethereum',\n        'destination_chain': 'Neutron',\n        'asset': 'solvBTC',\n        'amount': amount_wei,\n        'destination_address': neutron_address,\n        'deposit_tx_hash': evm_tx_hash,\n    }\n\n    async with httpx.AsyncClient() as client:\n        try:\n            resp = await client.post(f'{AXELAR_GATEWAY_URL}/transfer', json=request_body)\n            resp.raise_for_status()\n            data = resp.json()\n            return {'axelar_tx_hash': data['tx_hash']}\n        except httpx.HTTPError as exc:\n            raise HTTPException(status_code=502, detail=f'Axelar error: {exc}')",
	"get_key_address": "def get_key_address(key_name: str = \"my_validator\", keyring_backend: str = \"test\") -> str:\n    \"\"\"Return the bech32 address for a key stored in the local key-ring.\n\n    Args:\n        key_name: The name of the key to look up.\n        keyring_backend: One of [os|file|test]. \"test\" stores keys unencrypted for dev chains.\n\n    Raises:\n        RuntimeError: If the CLI call fails or returns an empty address.\n    \"\"\"\n    try:\n        cmd = [\n            \"simd\", \"keys\", \"show\", key_name,\n            \"--keyring-backend\", keyring_backend,\n            \"-a\"  # address only\n        ]\n        result = subprocess.run(cmd, capture_output=True, check=True, text=True)\n        address = result.stdout.strip()\n        if not address:\n            raise RuntimeError(\"Received empty address from key-ring query\")\n        return address\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f\"simd keys show failed: {e.stderr}\") from e",
	"validate_recipient_address": "def validate_recipient_address(address: str, expected_prefix: str = \"cosmos\") -> str:\n    \"\"\"Verify HRP and checksum of a bech32 address.\n\n    Args:\n        address: The address to validate.\n        expected_prefix: Human-readable prefix (HRP) for the target chain.\n    Returns:\n        The original address if valid.\n    Raises:\n        ValueError: If the address is malformed or has an unexpected prefix.\n    \"\"\"\n    hrp, data = bech32_decode(address)\n    if hrp != expected_prefix or data is None:\n        raise ValueError(f\"{address} is not a valid {expected_prefix} bech32 address\")\n    return address",
	"build_send_tx": "def build_send_tx(\n    sender: str,\n    recipient: str,\n    amount: str = \"1000stake\",\n    fee: str = \"200stake\",\n    chain_id: str = \"my-test-chain\",\n    outfile: str = \"unsigned_tx.json\",\n) -> str:\n    \"\"\"Create an unsigned MsgSend and persist it to disk.\n\n    Returns the file path of the unsigned tx JSON.\n    \"\"\"\n    cmd = [\n        \"simd\", \"tx\", \"bank\", \"send\", sender, recipient, amount,\n        \"--generate-only\",\n        \"--fees\", fee,\n        \"--chain-id\", chain_id,\n        \"--output\", \"json\"\n    ]\n    try:\n        with open(outfile, \"w\", encoding=\"utf-8\") as fp:\n            subprocess.run(cmd, check=True, text=True, stdout=fp)\n        if not os.path.exists(outfile):\n            raise RuntimeError(\"Unsigned TX file was not created\")\n        return outfile\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f\"Failed to build tx: {e.stderr}\") from e",
	"sign_tx": "def sign_tx(\n    unsigned_tx_path: str,\n    key_name: str = \"my_validator\",\n    keyring_backend: str = \"test\",\n    chain_id: str = \"my-test-chain\",\n    outfile: str = \"signed_tx.json\",\n) -> str:\n    \"\"\"Sign an unsigned transaction file with a local key-ring key.\"\"\"\n    cmd = [\n        \"simd\", \"tx\", \"sign\", unsigned_tx_path,\n        \"--from\", key_name,\n        \"--keyring-backend\", keyring_backend,\n        \"--chain-id\", chain_id,\n        \"--output\", \"json\",\n        \"--yes\"  # auto-confirm\n    ]\n    try:\n        with open(outfile, \"w\", encoding=\"utf-8\") as fp:\n            subprocess.run(cmd, check=True, text=True, stdout=fp)\n        if not os.path.exists(outfile):\n            raise RuntimeError(\"Signed TX file was not created\")\n        return outfile\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f\"Signing failed: {e.stderr}\") from e",
	"generate_gentx": "def generate_gentx(key_name: str, amount: str = \"100000000stake\") -> str:\n    \"\"\"\n    Produce a gentx for `key_name` staking `amount`.  Returns the full path to\n    the resulting gentx JSON file inside `<home>/config/gentx/`.\n    \"\"\"\n    # Run `<chain_binary> gentx ...` exactly as the user specified.\n    cmd = [\n        CHAIN_BINARY,\n        \"gentx\",\n        key_name,\n        amount,\n        \"--chain-id\",\n        CHAIN_ID,\n        \"--keyring-backend\",\n        KEYRING_BACKEND,\n        \"--home\",\n        KEY_HOME,\n    ]\n    try:\n        subprocess.check_call(cmd)\n    except subprocess.CalledProcessError as exc:\n        raise RuntimeError(f\"gentx command failed: {exc}\") from exc\n\n    # After a successful run the gentx sits in `<home>/config/gentx/`.\n    gentx_dir = os.path.join(KEY_HOME, \"config\", \"gentx\")\n    all_gentxs = [\n        os.path.join(gentx_dir, f)\n        for f in os.listdir(gentx_dir)\n        if f.endswith(\".json\")\n    ]\n    if not all_gentxs:\n        raise FileNotFoundError(\"No gentx file found after running gentx command.\")\n\n    # Return the newest file (highest mtime) which is the one we just created.\n    latest_path = max(all_gentxs, key=os.path.getmtime)\n    return latest_path",
	"validate_gentx": "def validate_gentx(\n    gentx_path: str,\n    key_name: str,\n    expected_amount: str = \"100000000\",\n    expected_denom: str = \"stake\",\n) -> bool:\n    \"\"\"\n    Perform three sanity checks on a gentx:\n      1. Confirm it is valid JSON.\n      2. Confirm it stakes exactly `expected_amount``expected_denom`.\n      3. Confirm the validator address was derived from `key_name`.\n    Returns True if the transaction passes all checks, else raises an Exception.\n    \"\"\"\n    # 1️⃣  Parse and validate JSON structure\n    try:\n        with open(gentx_path, \"r\") as fp:\n            tx = json.load(fp)\n    except json.JSONDecodeError as exc:\n        raise ValueError(f\"gentx is not valid JSON: {exc}\") from exc\n\n    # 2️⃣  Extract the create-validator message and validate the stake amount\n    try:\n        # cosmos-sdk v0.47+ layout\n        msg = tx[\"body\"][\"messages\"][0]\n        stake_obj = msg[\"value\"][\"value\"] if \"value\" in msg[\"value\"] else msg[\"value\"]\n        amount = stake_obj[\"amount\"]\n        denom = stake_obj[\"denom\"]\n    except (KeyError, TypeError):\n        # Legacy layout fallback\n        try:\n            msg = tx[\"value\"][\"msg\"][0][\"value\"]\n            amount = msg[\"value\"][\"amount\"]\n            denom = msg[\"value\"][\"denom\"]\n        except (KeyError, TypeError) as exc:\n            raise ValueError(\"Unable to extract stake amount/denom from gentx.\") from exc\n\n    if str(amount) != str(expected_amount) or denom != expected_denom:\n        raise ValueError(\n            f\"Gentx stakes {amount}{denom}; expected {expected_amount}{expected_denom}.\"\n        )\n\n    # 3️⃣  Confirm the validator address matches the operator address for key_name\n    try:\n        key_info_raw = subprocess.check_output(\n            [\n                CHAIN_BINARY,\n                \"keys\",\n                \"show\",\n                key_name,\n                \"--output\",\n                \"json\",\n                \"--keyring-backend\",\n                KEYRING_BACKEND,\n                \"--home\",\n                KEY_HOME,\n            ],\n            text=True,\n        )\n        key_info = json.loads(key_info_raw)\n        delegator_addr = key_info[\"address\"]\n        # Derive the valoper address; this assumes standard bech32 prefixes.\n        operator_addr = re.sub(r\"^([a-z]+)\", r\"\\1valoper\", delegator_addr)\n    except subprocess.CalledProcessError as exc:\n        raise RuntimeError(f\"Unable to fetch key {key_name}: {exc}\") from exc\n\n    validator_addr_in_tx = msg.get(\"validator_address\") or msg.get(\"value\", {}).get(\"validator_address\")\n    if not validator_addr_in_tx:\n        raise ValueError(\"Validator address missing from gentx.\")\n\n    if validator_addr_in_tx != operator_addr:\n        raise ValueError(\n            f\"Gentx signed by {validator_addr_in_tx}; expected {operator_addr}.\"\n        )\n\n    # All checks passed 🎉\n    return True",
	"append_to_shell_profile": "def append_to_shell_profile():\n    \"\"\"Append the export line to the first existing shell profile found.\"\"\"\n    for profile in PROFILE_CANDIDATES:\n        if profile.exists():\n            # Read the file once to avoid duplicates\n            content = profile.read_text()\n            if \"GAIA_V5_KEYRING_BACKEND\" in content:\n                print(f\"[Info] Variable already present in {profile} – skipping append.\")\n                return str(profile)\n            try:\n                with profile.open(\"a\", encoding=\"utf-8\") as f:\n                    f.write(\"\\n\" + EXPORT_LINE)\n                print(f\"[Success] Added GAIA_V5_KEYRING_BACKEND to {profile}\")\n                return str(profile)\n            except Exception as e:\n                raise RuntimeError(f\"Unable to append to {profile}: {e}\")\n    # If no profile exists, create ~/.bashrc and append the line\n    default_profile = Path.home() / \".bashrc\"\n    try:\n        with default_profile.open(\"a\", encoding=\"utf-8\") as f:\n            f.write(EXPORT_LINE)\n        print(f\"[Success] Created {default_profile} and set GAIA_V5_KEYRING_BACKEND.\")\n        return str(default_profile)\n    except Exception as e:\n        raise RuntimeError(f\"Failed to create {default_profile}: {e}\")",
	"reload_shell_profile": "def reload_shell_profile():\n    \"\"\"Source the active shell profile in a *sub-shell* and propagate variables to the Python process.\"\"\"\n    # Determine which profile exists\n    profile_path = next((p for p in (Path.home()/'.bashrc', Path.home()/'.zshrc') if p.exists()), None)\n    if not profile_path:\n        raise FileNotFoundError(\"No shell profile found to reload.\")\n\n    # Launch a bash subshell that sources the profile and prints the variable\n    try:\n        cmd = [\"bash\", \"-c\", f\"source {profile_path} && echo -n $GAIA_V5_KEYRING_BACKEND\"]\n        result = subprocess.check_output(cmd, text=True)\n        # Update current process environment so later Python code can see it\n        os.environ[\"GAIA_V5_KEYRING_BACKEND\"] = result.strip()\n        print(f\"[Success] Reloaded profile from {profile_path}. GAIA_V5_KEYRING_BACKEND={result.strip()}\")\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f\"Failed to source {profile_path}: {e}\")",
	"verify_env_var": "def verify_env_var():\n    value = os.environ.get(\"GAIA_V5_KEYRING_BACKEND\")\n    if value != \"pass\":\n        raise EnvironmentError(\"GAIA_V5_KEYRING_BACKEND is not set to 'pass'. Current value: {}\".format(value))\n    print(f\"[Verified] GAIA_V5_KEYRING_BACKEND={value}\")\n    return value",
	"replay_node": "def replay_node(node_home: str, halt_height: int = 1000):\n    # Runs `appd start` with --recover and --halt-height flags and waits\n    # for the process to exit automatically at the requested height.\n    cmd = f'appd start --home {shlex.quote(node_home)} --recover --halt-height {halt_height}'\n    try:\n        result = subprocess.run(\n            shlex.split(cmd),\n            capture_output=True,\n            text=True,\n            check=False\n        )\n        # Persist stdout so it can be inspected in the next step.\n        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix='.log', mode='w')\n        temp_file.write(result.stdout)\n        temp_file.close()\n        return {\n            'returncode': result.returncode,\n            'log_path': temp_file.name\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"verify_halt_height": "def verify_halt_height(log_path: str, halt_height: int = 1000):\n    # Examines the log file to confirm the node halted at the expected height.\n    try:\n        text = Path(log_path).read_text()\n        heights = [int(h) for h in re.findall(r'height[=: ]+(\\d+)', text)]\n        if not heights:\n            return {'success': False, 'reason': 'no_height_entries_found'}\n        last_height = max(heights)\n        return {\n            'success': last_height == halt_height,\n            'last_height': last_height,\n            'expected_height': halt_height\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"update_toml_key": "def update_toml_key(settings: ApiSettings):\n    \"\"\"Patch the [api] section inside app.toml with the supplied values.\"\"\"\n    cfg_path = Path(settings.home) / \"config\" / \"app.toml\"\n\n    if not cfg_path.exists():\n        raise HTTPException(status_code=404, detail=f\"{cfg_path} not found.\")\n\n    # Load current configuration.\n    with cfg_path.open(\"r\") as f:\n        cfg = toml.load(f)\n\n    # Ensure the api section exists then update keys.\n    cfg.setdefault(\"api\", {})\n    cfg[\"api\"].update({\n        \"enable\": settings.enable,\n        \"swagger\": settings.swagger,\n        \"address\": settings.address\n    })\n\n    # Persist changes.\n    with cfg_path.open(\"w\") as f:\n        toml.dump(cfg, f)\n\n    return {\"message\": \"[api] section updated successfully\", \"api\": cfg[\"api\"]}",
	"save_and_restart_node": "def save_and_restart_node(node: str = \"gaia\"):\n    \"\"\"Restart the node’s systemd service so the REST API starts with the new config.\"\"\"\n    service = SERVICE_NAME.get(node.lower())\n\n    if service is None:\n        raise HTTPException(status_code=400, detail=f\"Unsupported node '{node}'.\")\n\n    try:\n        # Requires the backend process to have permissions (run as root or via sudoers).\n        subprocess.run([\"systemctl\", \"restart\", service], check=True)\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=f\"Failed to restart {service}: {err}\")\n\n    return {\"message\": f\"{service} restarted successfully\"}",
	"compile_contract": "def compile_contract(payload: CompilePayload):\n    # Compile Solidity source\n    try:\n        compiled = solcx.compile_source(\n            payload.source,\n            output_values=['abi', 'bin'],\n            solc_version=SOLC_VERSION,\n        )\n    except solcx.exceptions.SolcError as e:\n        raise HTTPException(status_code=400, detail=f'Compilation error: {e}')\n\n    identifier = f\"<stdin>:{payload.contract_name}\"\n    if identifier not in compiled:\n        raise HTTPException(status_code=400, detail='Contract name not found after compilation.')\n\n    contract_interface = compiled[identifier]\n    abi = contract_interface['abi']\n    bytecode = '0x' + contract_interface['bin']  # Prefix bytecode with 0x for deployment\n\n    return {'abi': abi, 'bytecode': bytecode}",
	"update_environment": "def update_environment(service_file: str, env_key: str = \"GOGC\", env_value: str = \"100\") -> bool:\n    \"\"\"\n    Adds or updates Environment=\"GOGC=100\" inside the [Service] section of the\n    provided systemd unit file.\n\n    Returns True if the file was modified, False if no change was necessary.\n    \"\"\"\n    service_path = Path(service_file).expanduser()\n\n    if not service_path.exists():\n        raise FileNotFoundError(f\"The systemd file {service_path} does not exist.\")\n\n    original_text = service_path.read_text()\n    updated_text = original_text\n\n    pattern = re.compile(rf'^Environment=.*{env_key}=\\d+', re.MULTILINE)\n    replacement = f'Environment=\"{env_key}={env_value}\"'\n\n    if pattern.search(original_text):\n        # Replace current setting\n        updated_text = pattern.sub(replacement, original_text)\n    else:\n        # Insert new environment line directly under [Service] section\n        updated_text = original_text.replace(\"[Service]\", f\"[Service]\\n{replacement}\", 1)\n\n    if updated_text == original_text:\n        print(f\"{env_key} already set to {env_value}. No update performed.\")\n        return False\n\n    # Backup original file\n    backup_path = service_path.with_suffix(\".bak\")\n    shutil.copy(service_path, backup_path)\n\n    # Write new content\n    service_path.write_text(updated_text)\n    print(f\"Updated {service_path}. Backup stored at {backup_path}\")\n    return True\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Ensure GOGC=100 is present in a systemd service file.\")\n    parser.add_argument(\"--service-file\", required=True, help=\"Path to the systemd unit file (e.g., /etc/systemd/system/cosmosd.service)\")\n    parser.add_argument(\"--value\", default=\"100\", help=\"GC percentage to apply (default: 100)\")\n    args = parser.parse_args()\n\n    try:\n        modified = update_environment(args.service_file, \"GOGC\", args.value)\n        sys.exit(0 if modified else 1)\n    except Exception as err:\n        print(f\"Error: {err}\", file=sys.stderr)\n        sys.exit(2)\n",
	"validate_gc_setting": "def validate_gc_setting(host: str = \"http://localhost:6060\") -> int:\n    \"\"\"\n    Fetches Go runtime debug vars from the given host and returns the GCPercent value.\n    \"\"\"\n    url = f\"{host.rstrip('/')}/debug/vars\"\n    with urllib.request.urlopen(url, timeout=3) as response:\n        payload = json.loads(response.read().decode())\n        gc_percent = payload.get(\"GCPercent\")\n        print(f\"GCPercent reported: {gc_percent}\")\n        if gc_percent == 100:\n            print(\"✅ GOGC is correctly set to 100.\")\n        else:\n            print(\"❌ GOGC is NOT 100. Check your configuration.\")\n        return gc_percent\n\n\nif __name__ == \"__main__\":\n    parser = argparse.ArgumentParser(description=\"Validate that GOGC=100 has been applied.\")\n    parser.add_argument(\"--host\", default=\"http://localhost:6060\", help=\"Host where pprof/debug endpoint is exposed\")\n    args = parser.parse_args()\n    validate_gc_setting(args.host)\n",
	"construct_msg_vote_yes": "def construct_msg_vote_yes(voter: str, proposal_id: int) -> MsgVote:\n    \"\"\"Returns a MsgVote protobuf message (YES).\"\"\"\n    if not voter:\n        raise ValueError('Voter address must be provided')\n    if proposal_id <= 0:\n        raise ValueError('Proposal ID must be a positive integer')\n\n    msg = MsgVote()\n    msg.proposal_id = proposal_id\n    msg.voter = voter\n    msg.option = VoteOption.VOTE_OPTION_YES  # YES\n    return msg",
	"verify_bank_module": "def verify_bank_module(app_go_path: str = \"app/app.go\") -> bool:\n    '''\n    Verifies that the x/bank module is imported in `app/app.go` and included in\n    the ModuleManager. Returns True when both conditions pass, else raises.\n    '''\n    path = Path(app_go_path)\n    if not path.exists():\n        raise FileNotFoundError(f\"{app_go_path} not found\")\n\n    content = path.read_text()\n\n    # Check for import statement\n    if '\"github.com/cosmos/cosmos-sdk/x/bank\"' not in content:\n        raise ValueError(\"x/bank module import not found in app/app.go\")\n\n    # Check for module registration\n    if \"bank.NewAppModule\" not in content and \"bank.AppModuleBasic\" not in content:\n        raise ValueError(\"x/bank module not registered in ModuleManager\")\n\n    print(\"✅ x/bank module is correctly imported and registered.\")\n    return True\n\n\nif __name__ == \"__main__\":\n    verify_bank_module(*sys.argv[1:])",
	"create_cli_command_file": "def create_cli_command_file(file_path: str = \"cmd/bank_send.go\") -> None:\n    '''\n    Creates `cmd/bank_send.go` with the TxBankSendCmd implementation.\n    '''\n    path = Path(file_path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n\n    if path.exists():\n        print(f\"{file_path} already exists, skipping write.\")\n        return\n\n    path.write_text(GO_FILE_CONTENT)\n    print(f\"✅ {file_path} created with TxBankSendCmd.\")\n\n\nif __name__ == \"__main__\":\n    create_cli_command_file()",
	"register_command_root": "def register_command_root(root_file: str = \"cmd/root.go\") -> None:\n    '''\n    Inserts TxBankSendCmd into the tx sub-command tree within cmd/root.go.\n    '''\n    path = Path(root_file)\n    if not path.exists():\n        raise FileNotFoundError(f\"{root_file} not found\")\n\n    content = path.read_text()\n\n    # Skip if already exists\n    if \"TxBankSendCmd()\" in content:\n        print(\"TxBankSendCmd already registered, skipping.\")\n        return\n\n    pattern = r\"(?s)(func\\\\s+NewTxCmd\\\\s*\\\\(.*?\\\\)\\\\s*\\\\*cobra.Command\\\\s*{.*?})\"\n    match = re.search(pattern, content)\n    if not match:\n        raise ValueError(\"NewTxCmd definition not found in root.go\")\n\n    block = match.group(1)\n\n    if \"TxBankSendCmd()\" not in block:\n        modified_block = block.replace(\"return txCmd\", \"    txCmd.AddCommand(TxBankSendCmd())\\\\n\\\\n    return txCmd\")\n    else:\n        modified_block = block\n\n    updated_content = content.replace(block, modified_block)\n    path.write_text(updated_content)\n    print(\"✅ TxBankSendCmd registered in root.go.\")\n\n\nif __name__ == \"__main__\":\n    register_command_root()",
	"validate_cli_help": "def validate_cli_help() -> None:\n    '''\n    Runs `appd tx bank send --help` to ensure command wiring is correct.\n    '''\n    try:\n        subprocess.run([\"appd\", \"tx\", \"bank\", \"send\", \"--help\"], check=True)\n        print(\"✅ Help output rendered correctly.\")\n    except subprocess.CalledProcessError as e:\n        print(\"❌ Unable to render help output:\", e)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    validate_cli_help()",
	"broadcast_test_tx": "def broadcast_test_tx(from_key: str, to_addr: str, amount: str = \"1stake\", chain_id: str = \"localnet\", node: str = \"tcp://localhost:26657\") -> None:\n    '''\n    Broadcasts a small MsgSend to verify the new CLI command works end-to-end.\n    '''\n    cmd = [\n        \"appd\", \"tx\", \"bank\", \"send\", to_addr, amount,\n        \"--from\", from_key,\n        \"--chain-id\", chain_id,\n        \"--node\", node,\n        \"-y\"\n    ]\n\n    try:\n        subprocess.run(cmd, check=True)\n        print(\"✅ Test transaction broadcasted successfully.\")\n    except subprocess.CalledProcessError as e:\n        print(\"❌ Test transaction failed:\", e)\n        sys.exit(1)\n\n\nif __name__ == \"__main__\":\n    if len(sys.argv) < 3:\n        print(\"Usage: broadcast_test_tx.py <from-key> <to-addr> [amount] [chain-id] [node]\")\n        sys.exit(1)\n\n    broadcast_test_tx(*sys.argv[1:])",
	"get_neutron_mainnet_client": "def get_neutron_mainnet_client(mnemonic: str, rpc_url: str = \"https://rpc-kralum.neutron-1.neutron.org:443\") -> LedgerClient:\n    # Returns a cosmpy LedgerClient configured for Neutron mainnet\n    if not mnemonic:\n        raise ValueError(\"Mnemonic must not be empty\")\n\n    cfg = NetworkConfig(\n        chain_id=\"neutron-1\",\n        url=rpc_url,\n        fee_min_denom=\"untrn\",\n        gas_price=0.025,  # 0.025 NTRN/gas is a reasonable default for mainnet\n    )\n\n    wallet = LocalWallet.create_from_mnemonic(mnemonic)\n    return LedgerClient(cfg, wallet)\n",
	"ensure_wasm_file": "def ensure_wasm_file(path: str) -> str:\n    # Validates the existence and size (< 4 MiB) of the compiled .wasm file\n    if not os.path.isfile(path):\n        raise FileNotFoundError(f\"WASM file not found at {path}\")\n\n    size = os.path.getsize(path)\n    if size > 4 * 1024 * 1024:\n        raise ValueError(f\"WASM binary is {size} bytes which exceeds the 4 MiB limit.\")\n\n    return os.path.abspath(path)\n",
	"build_store_code_tx": "def build_store_code_tx(client: LedgerClient, wasm_path: str, memo: str = \"Upload contract\") -> Transaction:\n    with open(wasm_path, \"rb\") as f:\n        wasm_bytes = f.read()\n\n    msg = wasm_tx.MsgStoreCode(\n        sender=client.wallet.address(),\n        wasm_byte_code=wasm_bytes,\n        instantiate_permission=wasm_types.AccessConfig(\n            permission=wasm_types.AccessType.ACCESS_TYPE_EVERYBODY\n        ),\n    )\n\n    tx = client.tx.create([msg], memo=memo, gas_limit=2_500_000)\n    return tx\n",
	"instantiate_contract": "def instantiate_contract(client: LedgerClient, tx: Transaction):\n    resp = sign_and_broadcast_tx(client, tx)\n    print(\"✓ Contract instantiated\")\n    return resp\n",
	"extract_contract_address": "def extract_contract_address(response) -> str:\n    try:\n        logs = json.loads(response.raw_log)\n        for event in logs[0][\"events\"]:\n            if event[\"type\"] == \"instantiate\":\n                for attr in event[\"attributes\"]:\n                    if attr[\"key\"] in (\"_contract_address\", \"contract_address\"):\n                        return attr[\"value\"]\n    except (KeyError, ValueError, json.JSONDecodeError) as err:\n        raise RuntimeError(f\"Unable to find contract address: {err}\")\n    raise RuntimeError(\"Contract address not present in tx logs\")\n",
	"query_amber_contract_positions": "def query_amber_contract_positions(address: str):\n    \"\"\"Return all Amber positions owned by the given wallet address.\"\"\"\n    # Build the smart-query `{ \"positions\": { \"owner\": <address> } }`\n    query_object = {\"positions\": {\"owner\": address}}\n    query_b64    = base64.b64encode(json.dumps(query_object).encode()).decode()\n\n    url = f\"{LCD_ENDPOINT}/cosmwasm/wasm/v1/contract/{AMBER_CONTRACT}/smart/{query_b64}\"\n\n    async with httpx.AsyncClient() as client:\n        resp = await client.get(url, timeout=10)\n\n    if resp.status_code != 200:\n        raise HTTPException(status_code=resp.status_code, detail=resp.text)\n\n    return resp.json()  # Forward Amber’s JSON response verbatim",
	"construct_tx_amber_emergency_withdraw": "def construct_tx_amber_emergency_withdraw(payload: dict):\n    \"\"\"\n    Body example:\n    {\n      \"sender\": \"neutron1...\",\n      \"position_id\": 42\n    }\n    \"\"\"\n    sender      = payload.get(\"sender\")\n    position_id = payload.get(\"position_id\")\n    if sender is None or position_id is None:\n        raise HTTPException(status_code=400, detail=\"'sender' and 'position_id' are required\")\n\n    # 1. Build MsgExecuteContract\n    msg = wasm_tx.MsgExecuteContract(\n        sender   = sender,\n        contract = AMBER_CONTRACT,\n        msg      = json.dumps({\"emergency_withdraw\": {\"position_id\": int(position_id)}}).encode(),\n        funds    = []  # No funds required\n    )\n\n    # 2. Ask the LCD for account_number / sequence\n    account_info = lcd.auth.account_info(Address(sender))\n    account_number = int(account_info.base_account.account_number)\n    sequence       = int(account_info.base_account.sequence)\n\n    # 3. Build the unsigned Tx\n    tx = Transaction()\n    tx.add_message(msg)\n    tx.seal(\n        gas_limit = FEE_GAS,\n        fee_denom = FEE_DENOM,\n        fee_amount = FEE_AMOUNT,\n        memo = \"Amber emergency withdraw\"\n    )\n\n    # 4. Encode SignDoc fields for Keplr\n    sign_doc = tx.get_sign_doc(chain_id=CHAIN_ID, account_number=account_number, sequence=sequence)\n\n    response = {\n        \"bodyBytes\":      base64.b64encode(sign_doc.body_bytes).decode(),\n        \"authInfoBytes\":  base64.b64encode(sign_doc.auth_info_bytes).decode(),\n        \"chainId\":        CHAIN_ID,\n        \"accountNumber\":  str(account_number)\n    }\n\n    # Return everything the frontend needs to call `keplr.signDirect`\n    return response",
	"graceful_shutdown": "def graceful_shutdown(pid: Optional[int] = None, *, use_systemctl: bool = False, service_name: Optional[str] = None) -> None:\n    \"\"\"Send a graceful shutdown signal.\n\n    Args:\n        pid (int, optional): The PID of the running process. Required if `use_systemctl` is False.\n        use_systemctl (bool): Whether to stop a systemd service instead of sending SIGINT.\n        service_name (str, optional): Name of the systemd service. Required if `use_systemctl` is True.\n\n    Raises:\n        ValueError: If required arguments are missing.\n        RuntimeError: If the shutdown command fails.\n    \"\"\"\n    if use_systemctl:\n        if not service_name:\n            raise ValueError(\"'service_name' is required when 'use_systemctl' is True\")\n        try:\n            result = subprocess.run([\"systemctl\", \"stop\", service_name], check=True, capture_output=True, text=True)\n            print(result.stdout.strip())\n        except subprocess.CalledProcessError as err:\n            raise RuntimeError(f\"Failed to stop service '{service_name}': {err.stderr.strip()}\") from err\n    else:\n        if pid is None:\n            raise ValueError(\"'pid' is required when 'use_systemctl' is False\")\n        try:\n            os.kill(pid, signal.SIGINT)\n            print(f\"Sent SIGINT to PID {pid} …\")\n        except ProcessLookupError:\n            raise RuntimeError(f\"Process with PID {pid} does not exist.\")\n        except PermissionError:\n            raise RuntimeError(f\"Permission denied to signal PID {pid}.\")",
	"wait_for_exit": "def wait_for_exit(pid: int, *, log_path: Optional[str] = None, timeout: int = 120, poll_interval: float = 1.0) -> None:\n    \"\"\"Wait for a process to exit and confirm profiler stop message.\n\n    Args:\n        pid (int): The PID to monitor.\n        log_path (str, optional): Path to the application log file.\n        timeout (int): Maximum seconds to wait before giving up.\n        poll_interval (float): Seconds between checks.\n\n    Raises:\n        TimeoutError: If the process is still running after the timeout period.\n    \"\"\"\n    start_time = time.time()\n    profiler_msg_found = False\n\n    log_file: Optional[Path] = Path(log_path) if log_path else None\n    log_offset = log_file.stat().st_size if log_file and log_file.exists() else 0\n\n    while True:\n        # Check if the process has exited\n        if not os.path.exists(f\"/proc/{pid}\"):\n            print(f\"PID {pid} has exited.\")\n            break\n\n        # Optionally scan new log output for profiler message\n        if log_file and log_file.exists():\n            with log_file.open(\"r\") as lf:\n                lf.seek(log_offset)\n                for line in lf:\n                    if \"stopping CPU profiler\" in line:\n                        profiler_msg_found = True\n                        print(\"Detected 'stopping CPU profiler' in logs.\")\n                        break\n                log_offset = lf.tell()\n\n        if time.time() - start_time > timeout:\n            raise TimeoutError(f\"Process {pid} did not exit within {timeout}s.\")\n\n        time.sleep(poll_interval)\n\n    if log_file and not profiler_msg_found:\n        print(\"Warning: 'stopping CPU profiler' not found in logs. The node may not have flushed the profile correctly.\")",
	"_strip_0x": "def _strip_0x(hex_str: str) -> str:\n    \"\"\"Remove 0x prefix, if present.\"\"\"\n    return hex_str[2:] if hex_str.startswith(\"0x\") else hex_str\n\ndef _hex_to_bytes(hex_str: str, expected_len: int) -> bytes:\n    \"\"\"Convert hex to bytes, validating exact length.\"\"\"\n    hex_str = _strip_0x(hex_str)\n    if len(hex_str) != expected_len:\n        raise ValueError(f\"Expected {expected_len} hex chars, got {len(hex_str)}.\")\n    return bytes.fromhex(hex_str)\n\n@app.post(\"/api/compute_create2_address\")\nasync def compute_create2_address(req: Create2Request):\n    try:\n        deployer_bytes = _hex_to_bytes(req.deployer, 40)   # 20 bytes\n        salt_bytes = _hex_to_bytes(req.salt, 64)           # 32 bytes\n        init_code_hash_bytes = _hex_to_bytes(req.init_code_hash, 64)  # 32 bytes\n    except ValueError as err:\n        raise HTTPException(status_code=400, detail=str(err))\n\n    # CREATE2 formula: keccak256(0xff ++ deployer ++ salt ++ initCodeHash)[12:]\n    data = b\"\\xff\" + deployer_bytes + salt_bytes + init_code_hash_bytes\n    derived = keccak(data)[12:]  # Take the right-most 20 bytes\n    checksum_addr = to_checksum_address(\"0x\" + derived.hex())\n\n    return {\"create2_address\": checksum_addr}",
	"fetch_receipt": "def fetch_receipt(tx_hash: str) -> dict | None:\n    \"\"\"Low-level helper that wraps the JSON-RPC request.\"\"\"\n    payload = {\n        \"jsonrpc\": \"2.0\",\n        \"method\": \"eth_getTransactionReceipt\",\n        \"params\": [tx_hash],\n        \"id\": 1,\n    }\n\n    try:\n        async with httpx.AsyncClient() as client:\n            resp = await client.post(RPC_ENDPOINT, json=payload, timeout=10)\n            resp.raise_for_status()\n    except httpx.RequestError as e:\n        raise HTTPException(status_code=502, detail=f\"RPC connection error: {str(e)}\")\n    except httpx.HTTPStatusError as e:\n        raise HTTPException(status_code=e.response.status_code, detail=f\"RPC returned {e.response.status_code}\")\n\n    body = resp.json()\n\n    # Handle RPC-level errors\n    if body.get(\"error\"):\n        raise HTTPException(status_code=500, detail=body[\"error\"])\n\n    return body.get(\"result\")\n\n@app.get(\"/api/tx_receipt\")\nasync def tx_receipt(tx_hash: str):\n    \"\"\"REST: GET /api/tx_receipt?tx_hash=0x…\"\"\"\n    receipt = await fetch_receipt(tx_hash)\n    if receipt is None:\n        raise HTTPException(status_code=404, detail=\"Receipt not found\")\n    return receipt",
	"_human_readable_status": "def _human_readable_status(status_hex: str) -> str:\n    \"\"\"Convert 0x0 / 0x1 ⇒ Failed / Success.\"\"\"\n    try:\n        return \"Success\" if int(status_hex, 16) == 1 else \"Failed\"\n    except ValueError:\n        return \"Unknown\"\n\ndef decode_receipt(receipt: dict) -> dict:\n    \"\"\"Transform the RPC receipt into a cleaner JSON structure.\"\"\"\n    if receipt is None:\n        raise HTTPException(status_code=400, detail=\"Empty receipt supplied\")\n\n    return {\n        \"transactionHash\": receipt.get(\"transactionHash\"),\n        \"blockNumber\": int(receipt.get(\"blockNumber\", \"0x0\"), 16),\n        \"status\": _human_readable_status(receipt.get(\"status\", \"0x0\")),\n        \"gasUsed\": int(receipt.get(\"gasUsed\", \"0x0\"), 16),\n        \"contractAddress\": receipt.get(\"contractAddress\"),\n        \"logsCount\": len(receipt.get(\"logs\", [])),\n        \"logs\": receipt.get(\"logs\", []),\n    }\n\n@app.get(\"/api/decode_receipt\")\nasync def decode_receipt_endpoint(tx_hash: str):\n    \"\"\"REST: GET /api/decode_receipt?tx_hash=0x…\"\"\"\n    receipt = await fetch_receipt(tx_hash)\n    if receipt is None:\n        raise HTTPException(status_code=404, detail=\"Receipt not found\")\n    return decode_receipt(receipt)",
	"verify_grpcurl_installation": "def verify_grpcurl_installation():\n    \"\"\"Verify that `grpcurl` is installed on the host machine.\"\"\"\n    try:\n        # Attempt to execute `grpcurl -help` to confirm installation\n        completed_process = subprocess.run(\n            [\"grpcurl\", \"-help\"],\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n        # Return the first 500 characters of stdout to avoid overly large payloads\n        return {\n            \"installed\": True,\n            \"output\": completed_process.stdout[:500],\n        }\n    except FileNotFoundError:\n        # grpcurl binary not found in PATH\n        raise HTTPException(\n            status_code=404,\n            detail=\"grpcurl is not installed or not found in PATH.\",\n        )\n    except subprocess.CalledProcessError as exc:\n        # grpcurl returned a non-zero exit code\n        raise HTTPException(\n            status_code=500,\n            detail=f\"grpcurl -help failed: {exc.stderr}\",\n        )",
	"grpcurl_list_services": "def grpcurl_list_services(\n    host: str = Query(\"localhost:9090\", description=\"gRPC server host:port\"),\n    plaintext: bool = Query(True, description=\"Use plaintext (disable TLS).\"),\n    insecure: bool = Query(False, description=\"Allow insecure TLS without trusted certs.\"),\n):\n    \"\"\"List gRPC services exposed by the server via reflection.\"\"\"\n    # Build grpcurl command\n    cmd = [\"grpcurl\"]\n    if plaintext:\n        cmd.append(\"-plaintext\")\n    if insecure:\n        cmd.append(\"-insecure\")\n    cmd.extend([host, \"list\"])\n\n    try:\n        completed_process = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n        services = [line.strip() for line in completed_process.stdout.splitlines() if line.strip()]\n        return {\"host\": host, \"services\": services}\n    except subprocess.CalledProcessError as exc:\n        raise HTTPException(\n            status_code=500,\n            detail=f\"grpcurl list failed: {exc.stderr}\",\n        )",
	"install_hardhat_etherscan_plugin": "def install_hardhat_etherscan_plugin(project_path: str = '.'):\n    \"\"\"\n    Installs @nomiclabs/hardhat-etherscan as a dev-dependency inside the given project directory.\n    \"\"\"\n    try:\n        result = subprocess.run(\n            ['npm', 'install', '--save-dev', '@nomiclabs/hardhat-etherscan'],\n            cwd=project_path,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            check=True\n        )\n        print(result.stdout)\n        return {'status': 'success', 'message': 'Plugin installed successfully'}\n    except subprocess.CalledProcessError as e:\n        print(e.stderr, file=sys.stderr)\n        return {'status': 'error', 'message': e.stderr}",
	"configure_etherscan_api_key": "def configure_etherscan_api_key(key: str, env_path: str = '.env'):\n    \"\"\"\n    Persists ETHERSCAN_API_KEY to .env, replacing any existing value.\n    \"\"\"\n    try:\n        lines = []\n        if os.path.isfile(env_path):\n            with open(env_path, 'r') as f:\n                lines = f.readlines()\n        # Remove stale entries\n        lines = [l for l in lines if not l.startswith('ETHERSCAN_API_KEY=')]\n        lines.append(f'ETHERSCAN_API_KEY={key}\\n')\n        with open(env_path, 'w') as f:\n            f.writelines(lines)\n        return {'status': 'success', 'message': 'ETHERSCAN_API_KEY written to .env'}\n    except Exception as e:\n        return {'status': 'error', 'message': str(e)}",
	"compile_contracts": "def compile_contracts(project_path: str = '.'):\n    \"\"\"\n    Executes `npx hardhat compile` inside the project directory.\n    \"\"\"\n    try:\n        result = subprocess.run(\n            ['npx', 'hardhat', 'compile'],\n            cwd=project_path,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            check=True\n        )\n        return {'status': 'success', 'output': result.stdout}\n    except subprocess.CalledProcessError as e:\n        print(e.stderr, file=sys.stderr)\n        return {'status': 'error', 'message': e.stderr}",
	"verify_contract": "def verify_contract(network: str, address: str, constructor_args: List[str] | None = None, project_path: str = '.'):\n    \"\"\"\n    Launches Hardhat verification for a deployed contract.\n    \"\"\"\n    try:\n        cmd = ['npx', 'hardhat', 'verify', '--network', network, address]\n        if constructor_args:\n            cmd.extend(constructor_args)\n        result = subprocess.run(\n            cmd,\n            cwd=project_path,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.PIPE,\n            text=True,\n            check=True\n        )\n        return {'status': 'success', 'output': result.stdout}\n    except subprocess.CalledProcessError as e:\n        print(e.stderr, file=sys.stderr)\n        return {'status': 'error', 'message': e.stderr}",
	"_build_execute_msg": "def _build_execute_msg(sender: str, amount: str) -> MsgExecuteContract:\n    return MsgExecuteContract(\n        sender=sender,\n        contract=BOOST_CONTRACT_ADDRESS,\n        msg=json.dumps({\n            'lock': {\n                'amount': amount,\n                'duration': '24_months'\n            }\n        }).encode(),\n        funds=[{'amount': amount, 'denom': 'untrn'}]\n    )\n\n\n@app.post('/api/boost/lock')\nasync def sign_and_broadcast(payload: dict = Body(...)):\n    \"\"\"Signs & broadcasts the Boost lock transaction and returns `tx_hash`.\"\"\"\n    sender = payload.get('sender')\n    amount = payload.get('amount', '500000000')\n\n    if not sender:\n        raise HTTPException(status_code=400, detail='sender field is required')\n\n    mnemonic = os.getenv('NEUTRON_MNEMONIC')\n    if not mnemonic:\n        raise HTTPException(status_code=500, detail='Server wallet not configured')\n\n    key = PrivateKey.from_mnemonic(mnemonic)\n    if key.address() != sender:\n        raise HTTPException(status_code=400, detail='Sender must match backend wallet address.')\n\n    client = LedgerClient(NetworkConfig(chain_id=CHAIN_ID, url=RPC_ENDPOINT))\n\n    # Compose transaction\n    tx = Transaction()\n    tx.add_message(_build_execute_msg(sender, amount))\n    tx.with_gas(300000)  # gas limit estimate – adjust as needed\n    tx.with_chain_id(CHAIN_ID)\n\n    try:\n        signed_tx = tx.build_and_sign(key)\n        tx_response = client.send_tx_block_mode(signed_tx)\n        return {'tx_hash': tx_response.tx_hash}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"tx_status": "def tx_status(tx_hash: str):\n    client = LedgerClient(NetworkConfig(chain_id=CHAIN_ID, url=RPC_ENDPOINT))\n    try:\n        tx_response = client.query_tx(tx_hash)\n        if not tx_response:\n            return { 'status': 'PENDING' }\n        return { 'status': 'COMMITTED', 'height': tx_response.height }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"select_rpc_endpoint": "def select_rpc_endpoint() -> str:\n    # Returns the JSON-RPC endpoint configured in the environment.\n    rpc_url = os.getenv(\"RPC_URL\")\n    if not rpc_url:\n        raise EnvironmentError(\"RPC_URL environment variable is not set.\")\n    return rpc_url\n",
	"authenticate_debug_namespace": "def authenticate_debug_namespace() -> Dict[str, str]:\n    # Builds Basic-Auth headers for the private debug RPC namespace.\n    user = os.getenv(\"RPC_USER\")\n    password = os.getenv(\"RPC_PASSWORD\")\n    if user is None or password is None:\n        raise EnvironmentError(\"RPC_USER or RPC_PASSWORD environment variables are missing.\")\n    token_bytes = f\"{user}:{password}\".encode()\n    token_b64 = base64.b64encode(token_bytes).decode()\n    return {\"Authorization\": f\"Basic {token_b64}\"}\n",
	"broadcast_approve": "def broadcast_approve(body: BroadcastBody):\n    try:\n        wallet = PrivateKey.from_mnemonic(body.mnemonic)\n        sender = wallet.public_key.address()\n\n        tx = Transaction()\n        tx.add_message(body.msg)            # Convert dict→proto inside cosmpy in real code\n\n        client = LedgerClient(NETWORK)\n        tx.with_sequence(client.get_sequence(sender))\n        tx.with_account_number(client.get_number(sender))\n        tx.with_chain_id(NETWORK.chain_id)\n        tx.sign(wallet)\n\n        result = client.broadcast_tx(tx)\n        return result                      # JSON tx response\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"construct_lend": "def construct_lend(body: LendBody):\n    try:\n        # Optional inner payload for the lending pool (often empty)\n        inner_msg = {}\n\n        wrapped_send = {\n            'send': {\n                'contract': body.amber_pool,\n                'amount': str(body.amount),\n                'msg': b64encode(json.dumps(inner_msg).encode()).decode()\n            }\n        }\n\n        encoded = b64encode(json.dumps(wrapped_send).encode()).decode()\n        exec_msg = {\n            'type_url': '/cosmwasm.wasm.v1.MsgExecuteContract',\n            'value': {\n                'sender': body.sender,\n                'contract': body.cw20_contract,\n                'msg': encoded,\n                'funds': []\n            }\n        }\n\n        return { 'msg': exec_msg }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"broadcast_lend": "def broadcast_lend(body: LendBroadcastBody):\n    try:\n        wallet = PrivateKey.from_mnemonic(body.mnemonic)\n        sender = wallet.public_key.address()\n        client = LedgerClient(NETWORK)\n\n        tx = Transaction()\n        tx.add_message(body.msg)\n        tx.with_sequence(client.get_sequence(sender))\n        tx.with_account_number(client.get_number(sender))\n        tx.with_chain_id(NETWORK.chain_id)\n        tx.sign(wallet)\n\n        return client.broadcast_tx(tx)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"lock_status": "def lock_status(address: str, lock_id: int) -> Dict:\n    \"\"\"Return the lock information for <address, lock_id>. Raises 400 if lock not found.\"\"\"\n    try:\n        # Build CosmWasm smart-query\n        query_msg = {\n            \"lock\": {\n                \"address\": address,\n                \"lock_id\": lock_id\n            }\n        }\n        query_b64 = base64.b64encode(json.dumps(query_msg).encode()).decode()\n        url = f\"{LCD_ENDPOINT}/wasm/v1/contract/{LOCK_CONTRACT_ADDR}/smart/{query_b64}\"\n\n        async with httpx.AsyncClient(timeout=10) as client:\n            resp = await client.get(url)\n        if resp.status_code != 200:\n            raise HTTPException(status_code=resp.status_code, detail=resp.text)\n\n        data = resp.json()\n        # Adjust the JSON path depending on contract schema\n        lock_info = data.get(\"data\") or data  # fallback\n\n        if not lock_info:\n            raise HTTPException(status_code=404, detail=\"Lock not found\")\n\n        if not lock_info.get(\"unlockable\", False):\n            return {\"eligible\": False, \"reason\": \"Lock period not finished\"}\n\n        return {\n            \"eligible\": True,\n            \"lock_info\": lock_info\n        }\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"check_dependency": "def check_dependency():\n    \"\"\"Return installation status and version of the `pass` utility.\"\"\"\n    # Locate the binary first\n    pass_path = shutil.which(\"pass\")\n    if pass_path is None:\n        raise HTTPException(status_code=404, detail=\"`pass` utility is not installed on this host.\")\n\n    # Obtain version information\n    try:\n        version_output = subprocess.check_output([\"pass\", \"--version\"], text=True).strip()\n    except subprocess.CalledProcessError as exc:\n        raise HTTPException(status_code=500, detail=f\"Failed to execute 'pass --version': {exc}\")\n\n    return {\"installed\": True, \"path\": pass_path, \"version\": version_output}",
	"config_keyring_backend": "def config_keyring_backend():\n    \"\"\"Run `gaiad config keyring-backend pass` and return the CLI response.\"\"\"\n    cmd = shlex.split(\"gaiad config keyring-backend pass\")\n    try:\n        output = subprocess.check_output(cmd, stderr=subprocess.STDOUT, text=True)\n    except subprocess.CalledProcessError as exc:\n        raise HTTPException(status_code=500, detail=f\"gaiad exited with code {exc.returncode}: {exc.output}\")\n\n    return {\"success\": True, \"output\": output.strip()}",
	"validate_keyring_setting": "def validate_keyring_setting():\n    \"\"\"Confirm that client.toml contains the correct keyring-backend setting.\"\"\"\n    client_toml_path = Path.home() / \".gaia\" / \"config\" / \"client.toml\"\n    if not client_toml_path.exists():\n        raise HTTPException(status_code=404, detail=f\"{client_toml_path} not found. Make sure Gaia is initialized.\")\n\n    try:\n        content = client_toml_path.read_text()\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=f\"Unable to read {client_toml_path}: {exc}\")\n\n    expected_line = 'keyring-backend = \"pass\"'\n    valid = expected_line in content\n    return {\n        \"file\": str(client_toml_path),\n        \"contains_setting\": valid,\n        \"expected_line\": expected_line\n    }",
	"get_transaction_receipt_once": "def get_transaction_receipt_once(tx_hash: str, rpc_endpoint: str) -> Optional[dict]:\n    \"\"\"Fire exactly one eth_getTransactionReceipt call.\"\"\"\n\n    payload = {\n        'jsonrpc': '2.0',\n        'id': 1,\n        'method': 'eth_getTransactionReceipt',\n        'params': [tx_hash],\n    }\n\n    async with httpx.AsyncClient() as client:\n        resp = await client.post(rpc_endpoint, json=payload, timeout=10)\n        resp.raise_for_status()\n        data = resp.json()\n\n    # `result` is None while the tx is pending\n    return data.get('result')",
	"_get_receipt_once": "def _get_receipt_once(tx_hash: str, rpc_endpoint: str):\n    \"\"\"Light wrapper around the function from Step 3 so we keep the file self-contained.\"\"\"\n    payload = {\n        'jsonrpc': '2.0',\n        'id': 1,\n        'method': 'eth_getTransactionReceipt',\n        'params': [tx_hash],\n    }\n    async with httpx.AsyncClient() as client:\n        res = await client.post(rpc_endpoint, json=payload, timeout=10)\n        res.raise_for_status()\n        return res.json().get('result')\n\n\nasync def poll_for_receipt(tx_hash: str, rpc_endpoint: str, timeout: int, interval: int):\n    \"\"\"Repeat JSON-RPC calls until we get a non-null receipt or hit the timeout.\"\"\"\n    deadline = asyncio.get_running_loop().time() + timeout\n    while True:\n        receipt = await _get_receipt_once(tx_hash, rpc_endpoint)\n        if receipt is not None:\n            return receipt\n        if asyncio.get_running_loop().time() >= deadline:\n            raise TimeoutError(f'Receipt not found within {timeout}s')\n        await asyncio.sleep(interval)\n\n\n@app.get('/api/poll_receipt')\nasync def api_poll_receipt(\n    tx_hash: str,\n    rpc_endpoint: Optional[str] = None,\n    timeout: int = DEFAULT_TIMEOUT,\n    interval: int = DEFAULT_INTERVAL,\n):\n    \"\"\"Frontend-facing endpoint: /api/poll_receipt?tx_hash=<hash>&rpc_endpoint=<opt>\"\"\"\n\n    if not (tx_hash.startswith('0x') and len(tx_hash) == 66):\n        raise HTTPException(status_code=400, detail='Invalid transaction hash')\n\n    endpoint = rpc_endpoint or DEFAULT_RPC\n\n    try:\n        receipt = await poll_for_receipt(tx_hash, endpoint, timeout, interval)\n        return {'receipt': receipt}\n    except TimeoutError as err:\n        raise HTTPException(status_code=504, detail=str(err))\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"is_valid_bech32": "def is_valid_bech32(address: str, expected_prefix: str) -> bool:\n    \"\"\"Return True if `address` is a valid bech32 string with the given prefix.\"\"\"\n    hrp, data = bech32_decode(address)\n    return hrp == expected_prefix and data is not None\n\n\n@app.get('/api/validate_recipient')\nasync def validate_recipient(address: str, prefix: str = 'cosmos'):\n    if not is_valid_bech32(address, prefix):\n        raise HTTPException(status_code=400, detail='Invalid bech32 address')\n    return {'valid': True}",
	"construct_msg_send": "def construct_msg_send(req: MsgSendRequest):\n    try:\n        msg = bank_tx_pb2.MsgSend(\n            from_address=req.sender,\n            to_address=req.recipient,\n            amount=[{'amount': str(req.amount), 'denom': req.denom}]\n        )\n        return {'proto_hex': msg.SerializeToString().hex()}\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"check_tx": "def check_tx(tx_hash: str, timeout: int = 30):\n    \"\"\"Return the tx result as soon as it is committed or raise 404 after `timeout` seconds.\"\"\"\n    try:\n        for _ in range(timeout):\n            try:\n                return client.tx_by_hash(tx_hash)\n            except Exception:\n                await asyncio.sleep(1)\n        raise HTTPException(status_code=404, detail='Transaction not found within timeout window.')\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"get_latest_block": "def get_latest_block():\n    \"\"\"Fetch the latest block from the configured Cosmos RPC node.\"\"\"\n    try:\n        rpc_endpoint = f\"{COSMOS_RPC_URL.rstrip('/')}/block\"  # no height param = latest\n        response = requests.get(rpc_endpoint, timeout=10)\n        response.raise_for_status()\n        return response.json()  # CometBFT returns `{ \"result\": { \"block\": {...} } }`\n    except requests.exceptions.RequestException as err:\n        raise HTTPException(status_code=502, detail=f\"Failed to fetch latest block: {err}\")",
	"open_position": "def open_position(req: OpenPositionRequest):\n    try:\n        # 1. Build client & wallet\n        net_cfg = NetworkConfig(\n            chain_id=CHAIN_ID,\n            url=RPC_ENDPOINT,\n            fee_minimum_gas_price=req.gas_price,\n            fee_denomination='untrn'\n        )\n        client = LedgerClient(net_cfg)\n        wallet = Wallet(req.mnemonic)\n\n        # 2. Craft the transaction\n        tx = (\n            Transaction()\n            .with_messages(req.open_position_msg)\n            .with_sequence(client.query_account_sequence(wallet.address()))\n            .with_account_num(client.query_account_number(wallet.address()))\n            .with_gas(req.gas_limit)\n            .with_chain_id(net_cfg.chain_id)\n        )\n\n        # 3. Sign & broadcast\n        signed_tx = wallet.sign(tx)\n        tx_response = client.broadcast_tx_block(signed_tx)\n\n        if tx_response.is_error:\n            raise HTTPException(400, f'Broadcast failed: {tx_response.log}')\n        return {\"tx_hash\": tx_response.tx_hash, \"height\": tx_response.height}\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"validate_amount": "def validate_amount(cls, v):\n        try:\n            if float(v) < 0:\n                raise ValueError\n            return v\n        except ValueError:\n            raise ValueError('`amount` must be a positive number represented as a string')\n\n@app.post('/api/to_wei')\nasync def to_wei(payload: AmountIn):\n    \"\"\"Convert an Ether amount to Wei using the `cast` CLI.\n    Foundry’s `cast` must be installed and present in the PATH.\n    \"\"\"\n    try:\n        # Build and execute the CLI command safely\n        cmd = ['cast', 'to-wei', payload.amount, 'ether']\n        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n        wei_value = result.stdout.strip()\n        return { 'wei': wei_value }\n    except subprocess.CalledProcessError as e:\n        raise HTTPException(status_code=500, detail=f'cast error: {e.stderr.strip()}')\n    except FileNotFoundError:\n        raise HTTPException(status_code=500, detail='`cast` CLI not found on the server')",
	"api_trace_block_by_hash": "def api_trace_block_by_hash():\n    \"\"\"Proxy for EVM `debug_traceBlockByHash`.\"\"\"\n    data = request.get_json(force=True)\n    rpc_url: str | None = data.get('rpc_url')\n    block_hash: str | None = data.get('block_hash')\n\n    # -------------------------\n    # Basic input validation\n    # -------------------------\n    if not rpc_url or not rpc_url.startswith(('http://', 'https://')):\n        return jsonify({'error': 'Valid rpc_url is required'}), 400\n\n    if not block_hash or not block_hash.startswith('0x') or len(block_hash) != 66:\n        return jsonify({'error': 'block_hash must be a 0x-prefixed 32-byte hash'}), 400\n\n    payload = {\n        'method': 'debug_traceBlockByHash',\n        'params': [block_hash, {}],  # Empty tracer object → default parity-style trace\n        'id': 1,\n        'jsonrpc': '2.0'\n    }\n\n    try:\n        # Forward the request to the given RPC endpoint\n        res = requests.post(rpc_url, json=payload, timeout=20)\n        res.raise_for_status()\n        body = res.json()\n\n        # Check for JSON-RPC error objects\n        if 'error' in body:\n            return jsonify({'error': body['error']}), 502  # Bad gateway\n\n        return jsonify({'trace': body['result']}), 200\n\n    except requests.exceptions.RequestException as err:\n        # Network-level or HTTP-level error\n        return jsonify({'error': str(err)}), 502\n\n\nif __name__ == '__main__':\n    # Bind on 0.0.0.0 so Mintlify can expose the port\n    app.run(host='0.0.0.0', port=int(os.getenv('PORT', 8000)))",
	"save_privkey_to_file": "def save_privkey_to_file(privkey_hex: str) -> str:\n    \"\"\"\n    Persist a hex-encoded private key in a temporary file that is readable only by\n    the current user. The function returns the absolute file path so that it can\n    be consumed by the next step.\n    \"\"\"\n    # Basic validation — ensure every character is hexadecimal\n    if not privkey_hex or any(c not in \"0123456789abcdefABCDEF\" for c in privkey_hex.strip()):\n        raise ValueError(\"Invalid hex-encoded private key provided.\")\n\n    # Create a secure temp file that survives after close (delete=False)\n    tmp_file = tempfile.NamedTemporaryFile(mode=\"w\", suffix=\".hex\", delete=False)\n    try:\n        tmp_file.write(privkey_hex.strip())\n        tmp_file.flush()\n        tmp_file.close()\n\n        # Restrict permissions to 0o600 (read/write by owner only)\n        os.chmod(tmp_file.name, stat.S_IRUSR | stat.S_IWUSR)\n        return tmp_file.name\n    except Exception as err:\n        # Best-effort cleanup on failure\n        tmp_file.close()\n        if os.path.exists(tmp_file.name):\n            os.remove(tmp_file.name)\n        raise err",
	"import_key": "def import_key(name: str, privkey_file: str, passphrase: str) -> str:\n    \"\"\"\n    Imports the private key into the local `simd` keyring (file backend).\n    The CLI prompts twice for a passphrase; both prompts are satisfied by\n    piping the provided `passphrase` via STDIN.\n\n    Returns the command's STDOUT on success.\n    \"\"\"\n    if not os.path.exists(privkey_file):\n        raise FileNotFoundError(f\"Private key file {privkey_file} does not exist.\")\n\n    # Construct the CLI command safely\n    cmd = f\"simd keys import {shlex.quote(name)} {shlex.quote(privkey_file)} --keyring-backend file\"\n\n    # Provide the passphrase twice, each followed by a newline\n    pass_input = f\"{passphrase}\\n{passphrase}\\n\".encode()\n\n    proc = subprocess.run(\n        shlex.split(cmd),\n        input=pass_input,\n        capture_output=True,\n    )\n\n    # Always wipe the temporary file after use\n    try:\n        os.remove(privkey_file)\n    except OSError:\n        pass\n\n    if proc.returncode != 0:\n        raise RuntimeError(f\"simd key import failed: {proc.stderr.decode()}\")\n\n    return proc.stdout.decode()",
	"show_address": "def show_address(name: str) -> str:\n    \"\"\"\n    Retrieves the address of the imported key from the `simd` keyring.\n    Returns the bech32 address as a string.\n    \"\"\"\n    cmd = f\"simd keys show {shlex.quote(name)} --keyring-backend file --address\"\n    proc = subprocess.run(shlex.split(cmd), capture_output=True)\n\n    if proc.returncode != 0:\n        raise RuntimeError(f\"simd keys show failed: {proc.stderr.decode()}\")\n\n    return proc.stdout.decode().strip()",
	"get_auth_headers": "def get_auth_headers() -> Dict[str, str]:\n    \"\"\"\n    Build Authorization header for the Cosmos-EVM node.\n\n    1. If COSMOS_EVM_JWT is set, use Bearer <token>.\n    2. Else, if COSMOS_EVM_USER and COSMOS_EVM_PASSWORD are set, use Basic Auth.\n    3. Otherwise, return empty dict (assumes node does not require auth).\n    \"\"\"\n    jwt_token = os.getenv(\"COSMOS_EVM_JWT\")\n    if jwt_token:\n        return {\"Authorization\": f\"Bearer {jwt_token}\"}\n\n    user = os.getenv(\"COSMOS_EVM_USER\")\n    password = os.getenv(\"COSMOS_EVM_PASSWORD\")\n    if user and password:\n        credentials = f\"{user}:{password}\"\n        encoded = base64.b64encode(credentials.encode()).decode()\n        return {\"Authorization\": f\"Basic {encoded}\"}\n\n    # No credentials provided\n    return {}\n",
	"write_mem_profile": "def write_mem_profile(filename: str = \"mem.prof\"):\n    \"\"\"\n    Calls the debug_writeMemProfile method on the Cosmos-EVM node.\n    By default writes to 'mem.prof'.\n    \"\"\"\n    url = get_rpc_endpoint()\n    headers = {\"Content-Type\": \"application/json\"}\n    headers.update(get_auth_headers())\n\n    payload = {\n        \"jsonrpc\": \"2.0\",\n        \"id\": 1,\n        \"method\": \"debug_writeMemProfile\",\n        \"params\": [filename]\n    }\n\n    try:\n        resp = requests.post(url, headers=headers, json=payload, timeout=10)\n    except requests.exceptions.RequestException as e:\n        raise HTTPException(status_code=502, detail=f\"Failed to reach node: {e}\")\n\n    if resp.status_code != 200:\n        raise HTTPException(status_code=resp.status_code, detail=f\"Node responded with HTTP {resp.status_code}: {resp.text}\")\n\n    try:\n        response_json = resp.json()\n    except json.JSONDecodeError:\n        raise HTTPException(status_code=502, detail=\"Non-JSON response returned from node.\")\n\n    if \"error\" in response_json:\n        raise HTTPException(status_code=500, detail=response_json[\"error\"])\n\n    # success: result field may be None or some output\n    return {\"success\": True, \"result\": response_json.get(\"result\")}\n",
	"modify_parameter": "def modify_parameter(lines: list[str]) -> list[str]:\n    \"\"\"Return a new list of lines where `unsafe-cors = true` is guaranteed.\"\"\"\n\n    modified_lines = []\n    in_relevant_section = False\n    parameter_set = False\n\n    for line in lines:\n        stripped = line.strip().lower()\n\n        # Track which section we are in\n        if stripped.startswith(\"[\") and stripped.endswith(\"]\"):\n            in_relevant_section = stripped in SECTION_HEADERS\n\n        if in_relevant_section and stripped.startswith(\"unsafe-cors\"):\n            # Replace whatever value was there with `true`\n            modified_lines.append(\"unsafe-cors = true\\n\")\n            parameter_set = True\n        else:\n            modified_lines.append(line)\n\n    # If the flag did not previously exist, inject it into the first relevant section\n    if not parameter_set:\n        for i, line in enumerate(modified_lines):\n            if line.strip().lower() in SECTION_HEADERS:\n                # Insert immediately after the section header\n                modified_lines.insert(i + 1, \"unsafe-cors = true\\n\")\n                parameter_set = True\n                break\n\n    if not parameter_set:\n        # No relevant section found; fall back to appending under [api]\n        modified_lines.append(\"\\n[api]\\n\")\n        modified_lines.append(\"unsafe-cors = true\\n\")\n\n    return modified_lines",
	"restart_gaiad": "def restart_gaiad():\n    \"\"\"Restart the Gaia daemon to apply configuration changes.\"\"\"\n    # Preferred: use systemctl when it exists\n    try:\n        subprocess.check_call([\"systemctl\", \"restart\", \"gaiad\"], stderr=subprocess.STDOUT)\n        return \"Restarted via systemctl\"\n    except (subprocess.CalledProcessError, FileNotFoundError):\n        # Fall back: find the gaiad process and send SIGHUP\n        for proc in psutil.process_iter([\"name\"]):\n            if proc.info.get(\"name\", \"\").startswith(\"gaiad\"):\n                proc.send_signal(signal.SIGHUP)\n                return f\"Sent SIGHUP to pid {proc.pid}\"\n        raise RuntimeError(\"gaiad process not found; manual restart required\")",
	"verify_cors_header": "def verify_cors_header(rest_endpoint: str | None = None, origin: str = \"http://example.com\") -> bool:\n    \"\"\"Return True if Access-Control-Allow-Origin is `*` or matches the supplied origin.\"\"\"\n    url = rest_endpoint or DEFAULT_REST_ENDPOINT\n    try:\n        response = requests.get(url, headers={\"Origin\": origin}, timeout=5)\n        allowed = response.headers.get(\"Access-Control-Allow-Origin\", \"\")\n        return allowed == \"*\" or allowed == origin\n    except requests.RequestException as err:\n        raise RuntimeError(f\"Failed to query REST endpoint {url}: {err}\") from err",
	"_detect_package_manager": "def _detect_package_manager() -> str:\n    \"\"\"Return the first supported package-manager binary found in PATH.\"\"\"\n    for manager in (\"apt-get\", \"yum\", \"dnf\", \"pacman\", \"apk\"):\n        if shutil.which(manager):\n            return manager\n    raise FileNotFoundError(\"No supported package manager found on this host.\")\n\n\n@app.get(\"/api/detect-package-manager\")\nasync def detect_package_manager():\n    \"\"\"HTTP GET → { \"package_manager\": \"apt-get\" }\"\"\"\n    try:\n        manager = _detect_package_manager()\n        return {\"package_manager\": manager}\n    except FileNotFoundError as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"update_package_cache": "def update_package_cache(manager: str):\n    \"\"\"HTTP POST body ⇒ {\"manager\":\"apt-get\"}. Runs the correct cache update command.\"\"\"\n    if manager not in CMD_CACHE:\n        raise HTTPException(status_code=400, detail=f\"Unsupported package manager: {manager}\")\n    try:\n        proc = subprocess.run(CMD_CACHE[manager], check=True, capture_output=True, text=True)\n        return {\"stdout\": proc.stdout}\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=err.stderr or str(err))",
	"install_ufw": "def install_ufw(manager: str):\n    \"\"\"HTTP POST body ⇒ {\"manager\":\"apt-get\"}. Installs UFW.\"\"\"\n    if manager not in CMD_INSTALL_UFW:\n        raise HTTPException(status_code=400, detail=f\"Unsupported package manager: {manager}\")\n    try:\n        proc = subprocess.run(CMD_INSTALL_UFW[manager], check=True, capture_output=True, text=True)\n        return {\"stdout\": proc.stdout}\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=err.stderr or str(err))",
	"enable_firewall": "def enable_firewall():\n    \"\"\"HTTP POST ⇒ enables UFW.\"\"\"\n    try:\n        proc = subprocess.run(CMD_ENABLE, check=True, capture_output=True, text=True)\n        return {\"stdout\": proc.stdout}\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=err.stderr or str(err))",
	"firewall_status": "def firewall_status():\n    \"\"\"HTTP GET → returns `ufw status verbose`.\"\"\"\n    try:\n        proc = subprocess.run(CMD_STATUS, check=True, capture_output=True, text=True)\n        return {\"status\": proc.stdout}\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=err.stderr or str(err))",
	"verify_foundry_installation": "def verify_foundry_installation():\n    '''\n    Ensures Foundry's cast CLI is installed and returns its version.\n    '''\n    try:\n        result = subprocess.run(['cast', '--version'], capture_output=True, text=True, check=True)\n        return result.stdout.strip()\n    except FileNotFoundError:\n        raise EnvironmentError('Foundry cast CLI is not installed or not in PATH.')\n    except subprocess.CalledProcessError as e:\n        raise EnvironmentError(f'Error executing cast --version: {e.stderr}')",
	"get_account_balance": "def get_account_balance(\n    address: str = Query(..., description='EVM account address starting with 0x'),\n    rpc_url: str = Query(..., description='HTTPS JSON-RPC endpoint for the target chain')\n):\n    '''\n    Uses Foundry's cast CLI to fetch an EVM account balance and returns both wei and ether values.\n    '''\n    # Ensure Foundry is installed\n    try:\n        verify_foundry_installation()\n    except EnvironmentError as e:\n        raise HTTPException(status_code=500, detail=str(e))\n\n    # Simple address validation\n    if not address.startswith('0x') or len(address) != 42:\n        raise HTTPException(status_code=400, detail='Invalid Ethereum address format')\n\n    try:\n        result = subprocess.run(\n            ['cast', 'balance', address, '--rpc-url', rpc_url],\n            capture_output=True,\n            text=True,\n            check=True\n        )\n        balance_wei = result.stdout.strip()\n        balance_ether = str(Decimal(balance_wei) / Decimal(10 ** 18))\n\n        return {\n            'address': address,\n            'balance_wei': balance_wei,\n            'balance_ether': balance_ether,\n            'rpc_url': rpc_url\n        }\n    except subprocess.CalledProcessError as e:\n        raise HTTPException(status_code=500, detail=f'Cast query failed: {e.stderr}')",
	"search_circuit_docs": "def search_circuit_docs(query: str) -> dict:\n    \"\"\"Return search results from the Cosmos docs search API.\"\"\"\n    try:\n        url = f\"{BASE_URL}?q={urllib.parse.quote_plus(query)}\"\n        resp = requests.get(url, timeout=10)\n        resp.raise_for_status()\n        return resp.json()\n    except requests.RequestException as exc:\n        print(f\"[ERROR] Documentation search failed: {exc}\")\n        return {}\n\nif __name__ == \"__main__\":\n    query = \" \".join(sys.argv[1:]) if len(sys.argv) > 1 else \"Cosmos SDK circuit breaker module integration BaseApp\"\n    results = search_circuit_docs(query)\n    print(json.dumps(results, indent=2))",
	"check_system_prerequisites": "def check_system_prerequisites():\n    '''Verify that curl, bash, and git are installed and git is up to date (>= 2.30).'''\n    required_bins = ['curl', 'bash', 'git']\n    missing = [bin for bin in required_bins if shutil.which(bin) is None]\n    if missing:\n        raise EnvironmentError(f\"Missing required binaries: {', '.join(missing)}\")\n\n    # Check git version\n    try:\n        result = subprocess.run(['git', '--version'], capture_output=True, text=True, check=True)\n        version_str = result.stdout.strip()  # e.g., 'git version 2.35.1'\n        version_number = version_str.split()[-1]\n        major, minor, *_ = map(int, version_number.split('.'))\n        if (major, minor) < (2, 30):\n            raise EnvironmentError(f'git version 2.30 or higher is required, found {version_number}')\n    except subprocess.CalledProcessError as e:\n        raise EnvironmentError(f'Could not determine git version: {e}')\n\n    return {\n        'curl_path': shutil.which('curl'),\n        'bash_path': shutil.which('bash'),\n        'git_version': version_number,\n    }\n",
	"download_foundryup": "def download_foundryup():\n    '''Download and run the Foundry installation script.'''\n    cmd = 'curl -L https://foundry.paradigm.xyz | bash'\n    try:\n        subprocess.run(cmd, shell=True, check=True)\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f'Failed to download and install foundryup: {e}')\n\n    # Add ~/.foundry/bin to PATH for current process so subsequent steps can find foundryup\n    foundry_bin = Path.home() / '.foundry' / 'bin'\n    os.environ['PATH'] += os.pathsep + str(foundry_bin)\n    return str(foundry_bin)\n",
	"source_shell_profile": "def source_shell_profile(profile_path: str = None):\n    '''Reload shell profile so that Foundry tools are in PATH. If sourcing in the current Python process is not possible, update PATH manually as fallback.'''\n    # Determine which profile to source\n    if profile_path is None:\n        bashrc = Path.home() / '.bashrc'\n        zshrc = Path.home() / '.zshrc'\n        profile_path = zshrc if zshrc.exists() else bashrc\n\n    if not Path(profile_path).exists():\n        raise FileNotFoundError(f'Shell profile {profile_path} does not exist.')\n\n    # Since \"source\" only affects the current shell, we emulate by appending Foundry bin to PATH.\n    foundry_bin = Path.home() / '.foundry' / 'bin'\n    os.environ['PATH'] += os.pathsep + str(foundry_bin)\n    return str(profile_path)\n",
	"run_foundryup_install": "def run_foundryup_install():\n    '''Run \\\"foundryup\\\" to install or update the Foundry toolchain.'''\n    try:\n        subprocess.run(['foundryup'], check=True)\n    except FileNotFoundError:\n        raise RuntimeError('foundryup not found in PATH. Did you run download_foundryup()?')\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f'foundryup execution failed: {e}')\n    return True\n",
	"connect_rpc_endpoint": "def connect_rpc_endpoint(rpc_endpoint: str = 'https://rpc-kralum.neutron.org') -> str:\n    \"\"\"\n    Attempts to connect to the given Neutron RPC endpoint by querying the `/status`\n    route. Returns the endpoint string if successful; raises an exception otherwise.\n    \"\"\"\n    try:\n        # Hit `/status` to confirm the node is alive\n        url = rpc_endpoint.rstrip('/') + '/status'\n        response = requests.get(url, timeout=5)\n        response.raise_for_status()\n\n        # Basic sanity check on the payload\n        if 'result' not in response.json():\n            raise ValueError('Unexpected response payload from RPC endpoint.')\n\n        return rpc_endpoint\n    except requests.RequestException as err:\n        raise ConnectionError(\n            f'Unable to reach Neutron RPC endpoint at {rpc_endpoint}: {err}'\n        ) from err",
	"neutrond_status": "def neutrond_status(rpc_endpoint: str) -> Dict:\n    \"\"\"\n    Executes `neutrond status --node <rpc_endpoint>` via subprocess and returns\n    the parsed JSON dictionary containing the node's sync information.\n    \"\"\"\n    try:\n        cmd = [\n            'neutrond',\n            'status',\n            '--node',\n            rpc_endpoint,\n        ]\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n        return json.loads(result.stdout)\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f'`neutrond status` failed: {err.stderr}') from err\n    except json.JSONDecodeError as err:\n        raise ValueError('Failed to parse JSON from neutrond output.') from err",
	"extract_block_height": "def extract_block_height(status_json: Dict) -> int:\n    \"\"\"\n    Extracts the latest block height from the status JSON returned by `neutrond status`.\n    \"\"\"\n    try:\n        height_str = status_json['result']['sync_info']['latest_block_height']\n        return int(height_str)\n    except (KeyError, TypeError, ValueError) as err:\n        raise ValueError(\n            'Invalid status JSON format: unable to locate `latest_block_height`.'\n        ) from err",
	"allow_cosmos_prometheus_port": "def allow_cosmos_prometheus_port():\n    \"\"\"Allow TCP traffic on port 26660 with a descriptive comment.\"\"\"\n    cmd = [\n        \"sudo\",\n        \"ufw\",\n        \"allow\",\n        \"26660/tcp\",\n        \"comment\",\n        \"Cosmos Prometheus\"\n    ]\n\n    try:\n        # Run the UFW command and capture output\n        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n        return {\n            \"status\": \"success\",\n            \"output\": result.stdout.strip() or \"Rule applied successfully.\"\n        }\n    except subprocess.CalledProcessError as exc:\n        # Return error information without crashing the application\n        return {\n            \"status\": \"error\",\n            \"error\": exc.stderr.strip(),\n            \"code\": exc.returncode\n        }\n",
	"reload_firewall": "def reload_firewall():\n    \"\"\"Reload the UFW firewall to activate any pending rule changes.\"\"\"\n    cmd = [\"sudo\", \"ufw\", \"reload\"]\n\n    try:\n        # Run the UFW reload command and capture output\n        result = subprocess.run(cmd, capture_output=True, text=True, check=True)\n        return {\n            \"status\": \"success\",\n            \"output\": result.stdout.strip() or \"Firewall reloaded successfully.\"\n        }\n    except subprocess.CalledProcessError as exc:\n        # Return error details for debugging\n        return {\n            \"status\": \"error\",\n            \"error\": exc.stderr.strip(),\n            \"code\": exc.returncode\n        }\n",
	"install_openzeppelin": "def install_openzeppelin(project_path: str = \".\"):\n    \"\"\"Install OpenZeppelin Contracts with npm.\"\"\"\n    try:\n        # Ensure we are operating in an absolute path for safety\n        project_dir = pathlib.Path(project_path).resolve()\n        subprocess.run(\n            [\"npm\", \"install\", \"@openzeppelin/contracts\"],\n            cwd=project_dir,\n            check=True,\n        )\n        return {\"status\": \"success\", \"message\": \"@openzeppelin/contracts installed.\"}\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=f\"npm install failed: {err}\")",
	"create_contract": "def create_contract(project_path: str = \".\", filename: str = \"MyToken.sol\"):\n    \"\"\"Create a Solidity file with OpenZeppelin imports.\"\"\"\n    try:\n        contracts_dir = pathlib.Path(project_path).resolve() / \"contracts\"\n        contracts_dir.mkdir(parents=True, exist_ok=True)\n        contract_file = contracts_dir / filename\n        contract_file.write_text(SAMPLE_ERC20)\n        return {\"status\": \"success\", \"message\": f\"Contract written to {contract_file}\"}\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=f\"Unable to write contract: {err}\")",
	"locate_config_file": "def locate_config_file(node_home: str) -> str:\n    '''\n    Locate the app.toml file inside a Cosmos-SDK node home directory.\n\n    Args:\n        node_home (str): Absolute path to the node's home (e.g. '/home/ubuntu/.appd')\n    Returns:\n        str: Absolute path string to app.toml\n    Raises:\n        FileNotFoundError: If the file cannot be found\n    '''\n    config_path = Path(node_home) / 'config' / 'app.toml'\n    if not config_path.exists():\n        raise FileNotFoundError(f'Configuration file not found at {config_path}')\n    return str(config_path)\n",
	"load_config_file": "def load_config_file(file_path: str) -> dict:\n    '''\n    Load a TOML configuration file and return its contents as a Python dict.\n    Prefers the built-in `tomllib` (Python 3.11+); falls back to the external\n    `toml` package when necessary.\n    '''\n    try:\n        import tomllib  # Python 3.11+\n        with open(file_path, 'rb') as fp:\n            return tomllib.load(fp)\n    except ModuleNotFoundError:\n        try:\n            import toml  # type: ignore\n        except ModuleNotFoundError as exc:\n            raise ModuleNotFoundError('`toml` library required. Install via `pip install toml`.') from exc\n        with open(file_path, 'r', encoding='utf-8') as fp:\n            return toml.load(fp)\n",
	"update_toml_value": "def update_toml_value(config_data: dict, key: str = 'minimum-gas-prices', value: str = '0.01token') -> dict:\n    '''\n    Update (or add) a key in the TOML configuration dictionary.\n    '''\n    config_data[key] = value\n    return config_data\n",
	"save_file": "def save_file(config_data: dict, file_path: str) -> None:\n    '''\n    Persist the in-memory TOML dictionary back to disk.\n    Uses the `toml` library for serialization.\n    '''\n    try:\n        import toml  # type: ignore\n    except ModuleNotFoundError as exc:\n        raise ModuleNotFoundError('`toml` library required. Install via `pip install toml`.') from exc\n\n    with open(file_path, 'w', encoding='utf-8') as fp:\n        toml.dump(config_data, fp)\n",
	"restart_node_process": "def restart_node_process(service_name: str) -> None:\n    '''\n    Restart the Cosmos-SDK node systemd service so configuration changes take effect.\n    '''\n    try:\n        subprocess.run(['systemctl', 'restart', service_name], check=True, capture_output=True)\n        print(f'[✓] Service {service_name} restarted')\n    except subprocess.CalledProcessError as err:\n        stderr = err.stderr.decode() if err.stderr else str(err)\n        raise RuntimeError(f'Failed to restart {service_name}: {stderr}') from err\n",
	"verify_config_value": "def verify_config_value(binary: str, expected_value: str = '0.01token', retries: int = 5, delay: int = 3) -> bool:\n    '''\n    Poll the node CLI until it reports the desired minimum-gas-prices value.\n    '''\n    for attempt in range(1, retries + 1):\n        try:\n            result = subprocess.run([binary, 'status'], capture_output=True, text=True, check=True)\n            data = json.loads(result.stdout)\n\n            mgp = (\n                data.get('MinimumGasPrices')\n                or data.get('minimum_gas_prices')\n                or data.get('NodeInfo', {}).get('minimum_gas_price')\n            )\n\n            if mgp == expected_value:\n                print(f'[✓] minimum-gas-prices verified as {mgp}')\n                return True\n\n            print(f'[Attempt {attempt}] Current value {mgp} != expected {expected_value}')\n\n        except Exception as exc:\n            print(f'[Attempt {attempt}] Error verifying min gas price: {exc}')\n\n        time.sleep(delay)\n\n    raise RuntimeError('Unable to confirm minimum-gas-prices change after multiple attempts')\n",
	"foundryup_update": "def foundryup_update():\n    \"\"\"Run `foundryup` to update Foundry. Returns the CLI output.\"\"\"\n    # Make sure the binary exists on the host machine.\n    if not shutil.which(\"foundryup\"):\n        raise HTTPException(status_code=404, detail=\"`foundryup` binary not found. Please install Foundry first.\")\n\n    try:\n        result = subprocess.run(\n            [\"foundryup\"],\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n        return {\"stdout\": result.stdout, \"stderr\": result.stderr}\n    except subprocess.CalledProcessError as e:\n        # Surface the actual CLI error back to the caller.\n        raise HTTPException(status_code=500, detail=e.stderr or \"`foundryup` failed with an unknown error.\")",
	"forge_version": "def forge_version():\n    \"\"\"Return the installed Forge version.\"\"\"\n    if not shutil.which(\"forge\"):\n        raise HTTPException(status_code=404, detail=\"`forge` binary not found. Have you installed Foundry?\")\n\n    try:\n        result = subprocess.run(\n            [\"forge\", \"--version\"],\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n        return {\"version\": result.stdout.strip()}\n    except subprocess.CalledProcessError as e:\n        raise HTTPException(status_code=500, detail=e.stderr or \"`forge --version` failed.\")",
	"cast_version": "def cast_version():\n    \"\"\"Return the installed Cast version.\"\"\"\n    if not shutil.which(\"cast\"):\n        raise HTTPException(status_code=404, detail=\"`cast` binary not found. Have you installed Foundry?\")\n\n    try:\n        result = subprocess.run(\n            [\"cast\", \"--version\"],\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n        return {\"version\": result.stdout.strip()}\n    except subprocess.CalledProcessError as e:\n        raise HTTPException(status_code=500, detail=e.stderr or \"`cast --version` failed.\")",
	"anvil_version": "def anvil_version():\n    \"\"\"Return the installed Anvil version.\"\"\"\n    if not shutil.which(\"anvil\"):\n        raise HTTPException(status_code=404, detail=\"`anvil` binary not found. Have you installed Foundry?\")\n\n    try:\n        result = subprocess.run(\n            [\"anvil\", \"--version\"],\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n        return {\"version\": result.stdout.strip()}\n    except subprocess.CalledProcessError as e:\n        raise HTTPException(status_code=500, detail=e.stderr or \"`anvil --version` failed.\")",
	"stop_node_service": "def stop_node_service(service_name: str = \"cosmosd\") -> None:\n    \"\"\"Stops a systemd-managed Cosmos SDK node.\n\n    Args:\n        service_name: The name of the systemd service running the node.\n    Raises:\n        RuntimeError: If the service fails to stop.\n    \"\"\"\n    try:\n        # `systemctl is-active` returns 0 if active, non-zero otherwise.\n        status = subprocess.run([\"systemctl\", \"is-active\", service_name], capture_output=True, text=True)\n        if status.returncode != 0:\n            print(f\"[INFO] Service '{service_name}' is already stopped.\")\n            return\n\n        print(f\"[INFO] Stopping service '{service_name}'…\")\n        stop = subprocess.run([\"sudo\", \"systemctl\", \"stop\", service_name], check=True)\n        print(f\"[SUCCESS] Service '{service_name}' stopped.\")\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"Failed to stop service '{service_name}': {err}\") from err",
	"edit_app_toml_snapshot_section": "def edit_app_toml_snapshot_section(\n    chain_id: str,\n    snapshot_interval: int = 1000,\n    snapshot_keep_recent: int = 2,\n) -> None:\n    \"\"\"Updates snapshot settings inside $HOME/.<chain-id>/config/app.toml.\n\n    The function searches for existing `snapshot-interval` and `snapshot-keep-recent` lines\n    and replaces their values. If a key is missing, it appends the config to the end of the file.\n    \"\"\"\n    path = os.path.expanduser(f\"~/.{chain_id}/config/app.toml\")\n    if not os.path.isfile(path):\n        raise FileNotFoundError(f\"app.toml not found at {path}\")\n\n    with open(path, \"r\", encoding=\"utf-8\") as fp:\n        lines = fp.readlines()\n\n    def upsert(key: str, value: int, lines: list[str]) -> list[str]:\n        pattern = re.compile(rf\"^\\s*{key}\\s*=\\s*\\d+\")\n        for i, line in enumerate(lines):\n            if pattern.match(line):\n                lines[i] = f\"{key} = {value}\\n\"\n                return lines\n        # Key not found; append.\n        lines.append(f\"{key} = {value}\\n\")\n        return lines\n\n    lines = upsert(\"snapshot-interval\", snapshot_interval, lines)\n    lines = upsert(\"snapshot-keep-recent\", snapshot_keep_recent, lines)\n\n    with open(path, \"w\", encoding=\"utf-8\") as fp:\n        fp.writelines(lines)\n\n    print(\n        f\"[SUCCESS] Updated snapshot settings in {path}: interval={snapshot_interval}, keep_recent={snapshot_keep_recent}\"\n    )",
	"start_node_service": "def start_node_service(service_name: str = \"cosmosd\") -> None:\n    \"\"\"Starts (or restarts) the Cosmos SDK node using systemd.\"\"\"\n    try:\n        print(f\"[INFO] Starting service '{service_name}'…\")\n        subprocess.run([\"sudo\", \"systemctl\", \"start\", service_name], check=True)\n        print(f\"[SUCCESS] Service '{service_name}' started.\")\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"Failed to start service '{service_name}': {err}\") from err",
	"verify_snapshot_creation": "def verify_snapshot_creation(chain_id: str, check_interval: int = 30) -> None:\n    \"\"\"Polls the snapshot directory until at least one snapshot appears.\n\n    Args:\n        chain_id: The chain ID used to locate the data directory.\n        check_interval: Seconds between directory scans.\n    \"\"\"\n    snap_dir = Path(os.path.expanduser(f\"~/.{chain_id}/data/snapshots\"))\n    if not snap_dir.exists():\n        raise FileNotFoundError(f\"Snapshot directory not found: {snap_dir}\")\n\n    print(f\"[INFO] Watching {snap_dir} for new snapshot files… (Ctrl+C to exit)\")\n    try:\n        already_seen = {p.name for p in snap_dir.iterdir() if p.is_dir() or p.is_file()}\n        while True:\n            current = {p.name for p in snap_dir.iterdir() if p.is_dir() or p.is_file()}\n            new_files = current - already_seen\n            if new_files:\n                for f in new_files:\n                    print(f\"[SUCCESS] New snapshot detected: {f}\")\n                already_seen = current\n            time.sleep(check_interval)\n    except KeyboardInterrupt:\n        print(\"[INFO] Stopped watching snapshot directory.\")",
	"serve_snapshot_rpc": "def serve_snapshot_rpc(rpc_url: str = \"http://localhost:26657/snapshot/info\") -> dict:\n    \"\"\"Checks that the node’s RPC endpoint responds with snapshot info.\n\n    Args:\n        rpc_url: Full URL to the /snapshot/info endpoint.\n    Returns:\n        Parsed JSON response if successful.\n    Raises:\n        RuntimeError: If the RPC endpoint is unreachable or returns a non-200 code.\n    \"\"\"\n    try:\n        print(f\"[INFO] Querying snapshot info at {rpc_url}…\")\n        resp = requests.get(rpc_url, timeout=5)\n        if resp.status_code != 200:\n            raise RuntimeError(f\"Endpoint returned HTTP {resp.status_code}\")\n        json_resp = resp.json()\n        print(\"[SUCCESS] Snapshot RPC is live. Response snippet:\", json_resp.get(\"result\", {})[:1])\n        return json_resp\n    except (requests.ConnectionError, requests.Timeout) as err:\n        raise RuntimeError(f\"Failed to reach snapshot RPC at {rpc_url}: {err}\") from err",
	"get_vault": "def get_vault(asset: str):\n    asset = asset.lower()\n    if asset not in SUPERVAULTS:\n        raise HTTPException(status_code=404, detail=\"Unsupported asset\")\n    return SUPERVAULTS[asset]",
	"build_deposit_tx": "def build_deposit_tx(vault_addr: str, sender_addr: str, amount_micro: int = 3_000_000):\n    \"\"\"Create an unsigned Transaction object with a single CosmWasm execute msg.\"\"\"\n\n    # CosmWasm messages require base64-encoded JSON inside the high-level msg\n    msg_inner = base64.b64encode(json.dumps({\"deposit\": {}}).encode()).decode()\n\n    exec_msg = {\n        \"type\": \"wasm/MsgExecuteContract\",\n        \"value\": {\n            \"sender\":   sender_addr,\n            \"contract\": vault_addr,\n            \"msg\":       msg_inner,\n            \"funds\":     [{\"denom\": EBTC_DENOM, \"amount\": str(amount_micro)}]\n        }\n    }\n\n    tx = (\n        Transaction()\n        .with_messages(exec_msg)\n        .with_sequence(client.query_sequence(sender_addr))\n        .with_account_num(client.query_account_number(sender_addr))\n        .with_chain_id(NETWORK.chain_id)\n        .with_gas(300000)  # rough estimate; adjust as needed\n        .with_fee_denom(NETWORK.fee_denom)\n        .with_fee(7500)\n        .with_memo(\"eBTC → Supervault deposit\")\n        .with_timeout_height(client.query_height() + 50)  # ~5 min sooner than current block\n    )\n    return tx\n",
	"cw20_balance": "def cw20_balance(contract: str, addr: str) -> int:\n    \"\"\"Query CW20 balance via the contract's `balance` endpoint.\"\"\"\n    sc = SmartContract(contract, client)\n    try:\n        resp = sc.query({\"balance\": {\"address\": addr}})\n        return int(resp.get('balance', '0'))\n    except Exception:\n        # If the query fails treat balance as zero\n        return 0\n\n@app.get('/api/validate_balances', response_model=BalanceStatus)\nasync def validate_token_balances(address: str):\n    \"\"\"Checks that the user holds ≥1 WBTC and ≥1 LBTC.\"\"\"\n    try:\n        wbtc_bal = cw20_balance(WBTC_CONTRACT, address)\n        lbtc_bal = cw20_balance(LBTC_CONTRACT, address)\n        return BalanceStatus(\n            has_wbtc=wbtc_bal >= MICRO_FACTOR,\n            has_lbtc=lbtc_bal >= MICRO_FACTOR,\n        )\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"get_supervault_contract_address": "def get_supervault_contract_address():\n    \"\"\"Simple helper so the frontend can discover the Supervault contract.\"\"\"\n    return {\n        'supervault_address': os.getenv('SUPERVAULT_CONTRACT', 'neutron1supervaultxxxxxxxxxxxxxxxxxxxxxx')\n    }",
	"construct_tx_supervault_deposit": "def construct_tx_supervault_deposit(address: str):\n    \"\"\"Creates an unsigned deposit Tx and returns the raw bytes (base64).\"\"\"\n    try:\n        # Payload that the Supervault expects (often empty for simple deposits)\n        deposit_msg = {\"deposit\": {}}\n        deposit_payload_b64 = base64.b64encode(json.dumps(deposit_msg).encode()).decode()\n\n        def build_cw20_send(token_contract: str):\n            return {\n                \"typeUrl\": \"/cosmwasm.wasm.v1.MsgExecuteContract\",\n                \"value\": {\n                    \"sender\": address,\n                    \"contract\": token_contract,\n                    \"msg\": base64.b64encode(json.dumps({\n                        \"send\": {\n                            \"contract\": SUPERVAULT_CONTRACT,\n                            \"amount\": str(MICRO_FACTOR),  # 1 token\n                            \"msg\": deposit_payload_b64\n                        }\n                    }).encode()).decode(),\n                    \"funds\": []\n                }\n            }\n\n        # Compose both messages\n        msgs = [build_cw20_send(WBTC_CONTRACT), build_cw20_send(LBTC_CONTRACT)]\n\n        tx = Transaction()\n        for m in msgs:\n            tx.add_message(m[\"value\"])\n\n        # Gas/fee estimates — tune to production needs\n        tx.set_fee(5000, \"untrn\")\n        tx.set_gas(400000)\n\n        unsigned_tx = tx.get_unsigned()\n        return {\"tx_bytes\": base64.b64encode(unsigned_tx.SerializeToString()).decode()}\n\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"load_app_config": "def load_app_config(chain_id: str):\n    \"\"\"Load ~/.<chain-id>/config/app.toml and return a (config_dict, file_path) tuple.\"\"\"\n    config_path = os.path.expanduser(f\"~/.{chain_id}/config/app.toml\")\n\n    if not os.path.isfile(config_path):\n        raise FileNotFoundError(f\"app.toml not found at {config_path}\")\n\n    try:\n        with open(config_path, \"r\", encoding=\"utf-8\") as fp:\n            config = toml.load(fp)\n    except Exception as err:\n        raise RuntimeError(f\"Failed to parse {config_path}: {err}\")\n\n    return config, config_path",
	"enable_grpc": "def enable_grpc(chain_id: str, address: str = \":9090\"):\n    \"\"\"Enable gRPC and set its listen address (default :9090).\"\"\"\n    config, path = load_app_config(chain_id)\n\n    grpc_cfg = config.get(\"grpc\", {})\n    grpc_cfg[\"enable\"] = True\n    if address:\n        grpc_cfg[\"address\"] = address\n    config[\"grpc\"] = grpc_cfg\n\n    # Persist changes back to disk\n    with open(path, \"w\", encoding=\"utf-8\") as fp:\n        toml.dump(config, fp)\n\n    return {\"status\": \"success\", \"path\": path, \"grpc\": grpc_cfg}",
	"enable_swagger": "def enable_swagger(chain_id: str, address: str = \"tcp://0.0.0.0:1317\"):\n    \"\"\"Enable Swagger UI and REST API address.\"\"\"\n    config, path = load_app_config(chain_id)\n\n    api_cfg = config.get(\"api\", {})\n    api_cfg[\"swagger\"] = True\n    api_cfg[\"address\"] = address\n    config[\"api\"] = api_cfg\n\n    with open(path, \"w\", encoding=\"utf-8\") as fp:\n        toml.dump(config, fp)\n\n    return {\"status\": \"success\", \"path\": path, \"api\": api_cfg}",
	"check_endpoints": "def check_endpoints(grpc_addr: str = \"localhost:9090\", swagger_url: str = \"http://localhost:1317/swagger/\"):\n    \"\"\"Return a list of gRPC services and whether the Swagger UI is reachable.\"\"\"\n    # Check gRPC services\n    try:\n        result = subprocess.run([\n            \"grpcurl\", \"-plaintext\", grpc_addr, \"list\"\n        ], capture_output=True, text=True, check=True)\n        grpc_services = result.stdout.strip().splitlines()\n    except subprocess.CalledProcessError as err:\n        raise RuntimeError(f\"grpcurl failed: {err.stderr}\")\n\n    # Check Swagger UI\n    try:\n        resp = requests.get(swagger_url, timeout=5)\n        swagger_ok = resp.status_code == 200\n    except requests.RequestException:\n        swagger_ok = False\n\n    return {\n        \"grpc_services\": grpc_services,\n        \"swagger_reachable\": swagger_ok\n    }",
	"ibc_transfer": "def ibc_transfer(req: IbcTransferRequest):\n    try:\n        net_cfg = NETWORKS.get(req.chain_id)\n        if not net_cfg:\n            raise HTTPException(status_code=400, detail=f'Unsupported chain_id {req.chain_id}')\n\n        mnemonic = os.getenv('MNEMONIC')\n        if not mnemonic:\n            raise HTTPException(status_code=500, detail='Backend mis-configuration: MNEMONIC environment variable not set')\n\n        wallet = LocalWallet.from_mnemonic(mnemonic, prefix=net_cfg.address_prefix)\n        client = LedgerClient(net_cfg)\n\n        msg = MsgTransfer(\n            source_port=req.port_id,\n            source_channel=req.channel_id,\n            token={'denom': req.denom, 'amount': str(req.amount)},\n            sender=wallet.address(),\n            receiver=req.receiver,\n            timeout_height=Height(revision_number=0, revision_height=0),\n            timeout_timestamp=req.timeout_timestamp,\n        )\n\n        tx = Transaction()\n        tx.add_message(msg)\n        tx.seal(client, wallet)\n        tx.sign(wallet)\n\n        broadcast_result = client.broadcast_transaction(tx)\n        if broadcast_result.code != 0:\n            raise HTTPException(\n                status_code=400,\n                detail=f'Broadcast failed (code={broadcast_result.code}): {broadcast_result.raw_log}',\n            )\n\n        return {'tx_hash': broadcast_result.tx_hash}\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"_wait_for_tx": "def _wait_for_tx(client: LedgerClient, tx_hash: str, poll_interval: int = 5, max_attempts: int = 60):\n    attempts = 0\n    while attempts < max_attempts:\n        tx_resp = client.query_tx(tx_hash)\n        if tx_resp:\n            if tx_resp.code == 0:\n                return {'status': 'success', 'tx_response': tx_resp}\n            else:\n                raise HTTPException(status_code=400, detail=f'Transaction failed (code={tx_resp.code}): {tx_resp.raw_log}')\n        await asyncio.sleep(poll_interval)\n        attempts += 1\n    raise HTTPException(status_code=504, detail='Timed out waiting for transaction confirmation')\n\n@app.get('/api/tx_status/{chain_id}/{tx_hash}')\nasync def tx_status(chain_id: str, tx_hash: str):\n    net_cfg = NETWORKS.get(chain_id)\n    if not net_cfg:\n        raise HTTPException(status_code=400, detail=f'Unsupported chain {chain_id}')\n    client = LedgerClient(net_cfg)\n    return await _wait_for_tx(client, tx_hash)",
	"validate_snapshot_archive": "def validate_snapshot_archive(archive_path: str, expected_checksum: str = None, expected_chain_id: str = None):\n    \"\"\"\n    Validate a snapshot archive by checking file existence, SHA-256 checksum, and chain-id.\n\n    Args:\n        archive_path (str): Path to the snapshot .tar.gz file.\n        expected_checksum (str, optional): Expected SHA-256 hex string.\n        expected_chain_id (str, optional): Expected chain-id to compare with the genesis inside the archive.\n\n    Returns:\n        dict: Validation summary containing the computed checksum.\n\n    Raises:\n        FileNotFoundError: If the archive is missing.\n        ValueError: On checksum or chain-id mismatch.\n    \"\"\"\n    archive = Path(archive_path)\n    if not archive.is_file():\n        raise FileNotFoundError(f\"Snapshot archive {archive} not found.\")\n\n    # Compute SHA-256\n    sha256 = hashlib.sha256()\n    with archive.open(\"rb\") as f:\n        for chunk in iter(lambda: f.read(8192), b\"\"):\n            sha256.update(chunk)\n    computed_checksum = sha256.hexdigest()\n\n    if expected_checksum and computed_checksum.lower() != expected_checksum.lower():\n        raise ValueError(f\"Checksum mismatch. Expected {expected_checksum}, got {computed_checksum}\")\n\n    if expected_chain_id:\n        # Peek inside the archive for a genesis.json file\n        try:\n            with tarfile.open(archive, \"r:gz\") as tar:\n                for member in tar.getmembers():\n                    if member.name.endswith(\"genesis.json\"):\n                        f = tar.extractfile(member)\n                        if f:\n                            genesis = json.load(f)\n                            chain_id = genesis.get(\"chain_id\")\n                            if chain_id != expected_chain_id:\n                                raise ValueError(f\"Chain-ID mismatch. Expected {expected_chain_id}, got {chain_id}\")\n                            break\n        except tarfile.TarError as err:\n            raise ValueError(f\"Unable to inspect archive: {err}\")\n\n    return {\n        \"archive\": str(archive),\n        \"checksum\": computed_checksum,\n        \"valid\": True\n    }",
	"backup_and_remove_data": "def backup_and_remove_data(node_home: str, backup_root: str = None):\n    \"\"\"\n    Copy `<home>/data` to a timestamped backup directory and then remove the original.\n\n    Args:\n        node_home (str): Path returned by `get_node_home()`.\n        backup_root (str, optional): Directory where backups will be stored. Defaults to `<home>/backup-<timestamp>`.\n\n    Returns:\n        str: Path to the backup directory that was created.\n    \"\"\"\n    data_dir = Path(node_home) / \"data\"\n    if not data_dir.exists():\n        raise FileNotFoundError(f\"Data directory {data_dir} does not exist.\")\n\n    timestamp = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n    backup_root = Path(backup_root) if backup_root else Path(node_home) / f\"backup-{timestamp}\"\n    backup_root.mkdir(parents=True, exist_ok=True)\n\n    shutil.copytree(data_dir, backup_root / \"data\", dirs_exist_ok=True)\n    # Remove original data directory after successful copy\n    shutil.rmtree(data_dir)\n\n    return str(backup_root)",
	"construct_simd_start_command": "def construct_simd_start_command(node_home: str, extra_flags: str = \"\") -> str:\n    \"\"\"\n    Build a fully-qualified `simd start` command string.\n    \"\"\"\n    base_cmd = f\"simd start --home={node_home}\"\n    full_cmd = f\"{base_cmd} {extra_flags}\".strip()\n    return full_cmd",
	"query_node_status": "def query_node_status(rpc_url: str = \"http://localhost:26657\"):\n    \"\"\"\n    Fetch `/status` from the local Tendermint RPC and return selected fields.\n    \"\"\"\n    try:\n        response = requests.get(f\"{rpc_url}/status\", timeout=5)\n        response.raise_for_status()\n        data = response.json()\n        info = data[\"result\"]\n        return {\n            \"network\": info[\"node_info\"][\"network\"],\n            \"latest_height\": int(info[\"sync_info\"][\"latest_block_height\"]),\n            \"catching_up\": info[\"sync_info\"][\"catching_up\"]\n        }\n    except Exception as err:\n        raise RuntimeError(f\"Failed to query node status: {err}\")",
	"get_supervault_share_balance": "def get_supervault_share_balance(address: str):\n    \"\"\"Return the amount of Supervault shares owned by `address`.\"\"\"\n    try:\n        if not SUPER_VAULT_CONTRACT:\n            raise ValueError('SUPER_VAULT_CONTRACT env var not set')\n\n        # Connect to public Neutron endpoints\n        client = LedgerClient(NETWORKS[CHAIN_ID])\n\n        # Contract-specific query (may differ in your implementation)\n        query_msg = {\n            'share': {\n                'owner': address,\n            }\n        }\n\n        result = client.query_contract_smart(SUPER_VAULT_CONTRACT, query_msg)\n        shares_raw = int(result.get('shares', '0'))\n        return {'shares': shares_raw}\n\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"prepare_withdraw": "def prepare_withdraw(req: PrepareWithdrawRequest):\n    \"\"\"Returns components required for a DIRECT-SIGN transaction.\"\"\"\n    try:\n        if not SUPER_VAULT_CONTRACT:\n            raise ValueError('SUPER_VAULT_CONTRACT env var not set')\n\n        ledger = LedgerClient(NETWORKS[CHAIN_ID])\n        acct = ledger.query_account(req.address)\n\n        # Contract-level execute message\n        execute_msg = {\n            'withdraw': {\n                'shares': str(req.shares_to_withdraw)\n            }\n        }\n\n        msg = MsgExecuteContract(\n            sender=req.address,\n            contract_address=SUPER_VAULT_CONTRACT,\n            msg=execute_msg,\n            funds=[],\n        )\n\n        tx = (\n            Transaction()\n            .with_messages(msg)\n            .with_sequence(acct.sequence)\n            .with_account_number(acct.account_number)\n            .with_chain_id(CHAIN_ID)\n            .with_gas(300000)\n            .with_fee('2000untrn')  # Adjust fee & gas to your needs\n        )\n\n        body_bytes, auth_info_bytes, _ = tx.to_sign_doc()\n\n        return PrepareWithdrawResponse(\n            body_bytes=base64.b64encode(body_bytes).decode(),\n            auth_info_bytes=base64.b64encode(auth_info_bytes).decode(),\n            account_number=acct.account_number,\n            chain_id=CHAIN_ID,\n        )\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"broadcast_withdraw": "def broadcast_withdraw(req: BroadcastWithdrawRequest):\n    \"\"\"Takes the signed tx fragments, creates TxRaw, broadcasts, and returns the tx-hash.\"\"\"\n    try:\n        body_bytes = base64.b64decode(req.body_bytes)\n        auth_info_bytes = base64.b64decode(req.auth_info_bytes)\n        signature = base64.b64decode(req.signature)\n\n        tx_raw = TxRaw(\n            body_bytes=body_bytes,\n            auth_info_bytes=auth_info_bytes,\n            signatures=[signature],\n        )\n\n        ledger = LedgerClient(NETWORKS[CHAIN_ID])\n        result = ledger.broadcast_tx(tx_raw.SerializeToString())\n\n        if result.code != 0:\n            raise ValueError(f'Tx failed with code {result.code}: {result.raw_log}')\n\n        return {'txhash': result.txhash}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"supervault_positions": "def supervault_positions(req: PositionsRequest):\n    \"\"\"Query Supervault for user positions via WASM smart-contract call.\"\"\"\n    try:\n        # Public Neutron main-net endpoints (no secrets required)\n        cfg = NetworkConfig(\n            chain_id='neutron-1',\n            lcd_url='https://rest-kralum.neutron-1.neutron.org',\n            grpc_url='grpc://grpc-kralum.neutron-1.neutron.org:443'\n        )\n\n        client = LedgerClient(cfg)\n\n        query_msg = {\n            'positions_by_user': {\n                'address': req.user_address\n            }\n        }\n\n        # Perform the query against Supervault\n        positions = client.query_contract(\n            contract_address=req.contract_address,\n            query=query_msg\n        )\n\n        return {'positions': positions}\n\n    except Exception as e:\n        # Always wrap low-level errors so the frontend gets a clean message\n        raise HTTPException(status_code=500, detail=str(e))",
	"_check_simd_binary": "def _check_simd_binary():\n    '''Verify that the `simd` binary exists in the user PATH and is executable.'''\n    simd_path = shutil.which(\"simd\")\n    if simd_path is None:\n        raise FileNotFoundError(\"`simd` binary not found in your PATH. Have you installed simd?\")\n    try:\n        result = subprocess.run(\n            [simd_path, \"version\"],\n            capture_output=True,\n            text=True,\n            check=True,\n            timeout=10\n        )\n    except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as exc:\n        raise RuntimeError(f\"`simd` binary found but not executable: {exc}\")\n    return {\"simd_path\": simd_path, \"version\": result.stdout.strip()}\n\n@router.get(\"/api/check_simd\")\nasync def check_simd():\n    '''HTTP endpoint that returns the path and version of the `simd` binary.'''\n    try:\n        return _check_simd_binary()\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"_construct_start_command": "def _construct_start_command(home_dir: str) -> str:\n    '''Return a safe string for starting simd with custom flags.'''\n    if not home_dir:\n        raise ValueError('home_dir parameter is required')\n    expanded_home = os.path.expanduser(home_dir)\n    # Ensure path exists\n    if not os.path.isdir(expanded_home):\n        raise FileNotFoundError(f'Provided home directory does not exist: {expanded_home}')\n    # Quote the directory to avoid shell injection\n    quoted_home = shlex.quote(expanded_home)\n    return f'simd start --mempool.max-txs=-1 --home={quoted_home}'\n\n@router.post('/api/build_start_cmd')\nasync def build_start_cmd(payload: dict):\n    '''Endpoint that returns the full `simd start` command string.'''\n    try:\n        home_dir = payload.get('home')\n        cmd = _construct_start_command(home_dir)\n        return {'command': cmd}\n    except Exception as exc:\n        raise HTTPException(status_code=400, detail=str(exc))",
	"_start_simd_process": "def _start_simd_process(command: str):\n    if _process_holder['proc'] is not None:\n        raise RuntimeError('A simd process is already running.')\n    args = shlex.split(command)\n    proc = subprocess.Popen(\n        args,\n        stdout=subprocess.PIPE,\n        stderr=subprocess.STDOUT,\n        text=True,\n        bufsize=1\n    )\n    _process_holder['proc'] = proc\n    return {'pid': proc.pid}\n\n@router.post('/api/start_simd')\nasync def start_simd(payload: dict):\n    try:\n        command = payload.get('command')\n        return _start_simd_process(command)\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"_log_streamer": "def _log_streamer():\n    proc = _process_holder.get('proc')\n    if proc is None or proc.stdout is None:\n        yield 'data: simd process not running\\n\\n'\n        return\n    while True:\n        line = proc.stdout.readline()\n        if line:\n            yield f'data: {line.rstrip()}\\n\\n'\n        await asyncio.sleep(0.05)\n        if proc.poll() is not None:\n            break\n    yield 'data: **simd process ended**\\n\\n'\n\n@router.get('/api/simd_logs')\nasync def simd_logs():\n    return StreamingResponse(_log_streamer(), media_type='text/event-stream')",
	"_cli_status": "def _cli_status():\n    res = subprocess.run(['simd', 'status'], capture_output=True, text=True, check=True)\n    return res.stdout\n\ndef _rpc_status(rpc_url: str):\n    r = requests.get(f'{rpc_url.rstrip('/')}/status')\n    r.raise_for_status()\n    return r.json()\n\n@router.get('/api/simd_status')\nasync def simd_status(rpc: str = 'http://localhost:26657'):\n    try:\n        try:\n            return _rpc_status(rpc)\n        except Exception:\n            # Fallback to CLI if RPC fails\n            return {'raw': _cli_status()}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"find_block": "def find_block(timestamp: int, rpc_url: str):\n    \"\"\"Return the block number closest to a given Unix timestamp.\"\"\"\n\n    # Basic sanity-checks -----------------------------------------------------\n    if timestamp <= 0:\n        raise HTTPException(status_code=400, detail='Timestamp must be > 0')\n    if not re.match(r'^https?://', rpc_url):\n        raise HTTPException(status_code=400, detail='rpc_url must start with http(s)://')\n\n    # Build the cast command --------------------------------------------------\n    cmd = [\n        'cast', 'find-block',\n        '--timestamp', str(timestamp),\n        '--rpc-url', rpc_url.strip()\n    ]\n\n    try:\n        # Run the process with a 10-second safety timeout\n        proc = run(cmd, capture_output=True, text=True, check=True, timeout=10)\n        block_no_str = proc.stdout.strip()\n\n        # cast normally returns a decimal block number, but guard against hex\n        try:\n            block_no = int(block_no_str, 0)\n        except ValueError:\n            block_no = block_no_str  # keep as string if it cannot be parsed\n\n        return JSONResponse({\n            'timestamp': timestamp,\n            'rpc_url': rpc_url,\n            'block_number': block_no\n        })\n\n    except CalledProcessError as e:\n        # CLI returned non-zero exit status\n        raise HTTPException(status_code=500, detail=f\"cast error: {e.stderr.strip()}\")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"compile_tests": "def compile_tests() -> Dict[str, str]:\n    \"\"\"Run `forge build` to compile the project’s contracts.\n\n    Returns\n    -------\n    Dict[str, str]\n        success : bool   - True if the build succeeded (exit-code 0).\n        stdout  : str    - Standard output from the CLI.\n        stderr  : str    - Standard error from the CLI (compiler warnings / errors).\n    \"\"\"\n    try:\n        result = subprocess.run(\n            [\"forge\", \"build\"],\n            capture_output=True,\n            text=True,\n            check=False  # Allow us to capture non-zero exit codes instead of raising.\n        )\n        return {\n            \"success\": result.returncode == 0,\n            \"stdout\": result.stdout,\n            \"stderr\": result.stderr,\n        }\n    except FileNotFoundError:\n        # The user does not have Foundry installed or forge is not in PATH.\n        return {\n            \"success\": False,\n            \"stdout\": \"\",\n            \"stderr\": \"Forge CLI not found. Please install Foundry and ensure `forge` is available in PATH.\",\n        }\n    except Exception as exc:\n        # Catch-all for any other unexpected error.\n        return {\n            \"success\": False,\n            \"stdout\": \"\",\n            \"stderr\": str(exc),\n        }",
	"execute_forge_test_fuzz": "def execute_forge_test_fuzz(fuzz_runs: int = 500) -> Dict[str, str]:\n    \"\"\"Run `forge test --fuzz-runs <N>`.\n\n    Parameters\n    ----------\n    fuzz_runs : int\n        Number of fuzz iterations you wish to run. Must be > 0.\n\n    Returns\n    -------\n    Dict[str, str]\n        success : bool   - True if all tests passed (exit-code 0).\n        stdout  : str    - Standard output of the test run.\n        stderr  : str    - Standard error of the test run.\n    \"\"\"\n    if fuzz_runs <= 0:\n        return {\n            \"success\": False,\n            \"stdout\": \"\",\n            \"stderr\": \"`fuzz_runs` must be a positive integer.\",\n        }\n\n    cmd = [\"forge\", \"test\", \"--fuzz-runs\", str(fuzz_runs)]\n    try:\n        result = subprocess.run(cmd, capture_output=True, text=True, check=False)\n        return {\n            \"success\": result.returncode == 0,\n            \"stdout\": result.stdout,\n            \"stderr\": result.stderr,\n        }\n    except FileNotFoundError:\n        return {\n            \"success\": False,\n            \"stdout\": \"\",\n            \"stderr\": \"Forge CLI not found. Please install Foundry and ensure `forge` is available in PATH.\",\n        }\n    except Exception as exc:\n        return {\n            \"success\": False,\n            \"stdout\": \"\",\n            \"stderr\": str(exc),\n        }",
	"review_test_output": "def review_test_output(forge_stdout: str) -> Dict[str, object]:\n    \"\"\"Analyse `forge test` output and summarise failures.\n\n    Parameters\n    ----------\n    forge_stdout : str\n        Raw standard-output from a Forge test run.\n\n    Returns\n    -------\n    Dict[str, object]\n        failed      : bool     - True if any test failed.\n        fail_cases  : List[str]- Lines that hint at failures or reverts.\n        raw_output  : str      - Echo back the original output for reference.\n    \"\"\"\n    failure_regex = re.compile(r\"(FAIL|revert|Assertion|Error)\", re.IGNORECASE)\n    fail_cases: List[str] = []\n\n    for line in forge_stdout.splitlines():\n        if failure_regex.search(line):\n            fail_cases.append(line.strip())\n\n    return {\n        \"failed\": len(fail_cases) > 0,\n        \"fail_cases\": fail_cases,\n        \"raw_output\": forge_stdout,\n    }",
	"open_celatone_explorer": "def open_celatone_explorer(chain_id: str, download_dir: str = \"/tmp\") -> webdriver.Chrome:\n    \"\"\"Launch Celatone (https://celatone.osmosis.zone) for the given chain and\n    return an initialized Selenium WebDriver.\n\n    Args:\n        chain_id (str): Either \"neutron-1\" (mainnet) or \"pion-1\" (testnet).\n        download_dir (str): Directory where Celatone will drop the metadata JSON.\n\n    Returns:\n        webdriver.Chrome: A configured Chrome WebDriver pointing at Celatone.\n    \"\"\"\n\n    if chain_id not in (\"neutron-1\", \"pion-1\"):\n        raise ValueError(\"Unsupported chain id. Use 'neutron-1' or 'pion-1'.\")\n\n    url = f\"https://celatone.osmosis.zone/{chain_id}\"\n\n    # Configure Chrome for head-less use and automatic downloads\n    chrome_opts = Options()\n    chrome_opts.add_argument(\"--headless=new\")\n    chrome_opts.add_argument(\"--window-size=1920,1080\")\n    chrome_opts.add_experimental_option(\n        \"prefs\",\n        {\n            \"download.default_directory\": download_dir,\n            \"download.prompt_for_download\": False,\n            \"download.directory_upgrade\": True,\n            \"safebrowsing.enabled\": True,\n        },\n    )\n\n    try:\n        driver = webdriver.Chrome(options=chrome_opts)\n        driver.get(url)\n\n        # Wait until the search bar is rendered so we know the page finished loading\n        WebDriverWait(driver, 15).until(\n            EC.presence_of_element_located((\"css selector\", \"input[type='search']\"))\n        )\n        return driver\n    except WebDriverException as exc:\n        raise RuntimeError(f\"Failed to open Celatone explorer: {exc}\") from exc",
	"search_contract_address": "def search_contract_address(driver: webdriver.Chrome, contract_address: str, timeout: int = 15) -> None:\n    \"\"\"Paste the contract address into Celatone's search bar and navigate to the\n    contract page.\n\n    Args:\n        driver (webdriver.Chrome): Active Celatone WebDriver.\n        contract_address (str): Bech32 address of the target contract.\n        timeout (int): Max seconds to wait for the contract page to load.\n    \"\"\"\n\n    try:\n        # Locate the search bar element and submit the address\n        search_box = driver.find_element(By.CSS_SELECTOR, \"input[type='search']\")\n        search_box.clear()\n        search_box.send_keys(contract_address + Keys.ENTER)\n\n        # Wait until URL contains the contract address, indicating navigation\n        WebDriverWait(driver, timeout).until(\n            EC.url_contains(contract_address.lower())\n        )\n    except TimeoutException:\n        raise RuntimeError(\"Celatone did not navigate to the contract page in time.\")",
	"navigate_to_metadata_tab": "def navigate_to_metadata_tab(driver: webdriver.Chrome, timeout: int = 10) -> None:\n    \"\"\"Click Celatone's \"Metadata\" tab for the currently opened contract page.\"\"\"\n    try:\n        # The tab usually appears as a button or anchor containing the visible text \"Metadata\"\n        metadata_tab = WebDriverWait(driver, timeout).until(\n            EC.element_to_be_clickable((By.XPATH, \"//button[contains(., 'Metadata')] | //a[contains(., 'Metadata')]\"))\n        )\n        metadata_tab.click()\n\n        # Wait until the JSON download (</>) icon is visible in the Metadata view\n        WebDriverWait(driver, timeout).until(\n            EC.presence_of_element_located((By.XPATH, \"//button[contains(@title, 'Download') or contains(@aria-label, 'Download')]\"))\n        )\n    except (TimeoutException, NoSuchElementException):\n        raise RuntimeError(\"Could not open the Metadata tab on Celatone.\")",
	"download_metadata_json": "def download_metadata_json(driver: webdriver.Chrome, download_dir: str, timeout: int = 30) -> Path:\n    \"\"\"Click the download button and wait until the metadata JSON is fully\n    written to disk.\n\n    Args:\n        driver (webdriver.Chrome): Active WebDriver on the Metadata tab.\n        download_dir (str): Directory configured in open_celatone_explorer().\n        timeout (int): Max seconds to wait for the file to finish downloading.\n\n    Returns:\n        Path: Absolute path to the downloaded metadata JSON file.\n    \"\"\"\n\n    # Grab a snapshot of existing files so we can detect the new one later\n    pre_existing = set(Path(download_dir).iterdir()) if os.path.isdir(download_dir) else set()\n\n    # Click the download (code / </>) button\n    try:\n        download_btn = driver.find_element(By.XPATH, \"//button[contains(@title, 'Download') or contains(@aria-label, 'Download')]\")\n        download_btn.click()\n    except Exception as exc:\n        raise RuntimeError(\"Failed to click Celatone's download button\") from exc\n\n    # Poll for a new .json file that was not present earlier\n    end_time = time.time() + timeout\n    while time.time() < end_time:\n        current_files = set(Path(download_dir).iterdir())\n        new_files = [f for f in current_files - pre_existing if f.suffix.lower() == \".json\"]\n        if new_files:\n            # Celatone sometimes writes a *.crdownload first; wait until file stabilises.\n            candidate = new_files[0]\n            if not candidate.name.endswith(\".crdownload\"):\n                return candidate.resolve()\n        time.sleep(0.5)\n\n    raise TimeoutException(\"Timed out waiting for metadata JSON download to complete.\")",
	"query_cron_list_schedules": "def query_cron_list_schedules(node_url: str = \"https://rest.kralum.neutron-1.neutron.org\") -> list:\n    \"\"\"Fetch the list of cron schedules from a Neutron REST endpoint.\n\n    Args:\n        node_url: Base URL of the Neutron REST API (without a trailing slash).\n\n    Returns:\n        A list of schedule objects returned by the chain.\n\n    Raises:\n        RuntimeError: If the request fails or the response cannot be parsed.\n    \"\"\"\n    # Ensure the base URL has no trailing slash to avoid errors when composing the endpoint.\n    base_url = node_url.rstrip(\"/\")\n    endpoint = f\"{base_url}/neutron/cron/schedules\"\n\n    try:\n        response = requests.get(endpoint, timeout=10)\n        response.raise_for_status()\n    except requests.RequestException as exc:\n        raise RuntimeError(f\"Failed to query cron schedules: {exc}\") from exc\n\n    try:\n        json_data = response.json()\n    except ValueError as exc:\n        raise RuntimeError(\"Received invalid JSON from the Neutron REST endpoint\") from exc\n\n    # The REST API generally returns `{ \\\"schedules\\\": [...] }`.\n    return json_data.get(\"schedules\", [])\n",
	"schedule_removed": "def schedule_removed(name: str) -> bool:\n    \"\"\"Returns True only if the schedule no longer exists.\"\"\"\n    try:\n        # neutrond must be in $PATH and already configured for neutron-1\n        out = subprocess.run(\n            [\n                \"neutrond\",\n                \"query\",\n                \"cron\",\n                \"show-schedule\",\n                name,\n                \"--output=json\"\n            ],\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n        # If the command succeeds, the schedule is still present\n        print(f\"Schedule still exists: {out.stdout}\")\n        return False\n    except subprocess.CalledProcessError as err:\n        # Cron module returns non-zero + \"not found\" when the schedule is gone\n        if \"not found\" in err.stderr.lower():\n            return True\n        raise",
	"query_contracts_by_creator": "def query_contracts_by_creator(\n    creator_address: str,\n    limit: int = 1000,\n    pagination_key: Optional[str] = None,\n) -> Dict[str, Any]:\n    \"\"\"Query one page of contracts created by `creator_address`.\n\n    Args:\n        creator_address (str): Bech32 Neutron address.\n        limit (int, optional): Maximum results per page. Defaults to 1000.\n        pagination_key (str, optional): The opaque `next_key` from the previous\n            response. If provided, the query continues from that key.\n\n    Returns:\n        Dict[str, Any]: JSON response from the LCD containing contracts and pagination data.\n    \"\"\"\n    params = {\n        \"creator\": creator_address,\n        \"pagination.limit\": str(limit),\n    }\n    if pagination_key:\n        params[\"pagination.key\"] = pagination_key\n\n    url = f\"{LCD_URL}/cosmwasm/wasm/v1/contracts\"\n\n    async with httpx.AsyncClient(timeout=10) as client:\n        response = await client.get(url, params=params)\n        response.raise_for_status()  # Raises if HTTP != 200\n        return response.json()\n",
	"fetch_all_contracts_by_creator": "def fetch_all_contracts_by_creator(creator_address: str, page_limit: int = 1000) -> List[str]:\n    \"\"\"Return a complete list of contract addresses deployed by `creator_address`.\"\"\"\n    contracts: List[str] = []\n    next_key: Optional[str] = None\n\n    while True:\n        page = await query_contracts_by_creator(\n            creator_address=creator_address,\n            limit=page_limit,\n            pagination_key=next_key,\n        )\n\n        # Extract contracts list from page data and extend our accumulator\n        contracts.extend(page.get(\"contracts\", []))\n\n        # Determine if more pages exist\n        next_key = page.get(\"pagination\", {}).get(\"next_key\")\n        if not next_key:\n            break  # No more pages\n\n    return contracts\n\n# Example standalone execution for quick testing\nif __name__ == \"__main__\":\n    address = \"neutron1...\"  # Replace with a real creator address\n    all_contracts = asyncio.run(fetch_all_contracts_by_creator(address))\n    print(f\"Total contracts found: {len(all_contracts)}\")\n    for idx, c in enumerate(all_contracts, start=1):\n        print(f\"{idx}. {c}\")\n",
	"broadcast_raw_tx": "def broadcast_raw_tx(request: Request):\n    \"\"\"Broadcast an already-signed RLP-encoded transaction and return its tx-hash.\"\"\"\n    body = await request.json()\n    raw_tx = body.get('raw_tx')\n\n    # Basic validation.\n    if not raw_tx or not raw_tx.startswith('0x'):\n        raise HTTPException(status_code=400, detail='Invalid raw transaction hex string.')\n\n    # Compose the JSON-RPC payload.\n    payload = {\n        'jsonrpc': '2.0',\n        'method': 'eth_sendRawTransaction',\n        'params': [raw_tx],\n        'id': 1\n    }\n\n    try:\n        rpc_resp = requests.post(RPC_URL, json=payload, timeout=30)\n        rpc_resp.raise_for_status()\n        data = rpc_resp.json()\n\n        # Handle any RPC-level error returned by the node.\n        if 'error' in data:\n            raise HTTPException(status_code=500, detail=data['error']['message'])\n\n        # Success: return the tx-hash to the caller.\n        return {'tx_hash': data['result']}\n    except requests.RequestException as exc:\n        # Network-level failure.\n        raise HTTPException(status_code=500, detail=str(exc))",
	"tx_receipt": "def tx_receipt(tx_hash: str):\n    \"\"\"Return the transaction receipt (or null if not yet mined).\"\"\"\n    if not tx_hash or not tx_hash.startswith('0x'):\n        raise HTTPException(status_code=400, detail='Invalid transaction hash.')\n\n    payload = {\n        'jsonrpc': '2.0',\n        'method': 'eth_getTransactionReceipt',\n        'params': [tx_hash],\n        'id': 1\n    }\n\n    try:\n        rpc_resp = requests.post(RPC_URL, json=payload, timeout=30)\n        rpc_resp.raise_for_status()\n        data = rpc_resp.json()\n\n        if 'error' in data:\n            raise HTTPException(status_code=500, detail=data['error']['message'])\n\n        # data['result'] is either the receipt object or null if the tx is pending.\n        return {'receipt': data['result']}\n    except requests.RequestException as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"update_node_start_flags": "def update_node_start_flags(service_name: str = SERVICE_NAME, flag: str = CPU_PROFILE_FLAG):\n    \"\"\"Append a CPU-profiling flag to the ExecStart line of a systemd service.\n\n    1. Backs up the original unit file to `/etc/systemd/system/<service>.bak`.\n    2. Appends the profiling flag if it is not already present.\n    3. Reloads systemd so the change takes effect.\n    \"\"\"\n    unit_path = Path(\"/etc/systemd/system\") / service_name\n    backup_path = unit_path.with_suffix(\".bak\")\n\n    if not unit_path.exists():\n        raise FileNotFoundError(f\"Service file {unit_path} not found. Run on the host where the node is installed.\")\n\n    # Backup first\n    if not backup_path.exists():\n        shutil.copy(unit_path, backup_path)\n\n    # Read & update\n    with unit_path.open(\"r\") as f:\n        lines = f.readlines()\n\n    updated_lines = []\n    exec_found = False\n    for line in lines:\n        if line.startswith(\"ExecStart=\"):\n            exec_found = True\n            if flag not in line:\n                # Insert the profiling flag just before the linebreak\n                parts = line.strip().split(\" \")\n                parts.insert(-1, flag)\n                line = \" \".join(parts) + \"\\n\"\n        updated_lines.append(line)\n\n    if not exec_found:\n        raise ValueError(\"No ExecStart entry found in service file. Manual intervention required.\")\n\n    with unit_path.open(\"w\") as f:\n        f.writelines(updated_lines)\n\n    # Reload systemd\n    subprocess.run([\"systemctl\", \"daemon-reload\"], check=True)\n    print(f\"[✔] {service_name} updated with CPU profiling flag.\")\n\n# Example direct call (uncomment when running as root)\n# update_node_start_flags()",
	"check_profile_growth": "def check_profile_growth(profile_path: Path = PROFILE_PATH, wait_seconds: int = 5):\n    \"\"\"Checks that the profile file exists and increases in size over a short interval.\"\"\"\n    if not profile_path.exists():\n        raise FileNotFoundError(f\"{profile_path} does not exist. Did you enable profiling?\")\n\n    size_before = profile_path.stat().st_size\n    time.sleep(wait_seconds)\n    size_after = profile_path.stat().st_size\n\n    if size_after > size_before:\n        print(f\"[✔] cpu.prof is growing (size {size_before} → {size_after} bytes).\")\n    else:\n        raise RuntimeError(\"cpu.prof did not grow; profiling may not be active.\")\n\n# Example direct call\n# check_profile_growth()",
	"proxy_rpc": "def proxy_rpc(request: RpcRequest):\n    # Build a standard JSON-RPC 2.0 payload\n    payload = {\n        \"jsonrpc\": \"2.0\",\n        \"id\": uuid.uuid4().hex,\n        \"method\": request.method,\n        \"params\": request.params,\n    }\n\n    async with httpx.AsyncClient() as client:\n        try:\n            resp = await client.post(RPC_URL, json=payload, timeout=15)\n            resp.raise_for_status()\n        except (httpx.RequestError, httpx.HTTPStatusError) as e:\n            # Surface network/HTTP errors to the caller.\n            raise HTTPException(status_code=502, detail=str(e))\n\n    # Forward the JSON-RPC response (success or error) verbatim.\n    return resp.json()\n",
	"get_rpc_url": "def get_rpc_url(chain: str):\n    \"\"\"Return a pre-configured JSON-RPC endpoint for the requested chain.\"\"\"\n    if chain not in RPC_ENDPOINTS:\n        raise HTTPException(status_code=400, detail=f'Unsupported chain: {chain}')\n    return {\n        'chain': chain,\n        'rpc_url': RPC_ENDPOINTS[chain],\n    }",
	"get_chain_id": "def get_chain_id(rpc_url: str):\n    \"\"\"Return the EVM chain-ID reported by the given RPC URL using `cast`.\"\"\"\n    cmd = ['cast', 'chain-id', '--rpc-url', rpc_url]\n    try:\n        result = subprocess.run(\n            cmd,\n            capture_output=True,\n            text=True,\n            check=True,\n            timeout=10,\n        )\n        # `cast chain-id` prints the ID as plain text; convert to int for clarity.\n        chain_id = int(result.stdout.strip())\n        return {\n            'rpc_url': rpc_url,\n            'chain_id': chain_id,\n        }\n    except FileNotFoundError:\n        raise HTTPException(\n            status_code=500,\n            detail=\"Foundry 'cast' executable was not found in $PATH.\"\n        )\n    except subprocess.TimeoutExpired:\n        raise HTTPException(\n            status_code=500,\n            detail='Timeout while querying the chain-ID.'\n        )\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(\n            status_code=500,\n            detail=f'Failed to fetch chain-ID: {err.stderr}'\n        )\n    except ValueError:\n        raise HTTPException(\n            status_code=500,\n            detail='Non-numeric chain-ID returned by cast.'\n        )",
	"compile_application": "def compile_application():\n    \"\"\"Rebuild the chain binary with the freshly-added ABCI override.\"\"\"\n    try:\n        # `make install` compiles and copies the binary into $GOBIN.\n        subprocess.run([\"make\", \"install\"], check=True, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)\n        print(\"✅  Binary compiled and installed to $GOBIN.\")\n    except subprocess.CalledProcessError as exc:\n        print(\"❌  Compilation failed:\\n\", exc.stdout.decode())\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    compile_application()",
	"monitor_logs": "def monitor_logs():\n    try:\n        with open(LOG_PATH, \"r\") as fh:\n            matches = [line.strip() for line in fh if PATTERN.search(line)]\n        if matches:\n            print(\"🎉  Found %d PrepareProposal invocations:\" % len(matches))\n            for ln in matches:\n                print(\"   \", ln)\n        else:\n            print(\"⚠️   No PrepareProposal logs detected. Ensure the node ran long enough to produce a block and that logging level isn't filtering them out.\")\n    except FileNotFoundError:\n        print(\"node.log not found. Did you run Step 5?\")\n        sys.exit(1)\n\nif __name__ == \"__main__\":\n    monitor_logs()",
	"is_valid_base64": "def is_valid_base64(data: str) -> bool:\n    \"\"\"Performs a strict base64 validation (length & charset).\"\"\"\n    base64_regex = re.compile(r\"^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$\")\n    if not base64_regex.match(data):\n        return False\n    try:\n        base64.b64decode(data, validate=True)\n        return True\n    except Exception:\n        return False\n\n@app.post(\"/api/decode_tx\")\nasync def decode_tx(request: DecodeRequest):\n    # Step 1: sanity-check inside backend for extra safety\n    if not is_valid_base64(request.raw_tx):\n        raise HTTPException(status_code=400, detail=\"Invalid base64 provided.\")\n\n    # Step 2: call `simd tx decode <base64>` via subprocess\n    try:\n        result = subprocess.run(\n            [\"simd\", \"tx\", \"decode\", request.raw_tx],\n            capture_output=True,\n            text=True,\n            check=True,\n        )\n    except FileNotFoundError:\n        raise HTTPException(status_code=500, detail=\"simd binary not found on server.\")\n    except subprocess.CalledProcessError as err:\n        raise HTTPException(status_code=500, detail=f\"simd error: {err.stderr.strip()}\")\n\n    # Step 3: ensure stdout is valid JSON\n    try:\n        decoded_json = json.loads(result.stdout)\n    except json.JSONDecodeError:\n        raise HTTPException(status_code=500, detail=\"simd returned non-JSON output.\")\n\n    return decoded_json",
	"api_list_snapshots": "def api_list_snapshots(home: str):\n    \"\"\"Return `{ \"raw_output\": \"<stdout>\" }` containing the snapshot list.\"\"\"\n    try:\n        raw_output = _list_snapshots(home)\n        return {\"raw_output\": raw_output}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))\n\ndef _list_snapshots(home: str) -> str:\n    \"\"\"Helper that actually executes the shell commands.\"\"\"\n    commands = [\n        [\"simd\", \"snapshot\", \"list\", f\"--home={home}\"],\n        [\"ls\", \"-lh\", f\"{home}/data/snapshots\"]\n    ]\n    for cmd in commands:\n        try:\n            result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n            if result.stdout.strip():\n                return result.stdout\n        except FileNotFoundError:\n            # Command not available; try next\n            continue\n        except subprocess.CalledProcessError:\n            # Command failed; try next\n            continue\n    raise RuntimeError(\"Unable to list snapshots. Ensure `simd` is installed or snapshots directory exists.\")",
	"api_parse_snapshots": "def api_parse_snapshots(data: Dict[str, str]):\n    \"\"\"POST `{ \"raw_output\": \"...\" }` → `{ \"snapshots\": [...] }`.\"\"\"\n    try:\n        raw_output = data.get(\"raw_output\", \"\")\n        snapshots = _parse_snapshot_output(raw_output)\n        return {\"snapshots\": snapshots}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))\n\ndef _parse_snapshot_output(raw_output: str) -> List[Dict]:\n    \"\"\"Convert CLI output into structured objects.\"\"\"\n    snapshots = []\n    for line in raw_output.splitlines():\n        match = SNAPSHOT_REGEX.search(line)\n        if match:\n            snapshots.append({\n                \"height\": int(match.group(\"height\")),\n                \"format\": match.group(\"format\"),\n                \"hash\": match.group(\"hash\")\n            })\n    if not snapshots:\n        raise ValueError(\"No snapshots found in provided output.\")\n    return snapshots",
	"stop_evmd": "def stop_evmd():\n    \"\"\"\n    Attempt to stop the evmd process gracefully. If systemd is not being used,\n    fall back to killing the process by name.\n    \"\"\"\n    try:\n        # Preferred: managed by systemd\n        subprocess.run([\"systemctl\", \"stop\", \"evmd\"], check=True)\n        return {\"status\": \"evmd stopped via systemctl\"}\n    except subprocess.CalledProcessError:\n        try:\n            # Fallback for non-systemd environments\n            subprocess.run([\"pkill\", \"-f\", \"evmd\"], check=True)\n            return {\"status\": \"evmd stopped via pkill\"}\n        except subprocess.CalledProcessError as err:\n            logging.exception(\"Unable to stop evmd: %s\", err)\n            raise HTTPException(status_code=500, detail=\"Unable to stop evmd process\")",
	"read_app_toml": "def read_app_toml():\n    \"\"\"Return the full app.toml contents so it can be inspected in the UI.\"\"\"\n    try:\n        with open(APP_TOML_PATH, \"r\") as file:\n            cfg = toml.load(file)\n        return cfg\n    except FileNotFoundError:\n        raise HTTPException(status_code=404, detail=f\"app.toml not found at {APP_TOML_PATH}\")\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"update_json_rpc": "def update_json_rpc(namespaces: Namespaces):\n    \"\"\"\n    Overwrite the `api` field under the [json-rpc] section with a comma-separated\n    list of namespaces supplied by the caller.\n    \"\"\"\n    try:\n        with open(APP_TOML_PATH, \"r\") as file:\n            cfg = toml.load(file)\n\n        # Ensure the section exists and update it\n        cfg.setdefault(\"json-rpc\", {})[\"api\"] = \",\".join(namespaces.namespaces)\n\n        with open(APP_TOML_PATH, \"w\") as file:\n            toml.dump(cfg, file)\n\n        return {\"status\": \"updated\", \"api\": cfg[\"json-rpc\"][\"api\"]}\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"get_json_rpc_api": "def get_json_rpc_api():\n    \"\"\"Read back the api field to verify that the previous write persisted.\"\"\"\n    try:\n        with open(APP_TOML_PATH, \"r\") as file:\n            cfg = toml.load(file)\n        return {\"api\": cfg.get(\"json-rpc\", {}).get(\"api\", \"\")}\n    except Exception as err:\n        raise HTTPException(status_code=500, detail=str(err))",
	"start_evmd": "def start_evmd():\n    \"\"\"\n    Start (or restart) the evmd process after configuration changes.\n    \"\"\"\n    try:\n        subprocess.run([\"systemctl\", \"start\", \"evmd\"], check=True)\n        return {\"status\": \"evmd restarted\"}\n    except subprocess.CalledProcessError as err:\n        logging.exception(\"Unable to start evmd: %s\", err)\n        raise HTTPException(status_code=500, detail=\"Unable to start evmd\")",
	"query_bank_balances": "def query_bank_balances(address: str) -> dict:\n    \"\"\"Run `simd q bank balances` and return the parsed JSON payload.\"\"\"\n    if not address:\n        raise ValueError(\"Address is required.\")\n    try:\n        cmd = [\n            \"simd\", \"q\", \"bank\", \"balances\", address,\n            \"--output\", \"json\",\n        ]\n        output = subprocess.check_output(cmd, text=True)\n        return json.loads(output)\n    except subprocess.CalledProcessError as e:\n        raise RuntimeError(f\"Failed to query balances for {address}: {e}\") from e",
	"parse_balances": "def parse_balances(balances_json: dict) -> list:\n    \"\"\"Extract denomination and amount pairs from a simd balance query response.\"\"\"\n    if not isinstance(balances_json, dict):\n        raise TypeError(\"balances_json must be a dict\")\n    tokens = []\n    for coin in balances_json.get(\"balances\", []):\n        denom = coin.get(\"denom\")\n        amount = coin.get(\"amount\")\n        if denom and amount:\n            tokens.append({\"denom\": denom, \"amount\": amount})\n    return tokens",
	"check_balance": "def check_balance(address: str):\n    \"\"\"Return each balance and whether both are ≥ 1.\"\"\"\n    try:\n        payload = { 'balance': { 'address': address } }\n\n        maxbtc = int(client.wasm_contract_query(CW20_MAXBTC, payload)['balance'])\n        unibtc = int(client.wasm_contract_query(CW20_UNIBTC, payload)['balance'])\n        ok = maxbtc >= REQUIRED_AMOUNT and unibtc >= REQUIRED_AMOUNT\n\n        return BalanceResponse(maxbtc=maxbtc, unibtc=unibtc, eligible=ok)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f'Balance query failed: {e}')",
	"get_supervault_details": "def get_supervault_details():\n    try:\n        details = {\n            'supervault_address': os.getenv('MAXUNI_SUPERVAULT', 'neutron1supervaultxxxxxxxxxxxxxxxxxxxx'),\n            'assets': [\n                { 'symbol': 'maxBTC', 'cw20': os.getenv('CW20_MAXBTC', 'neutron1xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx') },\n                { 'symbol': 'uniBTC', 'cw20': os.getenv('CW20_UNIBTC', 'neutron1yyyyyyyyyyyyyyyyyyyyyyyyyyyyyy') }\n            ]\n        }\n        return details\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"build_deposit": "def build_deposit(req: BuildDepositRequest):\n    try:\n        supervault = os.getenv('MAXUNI_SUPERVAULT', 'neutron1supervaultxxxxxxxxxxxxxxxxxxxx')\n\n        # ExecuteMsg expected by the Supervault contract\n        exec_msg = {\n            'deposit': {\n                'assets': [\n                    { 'token': os.getenv('CW20_MAXBTC', 'neutron1xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'), 'amount': str(req.amount_maxbtc) },\n                    { 'token': os.getenv('CW20_UNIBTC', 'neutron1yyyyyyyyyyyyyyyyyyyyyyyyyyyyyy'), 'amount': str(req.amount_unibtc) }\n                ]\n            }\n        }\n\n        tx = Transaction()\n        tx.add_message(\n            MsgExecuteContract(\n                sender = req.sender,\n                contract = supervault,\n                msg = exec_msg,\n                funds = []  # CW20 -> no native funds\n            )\n        )\n        # Fee/memo left empty so they can be set at signing time\n        unsigned_bytes = tx.get_tx_bytes(sign=False)  # Do **not** sign here!\n        return BuildDepositResponse(tx_bytes=unsigned_bytes.hex(), body=tx.get_tx_json(sign=False))\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f'Failed to build deposit tx: {e}')",
	"broadcast": "def broadcast(req: BroadcastRequest):\n    try:\n        # ------------  Recover server key (DO NOT USE IN PRODUCTION)  ------------\n        mnemonic = os.getenv('SERVER_MNEMONIC')\n        if not mnemonic:\n            raise ValueError('SERVER_MNEMONIC is not set in the environment.')\n        wallet = PrivateKey.from_mnemonic(mnemonic)\n\n        # ------------  Re-hydrate tx and sign  ------------\n        tx = Transaction(tx_bytes=bytes.fromhex(req.tx_bytes))\n        tx.sign(wallet)\n        signed_bytes = tx.get_tx_bytes()\n\n        # ------------  Broadcast  ------------\n        result = client.broadcast_tx_block(signed_bytes)\n        return BroadcastResponse(tx_hash=result.tx_hash, height=result.height)\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f'Broadcast failed: {e}')",
	"get_wasm_file_path": "def get_wasm_file_path(relative_path: str) -> Path:\n    path = Path(relative_path).expanduser().resolve()\n    if not path.is_file():\n        raise FileNotFoundError(f'WASM file not found at {path}')\n    return path",
	"validate_wasm_checksum": "def validate_wasm_checksum(wasm_path: Path) -> str:\n    if not wasm_path.is_file():\n        raise FileNotFoundError(f'File not found: {wasm_path}')\n\n    sha256 = hashlib.sha256()\n    with wasm_path.open('rb') as f:\n        for chunk in iter(lambda: f.read(8192), b''):\n            sha256.update(chunk)\n    checksum = sha256.hexdigest()\n    return checksum",
	"construct_tx_store_code": "def construct_tx_store_code(wasm_path: Path, sender_address: str) -> Transaction:\n    wasm_bytes = wasm_path.read_bytes()\n\n    access_config = types_pb2.AccessConfig(\n        permission=types_pb2.AccessType.ACCESS_TYPE_EVERYBODY,\n        address=''  # empty when permission is Everybody\n    )\n\n    msg = wasm_tx_pb2.MsgStoreCode(\n        sender=sender_address,\n        wasm_byte_code=wasm_bytes,\n        instantiate_permission=access_config\n    )\n\n    tx = Transaction()\n    tx.add_message(msg)\n    # You can still tweak gas / fee before signing, e.g.:\n    # tx = tx.with_gas(1_500_000).with_fee('5000untrn')\n    return tx",
	"extract_code_id_from_tx": "def extract_code_id_from_tx(response) -> int:\n    raw_log = response.tx_response.raw_log\n\n    # Attempt JSON parsing (preferred because it is deterministic)\n    try:\n        parsed_logs = json.loads(raw_log)[0]\n        for event in parsed_logs.get('events', []):\n            if event.get('type') == 'store_code':\n                for attr in event.get('attributes', []):\n                    if attr.get('key') == 'code_id':\n                        return int(attr.get('value'))\n    except (json.JSONDecodeError, KeyError, IndexError):\n        pass\n\n    # Fallback: regex scanning for robustness\n    match = re.search(r'\\\"code_id\\\":\\s*\\\"?(\\d+)\\\"?', raw_log)\n    if match:\n        return int(match.group(1))\n\n    raise ValueError('code_id not found in transaction logs')",
	"update_chain_id": "def update_chain_id(genesis_path: str, new_chain_id: str = \"testing\") -> dict:\n    \"\"\"Return a modified genesis dict with the chain_id changed.\"\"\"\n    with open(genesis_path, \"r\", encoding=\"utf-8\") as f:\n        genesis_data = json.load(f)\n\n    genesis_data[\"chain_id\"] = new_chain_id\n    return genesis_data",
	"get_account_info": "def get_account_info(address: str):\n    try:\n        async with httpx.AsyncClient(timeout=10) as client:\n            url = f\"{NODE_RPC}/cosmos/auth/v1beta1/accounts/{address}\"\n            res = await client.get(url)\n        res.raise_for_status()\n        account_data = res.json()\n\n        # Handle vesting / module accounts by drilling down into nested structures.\n        base_account = (account_data.get(\"account\", {})\n                        .get(\"base_account\") or account_data.get(\"account\", {}))\n\n        account_number = int(base_account.get(\"account_number\", \"0\"))\n        sequence = int(base_account.get(\"sequence\", \"0\"))\n\n        return AccountInfoResponse(\n            address=address,\n            account_number=account_number,\n            sequence=sequence,\n        )\n    except httpx.HTTPStatusError as e:\n        raise HTTPException(status_code=e.response.status_code,\n                            detail=f\"RPC error: {e.response.text}\")\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=str(e))",
	"generate_unsigned_send_tx": "def generate_unsigned_send_tx(payload: GenerateTxRequest):\n    try:\n        # 1. Build message\n        msg = MsgSend(\n            from_address=payload.sender,\n            to_address=payload.recipient,\n            amount=[Coin(denom=payload.denom, amount=str(payload.amount))],\n        )\n\n        # 2. Initialise Transaction object (no private key → no signatures)\n        cfg = NetworkConfig(\n            chain_id=CHAIN_ID,\n            url=RPC_URL,\n            fee_minimum_gas_price=0,\n        )\n        tx = Transaction(cfg)\n        tx.add_message(msg)\n        tx.fee = 0  # Fee left zero; user/wallet can update later.\n        tx.gas_limit = GAS_LIMIT_DEFAULT\n\n        # Important: We do *not* call tx.sign() → therefore signatures remain empty.\n\n        # 3. Manually patch account_number & sequence so downstream wallets match CLI `--generate-only` output.\n        raw = tx._proto\n        raw.auth_info.signer_infos.clear()  # Ensure no signer info (generate-only)\n        raw.body.memo = \"\"\n        tx_bytes = raw.SerializeToString()\n\n        # 4. Return JSON (base64 encoded TxRaw) matching `--output json` semantics\n        unsigned_tx_json = json.dumps({\n            \"body\": json.loads(raw.body.SerializeToString().hex()),\n            \"auth_info\": json.loads(raw.auth_info.SerializeToString().hex()),\n            \"signatures\": [],\n            \"account_number\": str(payload.account_number),\n            \"sequence\": str(payload.sequence),\n            \"chain_id\": CHAIN_ID,\n        })\n\n        return GenerateTxResponse(unsigned_tx=unsigned_tx_json)\n\n    except Exception as e:\n        raise HTTPException(status_code=500, detail=f\"Could not build unsigned tx: {e}\")",
	"detect_node_home_and_binary": "def detect_node_home_and_binary():\n    \"\"\"Return a tuple of (home_path: Path, binary_name: str).\"\"\"\n    # 1. Environment overrides -------------------------------------------------\n    env_home = os.getenv(\"COSMOS_HOME\")\n    env_bin  = os.getenv(\"COSMOS_BINARY\")\n    if env_home and env_bin:\n        return Path(env_home).expanduser(), env_bin\n\n    # 2. Best-effort process scan ---------------------------------------------\n    try:\n        pgrep_output = subprocess.check_output([\"pgrep\", \"-fa\", \"d$\"]).decode()\n        # Pick the first matching daemon process\n        line        = pgrep_output.splitlines()[0]\n        _pid, *cmd  = line.strip().split()\n        binary_path = Path(cmd[0])\n        binary_name = binary_path.name\n        # Attempt to extract an explicit --home flag\n        home_path = None\n        if \"--home\" in cmd:\n            idx = cmd.index(\"--home\")\n            if idx + 1 < len(cmd):\n                home_path = Path(cmd[idx + 1]).expanduser()\n        if not home_path:\n            home_path = Path.home() / f\".{binary_name}\"\n        return home_path, binary_name\n    except Exception:\n        # 3. Conservative fallback --------------------------------------------\n        return Path.home() / \".appd\", \"appd\"\n\n\n@app.get(\"/api/node-info\")\ndef api_node_info():\n    \"\"\"Return `{ home: str, binary: str }` or HTTP 500 on failure.\"\"\"\n    try:\n        home, binary = detect_node_home_and_binary()\n        return {\"home\": str(home), \"binary\": binary}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"stop_node_process": "def stop_node_process(binary_name: str, timeout: int = TIMEOUT_SEC) -> bool:\n    \"\"\"Return True on graceful shutdown, False if SIGKILL had to be used.\"\"\"\n    try:\n        pid_bytes = subprocess.check_output([\"pgrep\", \"-f\", binary_name])\n        pids      = [int(pid) for pid in pid_bytes.decode().split()]\n    except subprocess.CalledProcessError:\n        raise RuntimeError(f\"No running process found for '{binary_name}'.\")\n\n    # Send SIGTERM to every matching PID\n    for pid in pids:\n        os.kill(pid, signal.SIGTERM)\n\n    # Wait until the first PID exits (others should follow)\n    start = time.time()\n    while time.time() - start < timeout:\n        try:\n            os.kill(pids[0], 0)  # check still alive\n            time.sleep(1)\n        except OSError:  # process is gone\n            return True\n\n    # Escalate to SIGKILL if we’re still here\n    for pid in pids:\n        os.kill(pid, signal.SIGKILL)\n    return False\n\n\n@app.post(\"/api/node-stop\")\ndef api_node_stop(binary: str):\n    try:\n        graceful = stop_node_process(binary)\n        return {\"graceful\": graceful}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"ensure_snapshot_dir": "def ensure_snapshot_dir(home_path: str) -> Path:\n    snap_dir = Path(home_path).expanduser() / \"data\" / \"snapshots\"\n    snap_dir.mkdir(parents=True, exist_ok=True)\n    return snap_dir\n\n\n@app.post(\"/api/snapshot/ensure-dir\")\ndef api_ensure_snapshot_dir(home: str):\n    try:\n        path = ensure_snapshot_dir(home)\n        return {\"snapshot_dir\": str(path)}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"export_snapshot": "def export_snapshot(binary: str, home_path: str) -> str:\n    cmd = [binary, \"snapshots\", \"export\", \"--home\", home_path]\n    result = subprocess.run(cmd, capture_output=True, text=True)\n    if result.returncode != 0:\n        raise RuntimeError(result.stderr.strip())\n    return result.stdout.strip()\n\n\n@app.post(\"/api/snapshot/export\")\ndef api_export_snapshot(binary: str, home: str):\n    try:\n        output = export_snapshot(binary, home)\n        return {\"status\": \"exported\", \"cli_output\": output}\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"verify_snapshot": "def verify_snapshot(binary: str, home_path: str):\n    snap_dir   = Path(home_path).expanduser() / \"data\" / \"snapshots\"\n    archives   = [p.name for p in snap_dir.glob(\"*.tar*\")]\n\n    list_cmd   = [binary, \"snapshots\", \"list\", \"--home\", home_path]\n    list_proc  = subprocess.run(list_cmd, capture_output=True, text=True)\n    if list_proc.returncode != 0:\n        raise RuntimeError(list_proc.stderr.strip())\n\n    return {\"archives_on_disk\": archives, \"cli_output\": list_proc.stdout.strip()}\n\n\n@app.get(\"/api/snapshot/verify\")\ndef api_verify_snapshot(binary: str, home: str):\n    try:\n        res = verify_snapshot(binary, home)\n        if not res[\"archives_on_disk\"]:\n            raise RuntimeError(\"Snapshot directory is empty.\")\n        return res\n    except Exception as exc:\n        raise HTTPException(status_code=500, detail=str(exc))",
	"resolve_ens": "def resolve_ens():\n    \"\"\"Resolve an ENS name to a checksummed Ethereum address.\"\"\"\n    ens_name = request.args.get('ens')\n    if not ens_name:\n        return jsonify({\"error\": \"Query param 'ens' is required.\"}), 400\n\n    try:\n        address = w3.ens.address(ens_name)\n        if address is None:\n            return jsonify({\"error\": f\"ENS name '{ens_name}' not found.\"}), 404\n        return jsonify({\"address\": Web3.toChecksumAddress(address)})\n    except Exception as e:\n        # Catch anything unexpected (e.g., network issues)\n        return jsonify({\"error\": str(e)}), 500\n\n# Allow this file to be run directly for local dev\nautostart = os.getenv(\"FLASK_AUTOSTART\", \"true\").lower() == \"true\"\nif __name__ == '__main__' and autostart:\n    app.run(host='0.0.0.0', port=8000, debug=True)",
	"eth_balance": "def eth_balance():\n    \"\"\"Return balance for an address OR ENS name provided via ?value.\"\"\"\n    value = request.args.get('value')  # can be address or ENS name\n    if not value:\n        return jsonify({\"error\": \"Query param 'value' is required.\"}), 400\n\n    # Resolve ENS if necessary\n    try:\n        if \".\" in value:  # naïve ENS check\n            resolved = w3.ens.address(value)\n            if resolved is None:\n                return jsonify({\"error\": f\"ENS name '{value}' not found.\"}), 404\n            address = Web3.toChecksumAddress(resolved)\n        else:\n            address = Web3.toChecksumAddress(value)\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 400\n\n    # Query balance\n    try:\n        balance_wei = w3.eth.get_balance(address)\n        balance_eth = w3.fromWei(balance_wei, 'ether')\n        return jsonify({\"address\": address, \"balance\": str(balance_eth)})\n    except Exception as e:\n        return jsonify({\"error\": str(e)}), 500\n\n# Allow this file to be run directly for local dev\nautostart = os.getenv(\"FLASK_AUTOSTART\", \"true\").lower() == \"true\"\nif __name__ == '__main__' and autostart:\n    app.run(host='0.0.0.0', port=8000, debug=True)",
	"github_login": "def github_login():\n    \"\"\"Redirect the browser to GitHub’s OAuth consent page.\"\"\"\n    if not GITHUB_CLIENT_ID:\n        raise HTTPException(500, 'GITHUB_CLIENT_ID is missing.')\n\n    state = secrets.token_hex(16)\n    _state_store[state] = True  # Prevent CSRF\n\n    auth_url = (\n        'https://github.com/login/oauth/authorize'\n        f'?client_id={GITHUB_CLIENT_ID}'\n        '&scope=repo'\n        f'&state={state}'\n    )\n    return RedirectResponse(auth_url)\n\n@app.get('/api/github/callback')\nasync def github_callback(code: str, state: str):\n    \"\"\"Exchange the temporary code for a permanent GitHub access token.\"\"\"\n    if state not in _state_store:\n        raise HTTPException(400, 'Invalid OAuth state.')\n    _state_store.pop(state, None)\n\n    if not GITHUB_CLIENT_SECRET:\n        raise HTTPException(500, 'GITHUB_CLIENT_SECRET is missing.')\n\n    async with httpx.AsyncClient() as client:\n        token_resp = await client.post(\n            'https://github.com/login/oauth/access_token',\n            headers={\n                'Accept': 'application/json'\n            },\n            data={\n                'client_id': GITHUB_CLIENT_ID,\n                'client_secret': GITHUB_CLIENT_SECRET,\n                'code': code,\n                'state': state,\n            }\n        )\n        token_resp.raise_for_status()\n        token_json = token_resp.json()\n\n    access_token = token_json.get('access_token')\n    if not access_token:\n        raise HTTPException(400, 'GitHub did not return an access token.')\n\n    # In production you would typically set a secure session cookie here.\n    return JSONResponse({'access_token': access_token})",
	"github_push": "def github_push(\n    access_token: str = Body(..., embed=True),\n    repo_name: str = Body(..., embed=True),\n    commit_message: str = Body(..., embed=True),\n    files: Dict[str, str] = Body(..., description='Mapping: filepath → file contents (utf-8 strings)')\n):\n    \"\"\"Create the repository (if needed) and push the provided files as a single commit.\"\"\"\n\n    headers = {\n        'Authorization': f'token {access_token}',\n        'Accept': 'application/vnd.github.v3+json'\n    }\n\n    async with httpx.AsyncClient(headers=headers) as client:\n        # 1️⃣  Get the authenticated user’s login name\n        user_resp = await client.get('https://api.github.com/user')\n        user_resp.raise_for_status()\n        owner = user_resp.json()['login']\n\n        # 2️⃣  Ensure the repository exists (create it if it does not)\n        repo_resp = await client.get(f'https://api.github.com/repos/{owner}/{repo_name}')\n        if repo_resp.status_code == 404:\n            create_resp = await client.post('https://api.github.com/user/repos', json={'name': repo_name})\n            create_resp.raise_for_status()\n        elif repo_resp.status_code != 200:\n            raise HTTPException(repo_resp.status_code, f'GitHub error: {repo_resp.text}')\n\n        # 3️⃣  Upload each file via the \"contents\" API\n        for path, content in files.items():\n            encoded = base64.b64encode(content.encode()).decode()\n            put_resp = await client.put(\n                f'https://api.github.com/repos/{owner}/{repo_name}/contents/{path}',\n                json={\n                    'message': commit_message,\n                    'content': encoded\n                }\n            )\n            if put_resp.status_code not in (200, 201):\n                raise HTTPException(put_resp.status_code, f'GitHub error: {put_resp.text}')\n\n    return {\n        'status': 'success',\n        'repository_url': f'https://github.com/{owner}/{repo_name}'\n    }",
	"_rpc_call": "def _rpc_call(payload: dict):\\n    \\\"\\\"\\\"Internal helper to perform an authenticated JSON-RPC call.\\\"\\\"\\\"\\n    auth = None\\n    if RPC_USERNAME and RPC_PASSWORD:\\n        auth = (RPC_USERNAME, RPC_PASSWORD)  # Basic-Auth tuple for httpx\\n\\n    try:\\n        async with httpx.AsyncClient(auth=auth, timeout=10) as client:\\n            response = await client.post(RPC_ENDPOINT, json=payload)\\n            response.raise_for_status()\\n    except httpx.HTTPError as http_err:\\n        raise HTTPException(status_code=502, detail=f\\\"RPC connection failed: {http_err}\\\")\\n    except Exception as err:\\n        raise HTTPException(status_code=500, detail=f\\\"Unexpected error: {err}\\\")\\n\\n    # Parse JSON-RPC response and bubble up any RPC-level errors.\\n    data = response.json()\\n    if \\\"error\\\" in data and data[\\\"error\\\"] is not None:\\n        raise HTTPException(status_code=500, detail=data[\\\"error\\\"])\\n\\n    return data.get(\\\"result\\\")",
	"personal_list_wallets": "def personal_list_wallets():\\n    \\\"\\\"\\\"Return the list of wallets managed by the node.\\\"\\\"\\\"\\n    payload = {\\n        \\\"jsonrpc\\\": \\\"2.0\\\",\\n        \\\"method\\\": \\\"personal_listWallets\\\",\\n        \\\"params\\\": [],\\n        \\\"id\\\": 1\\n    }\\n    result = await _rpc_call(payload)\\n    return {\\\"wallets\\\": result}\\n\\n# Remember to include the router in your FastAPI application\\n# app.include_router(router)",
	"start_abci_app": "def start_abci_app(home_dir: str = os.path.expanduser(\"~/.simapp\")):\n    \"\"\"Spawn `simd start --with-comet=false` and pipe its output.\"\"\"\n    cmd = [\n        \"simd\",\n        \"start\",\n        \"--with-comet=false\",\n        \"--home\",\n        home_dir,\n    ]\n    try:\n        proc = subprocess.Popen(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,          # decode bytes → str automatically\n            bufsize=1,          # line-buffered\n        )\n    except FileNotFoundError:\n        raise RuntimeError(\"`simd` binary not found in PATH. Make sure it is installed and executable.\")\n\n    print(f\"Started simd (ABCI-only). PID={proc.pid}\")\n    return proc",
	"wait_for_abci_ready": "def wait_for_abci_ready(proc, timeout: int = 60):\n    \"\"\"Block until the given `simd` process outputs `ABCI server started`.\"\"\"\n    deadline = time.time() + timeout\n    if proc.stdout is None:\n        raise RuntimeError(\"Process stdout pipe is not available.\")\n\n    for line in iter(proc.stdout.readline, \"\"):\n        print(line.rstrip())  # optional: stream logs to console\n        if \"ABCI server started\" in line:\n            print(\"✅ ABCI application is up and listening on tcp://localhost:26658\")\n            return True\n        if time.time() > deadline:\n            proc.terminate()\n            raise TimeoutError(\"Timed out waiting for ABCI server to start.\")\n    raise RuntimeError(\"simd process exited unexpectedly before readiness.\")",
	"start_cometbft": "def start_cometbft(home_dir: str = os.path.expanduser(\"~/.simapp\"), proxy_addr: str = \"tcp://127.0.0.1:26658\"):\n    \"\"\"Spawn `cometbft start` that points to the ABCI app via `--proxy_app`.\"\"\"\n    cmd = [\n        \"cometbft\",\n        \"start\",\n        \"--home\",\n        home_dir,\n        \"--proxy_app\",\n        proxy_addr,\n    ]\n    try:\n        proc = subprocess.Popen(\n            cmd,\n            stdout=subprocess.PIPE,\n            stderr=subprocess.STDOUT,\n            text=True,\n            bufsize=1,\n        )\n    except FileNotFoundError:\n        raise RuntimeError(\"`cometbft` binary not found in PATH. Install CometBFT or adjust PATH.\")\n\n    print(f\"Started CometBFT. PID={proc.pid}\")\n    return proc",
	"wait_for_cometbft_rpc": "def wait_for_cometbft_rpc(rpc_url: str = \"http://localhost:26657/status\", timeout: int = 60, interval: float = 2.0):\n    \"\"\"Repeatedly query the RPC `/status` endpoint until it responds with HTTP 200.\"\"\"\n    deadline = time.time() + timeout\n    while time.time() < deadline:\n        try:\n            resp = requests.get(rpc_url, timeout=5)\n            if resp.status_code == 200:\n                print(\"✅ CometBFT RPC is live on tcp://localhost:26657\")\n                return resp.json()\n        except requests.RequestException:\n            pass  # endpoint not ready yet\n        print(\"Waiting for CometBFT RPC endpoint …\")\n        time.sleep(interval)\n    raise TimeoutError(\"Timed out waiting for CometBFT RPC endpoint to become available.\")",
	"getValidatedTxHash": "export const getValidatedTxHash = (inputHash) => {\n  // Accept either `0x`-prefixed or plain 64-char hex\n  const pattern = /^0x?[0-9a-fA-F]{64}$/;\n  if (!pattern.test(inputHash)) {\n    throw new Error('Invalid transaction hash supplied.');\n  }\n  // Normalise to lowercase 0x-prefixed form before sending to backend\n  const cleaned = inputHash.toLowerCase();\n  return cleaned.startsWith('0x') ? cleaned : `0x${cleaned}`;\n};",
	"toHexMessage": "export const toHexMessage = (message) => {\n  if (typeof message !== 'string') {\n    throw new Error('Message must be a string');\n  }\n  // Convert each character to its UTF-8 char code, then to a two-digit hex value\n  const hexBody = Array.from(message)\n    .map(char => char.charCodeAt(0).toString(16).padStart(2, '0'))\n    .join('');\n\n  return '0x' + hexBody;\n};",
	"getRpcEndpoint": "export const getRpcEndpoint = () => {\n  // Use an environment variable if available, otherwise fallback to a public RPC.\n  return import.meta.env.VITE_COSMOS_EVM_RPC_ENDPOINT || \"https://rpc.evmos.org:8545\";\n};",
	"debugTraceBlockByNumber": "export const debugTraceBlockByNumber = async (\n  blockNumberHex = \"0xe\", // default block number in hex\n  endpoint = getRpcEndpoint()\n) => {\n  try {\n    const payload = {\n      jsonrpc: \"2.0\",\n      id: 1,\n      method: \"debug_traceBlockByNumber\",\n      params: [blockNumberHex, {}]\n    };\n\n    // Send the JSON-RPC request\n    const response = await fetch(endpoint, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\"\n      },\n      body: JSON.stringify(payload)\n    });\n\n    // Basic HTTP-level error handling\n    if (!response.ok) {\n      throw new Error(`Network error: ${response.status} ${response.statusText}`);\n    }\n\n    const data = await response.json();\n\n    // JSON-RPC-level error handling\n    if (data.error) {\n      throw new Error(`RPC Error: ${data.error.code} – ${data.error.message}`);\n    }\n\n    return data.result; // the actual trace data\n  } catch (error) {\n    console.error(\"Failed to trace block:\", error);\n    throw error;\n  }\n};",
	"getUserWalletAddress": "export const getUserWalletAddress = async () => {\n  const chainId = 'neutron-1';\n\n  // 1. Ensure Keplr is injected in the browser\n  if (!window.keplr) {\n    throw new Error('Keplr wallet not found. Please install the Keplr browser extension.');\n  }\n\n  // 2. Ask Keplr to enable the Neutron chain\n  await window.keplr.enable(chainId);\n\n  // 3. Retrieve the OfflineSigner and account list\n  const signer = window.getOfflineSigner(chainId);\n  const accounts = await signer.getAccounts();\n\n  if (!accounts || accounts.length === 0) {\n    throw new Error('No accounts detected for the selected chain.');\n  }\n\n  // 4. Return the first account address (default behaviour for Keplr)\n  return accounts[0].address;\n};",
	"connectRpc": "export const connectRpc = async (rpcUrl = 'http://localhost:8545') => {\n  const payload = {\n    jsonrpc: '2.0',\n    id: 1,\n    method: 'web3_clientVersion',\n    params: []\n  };\n\n  try {\n    const response = await fetch(rpcUrl, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(payload)\n    });\n\n    if (!response.ok) {\n      throw new Error(`RPC connection failed with status ${response.status}`);\n    }\n\n    const data = await response.json();\n\n    if (data.error) {\n      throw new Error(`RPC error: ${data.error.message}`);\n    }\n\n    console.info('JSON-RPC connection established:', data.result);\n    return rpcUrl; // Return the verified RPC URL for downstream steps\n  } catch (err) {\n    console.error('Failed to connect to JSON-RPC endpoint:', err);\n    throw err; // Re-throw so callers can handle it\n  }\n};",
	"createBlockFilter": "export const createBlockFilter = async (rpcUrl) => {\n  const payload = {\n    jsonrpc: '2.0',\n    id: 1,\n    method: 'eth_newBlockFilter',\n    params: []\n  };\n\n  try {\n    const response = await fetch(rpcUrl, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(payload)\n    });\n\n    if (!response.ok) {\n      throw new Error(`RPC request failed with status ${response.status}`);\n    }\n\n    const data = await response.json();\n\n    if (data.error) {\n      throw new Error(`RPC error: ${data.error.message}`);\n    }\n\n    const filterId = data.result;\n    if (!filterId) {\n      throw new Error('eth_newBlockFilter did not return a filter ID');\n    }\n\n    console.info('Created block filter:', filterId);\n    return filterId;\n  } catch (err) {\n    console.error('Failed to create block filter:', err);\n    throw err;\n  }\n};",
	"storeFilterId": "export const storeFilterId = (filterId) => {\n  try {\n    localStorage.setItem('blockFilterId', filterId);\n    console.info('Filter ID stored in localStorage');\n  } catch (err) {\n    console.warn('Unable to write filter ID to localStorage:', err);\n  }\n};\n\nexport const getStoredFilterId = () => {\n  try {\n    return localStorage.getItem('blockFilterId') || null;\n  } catch {\n    return null;\n  }\n};",
	"pollFilterChanges": "export const pollFilterChanges = (\n  rpcUrl,\n  filterId,\n  onNewBlocks = (hashArray) => {},\n  pollIntervalMs = 5000\n) => {\n  if (!filterId) {\n    throw new Error('pollFilterChanges requires a valid filterId');\n  }\n\n  let timerId = null;\n\n  const payload = {\n    jsonrpc: '2.0',\n    id: 1, // the ID can be arbitrary per request\n    method: 'eth_getFilterChanges',\n    params: [filterId]\n  };\n\n  const poll = async () => {\n    try {\n      const response = await fetch(rpcUrl, {\n        method: 'POST',\n        headers: { 'Content-Type': 'application/json' },\n        body: JSON.stringify(payload)\n      });\n\n      if (!response.ok) {\n        console.error(`eth_getFilterChanges failed: ${response.status}`);\n        return; // keep polling despite transient errors\n      }\n\n      const data = await response.json();\n      if (data.error) {\n        console.error('RPC error from eth_getFilterChanges:', data.error.message);\n        return;\n      }\n\n      const hashes = data.result || [];\n      if (hashes.length > 0) {\n        onNewBlocks(hashes);\n      }\n    } catch (err) {\n      console.error('Error while polling eth_getFilterChanges:', err);\n    }\n  };\n\n  // Start the interval polling\n  timerId = setInterval(poll, pollIntervalMs);\n  console.info(`Started polling filter ${filterId} every ${pollIntervalMs} ms`);\n\n  // Return a stop function so the caller can cancel polling\n  return () => {\n    if (timerId) {\n      clearInterval(timerId);\n      console.info('Stopped polling filter changes');\n    }\n  };\n};",
	"getBlockByNumber": "export const getBlockByNumber = async ({\n  rpcEndpoint,\n  blockNumber = '0x1',       // Hex string or tags like 'latest'\n  includeTxObjects = true,   // true: full tx objects, false: only tx hashes\n  fetchOptions = {}          // optional: extra init values for fetch (e.g., mode, credentials)\n} = {}) => {\n  if (!rpcEndpoint) {\n    throw new Error('Parameter \"rpcEndpoint\" is required.');\n  }\n\n  // Compose the JSON-RPC payload\n  const payload = {\n    jsonrpc: '2.0',\n    id: 1,\n    method: 'eth_getBlockByNumber',\n    params: [blockNumber, includeTxObjects]\n  };\n\n  try {\n    const response = await fetch(rpcEndpoint, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify(payload),\n      ...fetchOptions\n    });\n\n    // Network-level error handling\n    if (!response.ok) {\n      throw new Error(`JSON-RPC call failed with HTTP status ${response.status}`);\n    }\n\n    const body = await response.json();\n\n    // JSON-RPC-level error handling\n    if (body.error) {\n      const message = body.error.message || JSON.stringify(body.error);\n      throw new Error(`RPC Error: ${message}`);\n    }\n\n    return body.result; // the block object\n  } catch (err) {\n    console.error('[getBlockByNumber] RPC request failed:', err);\n    throw err;\n  }\n};",
	"getUserAddress": "export const getUserAddress = async (chainId = 'neutron-1') => {\n  // Check that Keplr is available in the browser\n  if (!window.keplr) {\n    throw new Error('Keplr wallet not found. Please install or unlock the Keplr browser extension.');\n  }\n\n  // Ask Keplr to enable the target chain (this may prompt the user)\n  await window.keplr.enable(chainId);\n\n  // Obtain an OfflineSigner instance for the chain\n  const signer = window.getOfflineSigner(chainId);\n  const accounts = await signer.getAccounts();\n\n  if (!accounts || accounts.length === 0) {\n    throw new Error('No accounts detected in Keplr for the selected chain.');\n  }\n\n  // Return signer (for later use) and address\n  return {\n    signer,\n    address: accounts[0].address,\n  };\n};",
	"queryShareBalance": "export const queryShareBalance = async (restEndpoint, contractAddress, userAddress) => {\n  // The exact query key (\"balance\") should match the Supervault contract’s API.\n  const queryPayload = { \"balance\": { \"address\": userAddress } };\n\n  // CosmWasm REST endpoints expect the query JSON to be base64-encoded.\n  const base64Query = btoa(JSON.stringify(queryPayload));\n  const url = `${restEndpoint}/cosmwasm/wasm/v1/contract/${contractAddress}/smart/${base64Query}`;\n\n  const response = await fetch(url);\n  if (!response.ok) {\n    throw new Error(`Contract query failed: ${response.status} ${response.statusText}`);\n  }\n\n  const { data } = await response.json();\n  // Assume the contract returns `{ balance: \"<amount>\" }`. Adjust as needed.\n  return data?.balance || '0';\n};",
	"validateRedeemAmount": "export const validateRedeemAmount = (requestedAmount, availableShares) => {\n  const req = BigInt(requestedAmount);\n  const avail = BigInt(availableShares);\n\n  if (req <= 0n) {\n    throw new Error('Redeem amount must be greater than zero.');\n  }\n  if (req > avail) {\n    throw new Error('Redeem amount exceeds the available share balance.');\n  }\n  // Validation successful\n  return true;\n};",
	"loadContractAddress": "export const loadContractAddress = () => {\n  // It’s recommended to store contract addresses in environment variables\n  // so you can easily switch between testnet, mainnet, and localnet.\n  const address =\n    import.meta.env.VITE_TEMPLATE_CONTRACT_ADDRESS ||\n    process.env.NEXT_PUBLIC_TEMPLATE_CONTRACT_ADDRESS;\n\n  if (!address) {\n    throw new Error(\n      'NeutronTemplate contract address is not defined in environment variables.'\n    );\n  }\n\n  // Basic sanity-check: Neutron bech32 addresses start with `ntrn1` and are 43 chars long.\n  if (!/^ntrn1[0-9a-z]{38}$/.test(address)) {\n    throw new Error('Invalid Neutron contract address format.');\n  }\n\n  return address;\n};",
	"constructWasmQueryMsg": "export const constructWasmQueryMsg = () => {\n  // Message schema follows the contract’s public interface.\n  return {\n    get_global_counter: {}\n  };\n};",
	"queryContractGlobalCounter": "export const queryContractGlobalCounter = async (rpcEndpoint) => {\n  try {\n    // 1. Connect to the chain.\n    const client = await StargateClient.connect(rpcEndpoint);\n\n    // 2. Prepare contract address & query msg.\n    const contractAddress = loadContractAddress();\n    const queryMsg = constructWasmQueryMsg();\n\n    // 3. Execute the smart query.\n    const response = await client.queryContractSmart(contractAddress, queryMsg);\n    // Expected response shape: { count: <number> }\n\n    if (!response || typeof response.count !== 'number') {\n      throw new Error('Unexpected response format from contract.');\n    }\n\n    return response.count;\n  } catch (error) {\n    console.error('Failed to query global counter:', error);\n    throw error;\n  }\n};",
	"connectEthWallet": "export const connectEthWallet = async () => {\n  // --- Constants -----------------------------------------------------------\n  const MIN_ETH_WEI = 10n ** 16n;            // ≈ 0.01 ETH for gas\n  const MIN_WBTC_SATS = 100000000n;          // 1 WBTC (8 dp)\n  const WBTC_ADDRESS = '0x2260FAC5E5542a773Aa44fBCfeDf7C193bc2C599'; // main-net\n  const BALANCE_OF_SELECTOR = '0x70a08231';  // keccak256('balanceOf(address)')[0:4]\n\n  // --- Pre-checks ----------------------------------------------------------\n  if (typeof window === 'undefined' || !window.ethereum) {\n    throw new Error('MetaMask (or compatible) wallet is not installed.');\n  }\n\n  // --- Request account -----------------------------------------------------\n  const [account] = await window.ethereum.request({ method: 'eth_requestAccounts' });\n  if (!account) throw new Error('No Ethereum account returned by MetaMask.');\n\n  // --- Check ETH balance ---------------------------------------------------\n  const ethBalanceHex = await window.ethereum.request({\n    method: 'eth_getBalance',\n    params: [account, 'latest']\n  });\n  const ethBalanceWei = BigInt(ethBalanceHex);\n  if (ethBalanceWei < MIN_ETH_WEI) {\n    throw new Error('Insufficient ETH for gas (need at least ≈0.01 ETH).');\n  }\n\n  // --- Check WBTC balance --------------------------------------------------\n  const paddedAcct = account.slice(2).padStart(64, '0');\n  const data = BALANCE_OF_SELECTOR + paddedAcct;\n  const wbtcBalanceHex = await window.ethereum.request({\n    method: 'eth_call',\n    params: [{ to: WBTC_ADDRESS, data }, 'latest']\n  });\n  const wbtcBalance = BigInt(wbtcBalanceHex);\n  if (wbtcBalance < MIN_WBTC_SATS) {\n    throw new Error('At least 1 WBTC is required to continue.');\n  }\n\n  // --- Return account details ---------------------------------------------\n  return { account, wbtcBalance: wbtcBalance.toString() };\n};",
	"approveErc20Spend": "export const approveErc20Spend = async ({ ownerAddress, bridgeAddress, amountSats = '100000000' }) => {\n  const WBTC_ADDRESS = '0x2260FAC5E5542a773Aa44fBCfeDf7C193bc2C599';\n  const APPROVE_SELECTOR = '0x095ea7b3'; // keccak256('approve(address,uint256)')[0:4]\n\n  // --- Encode parameters ---------------------------------------------------\n  const spenderPadded = bridgeAddress.slice(2).padStart(64, '0');\n  const amountHex = BigInt(amountSats).toString(16).padStart(64, '0');\n  const data = APPROVE_SELECTOR + spenderPadded + amountHex;\n\n  // --- Send tx via MetaMask -------------------------------------------------\n  const txHash = await window.ethereum.request({\n    method: 'eth_sendTransaction',\n    params: [{\n      from: ownerAddress,\n      to: WBTC_ADDRESS,\n      data,\n      value: '0x0'\n    }]\n  });\n\n  return txHash; // user can track this tx for confirmation\n};",
	"depositWbtcToBridge": "export const depositWbtcToBridge = async ({\n  ownerAddress,\n  bridgeAddress,\n  neutronAddress,\n  amountSats = '100000000'\n}) => {\n  /*\n    NOTE: Every bridge has its own ABI.\n    Adjust `DEPOSIT_SELECTOR` and encoding if your bridge differs.\n    Example ABI (pseudo):\n      function deposit(address token, uint256 amount, bytes destination) external;\n    Keccak-256 selector => 0xb6b55f25 (placeholder here).\n  */\n  const TOKEN_ADDRESS = '0x2260FAC5E5542a773Aa44fBCfeDf7C193bc2C599';\n  const DEPOSIT_SELECTOR = '0xb6b55f25'; // placeholder selector – update to real one!\n\n  // --- Encode parameters ---------------------------------------------------\n  const pad = (hex, bytes = 64) => hex.replace(/^0x/, '').padStart(bytes, '0');\n\n  const tokenParam   = pad(TOKEN_ADDRESS);\n  const amountParam  = pad(BigInt(amountSats).toString(16));\n\n  // Destination (Neutron bech32) converted to raw UTF-8 hex -----------------\n  const destUtf8Hex  = Buffer.from(neutronAddress, 'utf8').toString('hex');\n  const destLen      = pad(Number(destUtf8Hex.length / 2).toString(16));\n  const destParam    = destUtf8Hex.padEnd(64, '0'); // right-pad to 32B\n\n  const data = DEPOSIT_SELECTOR + tokenParam + amountParam + destLen + destParam;\n\n  // --- Send tx via MetaMask -------------------------------------------------\n  const txHash = await window.ethereum.request({\n    method: 'eth_sendTransaction',\n    params: [{\n      from: ownerAddress,\n      to: bridgeAddress,\n      data,\n      value: '0x0'\n    }]\n  });\n\n  return txHash;\n};",
	"requestUniqueKeyName": "export const requestUniqueKeyName = async () => {\n  try {\n    let name = '';\n\n    /* Loop until the user provides a unique name */\n    while (true) {\n      name = prompt('Enter a unique key name for your wallet:');\n      if (!name) throw new Error('Key name is required.');\n\n      // Ask the backend if the name is available\n      const resp = await fetch(`/api/keys/validate?name=${encodeURIComponent(name)}`);\n      if (!resp.ok) {\n        const errText = await resp.text();\n        throw new Error(`Validation request failed: ${errText}`);\n      }\n      const { available } = await resp.json();\n\n      if (available) {\n        alert(`Great! “${name}” is available.`);\n        return name;\n      }\n\n      alert(`The key name “${name}” already exists. Please choose another.`);\n    }\n  } catch (err) {\n    console.error(err);\n    throw err;\n  }\n};",
	"createKeyAndShowMnemonic": "export const createKeyAndShowMnemonic = async (name) => {\n  try {\n    const passphrase = prompt('Create a passphrase (min 8 chars) to secure your key:');\n    if (!passphrase || passphrase.length < 8) {\n      throw new Error('Passphrase must be at least 8 characters long.');\n    }\n\n    const res = await fetch('/api/keys/add', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ name, passphrase })\n    });\n\n    if (!res.ok) {\n      const errTxt = await res.text();\n      throw new Error(`Key creation failed: ${errTxt}`);\n    }\n\n    const { address, mnemonic } = await res.json();\n\n    /* Display mnemonic exactly once so the user can back it up */\n    alert(`IMPORTANT — BACKUP NOW!\\n\\nAddress: ${address}\\n\\n24-word mnemonic:\\n${mnemonic}`);\n\n    // Return values for further programmatic use if needed\n    return { address, mnemonic };\n  } catch (err) {\n    console.error(err);\n    throw err;\n  }\n};",
	"getSenderAddress": "export const getSenderAddress = async () => {\n  const chainId = 'neutron-1';\n\n  // Check that Keplr is installed\n  if (!window.keplr) {\n    throw new Error('Keplr wallet is not installed.');\n  }\n\n  // Ask Keplr to enable the chain\n  await window.keplr.enable(chainId);\n\n  // Get an OfflineSigner to access the user’s account(s)\n  const offlineSigner = window.getOfflineSigner(chainId);\n  const accounts = await offlineSigner.getAccounts();\n\n  if (!accounts || accounts.length === 0) {\n    throw new Error('No accounts found in the connected wallet.');\n  }\n\n  // Return the first account (default behaviour for most dApps)\n  return accounts[0].address;\n};",
	"getVaultContractAddress": "export const getVaultContractAddress = () => {\n  // In production you might fetch this from an API or .env file.\n  // Hard-coded here for demo purposes.\n  return 'neutron1xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx';\n};",
	"buildOptInAirdropsMsg": "export const buildOptInAirdropsMsg = (partnerId = 'all') => {\n  return {\n    opt_in_airdrops: {\n      partner_id: partnerId\n    }\n  };\n};",
	"queryAirdropStatus": "export const queryAirdropStatus = async (\n  contractAddress,\n  userAddress,\n  lcdEndpoint = 'https://rest-kralum.neutron-1.neutron.org'\n) => {\n  // Build the query `{ airdrop_status: { address: <USER_ADDR> } }`\n  const query = {\n    airdrop_status: {\n      address: userAddress,\n    },\n  };\n\n  // The LCD expects the query message to be base64-encoded\n  const base64Query = btoa(JSON.stringify(query));\n\n  const url = `${lcdEndpoint}/cosmwasm/wasm/v1/contract/${contractAddress}/smart/${base64Query}`;\n\n  const response = await fetch(url);\n  if (!response.ok) {\n    throw new Error(`LCD query failed with status ${response.status}`);\n  }\n\n  const result = await response.json();\n  return result.data; // `data` holds the smart-query response\n};",
	"gatherCallParameters": "export const gatherCallParameters = () => {\n  try {\n    const rpcUrl = document.getElementById('rpcUrl').value.trim();\n    const contractAddress = document.getElementById('contractAddress').value.trim();\n    const functionSignature = document.getElementById('functionSignature').value.trim();\n    const abiArgsRaw = (document.getElementById('abiArgs')?.value || '').trim();\n\n    if (!rpcUrl || !contractAddress || !functionSignature) {\n      throw new Error('RPC URL, contract address, and function signature are required.');\n    }\n\n    const args = abiArgsRaw.length ? abiArgsRaw.split(',').map(arg => arg.trim()) : [];\n\n    return {\n      rpc_url: rpcUrl,\n      contract_address: contractAddress,\n      function_signature: functionSignature,\n      args,\n    };\n  } catch (err) {\n    console.error(err);\n    alert(err.message);\n    throw err;\n  }\n};",
	"interpretGasCost": "export const interpretGasCost = (gasUnits, gasPriceGwei = 20) => {\n  if (typeof gasUnits !== 'number' || gasUnits <= 0) throw new Error('Invalid gasUnits.');\n  if (typeof gasPriceGwei !== 'number' || gasPriceGwei <= 0) throw new Error('Invalid gasPriceGwei.');\n\n  const GWEI_TO_WEI = 1_000_000_000n;       // 1e9\n  const ETHER_TO_WEI = 1_000_000_000_000_000_000n; // 1e18\n\n  const weiCostBig = BigInt(gasUnits) * (BigInt(Math.round(gasPriceGwei * 1e9)));\n  const etherCost = Number(weiCostBig) / Number(ETHER_TO_WEI);\n\n  return {\n    gasUnits,\n    gasPriceGwei,\n    weiCost: weiCostBig.toString(),\n    etherCost,\n  };\n};",
	"validateTxHash": "export const validateTxHash = (txHash) => {\n  // A valid hash looks like: 0x followed by exactly 64 hex characters\n  const HASH_REGEX = /^0x([A-Fa-f0-9]{64})$/;\n\n  if (typeof txHash !== 'string' || !HASH_REGEX.test(txHash)) {\n    throw new Error('Invalid transaction hash. Expecting a 0x-prefixed, 64-character hexadecimal string.');\n  }\n\n  // Return the normalized hash (lower-case) for consistency\n  return txHash.toLowerCase();\n};",
	"collectTxFields": "export const collectTxFields = async ({ to, value = \"0x0\", data = \"0x\", gasLimit }) => {\n  // 1. Ensure an EVM wallet is available in the browser\n  if (typeof window === \"undefined\" || !window.ethereum) {\n    throw new Error(\"No EVM wallet detected. Please install MetaMask or another Web3 wallet.\");\n  }\n\n  // 2. Ask the user to connect the wallet and fetch the first account\n  const [from] = await window.ethereum.request({ method: \"eth_requestAccounts\" });\n\n  // 3. Verify the user is on the expected Cosmos-EVM chain (replace the ID below)\n  const expectedChainIdHex = \"0x2323\"; // example: 0x2323 == 8995\n  const chainIdHex = await window.ethereum.request({ method: \"eth_chainId\" });\n  if (chainIdHex !== expectedChainIdHex) {\n    throw new Error(`Wrong network. Please switch your wallet to chainId ${expectedChainIdHex}.`);\n  }\n\n  // 4. Build the transaction object\n  const tx = {\n    from,\n    to,\n    value,        // amount in WEI, hex-prefixed string\n    data,         // calldata, hex-prefixed string\n    gasLimit,     // optional gas limit (hex string)\n    chainId: parseInt(chainIdHex, 16)\n  };\n\n  return tx;\n};",
	"queryPersonalCounter": "export const queryPersonalCounter = async (rpcEndpoint, contractAddress, queryMsg) => {\n  try {\n    // Initialise a readonly CosmWasm client (no signer required for queries)\n    const client = await CosmWasmClient.connect(rpcEndpoint);\n\n    // Execute the smart query\n    const response = await client.queryContractSmart(contractAddress, queryMsg);\n\n    return response; // e.g. { counter: 7 }\n  } catch (error) {\n    // Forward the error after logging for debugging purposes\n    console.error(\"Contract smart-query failed:\", error);\n    throw error;\n  }\n};",
	"getContractAddress": "export const getContractAddress = () => {\n  // Attempt to read the contract address from an input with id 'contract-address-input'\n  const inputEl = document.getElementById('contract-address-input');\n  if (!inputEl) {\n    throw new Error('Element with id \"contract-address-input\" not found in the DOM.');\n  }\n  const address = inputEl.value.trim();\n  if (!address) {\n    throw new Error('Contract address cannot be empty.');\n  }\n  return address;\n};",
	"validateAddressFormat": "export const validateAddressFormat = (address) => {\n  try {\n    const decoded = bech32.decode(address);\n    if (decoded.prefix !== 'neutron') {\n      throw new Error('Invalid bech32 prefix: expected neutron, got ' + decoded.prefix);\n    }\n    // Re-encode to verify checksum integrity\n    const recoded = bech32.encode(decoded.prefix, decoded.words);\n    if (recoded !== address.toLowerCase()) {\n      throw new Error('Checksum mismatch.');\n    }\n    return true;\n  } catch (err) {\n    throw new Error('Address validation failed: ' + err.message);\n  }\n};",
	"validateRpcEndpoint": "export const validateRpcEndpoint = async (rpcUrl) => {\n  const payload = {\n    jsonrpc: '2.0',\n    id: 1,\n    method: 'eth_blockNumber',\n    params: []\n  };\n\n  try {\n    const response = await fetch(rpcUrl, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(payload)\n    });\n\n    if (!response.ok) {\n      throw new Error(`Endpoint returned HTTP ${response.status}`);\n    }\n\n    const data = await response.json();\n\n    if (data.error) {\n      throw new Error(`RPC error: ${data.error.message}`);\n    }\n\n    // Convert the hex string (e.g., \"0x10d4f\") to an integer\n    const blockNumber = parseInt(data.result, 16);\n    console.info(`RPC endpoint is healthy. Current block: ${blockNumber}`);\n    return blockNumber;\n  } catch (error) {\n    console.error(error);\n    throw new Error(`Failed to validate RPC endpoint: ${error.message}`);\n  }\n};",
	"prepareGasPricePayload": "export const prepareGasPricePayload = (id = 1) => {\n  return {\n    jsonrpc: \"2.0\",\n    method: \"eth_gasPrice\",\n    params: [],\n    id\n  };\n};",
	"postJsonRpc": "export const postJsonRpc = async (payload, endpoint = \"http://localhost:8545\") => {\n  try {\n    const res = await fetch(endpoint, {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify(payload)\n    });\n\n    if (!res.ok) {\n      // Surface HTTP-level errors\n      const errText = await res.text();\n      throw new Error(`HTTP ${res.status}: ${errText}`);\n    }\n\n    return await res.json();\n  } catch (err) {\n    console.error(\"JSON-RPC request failed\", err);\n    throw err;\n  }\n};",
	"parseGasPriceResponse": "export const parseGasPriceResponse = (response) => {\n  if (!response || typeof response.result !== \"string\") {\n    throw new Error(\"Malformed JSON-RPC response: missing 'result' field.\");\n  }\n\n  // The result is a hex string (e.g., \"0x91b1d9f00\"). Convert to BigInt.\n  const weiBigInt = BigInt(response.result);\n  const wei = weiBigInt.toString(10); // decimal string\n\n  // Helper conversions\n  const gwei = (weiBigInt / 1_000_000_000n).toString(10);\n  const ether = Number(weiBigInt) / 1e18; // may lose precision but fine for display\n\n  return { wei, gwei, ether };\n};",
	"ensureWalletConnected": "export const ensureWalletConnected = async (chainId = 'neutron-1') => {\n  // Verify Keplr is installed\n  if (!window || !window.keplr) {\n    throw new Error('Keplr wallet is not installed.');\n  }\n  try {\n    // Request access to the Neutron chain\n    await window.keplr.enable(chainId);\n    // Obtain an OfflineSigner (Amino/Direct signer auto-selected)\n    const offlineSigner = await window.keplr.getOfflineSignerAuto(chainId);\n    return offlineSigner;\n  } catch (error) {\n    console.error('Failed to connect to Keplr:', error);\n    throw error;\n  }\n};",
	"validateContractAddress": "export const validateContractAddress = (address, expectedPrefix = 'neutron') => {\n  try {\n    const { prefix } = fromBech32(address);\n    if (prefix !== expectedPrefix) {\n      throw new Error(`Prefix mismatch: expected ${expectedPrefix}, got ${prefix}`);\n    }\n    return true;\n  } catch (error) {\n    console.error('Invalid contract address:', error);\n    throw new Error('Provided contract address is invalid.');\n  }\n};",
	"convertToBaseUnits": "export const convertToBaseUnits = (amountNTRN) => {\n  if (isNaN(amountNTRN)) {\n    throw new Error('Amount must be numeric.');\n  }\n  const MICRO_FACTOR = 1_000_000; // 1 NTRN = 1,000,000 untrn\n  const microAmount = BigInt(Math.floor(Number(amountNTRN) * MICRO_FACTOR));\n  return microAmount.toString();\n};",
	"constructTxWasmExecute": "export const constructTxWasmExecute = (sender, contract, depositMicro) => {\n  const executeMsg = { deposit: {} }; // Payload expected by the contract\n  const funds = [coin(depositMicro, 'untrn')];\n  return {\n    sender,\n    contract,\n    msg: executeMsg,\n    funds,\n  };\n};",
	"signAndBroadcastTx": "export const signAndBroadcastTx = async (signer, executeMsg, rpcEndpoint = 'https://rpc-kralum.neutron.org') => {\n  try {\n    const client = await SigningCosmWasmClient.connectWithSigner(rpcEndpoint, signer);\n    // Use 'auto' for fee estimation or replace with a custom fee object.\n    const fee = 'auto';\n    const result = await client.execute(\n      executeMsg.sender,\n      executeMsg.contract,\n      executeMsg.msg,\n      fee,\n      undefined,\n      executeMsg.funds,\n    );\n    console.log('Transaction broadcasted. Hash:', result.transactionHash);\n    return result;\n  } catch (error) {\n    console.error('Failed to sign/broadcast transaction:', error);\n    throw error;\n  }\n};",
	"calculateHealthFactor": "export const calculateHealthFactor = (positions) => {\n  if (!Array.isArray(positions)) {\n    throw new Error('Invalid positions array received.');\n  }\n\n  return positions.map((p) => {\n    // Attempt to use the pre-computed value first\n    if (p.health_factor !== undefined) {\n      return {\n        id: p.id,\n        collateral: Number(p.collateral),\n        debt: Number(p.debt),\n        healthFactor: Number(p.health_factor)\n      };\n    }\n\n    const collateral = Number(p.collateral);\n    const debt = Number(p.debt);\n\n    // Protect against division by zero\n    const healthFactor = debt === 0 ? Infinity : collateral / debt;\n\n    return {\n      id: p.id,\n      collateral,\n      debt,\n      healthFactor\n    };\n  });\n};",
	"presentResults": "export const presentResults = (computedPositions) => {\n  if (!Array.isArray(computedPositions)) {\n    throw new Error('Expected an array from calculateHealthFactor().');\n  }\n\n  return computedPositions.map((p) => {\n    const fmt = (v) => (v / 1e6).toLocaleString(undefined, { minimumFractionDigits: 2, maximumFractionDigits: 2 });\n    const hf   = p.healthFactor === Infinity ? '∞' : p.healthFactor.toFixed(2);\n\n    return `Position #${p.id} → HF: ${hf}, Collateral: ${fmt(p.collateral)} NTRN, Debt: ${fmt(p.debt)} NTRN`;\n  }).join('\\n');\n};",
	"validateEvmAddress": "export const validateEvmAddress = (address) => {\n  // Ensure a string was provided\n  if (typeof address !== \"string\") {\n    throw new Error(\"Address must be a string.\");\n  }\n\n  // Regex: 0x + 40 hexadecimal chars (case-insensitive)\n  const re = /^0x[a-fA-F0-9]{40}$/;\n\n  if (!re.test(address)) {\n    throw new Error(\"Invalid EVM address format.\");\n  }\n\n  // If the check passes, return the checksummed address (lower-cased here)\n  return address.toLowerCase();\n};",
	"getTransactionCount": "export const getTransactionCount = async ({ address, rpcEndpoint }) => {\n  // Validate parameters up-front\n  if (!address) throw new Error(\"'address' is required\");\n  if (!rpcEndpoint) throw new Error(\"'rpcEndpoint' is required\");\n\n  // JSON-RPC payload\n  const payload = {\n    jsonrpc: \"2.0\",\n    id: 1,\n    method: \"eth_getTransactionCount\",\n    params: [address, \"latest\"]\n  };\n\n  try {\n    const res = await fetch(rpcEndpoint, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\"\n      },\n      body: JSON.stringify(payload)\n    });\n\n    if (!res.ok) {\n      throw new Error(`RPC HTTP error: ${res.status} ${res.statusText}`);\n    }\n\n    const json = await res.json();\n\n    // Handle JSON-RPC error object\n    if (json.error) {\n      throw new Error(`RPC returned error: ${json.error.message || JSON.stringify(json.error)}`);\n    }\n\n    // json.result is a hex string, e.g. \"0x10\"\n    const nonceHex = json.result;\n    const nonce = parseInt(nonceHex, 16);\n\n    if (Number.isNaN(nonce)) {\n      throw new Error(`Unable to parse nonce from result: ${nonceHex}`);\n    }\n\n    return nonce;\n  } catch (err) {\n    // Re-throw with context so caller can surface it in UI\n    throw new Error(`Failed to fetch transaction count: ${err.message}`);\n  }\n};",
	"getWalletAddress": "export const getWalletAddress = async () => {\n  const chainId = 'neutron-1';\n\n  if (!window || !window.keplr) {\n    throw new Error('Keplr wallet is not installed in this browser.');\n  }\n\n  // Ask Keplr to enable the Neutron chain (will prompt the user on first run)\n  await window.keplr.enable(chainId);\n\n  // Retrieve the key information for this chain\n  const key = await window.keplr.getKey(chainId);\n\n  if (!key || !key.bech32Address) {\n    throw new Error('Failed to obtain a bech32 address from Keplr.');\n  }\n\n  return key.bech32Address; // e.g. neutron1...\n};",
	"fetchNtrnBalance": "export const fetchNtrnBalance = async (address) => {\n  // Public LCD endpoint — replace with your preferred endpoint or a proxy if needed\n  const LCD = 'https://lcd-neutron.blockpane.com';\n  const denom = 'untrn';\n\n  try {\n    const res = await fetch(`${LCD}/cosmos/bank/v1beta1/balances/${address}`);\n    if (!res.ok) {\n      throw new Error(`LCD error: ${res.status} ${res.statusText}`);\n    }\n    const data = await res.json();\n\n    /*  The response shape is:\n        {\n          \"balances\": [ { \"denom\": \"untrn\", \"amount\": \"12345\" }, ... ],\n          ...\n        }\n    */\n    const coin = (data.balances || []).find((c) => c.denom === denom);\n    const amount = coin ? Number(coin.amount) : 0;\n    return amount; // returns micro-denom amount (e.g. 2 000 000 000 for 2 000 NTRN)\n  } catch (err) {\n    console.error('[fetchNtrnBalance] ', err);\n    throw err;\n  }\n};",
	"validateLockAmount": "export const validateLockAmount = (rawBalance, amountToLock = 2_000_000_000) => {\n  if (rawBalance < amountToLock) {\n    throw new Error('Insufficient spendable NTRN balance (need ≥ 2,000 NTRN).');\n  }\n  /*\n    NOTE: Detecting whether funds are already vested or locked normally requires\n    contract-specific queries that are out of scope for a client-side snippet.\n    For simple front-end validation we only check spendable balance.\n  */\n  return true;\n};",
	"calculateUnlockTimestamp": "export const calculateUnlockTimestamp = () => {\n  const NOW_SEC = Math.floor(Date.now() / 1000); // JS Date gives ms\n  const LOCK_DURATION = 7_776_000; // 90 days in seconds\n  return NOW_SEC + LOCK_DURATION;\n};",
	"constructLockExecuteMsg": "export const constructLockExecuteMsg = ({ sender, amount = '2000000000', durationSeconds = 7_776_000 }) => {\n  if (!sender) throw new Error('`sender` is required');\n\n  const executeMsg = {\n    lock: {\n      duration_seconds: durationSeconds.toString()\n    }\n  };\n\n  return {\n    contract_address: 'neutron14lnmj4k0tqsfn3x8kmnmacg64ct2utyz0aaxtm5g3uwwp8kk4f6shcgrtt',\n    sender,\n    msg: executeMsg,\n    funds: [\n      {\n        denom: 'untrn',\n        amount: amount.toString()\n      }\n    ]\n  };\n};",
	"queryBoostMultiplier": "export const queryBoostMultiplier = async (address) => {\n  const BOOST_POINTER_CONTRACT = 'neutron1xxxxxxxxxxxxxxxxxxxxxxxxxxxxx'; // TODO: replace with real addr\n  const queryMsg = {\n    multiplier: {\n      address\n    }\n  };\n\n  // LCD expects the smart-query to be Base64-encoded\n  const base64Query = btoa(JSON.stringify(queryMsg));\n  const LCD = 'https://lcd-neutron.blockpane.com';\n\n  try {\n    const url = `${LCD}/cosmwasm/wasm/v1/contract/${BOOST_POINTER_CONTRACT}/smart/${base64Query}`;\n    const res = await fetch(url);\n    if (!res.ok) {\n      throw new Error(`LCD error: ${res.status} ${res.statusText}`);\n    }\n    const data = await res.json();\n    /*  Expected shape (example):\n        {\n          \"data\": {\n            \"multiplier\": \"1.25\"\n          }\n        }\n    */\n    return data.data?.multiplier ?? null;\n  } catch (err) {\n    console.error('[queryBoostMultiplier] ', err);\n    throw err;\n  }\n};",
	"signAndBroadcastClosePosition": "export const signAndBroadcastClosePosition = async ({\n  chainId           = 'neutron-1',\n  signDocBase64,               // from step 3\n  backendBroadcastUrl = '/api/amber/broadcast_signed_tx'\n}) => {\n  try {\n    const address     = await getUserAddress(chainId);\n    const signDocBytes = b64ToUint8(signDocBase64);\n\n    // Keplr — sign the SignDoc using signDirect\n    const { signed, signature } = await window.keplr.signDirect(\n      chainId,\n      address,\n      { typeUrl: '/cosmos.tx.v1beta1.SignDoc', value: signDocBytes }\n    );\n\n    // Convert binary blobs → base64 so they can be sent over HTTP\n    const bodyB64       = btoa(String.fromCharCode(...signed.bodyBytes));\n    const authInfoB64   = btoa(String.fromCharCode(...signed.authInfoBytes));\n    const sigB64        = btoa(String.fromCharCode(...signature.signature));\n\n    const res = await fetch(backendBroadcastUrl, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({\n        body_bytes: bodyB64,\n        auth_info_bytes: authInfoB64,\n        signatures: [sigB64]\n      })\n    });\n\n    if (!res.ok) {\n      const err = await res.json();\n      throw new Error(err.detail || 'Broadcast failed');\n    }\n\n    return await res.json(); // { txhash, height, ... }\n  } catch (err) {\n    console.error('[signAndBroadcastClosePosition] error:', err);\n    throw err;\n  }\n};",
	"fetchProjectionAndDisplay": "export const fetchProjectionAndDisplay = async (address) => {\n  try {\n    const res = await fetch(`/api/projection?address=${address}`);\n    if (!res.ok) {\n      throw new Error(`Backend responded with status ${res.status}`);\n    }\n\n    const data = await res.json();\n    const { points, projected_reward_ntrn, assumptions } = data;\n\n    const message = `With ${points} points and a per-point rate of ${assumptions.per_point_rate / 1_000_000} NTRN, you are projected to earn ≈ ${projected_reward_ntrn} NTRN this phase.`;\n\n    // Display the message however your UI prefers. Here we log to console.\n    console.log(message);\n    return message;\n  } catch (error) {\n    console.error('Failed to fetch projection:', error);\n    return 'Unable to compute projection at this time.';\n  }\n};",
	"constructSwapMsg": "export const constructSwapMsg = ({\n  sender,\n  contractAddress,\n  offerDenom = 'eBTC',\n  offerAmount = '1000000', // 1 eBTC in micro-units\n  askDenom = 'uniBTC',\n  maxSlippage = '0.005' // 0.5%\n}) => {\n  // Astroport-style swap execute message\n  const execMsg = {\n    swap: {\n      offer_asset: {\n        info: { native_token: { denom: offerDenom } },\n        amount: offerAmount\n      },\n      max_slippage: maxSlippage\n    }\n  };\n\n  // Construct the protobuf-ready envelope that cosmpy will later consume\n  return {\n    typeUrl: '/cosmwasm.wasm.v1.MsgExecuteContract',\n    value: {\n      sender,\n      contract: contractAddress,\n      msg: btoa(JSON.stringify(execMsg)), // base64-encoded JSON for CosmWasm\n      funds: [\n        { denom: offerDenom, amount: offerAmount }\n      ]\n    }\n  };\n};",
	"": "m",
	"{ chains, publicClient, webSocketPublicClient }": "export const { chains, publicClient, webSocketPublicClient } = configureChains(\n  supportedChains,\n  [\n    jsonRpcProvider({\n      rpc: () => ({\n        http: \"https://eth.bd.evmos.org:8545\"      // Public Evmos RPC\n      })\n    }),\n    publicProvider()                                 // Fallback public provider\n  ]\n);\n",
	"wagmiConfig": "export const wagmiConfig = createConfig({\n  autoConnect: true,\n  connectors,\n  publicClient\n});\n\nfunction App() {\n  return (\n    <WagmiConfig config={wagmiConfig}>\n      <RainbowKitProvider chains={chains}>\n        {/* Your routes / components go here */}\n        <ConnectWallet />\n      </RainbowKitProvider>\n    </WagmiConfig>\n  );\n}\n\nexport default App;\n",
	"validateAddresses": "export const validateAddresses = (delegatorAddress, validatorAddress) => {\n  // Generic Bech32 address shape: <prefix>1<38-char lowercase bech32 body>\n  const buildRegex = (prefix) => new RegExp(`^${prefix}1[0-9a-z]{38}$`);\n\n  if (!buildRegex('cosmos').test(delegatorAddress)) {\n    throw new Error('Invalid delegator Bech32 address');\n  }\n  if (!buildRegex('cosmosvaloper').test(validatorAddress)) {\n    throw new Error('Invalid validator Bech32 address');\n  }\n  return true; // everything looks good\n};",
	"checkBalance": "export const checkBalance = async (\n  address,\n  lcdEndpoint = 'https://lcd.cosmos.directory/gaia',\n  minAmount = 500 /* stake */\n) => {\n  const url = `${lcdEndpoint}/cosmos/bank/v1beta1/balances/${address}`;\n  const res = await fetch(url);\n  if (!res.ok) {\n    throw new Error(`LCD error: ${res.status} ${res.statusText}`);\n  }\n\n  const { balances } = await res.json();\n  const stakeObj = balances.find((b) => b.denom === 'stake');\n  const available = stakeObj ? BigInt(stakeObj.amount) : 0n;\n\n  const estimatedFee = 5000n; // tweak for your chain\n  if (available < BigInt(minAmount) + estimatedFee) {\n    throw new Error('Insufficient balance for 500stake delegation plus fees');\n  }\n  return Number(available);\n};",
	"validateBech32Address": "export const validateBech32Address = (address, prefix = 'cosmos') => {\n  if (typeof address !== 'string') return false;\n\n  // Bech32 addresses are conventionally lowercase\n  if (address !== address.toLowerCase()) return false;\n\n  // Basic structural rule: <prefix>1<38 bech32 chars (excluding \"1\", \"b\", \"i\", \"o\")\n  const regex = new RegExp('^' + prefix + '1[ac-hj-np-z02-9]{38}$');\n  return regex.test(address);\n};",
	"addEvmosNetwork": "export const addEvmosNetwork = async () => {\n  // 1. Grab config from backend\n  const res = await fetch('/api/network/evmos');\n  if (!res.ok) {\n    throw new Error(`Could not fetch network config: ${res.statusText}`);\n  }\n  const config = await res.json();\n\n  // 2. Ensure MetaMask is present\n  if (typeof window === 'undefined' || !window.ethereum) {\n    throw new Error('MetaMask is not installed or window.ethereum is undefined.');\n  }\n\n  try {\n    // 3. Ask MetaMask to add the chain (opens confirmation modal for the user)\n    await window.ethereum.request({\n      method: 'wallet_addEthereumChain',\n      params: [config]\n    });\n\n    // 4. Optionally switch to the newly-added chain\n    await window.ethereum.request({\n      method: 'wallet_switchEthereumChain',\n      params: [{ chainId: config.chainId }]\n    });\n\n    return 'Network added & switched successfully';\n  } catch (error) {\n    console.error('MetaMask network setup failed', error);\n    throw error; // Propagate so the caller can handle (e.g., display toast)\n  }\n};",
	"getKeccakHashFromInput": "export const getKeccakHashFromInput = async () => {\n  try {\n    // Ask the user for the data to hash\n    const data = window.prompt(\n      \"Enter data (plain text or 0x-prefixed hex) to hash with Keccak-256:\"\n    );\n\n    if (!data) {\n      throw new Error(\"No input provided.\");\n    }\n\n    // Call the backend\n    const response = await fetch(\"/api/keccak\", {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\"\n      },\n      body: JSON.stringify({ data })\n    });\n\n    if (!response.ok) {\n      // Surface backend error details if available\n      const err = await response.json().catch(() => ({ error: \"Unknown error\" }));\n      throw new Error(err.error || \"Failed to compute Keccak hash.\");\n    }\n\n    const { hash } = await response.json();\n    return hash; // e.g., 0x…\n  } catch (error) {\n    console.error(error);\n    alert(`Error: ${error.message}`);\n    return null;\n  }\n};",
	"connectWallet": "export const connectWallet = async () => {\n  const chainId = 'neutron-1';\n\n  // Detect supported wallets in order of preference\n  const wallet = (window.keplr || window.leap || window.walletConnect) ?? null;\n  if (!wallet) {\n    throw new Error('No supported wallet found. Please install Keplr or Leap, or connect via WalletConnect.');\n  }\n\n  try {\n    // Ask the wallet to enable access to Neutron\n    await wallet.enable(chainId);\n\n    // Retrieve an OfflineSigner that will be used in later steps\n    const signer = await wallet.getOfflineSignerAuto(chainId);\n\n    return { wallet, signer };\n  } catch (error) {\n    console.error('connectWallet() failed:', error);\n    throw new Error('Wallet connection was rejected or failed.');\n  }\n};",
	"ensureNetworkNeutron": "export const ensureNetworkNeutron = async (wallet) => {\n  const chainId = 'neutron-1';\n\n  // Neutron chain parameters — tweak RPC/REST endpoints as needed for production\n  const neutronChainInfo = {\n    chainId: 'neutron-1',\n    chainName: 'Neutron',\n    rpc: 'https://rpc-kralum.neutron-1.neutron.org',\n    rest: 'https://rest-kralum.neutron-1.neutron.org',\n    stakeCurrency: { coinDenom: 'NTRN', coinMinimalDenom: 'untrn', coinDecimals: 6 },\n    bip44: { coinType: 118 },\n    bech32Config: {\n      bech32PrefixAccAddr: 'neutron',\n      bech32PrefixAccPub: 'neutronpub',\n      bech32PrefixValAddr: 'neutronvaloper',\n      bech32PrefixValPub: 'neutronvaloperpub',\n      bech32PrefixConsAddr: 'neutronvalcons',\n      bech32PrefixConsPub: 'neutronvalconspub'\n    },\n    currencies: [\n      { coinDenom: 'NTRN', coinMinimalDenom: 'untrn', coinDecimals: 6 }\n    ],\n    feeCurrencies: [\n      { coinDenom: 'NTRN', coinMinimalDenom: 'untrn', coinDecimals: 6, gasPriceStep: { low: 0.01, average: 0.025, high: 0.04 } }\n    ],\n    features: ['stargate', 'ibc-transfer', 'cosmwasm']\n  };\n\n  try {\n    // Attempt to query the chain; if it throws, the chain likely isn't added yet\n    await wallet.getKey(chainId);\n  } catch (_) {\n    // Use Keplr/Leap experimental API to suggest the chain\n    if (wallet.experimentalSuggestChain) {\n      await wallet.experimentalSuggestChain(neutronChainInfo);\n    } else {\n      throw new Error('The connected wallet does not support adding new chains.');\n    }\n  }\n\n  // Re-enable to make sure we have permission on the (new) chain\n  await wallet.enable(chainId);\n};",
	"storeSessionAccount": "export const storeSessionAccount = async (signer) => {\n  try {\n    const accounts = await signer.getAccounts();\n    if (!accounts || accounts.length === 0) {\n      throw new Error('No accounts returned by signer.');\n    }\n    const { address, pubkey } = accounts[0];\n\n    // Save as JSON for later retrieval\n    const sessionData = JSON.stringify({ address, pubkey: Buffer.from(pubkey).toString('base64') });\n    sessionStorage.setItem('neutron_session_account', sessionData);\n\n    return { address, pubkey };\n  } catch (error) {\n    console.error('storeSessionAccount() failed:', error);\n    throw new Error('Unable to retrieve or store account information.');\n  }\n};",
	"prepareBinaryInput": "export const prepareBinaryInput = async (file) => {\n  if (!file) {\n    throw new Error('No file supplied for conversion.');\n  }\n\n  const formData = new FormData();\n  formData.append('file', file);\n\n  const response = await fetch('/api/cast/from-bin', {\n    method: 'POST',\n    body: formData,\n  });\n\n  if (!response.ok) {\n    const errorText = await response.text();\n    throw new Error(`Backend error: ${errorText}`);\n  }\n\n  const { hex } = await response.json();\n  return hex; // Forward to the caller for further handling\n};",
	"captureOutput": "export const captureOutput = async (hex) => {\n  if (typeof hex !== 'string' || !hex.startsWith('0x')) {\n    throw new Error('Invalid hex string supplied.');\n  }\n  try {\n    await navigator.clipboard.writeText(hex);\n    console.log('Hex string copied to clipboard');\n  } catch (err) {\n    console.error('Clipboard write failed:', err);\n  }\n  return hex; // Return for optional chaining\n};",
	"prepareProfileParameters": "export const prepareProfileParameters = () => ({\n  duration: 10,          // seconds\n  outputPath: 'mutex.prof'\n});",
	"getNeutronAddress": "export const getNeutronAddress = async () => {\n  const chainId = 'neutron-1'; // main-net chain ID\n  try {\n    if (!window?.keplr) {\n      throw new Error('Keplr wallet is not installed.');\n    }\n\n    // Request wallet connection for the chain\n    await window.keplr.enable(chainId);\n\n    // Retrieve the signer and the account list\n    const signer = window.getOfflineSigner(chainId);\n    const accounts = await signer.getAccounts();\n\n    if (!accounts.length) {\n      throw new Error('No account found inside Keplr.');\n    }\n\n    return accounts[0].address;\n  } catch (err) {\n    console.error(err);\n    throw err;\n  }\n};",
	"getUserEvmAddressInput": "export const getUserEvmAddressInput = () => {\n  const input = prompt('Enter the destination Ethereum (EVM) address (0x…)');\n  if (!input) {\n    throw new Error('No Ethereum address supplied by user.');\n  }\n  return input.trim();\n};",
	"validateEthereumAddress": "export const validateEthereumAddress = (evmAddress) => {\n  const regex = /^0x[a-fA-F0-9]{40}$/;\n  if (!regex.test(evmAddress)) {\n    throw new Error('Invalid Ethereum address format.');\n  }\n  return true;\n};",
	"constructSetTargetMsg": "export const constructSetTargetMsg = ({\n  contractAddress,\n  senderAddress,\n  evmAddress,\n}) => {\n  // Contract-level JSON payload\n  const payload = { set_target: { evm_address: evmAddress } };\n\n  // CosmWasm execute envelope\n  return {\n    typeUrl: '/cosmwasm.wasm.v1.MsgExecuteContract',\n    value: {\n      sender: senderAddress,\n      contract: contractAddress,\n      msg: Array.from(\n        new TextEncoder().encode(JSON.stringify(payload))\n      ),\n      funds: [],\n    },\n  };\n};",
	"queryBoostTarget": "export const queryBoostTarget = async (contractAddress) => {\n  try {\n    const queryMsg = { target: {} };\n    const encoded = btoa(JSON.stringify(queryMsg)); // base64-encode the query JSON\n\n    const endpoint = `https://rest-kralum.neutron.org/cosmwasm/wasm/v1/contract/${contractAddress}/smart/${encoded}`;\n    const resp = await fetch(endpoint);\n\n    if (!resp.ok) {\n      throw new Error(`Query failed with ${resp.status}: ${resp.statusText}`);\n    }\n\n    const result = await resp.json();\n    return result; // Expected shape: { data: { evm_address: '0x...' } }\n  } catch (err) {\n    console.error(err);\n    throw err;\n  }\n};",
	"displayPoints": "export const displayPoints = (points) => {\n  // Locate—or create—the DOM element for displaying points\n  let container = document.getElementById('points-display');\n  if (!container) {\n    container = document.createElement('div');\n    container.id = 'points-display';\n    document.body.appendChild(container);\n  }\n  container.textContent = `You have ${points} point${points === 1 ? '' : 's'} in the current campaign phase.`;\n};",
	"SECONDS_PER_YEAR": "export const SECONDS_PER_YEAR = 60 * 60 * 24 * 365;\n\nexport const rateToAPY = (ratePerSecond) => {\n  const r = Number(ratePerSecond);\n  if (isNaN(r)) {\n    throw new Error('rateToAPY received an invalid number');\n  }\n  const apy = (Math.pow(1 + r, SECONDS_PER_YEAR) - 1) * 100; // convert to %\n  return Number(apy.toFixed(2));\n};",
	"getAccountAddress": "export const getAccountAddress = async () => {\n  if (typeof window === \"undefined\" || !window.ethereum) {\n    throw new Error(\"No Ethereum provider found. Make sure MetaMask is installed.\");\n  }\n\n  try {\n    // Prompt user to connect their wallet\n    const accounts = await window.ethereum.request({\n      method: \"eth_requestAccounts\"\n    });\n\n    if (!accounts || accounts.length === 0) {\n      throw new Error(\"No accounts returned from provider.\");\n    }\n\n    // Return the first account by convention\n    return accounts[0];\n  } catch (err) {\n    console.error(\"Failed to fetch account address\", err);\n    throw new Error(\"Could not obtain account address. Check console for details.\");\n  }\n};",
	"detectLeapProvider": "export const detectLeapProvider = async () => {\n  // Ensure we're in a browser environment\n  if (typeof window === 'undefined') {\n    throw new Error('This function must be run in a browser context.');\n  }\n\n  // 1) Check if the Leap extension has already injected itself\n  if (window.leap) {\n    return window.leap;\n  }\n\n  // 2) Fallback: attempt to dynamically import the Cosmos Kit Leap adapter\n  try {\n    const { LeapWallet } = await import('@cosmos-kit/leap');\n    const leapAdapter = new LeapWallet();\n\n    // The adapter offers helper methods to check installation status\n    if (await leapAdapter.isInstalled?.()) {\n      return leapAdapter;\n    }\n  } catch (err) {\n    console.error('Failed to load @cosmos-kit/leap adapter:', err);\n  }\n\n  // If we reach here, Leap is not available\n  throw new Error('Leap Wallet provider not found. Please install the Leap browser extension.');\n};",
	"suggestNeutronChain": "export const suggestNeutronChain = async (leap) => {\n  const chainConfig = {\n    // Basic chain info\n    chainId: 'neutron-1',\n    chainName: 'Neutron',\n\n    // Public RPC & REST endpoints (replace with your own if self-hosting)\n    rpc: 'https://rpc-kralum.neutron.org',\n    rest: 'https://lcd-kralum.neutron.org',\n\n    // BIP-44 & Bech32 configuration\n    bip44: { coinType: 118 },\n    bech32Config: {\n      bech32PrefixAccAddr: 'neutron',\n      bech32PrefixAccPub: 'neutronpub',\n      bech32PrefixValAddr: 'neutronvaloper',\n      bech32PrefixValPub: 'neutronvaloperpub',\n      bech32PrefixConsAddr: 'neutronvalcons',\n      bech32PrefixConsPub: 'neutronvalconspub',\n    },\n\n    // Denomination definitions\n    stakeCurrency: {\n      coinDenom: 'NTRN',\n      coinMinimalDenom: 'untrn',\n      coinDecimals: 6,\n    },\n    currencies: [\n      {\n        coinDenom: 'NTRN',\n        coinMinimalDenom: 'untrn',\n        coinDecimals: 6,\n      },\n    ],\n    feeCurrencies: [\n      {\n        coinDenom: 'NTRN',\n        coinMinimalDenom: 'untrn',\n        coinDecimals: 6,\n        gasPriceStep: {\n          low: 0.01,\n          average: 0.025,\n          high: 0.04,\n        },\n      },\n    ],\n\n    // Feature flags recognised by Leap\n    features: ['stargate', 'ibc-transfer', 'cosmwasm'],\n  };\n\n  try {\n    await leap.experimentalSuggestChain(chainConfig);\n  } catch (error) {\n    console.error('Failed to suggest Neutron chain to Leap:', error);\n    throw new Error('Chain suggestion rejected or failed.');\n  }\n};",
	"enableNeutronChain": "export const enableNeutronChain = async (leap) => {\n  const chainId = 'neutron-1';\n  try {\n    await leap.enable(chainId);\n  } catch (error) {\n    console.error('User rejected or failed to enable Neutron chain:', error);\n    throw new Error('Failed to enable Neutron chain in Leap.');\n  }\n};",
	"retrieveLeapAccounts": "export const retrieveLeapAccounts = async (leap) => {\n  const chainId = 'neutron-1';\n\n  try {\n    // Prefer the more generic getOfflineSigner if available\n    const offlineSigner = leap.getOfflineSigner?.(chainId) || leap.getOfflineSignerOnlyAmino?.(chainId);\n\n    if (!offlineSigner) {\n      throw new Error('Could not obtain an OfflineSigner from Leap.');\n    }\n\n    const accounts = await offlineSigner.getAccounts();\n    if (!accounts || accounts.length === 0) {\n      throw new Error('No accounts returned by Leap.');\n    }\n\n    return {\n      offlineSigner,\n      address: accounts[0].address,\n    };\n  } catch (error) {\n    console.error('Error while retrieving Leap accounts:', error);\n    throw error;\n  }\n};",
	"openWebsocketConnection": "export const openWebsocketConnection = (url = 'ws://localhost:8546') => {\n  return new Promise((resolve, reject) => {\n    try {\n      const ws = new WebSocket(url);\n\n      // Resolve when the connection opens successfully\n      ws.onopen = () => {\n        console.log(`WebSocket connected to ${url}`);\n        resolve(ws);\n      };\n\n      // Reject if an error occurs while connecting\n      ws.onerror = (err) => {\n        console.error('WebSocket connection error:', err);\n        reject(new Error(`Unable to connect to ${url}`));\n      };\n    } catch (error) {\n      reject(error);\n    }\n  });\n};",
	"ethSubscribePendingTxs": "export const ethSubscribePendingTxs = (ws, requestId = 1) => {\n  if (!ws || ws.readyState !== WebSocket.OPEN) {\n    throw new Error('WebSocket is not open.');\n  }\n\n  const payload = {\n    id: requestId,\n    method: 'eth_subscribe',\n    params: ['newPendingTransactions']\n  };\n\n  ws.send(JSON.stringify(payload));\n\n  return requestId; // Return the request id used\n};",
	"storeSubscriptionId": "export const storeSubscriptionId = (ws, callback) => {\n  const handler = (event) => {\n    try {\n      const msg = JSON.parse(event.data);\n\n      // The response to our subscription request will have the same id we sent (1 by default) and a 'result' field.\n      if (msg.id === 1 && msg.result) {\n        const subscriptionId = msg.result;\n        console.log('Received subscription id:', subscriptionId);\n\n        // Persist for later use\n        localStorage.setItem('pendingTxSubscriptionId', subscriptionId);\n\n        // Stop listening for the acknowledgement once received\n        ws.removeEventListener('message', handler);\n\n        if (typeof callback === 'function') {\n          callback(subscriptionId);\n        }\n      }\n    } catch (err) {\n      console.error('Failed to parse subscription response:', err);\n    }\n  };\n\n  ws.addEventListener('message', handler);\n};",
	"listenForPendingTxNotifications": "export const listenForPendingTxNotifications = (ws, callback) => {\n  ws.addEventListener('message', (event) => {\n    try {\n      const msg = JSON.parse(event.data);\n\n      // A notification will contain the method 'eth_subscription'\n      if (msg.method === 'eth_subscription' && msg.params) {\n        const { subscription, result: txHash } = msg.params;\n\n        if (typeof callback === 'function') {\n          callback({ subscriptionId: subscription, txHash });\n        }\n      }\n    } catch (err) {\n      // Non-JSON or unrelated messages can be safely ignored\n    }\n  });\n};",
	"getSignedRawTx": "export const getSignedRawTx = async () => {\n  // Prompt the user to paste a raw, signed transaction.\n  // In production you would integrate with the wallet’s SDK instead of using window.prompt().\n  const rawTx = window.prompt('Please paste the 0x-prefixed, RLP-encoded transaction:');\n\n  // Basic validation\n  if (!rawTx) {\n    throw new Error('Transaction input cancelled by user.');\n  }\n  if (!rawTx.startsWith('0x')) {\n    throw new Error('Raw transaction must start with 0x.');\n  }\n  if (rawTx.length < 10) {\n    throw new Error('Raw transaction appears too short.');\n  }\n\n  return rawTx.trim();\n};",
	"captureTxHash": "export const captureTxHash = (txHash) => {\n  if (!txHash || !txHash.startsWith('0x')) {\n    throw new Error('Invalid transaction hash received.');\n  }\n  const storageKey = 'sentTxs';\n  const existing = JSON.parse(localStorage.getItem(storageKey) || '[]');\n  existing.push({ hash: txHash, timestamp: Date.now() });\n  localStorage.setItem(storageKey, JSON.stringify(existing));\n  return txHash;\n};",
	"getRpcUrl": "export const getRpcUrl = () => {\n  // You can hard-code, pull from an env variable, or prompt the user.\n  const defaultRpc = 'https://rpc.evmos.dev'; // Example RPC; replace for your chain\n  const rpc = window.prompt('Enter a Cosmos-EVM RPC URL', defaultRpc);\n  if (!rpc) throw new Error('RPC URL is required.');\n  return rpc.trim();\n};",
	"constructTxParams": "export const constructTxParams = ({ recipient, amount, gasPrice, gasLimit, data = '' }) => {\n  if (!recipient || !amount || !gasPrice || !gasLimit) {\n    throw new Error('Missing required transaction parameter(s).');\n  }\n  return {\n    recipient,\n    amount,       // Value expressed in wei (e.g., '1000000000000000000' for 1 ETH-denom token)\n    gas_price: gasPrice, // also in wei\n    gas_limit: gasLimit, // integer\n    data          // optional hex data string\n  };\n};",
	"connectNeutronWallet": "export const connectNeutronWallet = async (chainId = 'neutron-1') => {\n  // Ensure Keplr is available\n  if (typeof window === 'undefined' || !window.keplr) {\n    throw new Error('Keplr wallet is not installed.');\n  }\n\n  try {\n    await window.keplr.enable(chainId);\n    const signer = window.keplr.getOfflineSigner(chainId);\n    const accounts = await signer.getAccounts();\n    if (!accounts || accounts.length === 0) {\n      throw new Error('No account found in Keplr.');\n    }\n    return { signer, address: accounts[0].address };\n  } catch (err) {\n    console.error('Failed to connect to Keplr:', err);\n    throw err;\n  }\n};",
	"promptContractAddress": "export const promptContractAddress = () => {\n  // Browser prompt for simplicity; replace with a nicer UI as needed\n  const contractAddr = prompt('Enter the CosmWasm contract address to update admin for:');\n\n  if (!contractAddr) {\n    throw new Error('Contract address is required.');\n  }\n\n  const trimmed = contractAddr.trim();\n\n  // Basic bech32 length sanity-check (optional: use full bech32 validation)\n  if (trimmed.length < 40 || trimmed.length > 90) {\n    throw new Error('Invalid contract address length.');\n  }\n\n  return trimmed;\n};",
	"extractGasInfo": "export const extractGasInfo = (simulationResponse) => {\n  if (!simulationResponse || !simulationResponse.gas_info) {\n    throw new Error('Missing gas_info in simulation response');\n  }\n  const { gas_used, gas_wanted } = simulationResponse.gas_info;\n  return {\n    gasUsed: Number(gas_used),\n    gasWanted: Number(gas_wanted),\n  };\n};",
	"queryContractSmart": "export const queryContractSmart = async (rpcEndpoint, contractAddress, queryMsg) => {\n  if (!rpcEndpoint || !contractAddress || !queryMsg) {\n    throw new Error('RPC endpoint, contract address, and query message are all required.');\n  }\n\n  try {\n    // Create a read-only CosmWasm client\n    const client = await CosmWasmClient.connect(rpcEndpoint);\n\n    // Execute the smart query\n    const result = await client.queryContractSmart(contractAddress, queryMsg);\n\n    return result; // Expected shape: { amount: \"<uNTRN>\" }\n  } catch (err) {\n    console.error('Smart-contract query failed:', err);\n    throw err;\n  }\n};",
	"REST_ENDPOINT": "export const REST_ENDPOINT = \"https://rest-kralum.neutron-1.neutron.org\"; // Replace with your preferred REST endpoint\n\nexport const isFeeDenomEligible = async (denom = \"uusdc\", restEndpoint = REST_ENDPOINT) => {\n  try {\n    const res = await fetch(`${restEndpoint}/neutron/dynamicfees/params`);\n    if (!res.ok) throw new Error(`HTTP ${res.status}`);\n\n    const json = await res.json();\n    const prices = json?.params?.ntrn_prices ?? [];\n    const eligible = prices.some((d) => d.denom === denom);\n\n    if (!eligible) {\n      throw new Error(`${denom} is not found in ntrn_prices ‑ it cannot be used to pay fees.`);\n    }\n\n    return {\n      eligible: true,\n      raw: json\n    };\n  } catch (err) {\n    console.error(\"Dynamic-fees query failed\", err);\n    throw err;\n  }\n};",
	"getMinGasPrice": "export const getMinGasPrice = async (denom = \"uusdc\", restEndpoint = REST_ENDPOINT) => {\n  try {\n    const res = await fetch(`${restEndpoint}/neutron/globalfee/min_gas_prices`);\n    if (!res.ok) throw new Error(`HTTP ${res.status}`);\n\n    const json = await res.json(); // [{ denom: \"untrn\", amount: \"0.015\" }, ...]\n    const entry = (json || []).find((e) => e.denom === denom);\n    if (!entry) throw new Error(`No gas-price entry for denom ${denom}`);\n\n    return entry.amount; // string, e.g. \"0.07\"\n  } catch (err) {\n    console.error(\"Global-fee query failed\", err);\n    throw err;\n  }\n};",
	"setDefaultFeeDenom": "export const setDefaultFeeDenom = (denom = \"uusdc\") => {\n  try {\n    localStorage.setItem(\"NEUTRON_FEE_DENOM\", denom);\n  } catch (err) {\n    console.warn(\"Unable to write NEUTRON_FEE_DENOM to localStorage\", err);\n  }\n};",
	"collectTargetAddress": "export const collectTargetAddress = () => {\n  // Assuming there is an <input id=\"address-input\" /> in the DOM\n  const raw = document.getElementById('address-input')?.value?.trim();\n  // Basic sanity checks; for production use a bech32 library\n  if (!raw || !/^([a-z0-9]+)1[0-9a-z]{38}$/.test(raw)) {\n    throw new Error('Invalid bech32 address supplied.');\n  }\n  return raw;\n};",
	"fetchAndParseBalances": "export const fetchAndParseBalances = async (address) => {\n  const res = await fetch(`/api/balances?address=${encodeURIComponent(address)}`);\n  if (!res.ok) {\n    const { detail } = await res.json().catch(() => ({ detail: res.statusText }));\n    throw new Error(`Backend error: ${detail}`);\n  }\n  const data = await res.json();\n  // Ensure we always return an array even if no balances are found\n  return (data.balances || []).map(({ denom, amount }) => ({ denom, amount }));\n};",
	"createTxpoolPayload": "export const createTxpoolPayload = (depth = 'inspect') => {\n  // Acceptable values are 'inspect' or 'content'. Default = 'inspect'.\n  const allowed = ['inspect', 'content'];\n  if (!allowed.includes(depth)) {\n    throw new Error(`Invalid depth: ${depth}. Expected 'inspect' or 'content'.`);\n  }\n\n  const method = depth === 'content' ? 'txpool_content' : 'txpool_inspect';\n\n  return {\n    jsonrpc: '2.0',\n    method,\n    params: [],\n    id: Date.now() // simple unique identifier\n  };\n};",
	"getDelegatorAddress": "export const getDelegatorAddress = async (chainId = 'neutron-1') => {\n  if (!window || !window.keplr) {\n    throw new Error('Keplr wallet is not installed.');\n  }\n\n  try {\n    // Prompt wallet connection / network enable\n    await window.keplr.enable(chainId);\n\n    // Retrieve signer & accounts\n    const signer = window.getOfflineSigner(chainId);\n    const accounts = await signer.getAccounts();\n\n    if (!accounts.length) {\n      throw new Error('No accounts found in the connected wallet.');\n    }\n\n    return {\n      address: accounts[0].address,\n      signer,\n    };\n  } catch (err) {\n    console.error('[Keplr-Connect] ::', err);\n    throw new Error('Failed to connect the wallet.');\n  }\n};",
	"queryPendingStakingRewards": "export const queryPendingStakingRewards = async (\n  delegatorAddress,\n  restEndpoint = 'https://rest-kralum.neutron-1.neutron.org'\n) => {\n  const url = `${restEndpoint}/cosmos/distribution/v1beta1/delegators/${delegatorAddress}/rewards`;\n  try {\n    const res = await fetch(url);\n    if (!res.ok) {\n      throw new Error(`Distribution query failed :: ${res.status}`);\n    }\n    return await res.json();\n  } catch (error) {\n    console.error('[Query-Rewards] ::', error);\n    throw error;\n  }\n};",
	"calculatePartialRewards": "export const calculatePartialRewards = (\n  rewardsResponse,\n  fraction = 0.5,\n  denom = 'untrn'\n) => {\n  if (!rewardsResponse || !Array.isArray(rewardsResponse.rewards)) {\n    throw new Error('Malformed rewards response.');\n  }\n\n  const partial = rewardsResponse.rewards\n    .map((entry) => {\n      const coin = (entry.reward || []).find((c) => c.denom === denom);\n      const rawAmount = coin ? Number(coin.amount) : 0;\n      const half = Math.floor(rawAmount * fraction);\n      return {\n        validator_address: entry.validator_address,\n        amount: half.toString(),\n        denom,\n      };\n    })\n    .filter((c) => Number(c.amount) > 0);\n\n  return partial;\n};",
	"signAndBroadcastWithdrawal": "export const signAndBroadcastWithdrawal = async (\n  signerAddress,\n  signDoc,\n  apiUrl = '/api/broadcast_tx'\n) => {\n  if (!window.keplr) {\n    throw new Error('Keplr wallet missing.');\n  }\n\n  // Re-build the object expected by signDirect\n  const directSignDoc = {\n    bodyBytes: Uint8Array.from(atob(signDoc.body_bytes), (c) => c.charCodeAt(0)),\n    authInfoBytes: Uint8Array.from(atob(signDoc.auth_info_bytes), (c) => c.charCodeAt(0)),\n    chainId: signDoc.chain_id,\n    accountNumber: BigInt(signDoc.account_number),\n  };\n\n  // -------------------\n  // 1) Sign the TX bytes\n  // -------------------\n  const { signature } = await window.keplr.signDirect(\n    signDoc.chain_id,\n    signerAddress,\n    directSignDoc\n  );\n\n  // ------------------------------------------------\n  // 2) Send the signed payload to the backend (BFF)\n  // ------------------------------------------------\n  const res = await fetch(apiUrl, {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({\n      body_bytes: signDoc.body_bytes,\n      auth_info_bytes: signDoc.auth_info_bytes,\n      signature: Buffer.from(signature.signature).toString('base64'),\n    }),\n  });\n\n  if (!res.ok) {\n    const err = await res.json();\n    throw new Error(err.detail || 'Broadcast failed');\n  }\n\n  return await res.json(); // { txhash: '...' }\n};",
	"submitProposalToMainDao": "export const submitProposalToMainDao = async (offlineSigner, sender, proposal) => {\n  try {\n    const client = await SigningCosmWasmClient.connectWithSigner(rpcEndpoint, offlineSigner);\n\n    // Wrap the Cron messages in a CW-dao single-choice proposal\n    const execMsg = {\n      propose: {\n        msg: {\n          propose_single: {\n            title: proposal.title,\n            description: proposal.description,\n            msgs: proposal.messages,\n          },\n        },\n      },\n    };\n\n    const fee = \"auto\";\n    const result = await client.execute(sender, daoAddress, execMsg, fee);\n    return result;\n  } catch (error) {\n    console.error(\"Failed to submit proposal\", error);\n    throw error;\n  }\n};",
	"gatherProposalMetadata": "export const gatherProposalMetadata = ({\n  title,\n  description,\n  summary,\n  depositAmount,\n  depositDenom\n}) => {\n  // Basic validation\n  if (!title || !description || !summary) {\n    throw new Error('Title, description, and summary are required.');\n  }\n  if (!/^[0-9]+$/.test(depositAmount)) {\n    throw new Error('Deposit amount must be an integer string (micro-denom).');\n  }\n  if (!depositDenom) {\n    throw new Error('Deposit denom is required (e.g., \"uatom\").');\n  }\n\n  return {\n    title: title.trim(),\n    description: description.trim(),\n    summary: summary.trim(),\n    deposit_amount: depositAmount.trim(),\n    deposit_denom: depositDenom.trim()\n  };\n};",
	"submitTextProposal": "export const submitTextProposal = async ({ proposerAddress, metadata }) => {\n  try {\n    const res = await fetch('/api/proposal/submit', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ proposer_address: proposerAddress, ...metadata })\n    });\n\n    if (!res.ok) {\n      const err = await res.text();\n      throw new Error(`Backend error: ${err}`);\n    }\n\n    const data = await res.json();\n    /* data = {\n         tx_hash: 'ABC123...',\n         proposal_id: 42\n       }\n    */\n    return data;\n  } catch (error) {\n    console.error('[submitTextProposal] ❌', error);\n    throw error;\n  }\n};",
	"displayLastExecutionHeight": "export const displayLastExecutionHeight = (height) => {\n  if (height === undefined || height === null) {\n    console.error('Height is not provided.');\n    return;\n  }\n  console.log(`Last execution height: ${height}`);\n  // You can additionally inject this into the DOM, e.g.,\n  // document.getElementById('last-height').textContent = `Last execution height: ${height}`;\n};",
	"fetchSnapshots": "export const fetchSnapshots = async () => {\n  try {\n    const res = await fetch('/api/snapshots');\n    if (!res.ok) {\n      throw new Error(`Server responded with ${res.status}`);\n    }\n    const json = await res.json();\n    return json.snapshots;\n  } catch (err) {\n    console.error('Failed to fetch snapshots', err);\n    throw err;\n  }\n};",
	"prepareJsonRpcPayload": "export const prepareJsonRpcPayload = (\n  method = \"eth_chainId\", // default method\n  params = [],             // default empty params\n  id = 1                   // default request id\n) => {\n  /*\n    Returns a well-formed JSON-RPC 2.0 payload, e.g.\n    {\n      jsonrpc: \"2.0\",\n      method: \"eth_chainId\",\n      params: [],\n      id: 1\n    }\n  */\n  return {\n    jsonrpc: \"2.0\",\n    method,\n    params,\n    id\n  };\n};",
	"sendRpcRequest": "export const sendRpcRequest = async (\n  endpoint = \"http://localhost:8545\", // default local endpoint\n  payload\n) => {\n  try {\n    const response = await fetch(endpoint, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\"\n      },\n      body: JSON.stringify(payload)\n    });\n\n    if (!response.ok) {\n      // Any non-2xx HTTP status is treated as an error\n      throw new Error(`HTTP error! status: ${response.status}`);\n    }\n\n    const json = await response.json();\n    return json;\n  } catch (error) {\n    console.error(\"Error sending RPC request:\", error);\n    throw error; // propagate so caller can handle\n  }\n};",
	"parseChainIdFromResponse": "export const parseChainIdFromResponse = (\n  rpcResponse,\n  asDecimal = false // set true if you want decimal output\n) => {\n  // Handle JSON-RPC error object if present\n  if (rpcResponse.error) {\n    throw new Error(`RPC Error: ${rpcResponse.error.message || \"Unknown error\"}`);\n  }\n\n  const chainIdHex = rpcResponse.result;\n\n  if (typeof chainIdHex !== \"string\") {\n    throw new Error(\"Invalid RPC response: 'result' field is not a string\");\n  }\n\n  // Return either hex (default) or decimal representation\n  return asDecimal ? parseInt(chainIdHex, 16) : chainIdHex;\n};",
	"validateEthAddress": "export const validateEthAddress = (address) => {\n  const regex = /^0x[0-9a-fA-F]{40}$/;\n  if (!regex.test(address)) {\n    throw new Error('Invalid Ethereum address format.');\n  }\n  return true; // address is valid\n};",
	"selectRpcEndpoint": "export const selectRpcEndpoint = () => {\n  // A small pool of free public RPC providers\n  const endpoints = [\n    'https://cloudflare-eth.com',\n    'https://rpc.flashbots.net'\n  ];\n  return endpoints[Math.floor(Math.random() * endpoints.length)];\n};",
	"parseBalanceHexToDecimal": "export const parseBalanceHexToDecimal = (balanceHex) => {\n  if (!balanceHex || typeof balanceHex !== 'string') {\n    throw new Error('balanceHex must be a non-empty hex string.');\n  }\n  try {\n    const weiBigInt = BigInt(balanceHex); // BigInt handles the 0x prefix\n    const weiStr = weiBigInt.toString(10);\n    const etherStr = (weiBigInt / 10n ** 18n).toString(10);\n    return { wei: weiStr, ether: etherStr };\n  } catch (err) {\n    throw new Error('Failed to parse balance: ' + err.message);\n  }\n};",
	"ensureKeplrInstalled": "export const ensureKeplrInstalled = async () => {\n  // Verifies Keplr is injected into the browser window.\n  if (typeof window === 'undefined' || !window.keplr) {\n    // If not installed, open the official download page and throw an error.\n    window.open('https://www.keplr.app/download', '_blank');\n    throw new Error('Keplr extension is not installed.');\n  }\n\n  // At this point Keplr exists; returning it allows subsequent steps to use the instance.\n  return window.keplr;\n};",
	"enableNeutron": "export const enableNeutron = async (chainId = 'neutron-1') => {\n  if (!window.keplr) {\n    throw new Error('Keplr extension not detected.');\n  }\n  try {\n    await window.keplr.enable(chainId); // Opens the Keplr approval popup.\n    return true; // Success indicates the site now has access to the chain.\n  } catch (err) {\n    console.error(`User rejected enabling ${chainId}:`, err);\n    throw err;\n  }\n};",
	"getOfflineSignerAndAddress": "export const getOfflineSignerAndAddress = async (chainId = 'neutron-1') => {\n  if (!window.keplr) {\n    throw new Error('Keplr extension not found.');\n  }\n\n  // Obtain the signer (supports Amino & Direct)\n  const offlineSigner = window.getOfflineSigner(chainId);\n  const accounts = await offlineSigner.getAccounts();\n\n  if (!accounts || accounts.length === 0) {\n    throw new Error('No accounts returned from Keplr.');\n  }\n\n  return {\n    signer: offlineSigner,\n    address: accounts[0].address\n  };\n};",
	"gatherScheduleInputs": "export const gatherScheduleInputs = () => {\n  // In a real app you would read these from form fields or a config file.\n  const scheduleName = \"daily_rewards\";            // Unique schedule identifier\n  const period = 7200;                              // Blocks between executions\n  const executionStage = \"EXECUTION_STAGE_END_BLOCKER\"; // When to fire (Begin/End block)\n  const targetContract = \"neutron1contract...\";     // Rewards contract address\n\n  // CosmWasm execute payload that the cron job will run each period\n  const rewardsMsg = {\n    distribute: {}\n  };\n\n  // MsgExecuteContract that the Cron module will invoke\n  const compiledExecuteMsg = {\n    \"@type\": \"/cosmwasm.wasm.v1.MsgExecuteContract\",\n    \"sender\": targetContract,         // will be overwritten by Cron when executed\n    \"contract\": targetContract,\n    \"msg\": Buffer.from(JSON.stringify(rewardsMsg)).toString(\"base64\"),\n    \"funds\": []\n  };\n\n  return {\n    scheduleName,\n    period,\n    executionStage,\n    authority: \"neutron1mainDAOaddress...\", // DAO (gov) address that controls Cron\n    msgs: [compiledExecuteMsg]\n  };\n};",
	"promptWeiAmount": "export const promptWeiAmount = () => {\n  return new Promise((resolve, reject) => {\n    try {\n      // Ask the user for a Wei amount\n      const wei = window.prompt(\n        \"Enter a Wei amount (e.g., 420000000000000000):\"\n      );\n\n      // Basic validations ---------------------------------------------------\n      if (wei === null) {\n        return reject(new Error(\"Prompt was cancelled by the user.\"));\n      }\n      const trimmed = wei.trim();\n      if (!/^\\d+$/.test(trimmed)) {\n        return reject(\n          new Error(\"Wei amount must be a non-negative integer in string form.\")\n        );\n      }\n\n      // Return the clean, validated value\n      resolve(trimmed);\n    } catch (err) {\n      reject(err);\n    }\n  });\n};",
	"myContractAbi": "export const myContractAbi = [\n  {\n    inputs: [\n      { internalType: 'address', name: 'account', type: 'address' }\n    ],\n    name: 'balanceOf',\n    outputs: [\n      { internalType: 'uint256', name: '', type: 'uint256' }\n    ],\n    stateMutability: 'view',\n    type: 'function'\n  }\n  // 👉 add more fragments as required\n];",
	"readContract": "export const readContract = async ({ contractAddress, abi, functionName, args = [] }) => {\n  try {\n    const res = await fetch('/api/read-contract', {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({ contractAddress, abi, functionName, args }),\n    });\n\n    if (!res.ok) {\n      const { detail } = await res.json();\n      throw new Error(detail || 'Unexpected server error');\n    }\n\n    const { data } = await res.json();\n    return data;\n  } catch (error) {\n    console.error('Failed to read contract', error);\n    throw error;\n  }\n};",
	"collectMigrateMessage": "export const collectMigrateMessage = () => {\n  let msgInput = window.prompt(\"Enter the migrate message in JSON (default {}):\", \"{}\");\n  if (!msgInput || msgInput.trim() === \"\") {\n    msgInput = \"{}\";\n  }\n  try {\n    const msg = JSON.parse(msgInput);\n    return msg;\n  } catch (err) {\n    throw new Error(\"Invalid JSON supplied for migrate message.\");\n  }\n};",
	"constructMigrateTx": "export const constructMigrateTx = async ({\n  rpcEndpoint,\n  signer,\n  senderAddress,\n  contractAddress,\n  newCodeId,\n  migrateMsg,\n  gasPrice = \"0.025untrn\",\n  gasLimit = 300000,\n}) => {\n  try {\n    const client = await SigningCosmWasmClient.connectWithSigner(rpcEndpoint, signer, {\n      gasPrice: GasPrice.fromString(gasPrice),\n    });\n\n    const msg = {\n      typeUrl: \"/cosmwasm.wasm.v1.MsgMigrateContract\",\n      value: {\n        sender: senderAddress,\n        contract: contractAddress,\n        codeId: Long.fromNumber(newCodeId),\n        msg: toUtf8(JSON.stringify(migrateMsg)),\n      },\n    };\n\n    const fee = calculateFee(gasLimit, gasPrice);\n\n    return { client, msg, fee };\n  } catch (error) {\n    console.error(error);\n    throw new Error(\"Failed to construct migrate transaction.\");\n  }\n};",
	"signAndBroadcast": "export const signAndBroadcast = async (client, senderAddress, msg, fee) => {\n  try {\n    const result = await client.signAndBroadcast(senderAddress, [msg], fee);\n    if (result.code !== 0) {\n      throw new Error(`Broadcast failed with code ${result.code}: ${result.rawLog}`);\n    }\n    console.info(`Migration successful. Tx hash: ${result.transactionHash}`);\n    return result;\n  } catch (error) {\n    console.error(error);\n    throw new Error(\"Failed to sign and broadcast the migrate transaction.\");\n  }\n};",
	"ethSubscribeNewHeads": "export const ethSubscribeNewHeads = (ws) => {\n  return new Promise((resolve, reject) => {\n    // Use a timestamp as a simple unique id; production code may want a counter.\n    const id = Date.now();\n\n    const request = {\n      id,\n      jsonrpc: '2.0',\n      method: 'eth_subscribe',\n      params: ['newHeads']\n    };\n\n    // Handler waits for the matching response frame.\n    const handleMessage = (event) => {\n      try {\n        const data = JSON.parse(event.data);\n        if (data.id === id) {\n          ws.removeEventListener('message', handleMessage);\n          if (data.error) {\n            reject(new Error(`Subscription failed: ${data.error.message}`));\n          } else {\n            resolve(data.result); // This is the subscription ID\n          }\n        }\n      } catch (_) {\n        /* Ignore non-JSON frames */\n      }\n    };\n\n    ws.addEventListener('message', handleMessage);\n\n    // Fire the request\n    ws.send(JSON.stringify(request));\n  });\n};",
	"listenForNewBlocks": "export const listenForNewBlocks = (ws, subId, onNewBlock) => {\n  if (!subId) throw new Error('Subscription ID is required to listen for notifications.');\n  if (typeof onNewBlock !== 'function') throw new Error('onNewBlock callback must be a function.');\n\n  const handleMessage = (event) => {\n    try {\n      const data = JSON.parse(event.data);\n      if (\n        data.method === 'eth_subscription' &&\n        data.params &&\n        data.params.subscription === subId\n      ) {\n        // Pass the block header (data.params.result) to the callback\n        onNewBlock(data.params.result);\n      }\n    } catch (_) {\n      /* Ignore frames we can’t parse */\n    }\n  };\n\n  ws.addEventListener('message', handleMessage);\n\n  // Return a disposer in case the caller wants to stop listening later.\n  return () => ws.removeEventListener('message', handleMessage);\n};",
	"getWalletUrl": "export const getWalletUrl = async () => {\n  // Prompt the user for the keystore location\n  const rawUrl = window.prompt('Enter the remote URL where the wallet keystore will be created:');\n  if (!rawUrl) {\n    throw new Error('URL cannot be empty.');\n  }\n\n  try {\n    const url = new URL(rawUrl);\n\n    // Simple protocol + hostname validation\n    if (!['http:', 'https:'].includes(url.protocol)) {\n      throw new Error('URL must start with http:// or https://');\n    }\n    if (!url.hostname) {\n      throw new Error('URL must contain a valid hostname.');\n    }\n\n    return url.toString();\n  } catch (err) {\n    throw new Error(`Invalid URL provided: ${err.message}`);\n  }\n};",
	"getCometRpcEndpoint": "export const getCometRpcEndpoint = () => COMET_RPC_ENDPOINT;\n\n/**\n * Update the global RPC endpoint in a type-safe way.\n * @param {string} url – Full URL including protocol, e.g. \"http://my-node:26657\".\n */\nexport const setCometRpcEndpoint = (url) => {\n  try {\n    const parsed = new URL(url);\n    // Strip trailing slash so we can safely concatenate paths later\n    COMET_RPC_ENDPOINT = parsed.href.replace(/\\/$/, '');\n  } catch (err) {\n    console.error('Invalid RPC endpoint supplied:', err);\n    throw new Error('Provided RPC endpoint is not a valid URL.');\n  }\n};",
	"constructWasmExecuteMsg": "export const constructWasmExecuteMsg = () => {\n  // According to the NeutronTemplate contract schema, this message increments a global counter\n  return {\n    increment_global: {}\n  };\n};",
	"getBTCWalletAddress": "export const getBTCWalletAddress = async () => {\n  // Attempt to connect to Unisat (or any extension that injects `window.unisat`)\n  if (window.unisat && typeof window.unisat.requestAccounts === 'function') {\n    try {\n      const accounts = await window.unisat.requestAccounts();\n      if (accounts && accounts.length > 0) {\n        return accounts[0];\n      }\n    } catch (err) {\n      console.error('Failed to fetch address from Unisat:', err);\n    }\n  }\n\n  // Fallback: ask user to type it in\n  const address = prompt('Please enter the Bitcoin address that will fund 1 BTC:');\n  if (!address || address.trim() === '') {\n    throw new Error('A valid Bitcoin address is required.');\n  }\n  return address.trim();\n};",
	"ensureMetaMaskInstalledAndUnlocked": "export const ensureMetaMaskInstalledAndUnlocked = async () => {\n  // Verify MetaMask extension is present\n  if (typeof window === 'undefined' || !window.ethereum || !window.ethereum.isMetaMask) {\n    throw new Error('MetaMask is not installed. Please install it from https://metamask.io/');\n  }\n\n  // Request account access (prompts unlock if locked)\n  const accounts = await window.ethereum.request({ method: 'eth_requestAccounts' }).catch((err) => {\n    console.error(err);\n    throw new Error('User denied account authorization or MetaMask is locked.');\n  });\n\n  if (!accounts || accounts.length === 0) {\n    throw new Error('No MetaMask accounts found.');\n  }\n\n  return accounts[0]; // Return the active address\n};",
	"addCosmosEvmNetwork": "export const addCosmosEvmNetwork = async () => {\n  if (!window.ethereum) throw new Error('MetaMask is not available');\n\n  const evmosChain = {\n    chainId: '0x2329', // 9001 in hex\n    chainName: 'Evmos',\n    nativeCurrency: {\n      name: 'EVMOS',\n      symbol: 'EVMOS',\n      decimals: 18\n    },\n    rpcUrls: ['https://eth.bd.evmos.org:8545'],\n    blockExplorerUrls: ['https://escan.live']\n  };\n\n  try {\n    await window.ethereum.request({\n      method: 'wallet_addEthereumChain',\n      params: [evmosChain]\n    });\n  } catch (error) {\n    console.error(error);\n    throw new Error('Failed to add the Evmos network to MetaMask.');\n  }\n};",
	"openRemixIde": "export const openRemixIde = () => {\n  const remixUrl = 'https://remix.ethereum.org';\n  // Open Remix; MetaMask will prompt for connection in the new tab\n  window.open(remixUrl, '_blank', 'noopener,noreferrer');\n};",
	"verifyInjectedProvider": "export const verifyInjectedProvider = async () => {\n  if (!window.ethereum) {\n    throw new Error('MetaMask provider not found.');\n  }\n\n  const chainId = await window.ethereum.request({ method: 'eth_chainId' });\n  console.log(`Connected to chainId: ${chainId}`);\n\n  // Warn if user is on a different network\n  if (chainId !== '0x2329') {\n    console.warn('MetaMask is not connected to the expected Evmos network.');\n  }\n\n  return chainId;\n};",
	"deployContract": "export const deployContract = async ({ bytecode }) => {\n  if (!window.ethereum) throw new Error('MetaMask not found in browser.');\n\n  // Request the active account\n  const [from] = await window.ethereum.request({ method: 'eth_requestAccounts' });\n\n  // Raw deployment transaction parameters\n  const txParams = {\n    from,\n    data: bytecode\n  };\n\n  // Estimate gas for deployment\n  try {\n    txParams.gas = await window.ethereum.request({\n      method: 'eth_estimateGas',\n      params: [txParams]\n    });\n  } catch (error) {\n    console.warn('Gas estimation failed, defaulting to 3,000,000.', error);\n    txParams.gas = '0x2DC6C0'; // 3,000,000 in hex\n  }\n\n  // Send deployment transaction (MetaMask will prompt for confirmation)\n  const txHash = await window.ethereum.request({\n    method: 'eth_sendTransaction',\n    params: [txParams]\n  });\n\n  console.log('Deployment transaction hash:', txHash);\n  return txHash;\n};",
	"getVoterAddress": "export const getVoterAddress = async () => {\n  const chainId = 'cosmoshub-4'; // Change to your chain if different\n\n  // 1. Check that Keplr is present\n  if (!window.keplr) {\n    throw new Error('Keplr wallet is not installed.');\n  }\n\n  // 2. Request access to the chain\n  await window.keplr.enable(chainId);\n\n  // 3. Obtain the signer & first account (default)\n  const signer = window.keplr.getOfflineSigner(chainId);\n  const accounts = await signer.getAccounts();\n\n  if (!accounts || accounts.length === 0) {\n    throw new Error('No account found in the signer.');\n  }\n\n  // 4. Return the bech32 address\n  return accounts[0].address;\n};",
	"validateProposal": "export const validateProposal = async (proposalId = 5) => {\n  const lcdEndpoint = 'https://api.cosmos.network'; // Public LCD; replace if you run your own\n\n  const resp = await fetch(`${lcdEndpoint}/cosmos/gov/v1beta1/proposals/${proposalId}`);\n  if (!resp.ok) {\n    throw new Error(`Proposal ${proposalId} not found (HTTP ${resp.status}).`);\n  }\n\n  const data = await resp.json();\n  const status = data?.proposal?.status;\n  if (status !== 'PROPOSAL_STATUS_VOTING_PERIOD') {\n    throw new Error(`Proposal ${proposalId} is not in voting period. Current status: ${status}`);\n  }\n\n  return data.proposal; // Return the full proposal object if the check passes\n};",
	"queryVoteRecord": "export const queryVoteRecord = async (proposalId, voterAddress) => {\n  const lcdEndpoint = 'https://api.cosmos.network';\n\n  // Each chain may differ slightly in path. The Cosmos Hub LCD supports:\n  // /cosmos/gov/v1beta1/proposals/{proposal_id}/votes/{voter}\n  const url = `${lcdEndpoint}/cosmos/gov/v1beta1/proposals/${proposalId}/votes/${voterAddress}`;\n  const res = await fetch(url);\n\n  if (!res.ok) {\n    throw new Error(`Failed to fetch vote record (HTTP ${res.status}).`);\n  }\n\n  const data = await res.json();\n  const option = data?.vote?.option;\n\n  if (option !== 'VOTE_OPTION_YES') {\n    throw new Error(`Vote not recorded as YES. Found: ${option ?? 'none'}`);\n  }\n\n  return data.vote; // Full vote object\n};",
	"fetchCosmosEvmChainParams": "export const fetchCosmosEvmChainParams = async (chainSlug) => {\n  // Build the GitHub raw URL for the desired chain.json\n  const url = `https://raw.githubusercontent.com/cosmos/chain-registry/master/${chainSlug}/chain.json`;\n\n  try {\n    const response = await fetch(url);\n    if (!response.ok) {\n      throw new Error(`Unable to fetch chain data: ${response.statusText}`);\n    }\n\n    const chainData = await response.json();\n\n    // Extract useful EVM-specific fields with sensible fallbacks\n    const evmRpc   = chainData?.evm?.json_rpc || chainData?.apis?.rpc?.[0]?.address;\n    const evmChainId = chainData?.evm?.chain_id;\n    const symbol   = chainData?.currencies?.[0]?.symbol || chainData?.native_currency?.symbol;\n    const explorer = chainData?.explorers?.[0]?.url || null;\n\n    if (!evmRpc || !evmChainId) {\n      throw new Error('Fetched chain data is missing required EVM fields.');\n    }\n\n    return {\n      chainSlug,\n      evmRpc,\n      evmChainId,\n      symbol,\n      explorer,\n      raw: chainData // keep raw JSON for advanced use-cases\n    };\n  } catch (error) {\n    console.error('fetchCosmosEvmChainParams error:', error);\n    throw error;\n  }\n};",
	"getMetaMaskCurrentChainId": "export const getMetaMaskCurrentChainId = async () => {\n  if (!window.ethereum) {\n    throw new Error('MetaMask is not installed');\n  }\n  // Returned value is hex (e.g., \"0x2329\" for 9001); convert to integer.\n  const chainIdHex = await window.ethereum.request({ method: 'eth_chainId' });\n  return parseInt(chainIdHex, 16);\n};",
	"switchToCosmosEvmNetwork": "export const switchToCosmosEvmNetwork = async (chainParams) => {\n  if (!window.ethereum) {\n    throw new Error('MetaMask is not installed');\n  }\n\n  const { evmChainId, symbol, evmRpc, explorer, raw } = chainParams;\n  const chainIdHex = '0x' + evmChainId.toString(16);\n\n  try {\n    // First try to switch directly\n    await window.ethereum.request({\n      method: 'wallet_switchEthereumChain',\n      params: [{ chainId: chainIdHex }]\n    });\n  } catch (switchError) {\n    // Error code 4902 = chain not added yet\n    if (switchError.code === 4902) {\n      try {\n        // Add the network\n        await window.ethereum.request({\n          method: 'wallet_addEthereumChain',\n          params: [{\n            chainId: chainIdHex,\n            chainName: raw?.pretty_name || chainParams.chainSlug,\n            nativeCurrency: {\n              name: symbol,\n              symbol: symbol,\n              decimals: 18 // Most Cosmos EVM coins use 18 decimals\n            },\n            rpcUrls: [evmRpc],\n            blockExplorerUrls: explorer ? [explorer] : []\n          }]\n        });\n        // Then switch again\n        await window.ethereum.request({\n          method: 'wallet_switchEthereumChain',\n          params: [{ chainId: chainIdHex }]\n        });\n      } catch (addError) {\n        console.error('Error adding chain to MetaMask:', addError);\n        throw addError;\n      }\n    } else {\n      console.error('Error switching chain in MetaMask:', switchError);\n      throw switchError;\n    }\n  }\n};",
	"verifyMetaMaskChainId": "export const verifyMetaMaskChainId = async (expectedChainId) => {\n  const current = await getMetaMaskCurrentChainId();\n  if (current !== expectedChainId) {\n    throw new Error(`Chain ID verification failed. Expected ${expectedChainId}, got ${current}`);\n  }\n  return true; // Success\n};",
	"signAndBroadcastEmergencyWithdraw": "export const signAndBroadcastEmergencyWithdraw = async (signDocFromBackend, chainId = 'neutron-1') => {\n  const { keplr } = window;\n  if (!keplr) throw new Error('Keplr extension not available.');\n\n  // Decode base64-encoded fields returned by the backend\n  const toUint8Array = (b64) => Uint8Array.from(atob(b64), c => c.charCodeAt(0));\n\n  const signDoc = {\n    bodyBytes:     toUint8Array(signDocFromBackend.bodyBytes),\n    authInfoBytes: toUint8Array(signDocFromBackend.authInfoBytes),\n    chainId:       signDocFromBackend.chainId,\n    accountNumber: Number(signDocFromBackend.accountNumber)\n  };\n\n  // Fetch the signer address again (defensive)\n  const offlineSigner = keplr.getOfflineSigner(chainId);\n  const [account]     = await offlineSigner.getAccounts();\n\n  // 1. Sign the proto‐SignDoc (DIRECT mode)\n  const { signature } = await keplr.signDirect(chainId, account.address, signDoc);\n\n  // 2. POST the signed doc + signature back to the backend for final assembly & broadcast\n  const res = await fetch('/api/tx/broadcast', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({\n      bodyBytes:     signDocFromBackend.bodyBytes,\n      authInfoBytes: signDocFromBackend.authInfoBytes,\n      signature:     Buffer.from(signature.signature, 'base64').toString('base64')\n    })\n  });\n\n  if (!res.ok) {\n    const text = await res.text();\n    throw new Error(`Broadcast failed: ${text}`);\n  }\n\n  const { txhash } = await res.json();\n  return txhash;\n};",
	"fetchNodeVersion": "export const fetchNodeVersion = async (rpcUrl) => {\n  try {\n    const response = await fetch(`${rpcUrl}/status`);\n\n    if (!response.ok) {\n      throw new Error(`RPC responded with HTTP status ${response.status}`);\n    }\n\n    const data = await response.json();\n\n    // Tendermint RPC usually places the version in one of these fields\n    const version =\n      data?.result?.node_info?.version ||\n      data?.result?.application_version?.version ||\n      'Unknown';\n\n    return {\n      raw: data,\n      version,\n    };\n  } catch (error) {\n    console.error('Unable to fetch node version', error);\n    throw error;\n  }\n};",
	"getCreate2Address": "export const getCreate2Address = async () => {\n  try {\n    // Prompt the user for the three required parameters\n    const deployer = prompt(\"Enter the deployer (factory) address (0x…)\");\n    const salt = prompt(\"Enter the 32-byte salt in hex (WITHOUT 0x)\");\n    const initCodeHash = prompt(\"Enter the contract init-code hash (0x…)\");\n\n    // Basic client-side validation\n    if (!deployer || !salt || !initCodeHash) {\n      throw new Error(\"All three fields are required.\");\n    }\n\n    // Send the data to the backend for processing\n    const res = await fetch(\"/api/compute_create2_address\", {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify({\n        deployer,\n        salt,\n        init_code_hash: initCodeHash\n      })\n    });\n\n    if (!res.ok) {\n      // Surface backend error message, if any\n      const err = await res.json();\n      throw new Error(err.detail || \"Backend error while computing address.\");\n    }\n\n    const { create2_address } = await res.json();\n    alert(`Deterministic CREATE2 address: ${create2_address}`);\n    return create2_address;\n  } catch (error) {\n    console.error(error);\n    alert(error.message);\n    return null;\n  }\n};",
	"checkVerificationStatus": "export const checkVerificationStatus = async (network, contractAddress, apiKey) => {\n  const baseUrlMap = {\n    mainnet: 'https://api.etherscan.io/api',\n    goerli: 'https://api-goerli.etherscan.io/api',\n    sepolia: 'https://api-sepolia.etherscan.io/api',\n  };\n\n  const baseUrl = baseUrlMap[network];\n  if (!baseUrl) throw new Error(`Unsupported network ${network}`);\n\n  const url = `${baseUrl}?module=contract&action=getsourcecode&address=${contractAddress}&apikey=${apiKey}`;\n\n  try {\n    const res = await fetch(url);\n    if (!res.ok) throw new Error(`Explorer responded with ${res.status}`);\n    const data = await res.json();\n    const verified = data.status === '1' && data.result && data.result.length > 0 && data.result[0].SourceCode !== '';\n    return { verified, raw: data };\n  } catch (err) {\n    console.error(err);\n    throw new Error('Failed to fetch verification status');\n  }\n};",
	"hasMinBalance": "export const hasMinBalance = async (address, minAmount = 500000000) => {\n  const REST_ENDPOINT = 'https://rest-kralum.neutron.org';\n  const url = `${REST_ENDPOINT}/cosmos/bank/v1beta1/balances/${address}`;\n\n  const response = await fetch(url);\n  if (!response.ok) {\n    throw new Error(`LCD error: ${response.status} ${response.statusText}`);\n  }\n\n  const data = await response.json();\n  const balanceEntry = data.balances?.find((b) => b.denom === 'untrn');\n  const balance = balanceEntry ? parseInt(balanceEntry.amount, 10) : 0;\n  return balance >= minAmount;\n};",
	"constructBoostLockMsg": "export const constructBoostLockMsg = (amount = '500000000', durationMonths = 24) => {\n  const msg = {\n    lock: {\n      amount,\n      duration: `${durationMonths}_months`,\n    },\n  };\n  return msg;\n};\n\nexport const encodeMsgForContract = (msg) => window.btoa(JSON.stringify(msg));",
	"queryBoostPosition": "export const queryBoostPosition = async (address) => {\n  const BOOST_CONTRACT_ADDRESS = 'neutron1boostcontractaddress…'; // TODO: replace\n  const REST_ENDPOINT = 'https://rest-kralum.neutron.org';\n\n  const queryMsg = { position: { address } };\n  const encoded = window.btoa(JSON.stringify(queryMsg));\n  const url = `${REST_ENDPOINT}/cosmwasm/wasm/v1/contract/${BOOST_CONTRACT_ADDRESS}/smart/${encoded}`;\n\n  const res = await fetch(url);\n  if (!res.ok) {\n    throw new Error(`Contract query failed: ${res.status}`);\n  }\n  const data = await res.json();\n  return data.data; // The exact schema depends on the contract implementation\n};",
	"checkTokenBalance": "export const checkTokenBalance = async (address) => {\n  try {\n    // TODO: replace with the real uniBTC CW20 contract address\n    const cw20Contract = 'neutron1xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx';\n    const restEndpoint = 'https://rest-kralum.neutron.org';\n\n    // Build the CW20 balance query and base64-encode it for the REST endpoint\n    const query = { balance: { address } };\n    const encodedQuery = btoa(JSON.stringify(query));\n\n    const url = `${restEndpoint}/cosmwasm/wasm/v1/contract/${cw20Contract}/smart/${encodedQuery}`;\n    const res = await fetch(url);\n\n    if (!res.ok) {\n      throw new Error(`REST API returned ${res.status}`);\n    }\n\n    const json = await res.json();\n    const microAmount = BigInt(json?.data?.balance || 0n);\n\n    // Assume uniBTC uses 6 decimals on Neutron\n    const displayAmount = Number(microAmount) / 1_000_000;\n\n    return {\n      ok: displayAmount >= 2,\n      amount: displayAmount\n    };\n  } catch (err) {\n    console.error('Balance check failed', err);\n    throw err;\n  }\n};",
	"constructUnlockTx": "export const constructUnlockTx = async ({\n  chainId = 'neutron-1',\n  senderAddress,\n  contractAddress,\n  lockId,\n  fee = {\n    amount: [{ amount: '6000', denom: 'untrn' }],\n    gas: '300000'\n  },\n  memo = ''\n}) => {\n  // Cosmos SDK Tx requires accountNumber & sequence → fetch from LCD\n  const LCD_URL = 'https://rest-kralum.neutron-1.neutron.org';\n  const accountRes = await fetch(\n    `${LCD_URL}/cosmos/auth/v1beta1/accounts/${senderAddress}`\n  ).then((r) => r.json());\n\n  const baseAccount =\n    accountRes.account.base_account || accountRes.account; // handles vesting / eth-addr\n\n  const accountNumber = String(baseAccount.account_number);\n  const sequence = String(baseAccount.sequence);\n\n  // MsgExecuteContract to cancel the lock\n  const msg = {\n    type: 'wasm/MsgExecuteContract',\n    value: {\n      sender: senderAddress,\n      contract: contractAddress,\n      msg: {\n        cancel_lock: { lock_id: lockId }\n      },\n      funds: []\n    }\n  };\n\n  // Build the amino-compatible StdSignDoc\n  const signDoc = {\n    chain_id: chainId,\n    account_number: accountNumber,\n    sequence: sequence,\n    fee,\n    msgs: [msg],\n    memo\n  };\n\n  return {\n    signDoc,\n    msg,\n    fee,\n    memo\n  };\n};",
	"interpretReceipt": "export const interpretReceipt = (receipt) => {\n  if (!receipt) {\n    throw new Error('No receipt supplied');\n  }\n\n  const {\n    status,\n    gasUsed,\n    cumulativeGasUsed,\n    effectiveGasPrice,\n    blockNumber,\n    transactionHash,\n    logs,\n  } = receipt;\n\n  // Helper to convert hex strings (e.g., \"0x1a\") into decimal numbers\n  const hexToInt = (hex) => parseInt(hex, 16);\n\n  return {\n    transactionHash,\n    blockNumber: hexToInt(blockNumber),\n    status: status === '0x1' ? 'Success' : 'Failure',\n    gasUsed: hexToInt(gasUsed),\n    cumulativeGasUsed: hexToInt(cumulativeGasUsed),\n    effectiveGasPrice: hexToInt(effectiveGasPrice),\n    logs, // Raw logs are surfaced for the caller to decode as needed\n  };\n};",
	"fetchLatestBlock": "export const fetchLatestBlock = async () => {\n  const res = await fetch('/api/latest_block');\n  if (!res.ok) {\n    throw new Error(`Request failed with status ${res.status}`);\n  }\n  const json = await res.json();\n  return json.result?.block ?? json; // fallback if structure differs\n};",
	"validateTokenBalance": "export const validateTokenBalance = async (\n  address,\n  {\n    min = BigInt(1_000000), // 1.0 maxBTC in micro-denom units (example: 1e6)\n    denom = 'amaxbtc',      // replace with the exact on-chain denom for maxBTC\n    restEndpoint = 'https://rest-kralum.neutron.org' // example REST endpoint\n  } = {}\n) => {\n  try {\n    const url = `${restEndpoint}/cosmos/bank/v1beta1/balances/${address}/${denom}`;\n    const res = await fetch(url);\n    if (!res.ok) throw new Error(`LCD error: ${res.status}`);\n\n    const { balance } = await res.json();\n    const amount = BigInt(balance?.amount || 0);\n\n    if (amount < min) {\n      throw new Error(`Insufficient balance: need ≥ ${min} ${denom}, have ${amount}`);\n    }\n    return { ok: true, amount };\n  } catch (err) {\n    console.error(err);\n    return { ok: false, reason: err.message };\n  }\n};",
	"queryAmberMarketParameters": "export const queryAmberMarketParameters = async (\n  {\n    contract = 'neutron1ambercontractaddressxxxxxxxxxxxx', // Amber contract address\n    restEndpoint = 'https://rest-kralum.neutron.org'\n  } = {}\n) => {\n  // The Amber contract is assumed to expose `{ \"config\": {} }` or similar.\n  const query = { market_params: {} };\n  const encoded = btoa(JSON.stringify(query));\n  const url = `${restEndpoint}/cosmwasm/wasm/v1/contract/${contract}/smart/${encoded}`;\n\n  const res = await fetch(url);\n  if (!res.ok) throw new Error(`Amber query failed: ${res.status}`);\n\n  return await res.json(); // → { data: { max_leverage: '6', collateral_factor: '0.8', ... } }\n};",
	"constructOpenLeverageMsg": "export const constructOpenLeverageMsg = (\n  {\n    sender,\n    collateralAmount = '1000000',           // 1.0 maxBTC in micro-units\n    collateralDenom = 'amaxbtc',            // actual on-chain denom\n    leverage = '5',\n    contract = 'neutron1ambercontractaddressxxxxxxxxxxxx'\n  }\n) => {\n  if (!sender) throw new Error('`sender` (wallet address) is required');\n\n  // Amber-specific execute message\n  const executeMsg = {\n    open_position: {\n      collateral: {\n        denom: collateralDenom,\n        amount: collateralAmount\n      },\n      leverage\n    }\n  };\n\n  // Standard CosmWasm MsgExecuteContract to be signed later\n  return {\n    typeUrl: '/cosmwasm.wasm.v1.MsgExecuteContract',\n    value: {\n      sender,\n      contract,\n      msg: new TextEncoder().encode(JSON.stringify(executeMsg)),\n      funds: [{ denom: collateralDenom, amount: collateralAmount }]\n    }\n  };\n};",
	"queryPositionStatus": "export const queryPositionStatus = async (\n  {\n    owner,\n    contract = 'neutron1ambercontractaddressxxxxxxxxxxxx',\n    restEndpoint = 'https://rest-kralum.neutron.org',\n    retries = 10,\n    delayMs = 3000\n  }\n) => {\n  if (!owner) throw new Error('Owner address is required');\n\n  const query = { positions_by_owner: { owner } };\n  const encoded = btoa(JSON.stringify(query));\n  const url = `${restEndpoint}/cosmwasm/wasm/v1/contract/${contract}/smart/${encoded}`;\n\n  for (let i = 0; i < retries; i++) {\n    const res = await fetch(url);\n    if (res.ok) {\n      const data = await res.json();\n      if (data?.data?.positions?.length) {\n        return data.data.positions[0]; // Return the first position found\n      }\n    }\n    await new Promise(r => setTimeout(r, delayMs));\n  }\n  throw new Error('Position not found within timeout window');\n};",
	"queryVaultConfig": "export const queryVaultConfig = async (vaultAddress, lcdUrl = \"https://rest.neutron-1.neutron.org\") => {\n  /**\n   * Helper to base64-encode the JSON query in both browser and Node environments.\n   */\n  const base64Encode = (obj) => {\n    const jsonStr = JSON.stringify(obj);\n    if (typeof window !== \"undefined\" && window.btoa) {\n      return window.btoa(jsonStr);\n    }\n    return Buffer.from(jsonStr).toString(\"base64\");\n  };\n\n  try {\n    const queryMsg = { config: {} };        // ← { \"config\": {} }\n    const encoded = base64Encode(queryMsg); // base64\n\n    const endpoint = `${lcdUrl}/cosmwasm/wasm/v1/contract/${vaultAddress}/smart/${encoded}`;\n    const res = await fetch(endpoint);\n\n    if (!res.ok) {\n      throw new Error(`Contract query failed: ${res.status} ${res.statusText}`);\n    }\n\n    // Depending on LCD version the JSON key can be `data` or `result`.\n    const json = await res.json();\n    const config = json.data ?? json.result ?? json;\n\n    return config; // returns the full config object\n  } catch (err) {\n    console.error(\"[queryVaultConfig]\", err);\n    throw err;\n  }\n};",
	"parseRewardPolicy": "export const parseRewardPolicy = (config) => {\n  if (!config || typeof config !== \"object\") {\n    throw new Error(\"Invalid or empty config object supplied.\");\n  }\n\n  const forfeitableRewards = config.forfeitable_rewards ?? null;\n  const earlyExitPenalty = config.early_exit_penalty ?? null;\n\n  return {\n    forfeitableRewards,\n    earlyExitPenalty,\n    // Convenience flag\n    isForfeitable: Boolean(forfeitableRewards) || Boolean(earlyExitPenalty)\n  };\n};",
	"displayRewardPolicy": "export const displayRewardPolicy = (policy, targetElementId = \"reward-policy\") => {\n  try {\n    const el = document.getElementById(targetElementId);\n\n    // Fallback if no DOM target is available\n    const output = (msg) => {\n      if (el) {\n        el.innerHTML = msg;\n      } else {\n        console.log(msg);\n      }\n    };\n\n    if (!policy || !policy.isForfeitable) {\n      output(\"No early withdrawal penalties. All rewards are fully claimable.\");\n      return;\n    }\n\n    let html = \"<h4>Early Withdrawal Policy</h4>\";\n\n    if (policy.earlyExitPenalty && typeof policy.earlyExitPenalty === \"object\") {\n      html += \"<ul>\";\n      for (const [period, penalty] of Object.entries(policy.earlyExitPenalty)) {\n        html += `<li>Within ${period}: ${penalty}% penalty</li>`;\n      }\n      html += \"</ul>\";\n    } else if (policy.forfeitableRewards !== null) {\n      html += `<p>${policy.forfeitableRewards}% of accumulated rewards are forfeited on early exit.</p>`;\n    }\n\n    output(html);\n  } catch (err) {\n    console.error(\"[displayRewardPolicy]\", err);\n  }\n};",
	"convertEtherToWei": "export const convertEtherToWei = async () => {\n  // 1️⃣ Prompt the user for an Ether amount\n  const amount = prompt('Enter Ether amount to convert into Wei (e.g., 0.42):');\n\n  // Exit if the user cancels the prompt\n  if (amount === null) {\n    return null;\n  }\n\n  // 2️⃣ Basic validation\n  if (amount.trim() === '' || isNaN(amount) || Number(amount) < 0) {\n    alert('Please enter a valid positive number.');\n    return null;\n  }\n\n  try {\n    // 3️⃣ POST the amount to the backend\n    const resp = await fetch('/api/to_wei', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify({ amount: amount.trim() })\n    });\n\n    if (!resp.ok) {\n      const err = await resp.json();\n      throw new Error(err.detail || 'Conversion failed');\n    }\n\n    // 4️⃣ Parse and display the Wei result\n    const data = await resp.json();\n    alert(`${amount} ETH is ${data.wei} Wei`);\n    return data.wei;\n  } catch (error) {\n    console.error('Error converting ETH to Wei:', error);\n    alert(error.message);\n    throw error;\n  }\n};",
	"traceBlockByHash": "export const traceBlockByHash = async ({ rpcUrl, blockHash }) => {\n  // Basic argument validation\n  if (!rpcUrl) throw new Error('Parameter \"rpcUrl\" is required');\n  if (!blockHash || !blockHash.startsWith('0x')) {\n    throw new Error('Parameter \"blockHash\" must be a 0x-prefixed hash');\n  }\n\n  // Send the request to the backend-for-frontend (BFF)\n  const res = await fetch('/api/traceBlockByHash', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({ rpc_url: rpcUrl, block_hash: blockHash })\n  });\n\n  // Handle network-level errors\n  if (!res.ok) {\n    const { error } = await res.json().catch(() => ({ error: 'Unknown error' }));\n    throw new Error(error || 'Backend returned a non-200 status');\n  }\n\n  // Parse and return the trace result\n  const { trace } = await res.json();\n  return trace;\n};",
	"collectTransferParameters": "export const collectTransferParameters = (senderAddress, recipientAddress, valueWei) => {\n  const ethAddrRegex = /^0x[a-fA-F0-9]{40}$/;\n\n  if (!ethAddrRegex.test(senderAddress)) {\n    throw new Error(\"Invalid sender address provided.\");\n  }\n  if (!ethAddrRegex.test(recipientAddress)) {\n    throw new Error(\"Invalid recipient address provided.\");\n  }\n  if (valueWei === undefined || valueWei === null || valueWei === \"\") {\n    throw new Error(\"Value (in Wei) is required.\");\n  }\n\n  return {\n    senderAddress,\n    recipientAddress,\n    valueWei: valueWei.toString() // always return as string for consistency\n  };\n};",
	"constructTxObject": "export const constructTxObject = ({ senderAddress, recipientAddress, valueWei }) => {\n  const valueHex = \"0x\" + BigInt(valueWei).toString(16);\n  return {\n    from: senderAddress,\n    to: recipientAddress,\n    value: valueHex,\n    data: \"0x\" // empty data for a native transfer\n  };\n};",
	"estimateGas": "export const estimateGas = async (txObject, rpcEndpoint = getRpcEndpoint()) => {\n  try {\n    const payload = {\n      jsonrpc: \"2.0\",\n      id: 1,\n      method: \"eth_estimateGas\",\n      params: [txObject]\n    };\n\n    const res = await fetch(rpcEndpoint, {\n      method: \"POST\",\n      headers: { \"Content-Type\": \"application/json\" },\n      body: JSON.stringify(payload)\n    });\n\n    if (!res.ok) {\n      throw new Error(`Network error: ${res.status} ${res.statusText}`);\n    }\n\n    const json = await res.json();\n\n    if (json.error) {\n      throw new Error(`RPC Error: ${json.error.message || \"Unknown error\"}`);\n    }\n\n    if (!json.result) {\n      throw new Error(\"No result field returned from RPC response.\");\n    }\n\n    return json.result; // gas in hexadecimal string\n  } catch (err) {\n    console.error(\"estimateGas() failed\", err);\n    throw err;\n  }\n};",
	"parseGasHexToDecimal": "export const parseGasHexToDecimal = (gasHex, bufferFraction = 0.1) => {\n  if (!gasHex || typeof gasHex !== \"string\" || !gasHex.startsWith(\"0x\")) {\n    throw new Error(\"Invalid hex gas value provided.\");\n  }\n\n  const gasBigInt = BigInt(gasHex);\n  // Calculate buffer: gas * bufferFraction. Using integer arithmetic.\n  const bufferGas = gasBigInt / BigInt(Math.round(1 / bufferFraction));\n  const adjustedGas = gasBigInt + bufferGas;\n\n  return {\n    gas: gasBigInt.toString(),\n    adjustedGas: adjustedGas.toString()\n  };\n};",
	"fetchTransactionByHash": "export const fetchTransactionByHash = async (txHash, rpcUrl) => {\n  const payload = {\n    jsonrpc: \"2.0\",\n    id: Date.now(),\n    method: \"eth_getTransactionByHash\",\n    params: [txHash]\n  };\n\n  const res = await fetch(rpcUrl, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(payload)\n  });\n\n  if (!res.ok) {\n    throw new Error(`RPC call failed with status ${res.status}`);\n  }\n\n  const json = await res.json();\n  if (json.error) throw new Error(json.error.message);\n  if (!json.result) throw new Error(\"Transaction not found on RPC node\");\n\n  return json.result; // full tx object\n};",
	"verifyTxPending": "export const verifyTxPending = (tx) => {\n  if (tx.blockNumber !== null) {\n    throw new Error(\"Original transaction is already mined; cannot be replaced.\");\n  }\n  return true;\n};",
	"constructReplacementTx": "export const constructReplacementTx = (\n  originalTx,\n  { multiplier = 1.2 } = {}\n) => {\n  const toHex = (bn) => \"0x\" + bn.toString(16);\n  const bump = (valueHex) => {\n    const orig = BigInt(valueHex);\n    // ensure we bump by at least +10% even if multiplier is small\n    const bumped = orig * BigInt(Math.round(multiplier * 100)) / BigInt(100);\n    return bumped > orig ? bumped : orig + orig / BigInt(10);\n  };\n\n  const baseParams = {\n    from: originalTx.from,\n    to: originalTx.to,\n    data: originalTx.input,\n    gas: originalTx.gas,\n    nonce: originalTx.nonce,\n    value: originalTx.value\n  };\n\n  // Legacy gas pricing ---------------------------------------------------\n  if (originalTx.gasPrice && originalTx.gasPrice !== \"0x0\") {\n    baseParams.gasPrice = toHex(bump(originalTx.gasPrice));\n  }\n\n  // EIP-1559 style -------------------------------------------------------\n  if (originalTx.maxFeePerGas) {\n    baseParams.maxFeePerGas = toHex(bump(originalTx.maxFeePerGas));\n    baseParams.maxPriorityFeePerGas = toHex(\n      bump(originalTx.maxPriorityFeePerGas || \"0x0\")\n    );\n  }\n\n  return baseParams;\n};",
	"signReplacementTx": "export const signReplacementTx = async (txParams, { chainId } = {}) => {\n  if (!window.ethereum) throw new Error(\"No EVM-compatible wallet detected.\");\n\n  // Add chainId if provided (helps some wallets)\n  if (chainId) txParams.chainId = chainId;\n\n  try {\n    // 1️⃣  Attempt to just sign (keeps rawTx for manual broadcast)\n    const raw = await window.ethereum.request({\n      method: \"eth_signTransaction\",\n      params: [txParams]\n    });\n    if (!raw || !raw.raw) throw new Error(\"Wallet did not return raw transaction\");\n    return { rawTx: raw.raw };\n  } catch (e) {\n    // 2️⃣  Fallback: let the wallet sign *and* send (most common path)\n    const txHash = await window.ethereum.request({\n      method: \"eth_sendTransaction\",\n      params: [txParams]\n    });\n    return { txHash }; // already broadcast, nothing left to do\n  }\n};",
	"sendRawTransaction": "export const sendRawTransaction = async (rawTxHex, rpcUrl) => {\n  const payload = {\n    jsonrpc: \"2.0\",\n    id: Date.now(),\n    method: \"eth_sendRawTransaction\",\n    params: [rawTxHex]\n  };\n\n  const res = await fetch(rpcUrl, {\n    method: \"POST\",\n    headers: { \"Content-Type\": \"application/json\" },\n    body: JSON.stringify(payload)\n  });\n\n  if (!res.ok) throw new Error(`Broadcast failed – HTTP ${res.status}`);\n  const json = await res.json();\n  if (json.error) throw new Error(json.error.message);\n  return json.result; // txHash\n};",
	"parseTxpoolStatus": "export const parseTxpoolStatus = (jsonRpcResponse) => {\n  if (!jsonRpcResponse) {\n    throw new Error(\"Empty response object\");\n  }\n\n  if (jsonRpcResponse.error) {\n    // Surface the JSON-RPC error to the caller.\n    throw new Error(`JSON-RPC Error ${jsonRpcResponse.error.code}: ${jsonRpcResponse.error.message}`);\n  }\n\n  const { result } = jsonRpcResponse;\n  if (!result || typeof result.pending !== \"string\" || typeof result.queued !== \"string\") {\n    throw new Error(\"Malformed txpool_status response\");\n  }\n\n  // Convert hex strings (e.g., \"0x4e\") to decimal numbers.\n  const pending = parseInt(result.pending, 16);\n  const queued = parseInt(result.queued, 16);\n\n  return { pending, queued };\n};",
	"ensureWalletAndGetAddress": "export const ensureWalletAndGetAddress = async () => {\n  try {\n    const chainId = 'neutron-1';\n\n    // Basic Keplr presence check\n    if (!window.keplr) {\n      throw new Error('Keplr wallet is not installed. Please install it first.');\n    }\n\n    // Request connection to Neutron chain\n    await window.keplr.enable(chainId);\n\n    // Fetch the offline signer & accounts list\n    const offlineSigner = window.keplr.getOfflineSigner(chainId);\n    const accounts      = await offlineSigner.getAccounts();\n\n    if (!accounts || accounts.length === 0) {\n      throw new Error('No Neutron account found in Keplr.');\n    }\n\n    return accounts[0].address; // sender / depositor address\n  } catch (err) {\n    console.error('[ensureWalletAndGetAddress] →', err);\n    throw err;\n  }\n};",
	"checkEbtcBalance": "export const checkEbtcBalance = async (address, minAmountMicro = '3000000') => {\n  try {\n    // Public Neutron LCD endpoint (you may replace with your own)\n    const lcd = 'https://lcd-kralum.neutron-1.nomusa.xyz';\n\n    // eBTC IBC denom on Neutron (see docs/btc-summer/technical/reference)\n    const EBTC_DENOM = 'ibc/E2A000FD3EDD91C9429B473995CE2C7C555BCC8CFC1D0A3D02F514392B7A80E8';\n\n    const resp   = await fetch(`${lcd}/cosmos/bank/v1beta1/balances/${address}`);\n    if (!resp.ok) throw new Error(`LCD error ${resp.status}`);\n\n    const { balances } = await resp.json();\n    const coin = balances.find((c) => c.denom === EBTC_DENOM);\n    const amount = coin ? coin.amount : '0';\n\n    if (BigInt(amount) < BigInt(minAmountMicro)) {\n      throw new Error(`Insufficient eBTC balance. Need ≥ ${minAmountMicro}, have ${amount}`);\n    }\n\n    return {\n      ok: true,\n      amountMicro: amount\n    };\n  } catch (err) {\n    console.error('[checkEbtcBalance] →', err);\n    throw err;\n  }\n};",
	"fetchLatestBlockNumber": "export const fetchLatestBlockNumber = async (rpcUrl) => {\n  const payload = {\n    jsonrpc: '2.0',\n    id: 1,\n    method: 'eth_blockNumber',\n    params: []\n  };\n\n  try {\n    const response = await fetch(rpcUrl, {\n      method: 'POST',\n      headers: {\n        'Content-Type': 'application/json'\n      },\n      body: JSON.stringify(payload)\n    });\n\n    // Network-level error handling.\n    if (!response.ok) {\n      throw new Error(`RPC request failed with status ${response.status}`);\n    }\n\n    const data = await response.json();\n\n    // JSON-RPC-level error handling.\n    if (data.error) {\n      throw new Error(`RPC error: ${data.error.message || JSON.stringify(data.error)}`);\n    }\n\n    return data.result; // e.g., \"0x1a2b3c\"\n  } catch (err) {\n    console.error('[fetchLatestBlockNumber] →', err);\n    throw err;\n  }\n};",
	"hexToDecimal": "export const hexToDecimal = (hexString) => {\n  if (typeof hexString !== 'string' || !/^0x[0-9a-fA-F]+$/.test(hexString)) {\n    throw new Error('Invalid hex string supplied to hexToDecimal');\n  }\n\n  // Use BigInt for correctness on 64-bit+ values.\n  return Number(BigInt(hexString));\n};",
	"getUnorderedIBCChannels": "export const getUnorderedIBCChannels = async (lcdEndpoint) => {\n  try {\n    const response = await fetch(`${lcdEndpoint}/ibc/core/channel/v1beta1/channels?pagination.limit=1000`);\n    if (!response.ok) {\n      throw new Error(`Network response was not ok: ${response.status} ${response.statusText}`);\n    }\n    const data = await response.json();\n    if (!data.channels) {\n      throw new Error('No channels data found.');\n    }\n    return data.channels\n      .filter((ch) => {\n        const ordering = (ch.ordering || ch.order || '').toUpperCase();\n        return ordering === 'UNORDERED' || ordering === 'ORDER_UNORDERED';\n      })\n      .map((ch) => ({\n        portId: ch.port_id,\n        channelId: ch.channel_id,\n      }));\n  } catch (error) {\n    console.error('[getUnorderedIBCChannels]', error);\n    throw error;\n  }\n};",
	"generateTimeoutTimestamp": "export const generateTimeoutTimestamp = (secondsAhead = 600) => {\n  // Current Unix time in seconds\n  const currentSeconds = Math.floor(Date.now() / 1000);\n  const futureSeconds = currentSeconds + secondsAhead;\n  // Convert to nanoseconds\n  return (BigInt(futureSeconds) * 1000000000n).toString();\n};",
	"sendIbcTransfer": "export const sendIbcTransfer = async (transferPayload) => {\n  try {\n    const response = await fetch('/api/ibc_transfer', {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(transferPayload),\n    });\n    if (!response.ok) {\n      const errText = await response.text();\n      throw new Error(`IBC transfer failed: ${errText}`);\n    }\n    const data = await response.json();\n    return data.tx_hash;\n  } catch (error) {\n    console.error('[sendIbcTransfer]', error);\n    throw error;\n  }\n};",
	"fetchCurrentAdmin": "export const fetchCurrentAdmin = async (\n  contractAddress,\n  rpcEndpoint = \"https://rpc-kralum.neutron-1.neutron.org:443\"\n) => {\n  try {\n    const client = await CosmWasmClient.connect(rpcEndpoint);\n    const info = await client.getContract(contractAddress);\n    return info.admin || \"\"; // empty string means no admin set\n  } catch (error) {\n    console.error(\"[fetchCurrentAdmin]\", error);\n    throw new Error(\"Unable to fetch contract admin: \" + error.message);\n  }\n};",
	"validateNewAdminAddress": "export const validateNewAdminAddress = (address, prefix = \"neutron\") => {\n  try {\n    const { prefix: addrPrefix } = bech32.decode(address);\n    if (addrPrefix !== prefix) {\n      throw new Error(`Invalid prefix: expected '${prefix}', got '${addrPrefix}'`);\n    }\n    return true;\n  } catch (err) {\n    console.error(\"[validateNewAdminAddress]\", err);\n    throw new Error(\"Provided new admin address is not a valid Bech32 string.\");\n  }\n};",
	"buildUpdateAdminMsg": "export const buildUpdateAdminMsg = (sender, contract, newAdmin) => {\n  return {\n    typeUrl: \"/cosmwasm.wasm.v1.MsgUpdateAdmin\",\n    value: {\n      sender: sender,\n      newAdmin: newAdmin,\n      contract: contract\n    }\n  };\n};",
	"signAndBroadcastUpdateAdminMsg": "export const signAndBroadcastUpdateAdminMsg = async (\n  signer,\n  sender,\n  msg,\n  rpcEndpoint = \"https://rpc-kralum.neutron-1.neutron.org:443\",\n  memo = \"\"\n) => {\n  try {\n    const gasPrice = GasPrice.fromString(\"0.05untrn\");\n    const client = await SigningCosmWasmClient.connectWithSigner(\n      rpcEndpoint,\n      signer,\n      { gasPrice }\n    );\n\n    // Estimate gas or set a flat fee\n    const fee = {\n      amount: coins(0, \"untrn\"), // 0-fee, gasPrice will calculate final fee\n      gas: \"250000\"               // adjust based on contract complexity\n    };\n\n    const result = await client.signAndBroadcast(sender, [msg], fee, memo);\n    if (result.code !== 0) {\n      throw new Error(`Broadcast failed with code ${result.code}: ${result.rawLog}`);\n    }\n    return result;\n  } catch (error) {\n    console.error(\"[signAndBroadcastUpdateAdminMsg]\", error);\n    throw new Error(\"Transaction failed: \" + error.message);\n  }\n};",
	"validateBlockHeight": "export const validateBlockHeight = (blockHeight) => {\n  if (typeof blockHeight !== 'string' || !/^0x[0-9a-fA-F]+$/.test(blockHeight)) {\n    throw new Error('Block height must be a hex string like 0x1.');\n  }\n\n  const numericHeight = parseInt(blockHeight, 16);\n  if (Number.isNaN(numericHeight) || numericHeight < 1) {\n    throw new Error('Cosmos EVM rejects block heights < 1.');\n  }\n  return true; // Valid block height\n};",
	"constructJsonRpcPayload": "export const constructJsonRpcPayload = (\n  account,\n  blockHeight = '0x1', // Default block height\n  storageKeys = []     // Optional array of storage keys; defaults to an empty list\n) => {\n  // Input validation (reuse Step 1 & Step 2 helpers)\n  validateEthAddress(account);\n  validateBlockHeight(blockHeight);\n\n  return {\n    jsonrpc: '2.0',\n    method: 'eth_getProof',\n    params: [account, storageKeys, blockHeight],\n    id: 1\n  };\n};",
	"httpPostRpc": "export const httpPostRpc = async (\n  payload,\n  endpoint = 'http://localhost:8545',\n  timeoutMs = 10_000 // 10 second timeout\n) => {\n  const controller = new AbortController();\n  const timeout = setTimeout(() => controller.abort(), timeoutMs);\n\n  try {\n    const res = await fetch(endpoint, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(payload),\n      signal: controller.signal\n    });\n\n    if (!res.ok) {\n      throw new Error(`HTTP error ${res.status}: ${res.statusText}`);\n    }\n\n    const json = await res.json();\n    return json; // Raw JSON-RPC response\n  } catch (err) {\n    if (err.name === 'AbortError') {\n      throw new Error('RPC request timed out.');\n    }\n    throw err;\n  } finally {\n    clearTimeout(timeout);\n  }\n};",
	"parseRpcResponse": "export const parseRpcResponse = (rpcResponse) => {\n  if (!rpcResponse) {\n    throw new Error('Empty RPC response.');\n  }\n\n  if (rpcResponse.error) {\n    // Forward the RPC error message to the caller\n    throw new Error(`RPC Error: ${rpcResponse.error.message}`);\n  }\n\n  const { result } = rpcResponse;\n  if (!result) {\n    throw new Error('RPC result field is missing.');\n  }\n\n  const { balance, nonce, storageHash, codeHash, proof } = result;\n  return {\n    balance,\n    nonce,\n    storageHash,\n    codeHash,\n    proof\n  };\n};",
	"calculateSharesToWithdraw": "export const calculateSharesToWithdraw = (totalShares) => {\n  const numericShares = Number(totalShares);\n  if (!Number.isFinite(numericShares) || numericShares <= 0) {\n    throw new Error('Invalid share balance.');\n  }\n\n  // Use Math.floor to avoid fractional shares (contracts expect integers)\n  const sharesToWithdraw = Math.floor(numericShares * 0.10);\n  if (sharesToWithdraw === 0) {\n    throw new Error('Calculated shares_to_withdraw equals zero.');\n  }\n\n  return sharesToWithdraw;\n};",
	"signAndBroadcastWithdrawTx": "export const signAndBroadcastWithdrawTx = async ({ address, signPayload }) => {\n  const { body_bytes, auth_info_bytes, account_number, chain_id } = signPayload;\n\n  // Helper to convert base64 → Uint8Array\n  const toUint8Array = (b64) => Uint8Array.from(atob(b64), (c) => c.charCodeAt(0));\n\n  const signDoc = {\n    bodyBytes: toUint8Array(body_bytes),\n    authInfoBytes: toUint8Array(auth_info_bytes),\n    chainId: chain_id,\n    accountNumber: account_number,\n  };\n\n  // 1. Ask Keplr to sign the Tx\n  const { signature } = await window.keplr.signDirect(chain_id, address, signDoc);\n\n  // 2. Hand the signature back to the backend so it can assemble & broadcast\n  const res = await fetch('/api/supervault/broadcast-withdraw', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({\n      body_bytes: body_bytes,\n      auth_info_bytes: auth_info_bytes,\n      signature: signature.signature, // already base64\n    }),\n  });\n\n  const data = await res.json();\n  if (!res.ok) {\n    throw new Error(data.detail || 'Broadcast failed');\n  }\n\n  return data.txhash;\n};",
	"getSupervaultContractAddress": "export const getSupervaultContractAddress = () => {\n  // TODO: Replace the placeholder with the real Supervault address\n  const CONTRACT_ADDRESS = 'neutron1supervaultcontractaddressxxx';\n\n  if (!CONTRACT_ADDRESS || !CONTRACT_ADDRESS.startsWith('neutron')) {\n    throw new Error('Invalid or missing Supervault contract address configuration.');\n  }\n\n  return CONTRACT_ADDRESS;\n};",
	"filterPositionsByCampaign": "export const filterPositionsByCampaign = (positions, campaignName = 'Bitcoin Summer') => {\n  if (!Array.isArray(positions)) {\n    throw new Error('Expected positions to be an array.');\n  }\n\n  return positions.filter((position) => {\n    const campaigns = position.eligible_campaigns || [];\n    return campaigns.includes(campaignName);\n  });\n};",
	"PositionsTable": "export const PositionsTable = ({ positions }) => {\n  if (!positions || positions.length === 0) {\n    return <p>No Bitcoin Summer positions found.</p>;\n  }\n\n  return (\n    <table style={{ width: '100%', borderCollapse: 'collapse' }}>\n      <thead>\n        <tr>\n          <th style={{ borderBottom: '1px solid #ccc' }}>Position ID</th>\n          <th style={{ borderBottom: '1px solid #ccc' }}>Deposit Amount</th>\n          <th style={{ borderBottom: '1px solid #ccc' }}>Rewards Status</th>\n        </tr>\n      </thead>\n      <tbody>\n        {positions.map((p) => (\n          <tr key={p.position_id}>\n            <td style={{ padding: '4px 8px' }}>{p.position_id}</td>\n            <td style={{ padding: '4px 8px' }}>{p.deposit_amount}</td>\n            <td style={{ padding: '4px 8px' }}>{p.rewards_status}</td>\n          </tr>\n        ))}\n      </tbody>\n    </table>\n  );\n};",
	"captureSliderInput": "export const captureSliderInput = (sliderElementId) => {\n  const slider = document.getElementById(sliderElementId);\n  if (!slider) {\n    throw new Error(`Slider element with id \"${sliderElementId}\" not found.`);\n  }\n\n  const months = parseInt(slider.value, 10);\n  if (Number.isNaN(months) || months <= 0) {\n    throw new Error(`Invalid slider value: ${slider.value}`);\n  }\n\n  return months;\n};",
	"calculateBoostMultiplier": "export const calculateBoostMultiplier = (months) => {\n  const MAX_MONTHS = 48;\n  const multiplier = 1 + months / MAX_MONTHS; // 48 months → 1 + 48/48 = 2.0×\n  return +multiplier.toFixed(2);\n};",
	"saveLockDurationPreference": "export const saveLockDurationPreference = (months) => {\n  try {\n    localStorage.setItem('preferredLockDurationMonths', months.toString());\n  } catch (err) {\n    // localStorage can throw (e.g., in private mode)\n    console.error('Failed to store lock duration preference', err);\n  }\n};",
	"displayMultiplierPreview": "export const displayMultiplierPreview = ({ months, multiplier, minLockBase = 100 }) => {\n  const previewEl = document.getElementById('multiplierPreview');\n  if (!previewEl) {\n    console.warn('Preview element #multiplierPreview not found in DOM.');\n    return;\n  }\n\n  // Example heuristic: scale the base amount linearly with months.\n  const minLockAmount = ((minLockBase * months) / 48).toFixed(2);\n  previewEl.textContent = `Boost: ${multiplier}×  |  Minimum lock: ${minLockAmount} NTRN`;\n};",
	"validateRecipientAddress": "export const validateRecipientAddress = (address, expectedPrefix = 'neutron') => {\n  try {\n    const decoded = Bech32.decode(address);\n    if (decoded.prefix !== expectedPrefix) {\n      throw new Error(`Invalid Bech32 prefix: expected ${expectedPrefix}, got ${decoded.prefix}`);\n    }\n    return true;\n  } catch (error) {\n    console.error('Address validation failed:', error);\n    throw new Error('Provided recipient address is invalid.');\n  }\n};",
	"constructTxBankSend": "export const constructTxBankSend = (sender, recipient, amountMicro, denom = 'untrn') => {\n  return {\n    typeUrl: '/cosmos.bank.v1beta1.MsgSend',\n    value: {\n      fromAddress: sender,\n      toAddress: recipient,\n      amount: [coin(amountMicro, denom)],\n    },\n  };\n};",
	"promptUserForBlockSearch": "export const promptUserForBlockSearch = async () => {\n  // Ask for a timestamp (UNIX seconds or RFC-3339 date-time string)\n  const tsRaw = window.prompt(\n    'Enter a UNIX timestamp (seconds) or an RFC-3339 date/time string:',\n    ''\n  );\n  if (!tsRaw) {\n    throw new Error('A timestamp value is required.');\n  }\n\n  // Ask for the RPC endpoint URL (e.g. https://rpc-evmos.example)\n  const rpcUrl = window.prompt('Enter the RPC endpoint URL for the chain:', '');\n  if (!rpcUrl) {\n    throw new Error('An RPC URL is required.');\n  }\n\n  // Helper: convert a string that might be RFC-3339 into a UNIX timestamp\n  const normaliseTimestamp = (input) => {\n    // If it is only digits, treat as UNIX seconds already\n    if (/^\\d+$/.test(input.trim())) {\n      return parseInt(input.trim(), 10);\n    }\n    // Otherwise attempt RFC-3339/ISO-8601 parse using Date()\n    const d = new Date(input);\n    if (isNaN(d.getTime())) {\n      throw new Error('Invalid RFC-3339/ISO-8601 date-time string provided.');\n    }\n    return Math.floor(d.getTime() / 1000); // seconds\n  };\n\n  const timestamp = normaliseTimestamp(tsRaw);\n  return { timestamp, rpcUrl: rpcUrl.trim() };\n};",
	"constructIncrementMsg": "export const constructIncrementMsg = () => {\n  // The NeutronTemplate contract expects an execute payload of the form:\n  // {\n  //   increment_personal: {}\n  // }\n  return {\n    increment_personal: {},\n  };\n};",
	"constructMsgRemoveSchedule": "export const constructMsgRemoveSchedule = (authority, name = \"daily_rewards\") => {\n  if (!authority) {\n    throw new Error(\"Authority (DAO address) is required\");\n  }\n\n  // EncodeObject compatible with CosmJS\n  return {\n    typeUrl: \"/neutron.cron.MsgRemoveSchedule\",\n    value: {\n      authority,\n      name,\n    },\n  };\n};",
	"wrapInDaoProposal": "export const wrapInDaoProposal = (\n  registry,\n  msgs,\n  proposalModuleAddress,\n  title = \"Remove daily cron schedule\",\n  description = \"This proposal removes the 'daily_rewards' cron schedule.\"\n) => {\n  if (!proposalModuleAddress) throw new Error(\"proposalModuleAddress is required\");\n  if (!msgs.length) throw new Error(\"At least one message must be supplied\");\n\n  // Convert each EncodeObject -> stargate format expected by cw-dao\n  const encodedMsgs = msgs.map((msg) => {\n    const binary = registry.encode(msg);\n    return {\n      stargate: {\n        type_url: msg.typeUrl,\n        value: Buffer.from(binary).toString(\"base64\"),\n      },\n    };\n  });\n\n  // cw-proposal-single JSON payload\n  const proposeMsg = {\n    propose: {\n      title,\n      description,\n      msgs: encodedMsgs,\n    },\n  };\n\n  // Wrap into MsgExecuteContract (CosmWasm)\n  return {\n    typeUrl: \"/cosmwasm.wasm.v1.MsgExecuteContract\",\n    value: {\n      sender: \"\",                // filled automatically just before signing\n      contract: proposalModuleAddress,\n      msg: toUtf8(JSON.stringify(proposeMsg)),\n      funds: [],\n    },\n  };\n};",
	"getCreatorAddress": "export const getCreatorAddress = async (chainId = 'neutron-1') => {\n  // Make sure the browser has access to the Keplr extension\n  const { keplr } = window;\n  if (!keplr) {\n    throw new Error('Keplr extension was not detected. Please install/enable Keplr.');\n  }\n\n  // Ask Keplr to enable the Neutron chain if it is not already enabled\n  await keplr.enable(chainId);\n\n  // Obtain the OfflineSigner, then the account list\n  const offlineSigner = keplr.getOfflineSigner(chainId);\n  const accounts = await offlineSigner.getAccounts();\n\n  if (!accounts || accounts.length === 0) {\n    throw new Error('No accounts found in the connected wallet.');\n  }\n\n  // The first account will be used as the creator address\n  return accounts[0].address;\n};",
	"validateCreatorAddress": "export const validateCreatorAddress = (address, expectedPrefix = 'neutron') => {\n  try {\n    // Decode the bech32 string; will throw if invalid\n    const { prefix } = Bech32.decode(address);\n\n    // Ensure the address uses the expected bech32 prefix (\"neutron\")\n    if (prefix !== expectedPrefix) {\n      throw new Error(`Invalid bech32 prefix: expected \\\"${expectedPrefix}\\\", got \\\"${prefix}\\\".`);\n    }\n\n    return true; // valid\n  } catch (err) {\n    throw new Error(`Invalid bech32 address: ${err.message}`);\n  }\n};",
	"promptRawTx": "export const promptRawTx = () => {\n  // Ask the user to paste a raw, signed transaction.\n  const rawTx = prompt('Paste the 0x-prefixed RLP-encoded signed transaction:');\n\n  // Basic validation.\n  if (!rawTx || !rawTx.trim().startsWith('0x')) {\n    throw new Error('Invalid raw transaction hex string.');\n  }\n\n  return rawTx.trim();\n};",
	"broadcastRawTx": "export const broadcastRawTx = async (rawTx) => {\n  const response = await fetch('/api/broadcast_raw_tx', {\n    method: 'POST',\n    headers: { 'Content-Type': 'application/json' },\n    body: JSON.stringify({ raw_tx: rawTx })\n  });\n\n  if (!response.ok) {\n    // Attempt to surface any backend-provided error message.\n    let detail = 'Failed to broadcast transaction';\n    try {\n      const err = await response.json();\n      detail = err.detail || detail;\n    } catch (_) {}\n    throw new Error(detail);\n  }\n\n  const { tx_hash } = await response.json();\n  return tx_hash; // <- Store or display as needed.\n};",
	"waitForTxReceipt": "export const waitForTxReceipt = async (txHash, interval = 5000) => {\n  /*\n   * Poll `/api/tx_receipt/:txHash` every `interval` ms.  When the node\n   * returns a non-null receipt we resolve with that receipt.\n   */\n  while (true) {\n    const resp = await fetch(`/api/tx_receipt/${txHash}`);\n\n    if (!resp.ok) {\n      let detail = 'Unable to fetch transaction receipt';\n      try {\n        const err = await resp.json();\n        detail = err.detail || detail;\n      } catch (_) {}\n      throw new Error(detail);\n    }\n\n    const { receipt } = await resp.json();\n\n    if (receipt) {\n      return receipt; // 🎉  The transaction is now finalized on-chain.\n    }\n\n    // Wait before the next attempt.\n    await new Promise((resolve) => setTimeout(resolve, interval));\n  }\n};",
	"getBlockByHash": "export const getBlockByHash = async ({ rpcEndpoint, blockHash }) => {\n  // Basic argument validation\n  if (!rpcEndpoint || !blockHash) {\n    throw new Error(\"Both 'rpcEndpoint' and 'blockHash' parameters are required.\");\n  }\n\n  // Construct JSON-RPC payload\n  const payload = {\n    jsonrpc: \"2.0\",\n    id: 1,\n    method: \"eth_getBlockByHash\",\n    params: [blockHash, false] // `false` => return block data without full transaction objects\n  };\n\n  try {\n    // Issue POST request to the RPC endpoint\n    const response = await fetch(rpcEndpoint, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\"\n      },\n      body: JSON.stringify(payload)\n    });\n\n    // Throw if HTTP status is not OK (200–299)\n    if (!response.ok) {\n      const text = await response.text();\n      throw new Error(`HTTP ${response.status}: ${text}`);\n    }\n\n    // Parse the JSON-RPC response\n    const data = await response.json();\n\n    // Handle possible JSON-RPC errors\n    if (data.error) {\n      throw new Error(`RPC Error (${data.error.code}): ${data.error.message}`);\n    }\n\n    return data.result; // Block object\n  } catch (err) {\n    console.error(\"Failed to fetch block by hash:\", err);\n    throw err; // Propagate error to caller\n  }\n};",
	"validateBase64Input": "export const validateBase64Input = (inputStr) => {\n  // Regular-expression check for valid base64 padding/charset\n  const base64Regex = /^(?:[A-Za-z0-9+/]{4})*(?:[A-Za-z0-9+/]{2}==|[A-Za-z0-9+/]{3}=)?$/;\n  if (!base64Regex.test(inputStr)) {\n    throw new Error(\"Input is not valid base64.\");\n  }\n  // Double-check by actually decoding; browsers throw on bad padding\n  try {\n    atob(inputStr);\n  } catch (err) {\n    throw new Error(\"Failed to decode base64 string: \" + err.message);\n  }\n  return true; // Valid base64\n};",
	"prettyPrintJSON": "export const prettyPrintJSON = (jsonObj, downloadFileName = null) => {\n  const pretty = JSON.stringify(jsonObj, null, 2); // 2-space indent for readability\n\n  // Optionally offer a JSON file download to the user\n  if (downloadFileName) {\n    const blob = new Blob([pretty], { type: \"application/json\" });\n    const url = URL.createObjectURL(blob);\n    const anchor = document.createElement(\"a\");\n    anchor.href = url;\n    anchor.download = downloadFileName;\n    anchor.click();\n    URL.revokeObjectURL(url);\n  }\n\n  return pretty; // Useful for placing in a <pre> tag or console.log\n};",
	"connectWalletAndGetAddress": "export const connectWalletAndGetAddress = async () => {\n  const chainId = 'neutron-1';\n  const keplr = window.keplr;\n\n  if (!keplr) {\n    throw new Error('Keplr wallet is not installed.');\n  }\n\n  // Request wallet connection if it has not yet been approved\n  await keplr.enable(chainId);\n\n  // Get the offline-signer injected by Keplr\n  const signer = window.getOfflineSigner(chainId);\n  const accounts = await signer.getAccounts();\n\n  if (!accounts || accounts.length === 0) {\n    throw new Error('No account found in the wallet.');\n  }\n\n  return { signer, address: accounts[0].address };\n};",
	"WalletProvider: React.FC<React.PropsWithChildren>": "export const WalletProvider: React.FC<React.PropsWithChildren> = ({ children }) => (\n  <ChainProvider\n    chains={[neutronChain]}\n    assetLists={[]}\n    wallets={wallets}\n    walletConnectOptions={wcOptions}\n    walletConnect={walletconnect}\n    signerOptions={{\n      signingStargate: {\n        preferredSignType: 'direct',\n      },\n    }}\n  >\n    {children}\n  </ChainProvider>\n);",
	"walletConnectV2Config: WalletConnectOptions": "export const walletConnectV2Config: WalletConnectOptions = {\n  signClient: {\n    projectId: process.env.NEXT_PUBLIC_WC_PROJECT_ID || '',\n    relayUrl: 'wss://relay.walletconnect.com',\n    metadata: {\n      name: 'NeutronTemplate',\n      description: 'Neutron Template WalletConnect Integration',\n      url: 'https://your-dapp.com',\n      icons: ['https://your-dapp.com/icon.png'],\n    },\n  },\n  namespaces: {\n    cosmos: {\n      chains: ['cosmos:neutron-1'],\n      methods: [\n        'cosmos_getAccounts',\n        'cosmos_signDirect',\n        'cosmos_signAmino',\n        'cosmos_sendTransaction',\n      ],\n      events: ['chainChanged', 'accountsChanged'],\n    },\n  },\n};\n\n// Mobile wallet IDs recognised by Cosmos Kit\nexport const supportedMobileWallets = [\n  'keplr-mobile',\n  'leap-mobile',\n  'cosmostation-mobile',\n];\n\n// Helper that returns a ready-to-use mobile config bundle\nexport const getMobileWalletConfig = () => ({\n  walletConnectOptions: walletConnectV2Config,\n  wallets: supportedMobileWallets,\n});",
	"ConnectWalletButton: React.FC": "export const ConnectWalletButton: React.FC = () => {\n  const { connect, disconnect, status, address, viewWalletRepo } = useWallet();\n\n  const handleClick = async () => {\n    try {\n      if (status === WalletStatus.Connected) {\n        await disconnect();\n        return;\n      }\n\n      if (isMobile) {\n        // Mobile: open wallet list to launch deep-link\n        viewWalletRepo();\n      } else {\n        // Desktop: opens Cosmos Kit QR modal automatically\n        await connect();\n      }\n    } catch (err) {\n      console.error('Wallet connect error:', err);\n      alert(`Wallet connection failed: ${(err as Error).message}`);\n    }\n  };\n\n  return (\n    <button onClick={handleClick} className='px-4 py-2 rounded bg-indigo-600 text-white'>\n      {status === WalletStatus.Connected ? shorten(address) : 'Connect Wallet'}\n    </button>\n  );\n};",
	"usePersistWcSession": "export const usePersistWcSession = () => {\n  const { client, status } = useWallet();\n\n  // Save active session whenever it changes\n  useEffect(() => {\n    if (status === 'Connected' && client?.session) {\n      try {\n        localStorage.setItem(WC_SESSION_KEY, JSON.stringify(client.session));\n      } catch (err) {\n        console.warn('Unable to persist WalletConnect session', err);\n      }\n    }\n  }, [client, status]);\n\n  // Attempt to restore a previous session on first render\n  useEffect(() => {\n    const restore = async () => {\n      try {\n        const raw = localStorage.getItem(WC_SESSION_KEY);\n        if (raw && client?.restoreSession && status !== 'Connected') {\n          await client.restoreSession(JSON.parse(raw));\n        }\n      } catch (err) {\n        console.error('Failed to restore WalletConnect session', err);\n      }\n    };\n\n    restore();\n  }, [client]);\n};",
	"fetchValidatorDelegations": "export const fetchValidatorDelegations = async (\n  validatorAddress,\n  restEndpoint = 'https://lcd.cosmos.directory/cosmoshub'\n) => {\n  if (!validatorAddress) {\n    throw new Error('validatorAddress is required');\n  }\n\n  // Strip trailing slash for safe concatenation\n  const baseUrl = restEndpoint.replace(/\\/$/, '');\n\n  const allDelegations = [];\n  let nextKey = null;\n\n  try {\n    do {\n      // Build URL with pagination key when present\n      const params = new URLSearchParams();\n      if (nextKey) params.append('pagination.key', nextKey);\n\n      const url = `${baseUrl}/cosmos/staking/v1beta1/validators/${validatorAddress}/delegations?${params}`;\n      const res = await fetch(url);\n\n      if (!res.ok) {\n        throw new Error(`Failed to fetch delegations: ${res.status} ${res.statusText}`);\n      }\n\n      const json = await res.json();\n      const pageDelegations = json.delegation_responses || [];\n      allDelegations.push(...pageDelegations);\n\n      // Continue if the API returned a non-null pagination key\n      nextKey = json.pagination && json.pagination.next_key;\n    } while (nextKey);\n\n    return allDelegations;\n  } catch (err) {\n    console.error('fetchValidatorDelegations error:', err);\n    throw err; // Propagate so callers can handle it\n  }\n};",
	"calculateTotalStake": "export const calculateTotalStake = (\n  delegations,\n  denom = 'uatom',\n  microFactor = 1_000_000\n) => {\n  if (!Array.isArray(delegations)) {\n    throw new TypeError('delegations must be an array');\n  }\n\n  // Aggregate the micro amounts\n  const totalMicro = delegations.reduce((acc, d) => {\n    const bal = d.balance;\n    if (bal && bal.denom === denom) {\n      return acc + Number(bal.amount || 0);\n    }\n    return acc;\n  }, 0);\n\n  // Convert to main denom (e.g. ATOM)\n  const totalHuman = totalMicro / microFactor;\n\n  return {\n    denom,\n    micro: totalMicro.toString(),\n    human: totalHuman.toLocaleString(undefined, { maximumFractionDigits: 6 })\n  };\n};",
	"debugIntermediateRoots": "export const debugIntermediateRoots = async (txHash, rpcEndpoint) => {\n  if (!txHash || typeof txHash !== 'string') {\n    throw new Error('`txHash` must be a non-empty string.');\n  }\n\n  // Build the JSON-RPC payload exactly as required by the node.\n  const payload = {\n    method: 'debug_intermediateRoots',\n    params: [txHash],\n    id: 1,\n    jsonrpc: '2.0',\n  };\n\n  try {\n    const response = await fetch(rpcEndpoint, {\n      method: 'POST',\n      headers: { 'Content-Type': 'application/json' },\n      body: JSON.stringify(payload),\n    });\n\n    if (!response.ok) {\n      throw new Error(`RPC call failed with HTTP status ${response.status}`);\n    }\n\n    const json = await response.json();\n\n    if (json.error) {\n      // Preserve the original error message from the node for easier debugging.\n      throw new Error(`RPC error: ${json.error.message || JSON.stringify(json.error)}`);\n    }\n\n    return json.result;\n  } catch (err) {\n    console.error('[debugIntermediateRoots] Unexpected error:', err);\n    throw err;\n  }\n};",
	"activateRemixGithubPlugin": "export const activateRemixGithubPlugin = async () => {\n  // Ensure we are running inside the Remix IDE\n  if (!window.remix || typeof window.remix.call !== 'function') {\n    throw new Error('Remix plugin API not detected. Are you running this code inside the Remix IDE?');\n  }\n\n  try {\n    // Ask the Remix Plugin Manager to enable the GitHub plugin\n    await window.remix.call('pluginManager', 'activatePlugin', 'github');\n    return true;\n  } catch (error) {\n    console.error('Failed to activate the GitHub plugin:', error);\n    throw error;\n  }\n};",
	"getWalletList": "export const getWalletList = async () => {\\n  try {\\n    const res = await fetch('/api/personal_list_wallets');\\n    if (!res.ok) {\\n      throw new Error(`Backend responded with ${res.status}`);\\n    }\\n    const data = await res.json();\\n    return data.wallets;\\n  } catch (err) {\\n    console.error('Failed to fetch wallet list:', err);\\n    throw err;\\n  }\\n};"
}