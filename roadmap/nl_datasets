If you want **open datasets of natural-language prompts** (ideally paired with executable actions), these are the most relevant and well-maintained:

### NL → commands / tools

* **NL2Bash (Tellina)** – \~9–10k English ↔ Bash pairs (plus more), widely used for NL→CLI research. Data and code are public. ([GitHub][1], [aclanthology.org][2])
* **NL2CMD / Tellina logs** – follow-ups and competition material based on NL2Bash, with validation scripts and splits. ([cs.wm.edu][3], [Proceedings of Machine Learning Research][4])
* **Gorilla (APIBench / OpenFunctions)** – NL → API/function-call datasets for tool use; great if you want prompts that map to structured API calls rather than free text. ([huggingface.co][5], [GitHub][6], [gorilla.cs.berkeley.edu][7])

### NL → code / queries (good proxies for “prompt → deterministic action”)

* **CoNaLa** – curated Python intent ↔ snippet pairs (2.3k curated + \~600k mined). Useful for training/finetuning on intent→code mappings. ([conala-corpus.github.io][8], [huggingface.co][9])
* **CodeSearchNet** – millions of functions with natural-language descriptions; supports NL→code retrieval and generation tasks. ([GitHub][10], [ArXiv][11])
* **Spider (Text-to-SQL)** – NL→SQL across 200 databases; also **Spider 2.0** for enterprise-scale schemas. Great for learning structured action generation. ([yale-lily.github.io][12], [aclanthology.org][13], [spider2-sql.github.io][14])

### NL → multi-step web actions (agents)

* **Mind2Web / Online-Mind2Web** – natural-language tasks with recorded action sequences on real websites; useful if your “prompt → action(s)” spans multiple steps or tools. ([osu-nlp-group.github.io][15], [huggingface.co][16])
* **ToolBench family** – tasks for tool manipulation/planning; often used to train/evaluate tool-augmented LLMs. ([GitHub][17], [ArXiv][18])

---

## For **web3-specific** prompts

There isn’t (yet) a widely adopted, open **NL→web3-command** dataset. Two pragmatic ways to bootstrap:

1. **Programmatic harvesting from CLIs**
   Crawl `--help` trees and docs for:

   * EVM (Foundry `cast/forge`, Geth RPC), Cosmos/Neutron (`neutrond tx/q wasm`, IBC relayers), Solana (`solana`, `spl-token`).
     Generate templates and paraphrase NL prompts, then verify on testnets (anvil / local Cosmos devnet / solana-test-validator).

2. **Q\&A mining for NL prompts**
   Mine NL from **Ethereum StackExchange**, project GitHub issues, and official docs, then align each prompt to a canonical command/RPC + arguments. (Mark secrets as env vars and auto-verify with dry-runs.)

If helpful, I can scaffold a small repo that:

* extracts CLI schemas,
* generates NL paraphrases,
* and verifies NL↔command pairs on local testnets—so you get a web3 “nl2bash-style” dataset quickly.

Want me to start with a specific stack (e.g., **Neutron/CosmWasm** + **Foundry**) and produce a first JSONL batch?

[1]: https://github.com/TellinaTool/nl2bash?utm_source=chatgpt.com "GitHub - TellinaTool/nl2bash: Generating bash command ..."
[2]: https://aclanthology.org/L18-1491.pdf?utm_source=chatgpt.com "NL2Bash: A Corpus and Semantic Parser for Natural ..."
[3]: https://www.cs.wm.edu/~dcschmidt/PDF/NL2CMD__An_Updated_Workflow_for_Natural_Language_to_Bash_Commands_Translation_JMLTAP.pdf?utm_source=chatgpt.com "NL2CMD: An Updated Workflow for Natural Language to ..."
[4]: https://proceedings.mlr.press/v133/agarwal21b/agarwal21b.pdf?utm_source=chatgpt.com "NeurIPS 2020 NLC2CMD Competition: Translating Natural ..."
[5]: https://huggingface.co/datasets/gorilla-llm/APIBench?utm_source=chatgpt.com "gorilla-llm/APIBench · Datasets at Hugging Face"
[6]: https://github.com/ShishirPatil/gorilla?utm_source=chatgpt.com "ShishirPatil/gorilla: Gorilla: Training and Evaluating LLMs ..."
[7]: https://gorilla.cs.berkeley.edu/blogs/4_open_functions.html?utm_source=chatgpt.com "Gorilla OpenFunctions"
[8]: https://conala-corpus.github.io/?utm_source=chatgpt.com "CoNaLa: The Code/Natural Language Challenge"
[9]: https://huggingface.co/datasets/neulab/conala?utm_source=chatgpt.com "neulab/conala · Datasets at Hugging Face"
[10]: https://github.com/github/CodeSearchNet?utm_source=chatgpt.com "github/CodeSearchNet: Datasets, tools, and benchmarks ..."
[11]: https://arxiv.org/pdf/1909.09436?utm_source=chatgpt.com "CodeSearchNet Challenge Evaluating the State of ..."
[12]: https://yale-lily.github.io/spider?utm_source=chatgpt.com "Spider: Yale Semantic Parsing and Text-to-SQL Challenge"
[13]: https://aclanthology.org/D18-1425.pdf?utm_source=chatgpt.com "Spider: A Large-Scale Human-Labeled Dataset for ..."
[14]: https://spider2-sql.github.io/?utm_source=chatgpt.com "Spider 2.0"
[15]: https://osu-nlp-group.github.io/Mind2Web/?utm_source=chatgpt.com "Mind2Web: Towards a Generalist Agent for the Web"
[16]: https://huggingface.co/datasets/osunlp/Mind2Web?utm_source=chatgpt.com "osunlp/Mind2Web · Datasets at Hugging Face"
[17]: https://github.com/sambanova/toolbench?utm_source=chatgpt.com "ToolBench, an evaluation suite for LLM tool manipulation ..."
[18]: https://arxiv.org/html/2409.14826v1?utm_source=chatgpt.com "ToolPlanner: A Tool Augmented LLM for Multi Granularity ..."
